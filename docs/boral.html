<!DOCTYPE html><html><head><title>Help for package boral</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {boral}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#about.distributions'>
<p>Distributions available in boral</p></a></li>
<li><a href='#about.lvs'><p>Correlation structure for latent variables</p></a></li>
<li><a href='#about.ranefs'><p>Including response-specific random intercepts in boral</p></a></li>
<li><a href='#about.ssvs'>
<p>Stochastic search variable selection (SSVS) in boral</p></a></li>
<li><a href='#about.traits'><p>Including species traits in boral</p></a></li>
<li><a href='#boral'><p>Fitting boral (Bayesian Ordination and Regression AnaLysis) models</p></a></li>
<li><a href='#boral-package'><p>Bayesian Ordination and Regression AnaLysis (boral)</p></a></li>
<li><a href='#calc.condlogLik'><p>Conditional log-likelihood for a fitted model</p></a></li>
<li><a href='#calc.logLik.lv0'><p>Log-likelihood for a model fitted with no latent variables</p></a></li>
<li><a href='#calc.marglogLik'><p>Marginal log-likelihood for a fitted model</p></a></li>
<li><a href='#calc.varpart'><p>Variance partitioning for a latent variable model</p></a></li>
<li><a href='#coefsplot'><p>Caterpillar plots of the regression coefficients from a fitted model</p></a></li>
<li><a href='#create.life'>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a></p>
</p>
<p>Simulate a Multivariate response matrix</p></a></li>
<li><a href='#ds.residuals'><p>Dunn-Smyth Residuals for a fitted model</p></a></li>
<li><a href='#fitted.boral'><p>Extract Model Fitted Values for an boral object</p></a></li>
<li><a href='#get.dic'><p>Extract Deviance Information Criterion for a fitted model</p></a></li>
<li><a href='#get.enviro.cor'><p>Extract covariances and correlations due to shared environmental responses</p></a></li>
<li><a href='#get.hpdintervals'><p>Highest posterior density intervals for a fitted model</p></a></li>
<li><a href='#get.mcmcsamples'><p>Extract MCMC samples from models</p></a></li>
<li><a href='#get.measures'><p>Information Criteria for models</p></a></li>
<li><a href='#get.more.measures'><p>Additional Information Criteria for models</p></a></li>
<li><a href='#get.residual.cor'><p>Extract residual correlations and precisions from models</p></a></li>
<li><a href='#lvsplot'><p>Plot the latent variables from a fitted model</p></a></li>
<li><a href='#make.jagsboralmodel'><p>Write a text file containing a model for use into JAGS</p></a></li>
<li><a href='#make.jagsboralnullmodel'><p>Write a text file containing a model for use into JAGS</p></a></li>
<li><a href='#plot.boral'><p>Plots of a fitted boral object</p></a></li>
<li><a href='#predict.boral'><p>Predict using a model</p></a></li>
<li><a href='#ranefsplot'><p>Caterpillar plots of response-specific random effects from a fitted model</p></a></li>
<li><a href='#summary.boral'><p>Summary of fitted boral object</p></a></li>
<li><a href='#tidyboral'><p>Reformats output from a boral fit</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Bayesian Ordination and Regression AnaLysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-04-15</td>
</tr>
<tr>
<td>Author:</td>
<td>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Francis K.C. Hui &lt;fhui28@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Bayesian approaches for analyzing multivariate data in ecology. Estimation is performed using Markov Chain Monte Carlo (MCMC) methods via Three. JAGS types of models may be fitted: 1) With explanatory variables only, boral fits independent column Generalized Linear Models (GLMs) to each column of the response matrix; 2) With latent variables only, boral fits a purely latent variable model for model-based unconstrained ordination; 3) With explanatory and latent variables, boral fits correlated column GLMs with latent variables to account for any residual correlation between the columns of the response matrix. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>coda</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, corpcor, fishMod, graphics, grDevices, lifecycle, MASS,
mvtnorm, R2jags, reshape2, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvabund (&ge; 4.0.1), corrplot</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-24 09:55:36 UTC; fkch</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-24 22:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='about.distributions'>
Distributions available in boral
</h2><span id='topic+about.distributions'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This help file provides more information regarding the distributions i.e., the <code>family</code> argument, available in the boral package, to handle various responses types.
</p>


<h3>Details</h3>

<p>A variety of families are available in boral, designed to accommodate multivariate abundance data of varying response types. Please see the <code>family</code> argument in the <code><a href="#topic+boral">boral</a></code> which lists all distributions that are currently available. 
</p>
<p>For multivariate abundance data in ecology, species counts are often overdispersed. Using a negative binomial distribution (<code>family = "negative.binomial"</code>) to model the counts usually helps to account for this overdispersion. Please note the variance for the negative binomial distribution is parameterized as <code class="reqn">Var(y) = \mu + \phi\mu^2</code>, where <code class="reqn">\phi</code> is the dispersion parameter. 
</p>
<p>For non-negative continuous data such as biomass, the lognormal, Gamma, and tweedie distributions may be used (Foster and Bravington, 2013). For the gamma distribution, the variance is parameterized as <code class="reqn">Var(y) = \mu/\phi</code> where <code class="reqn">\phi</code> is the response-specific rate (henceforth referred to also as dispersion parameter). 
</p>
<p>For the tweedie distribution, a common power parameter is across all columns with this family, because there is almost always insufficient information to model response-specific power parameters. Specifically, the variance is parameterized as <code class="reqn">Var(y) = \phi \mu^p</code> where <code class="reqn">\phi</code> is the response-specific dispersion parameter and <code class="reqn">p</code> is a power parameter common to all columns assumed to be tweedie, with <code class="reqn">1 &lt; p &lt; 2</code>. 
</p>
<p>Normal responses are also implemented, just in case you encounter normal stuff in ecology (pun intended)! For the normal distribution, the variance is parameterized as <code class="reqn">Var(y) = \phi^2</code>, where <code class="reqn">\phi</code> is the response-specific standard deviation. 
</p>
<p>The beta distribution can be used to model data between values between but <em>not</em> including 0 and 1. In principle, this would make it useful for percent cover data in ecology, if it not were for the fact that percent cover is commonly characterized by having lots of zeros (which are not permitted for beta regression). An <em>ad-hoc</em> fix to this would be to add a very small value to shift the data away from exact zeros and/or ones. This is however heuristic, and pulls the model towards producing conservative results (see Smithson and Verkuilen, 2006, for a detailed discussion on beta regression, and Korhonen et al., 2007, for an example of an application to forest canopy cover data). Note the parameterization of the beta distribution used here is directly in terms of the mean <code class="reqn">\mu</code> and the dispersion parameter <code class="reqn">\phi</code> (more commonly know as the &quot;sample size&quot;). In terms of the two shape parameters, if we denote the two shape parameters as the vector <code class="reqn">(a,b)</code>, his is equivalent to <code class="reqn">a = \mu\phi</code> and <code class="reqn">b = (1-\mu)\phi</code>.
</p>
<p>For ordinal response columns, cumulative probit regression is used (Agresti, 2010). boral assumes all ordinal columns are measured using the same scale i.e., all columns have the same number of theoretical levels, even though some levels for some species may not be observed. The number of levels is then assumed to be given by the maximum value from all the ordinal columns of the response matrix. Because of this, all ordinal columns then assumed to have the <em>same</em> cutoffs, <code class="reqn">\bm{\tau}</code>, while the response-specific intercept, <code class="reqn">\beta_{0j}</code>, allows for deviations away from these common cutoffs. That is, 
</p>
<p style="text-align: center;"><code class="reqn">\Phi(P(y_{ij} \le k)) = \tau_k + \beta_{0j} + \ldots,</code>
</p>

<p>where <code class="reqn">\Phi(\cdot)</code> is the probit function, <code class="reqn">P(y_{ij} \le k)</code> is the cumulative probability of element <code class="reqn">y_{ij}</code> being less than or equal to level <code class="reqn">k</code>, <code class="reqn">\tau_k</code> is the cutoff linking levels <code class="reqn">k</code> and <code class="reqn">k+1</code> (and which are increasing in <code class="reqn">k</code>), <code class="reqn">\beta_{0j}</code> are the column effects, and <code class="reqn">\ldots</code> denotes what else is included in the model, e.g. latent variables and related coefficients. To ensure model identifiability, and also because they are interpreted as response-specific deviations from the common cutoffs, the <code class="reqn">\beta_{0j}</code>'s are treated as random effects and drawn from a normal distribution with mean zero and unknown standard deviation.
</p>
<p>The parameterization above is useful for modeling ordinal in ecology. When ordinal responses are recorded, usually the same scale is applied to all species e.g., level 1 = not there, level 2 = a bit there, level 3 = lots there, level 4 = everywhere! The quantity <code class="reqn">\tau_k</code> can thus be interpreted as this common scale, while <code class="reqn">\beta_{0j}</code> allows for deviations away from these to account for differences in species prevalence. Admittedly, the current implementation of boral for ordinal data can be quite slow. 
</p>
<p>For count distributions where zeros are not permitted, then the zero truncated Poisson (<code>family = "ztpoisson"</code>) and zero truncated negative binomial distributions (<code>family = "ztnegative.binomial"</code>) are possible. Note for these two distributions, and as is commonly implemented in other regression models e.g., the <code>countreg</code> package (Zeileis and Kleiber, 2018), the models are set up such that a log-link connects the mean of the <em>untruncated</em> distribution to the linear predictor. While not necessarily useful on its own, the zero truncated distributions may often be used in conjunction with an model for modeling presence-absence data, and together they can be used to construct the hurdle class of models (noting direct implementation of hurdle models is currently not available). 
</p>
<p>Finally, in the event different responses are collected for different columns, e.g., some columns of the response matrix are counts, while other columns are presence-absence, one can specify different distributions for each column. Aspects such as variable selection, residual analysis, and plotting of the latent variables are, in principle, not affected by having different distributions. Naturally though, one has to be more careful with interpretation of the row effects <code class="reqn">\alpha_i</code> and latent variables <code class="reqn">\bm{u}_i</code>, as different link functions will be applied to each column of the response matrix. A situation where different distributions may prove useful is when the response matrix is a species&ndash;traits matrix, where each row is a species and each column a trait such as specific leaf area. In this case, traits could be of different response types, and the goal perhaps is to perform unconstrained ordination to look for patterns between species on an underlying trait surface e.g., a defense index for a species (Moles et al., 2013).
</p>


<h3>Warnings</h3>


<ul>
<li><p> MCMC with lots of ordinal columns take an especially long time to run! Moreover, estimates for the cutoffs in cumulative probit regression may be poor for levels with little data. Major apologies for this advance =(
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Agresti, A. (2010). Analysis of Ordinal Categorical Data. Wiley.
</p>
</li>
<li><p> Foster, S. D. and Bravington, M. V. (2013). A Poisson-Gamma model for analysis of ecological non-negative continuous data. Journal of Environmental and Ecological Statistics, 20, 533-552.
</p>
</li>
<li><p> Korhonen, L., et al. (2007). Local models for forest canopy cover with beta regression. Silva Fennica, 41, 671-685.
</p>
</li>
<li><p>  Moles et al. (2013). Correlations between physical and chemical defences in plants: Trade-offs, syndromes, or just many different ways to skin a herbivorous cat? New Phytologist, 198, 252-263.
</p>
</li>
<li><p> Smithson, M., and Verkuilen, J. (2006). A better lemon squeezer? Maximum-likelihood regression with beta-distributed dependent variables. Psychological methods, 11, 54-71.
</p>
</li>
<li><p> Zeileis, A., and Kleiber C. (2018). countreg: Count Data Regression. R package version 0.2-1. URL http://R-Forge.R-project.org/projects/countreg/
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the main boral fitting function. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Please see main boral function for examples. 
</code></pre>

<hr>
<h2 id='about.lvs'>Correlation structure for latent variables</h2><span id='topic+about.lvs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This help file provides more information how (non-independence) correlation structures can be assumed for latent variables.</p>


<h3>Details</h3>

<p>In the main boral function, when latent varaibles are included, the default option is to assume that the latent variables are independent across the rows (sites) of the response matrix i.e., <code>lv.type = "independent"</code>. That is, <code class="reqn">\bm{u}_i \sim N(\bm{0},\bm{I}_d)</code> where <code>d = num.lv</code>. This is useful when we want to model between species correlations (is a parsimonious manner), but it does make an assumption that sites are independent. 
</p>
<p>If one <em>a-priori</em> believes that the sites are, in fact, correlated e.g., due to spatial correlation, and that it cannot be sufficiently well accounted for by row effects (see comment below), then we can account for this by assuming a non-independence correlation structure for the the latent variables across sites. Note however we continue to assume that the <code class="reqn">d</code> latent variables are still independent of one another. That is, if we let <code class="reqn">\bm{u}_i = (u_{i1}, \ldots, u_{id})</code>, then we assume that for <code class="reqn">l = 1,\ldots,d</code>,
</p>
<p style="text-align: center;"><code class="reqn">(u_{1l}, u_{2l}, \ldots, u_{nl}) \sim N(\bm{0}, \bm{\Sigma}),</code>
</p>

<p>where <code class="reqn">\bm{\Sigma}</code> is some correlation matrix. When <code class="reqn">\bm{\Sigma} = \bm{I}_n</code> then we are back in the independence case. However, if we allow for the off-diagonals to be non-zero, then we the latent variables to be correlated, <code class="reqn">\Sigma_{ij} = Cov(u_{il}, u_{jl})</code>. This in turn induces correlation across sites and species i.e., two species at two different sites are now correlated because of the correlation across sites. 
</p>
<p>While there are fancier structures and attempts at accounting for correlations between sites (Cressie and Wikle, 2015), in boral we assume relatively simple structures. Specifically, we can assume that sites further away are less correlated, and so <code class="reqn">\Sigma</code> can be characterized based on a distance matrix <code>distmat</code> and associated spatial covariance parameters which require estimation. Indeed, such simple spatial latent variable models have become rather popular in community ecology of late, at least as a first attempt at accounting for spatial (and also temporal) correlation e.g., Thorson et al., (2015, 2016); Ovaskainen et al., (2016, 2017). 
</p>
<p>At the moment, several correlation structures are permitted. Let <code class="reqn">D_{ij}</code> denote the distance between site <code class="reqn">i</code> and <code class="reqn">j</code> i.e., entry <code class="reqn">(i,j)</code> in <code>distmat</code>. Also, let <code class="reqn">(\vartheta_1,\vartheta_2)</code> denote the two spatial covariance parameters (noting that the second parameter is not required for some of structures). Then we have: 1) <code>lv.type = "exponential"</code> such that <code class="reqn">\Sigma_{ij} = \exp(-D_{ij}/\vartheta_1)</code>; 2) <code>lv.type = "squared.exponential"</code>, such that <code class="reqn">\Sigma_{ij} = \exp(-D_{ij}/\vartheta_1^2)</code>; 3) <code>lv.type = "power.exponential"</code>, such that <code class="reqn">\Sigma_{ij} = \exp(-(D_{ij}/\vartheta_1)^{\vartheta_2})</code> where <code class="reqn">\vartheta_1 \in (0,2]</code> ; 4) <code>lv.type = "spherical"</code>, such that <code class="reqn">(D_{ij} &lt; \vartheta_1)*(1 - 1.5*D_{ij}/\vartheta_1 + 0.5*(D_{ij}/\vartheta_1)^3)</code>. We refer the reader to the <code>geoR</code> and the function <code>cov.spatial</code> for more, simple information on spatial covariance functions (Ribeiro Jr and Diggle, 2016).
</p>
<p>It is important to keep in mind that moving away from an independence correlation structure for the latent variables <em>massively</em> increases computation time for MCMC sampling (and indeed any estimation method for latent variable models). Given JAGS is not the fastest of methods when it comes to MCMC sampling, then one should be cautious about moving away from indepndence. For example, if you <em>a-priori</em> have a nested experimental design which is inducing spatial correlation, then it is much faster and more effective to include (multiple) row effects in the model to account for this spatial correlation instead. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Cressie, N. and Wikle, C. K. (2015) Statistics for Spatio-temporal Data. John Wiley &amp; Sons.
</p>
</li>
<li><p> Ovaskainen et al. (2016). Uncovering hidden spatial structure in species communities with spatially explicit joint species distribution models. Methods in Ecology and Evolution, 7, 428-436.
</p>
</li>
<li><p> Ovaskainen et al. (2017). How to make more out of community data? A conceptual framework and its implementation as models and software. Ecology Letters, 20, 561-576.
</p>
</li>
<li><p> Ribeiro Jr, P. J., and Diggle P. J., (2016). geoR: Analysis of Geostatistical Data. R package version 1.7-5.2. <a href="https://CRAN.R-project.org/package=geoR">https://CRAN.R-project.org/package=geoR</a>.
</p>
</li>
<li><p> Thorson et al. (2016). Joint dynamic species distribution models: a tool for community ordination and spatio-temporal monitoring. Global Ecology and Biogeography, 25, 1144-1158
</p>
</li>
<li><p> Thorson et al. (2015). Spatial factor analysis: a new tool for estimating joint species distributions and correlations in species range. Methods in Ecology and Evolution, 6, 627-63
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the main boral fitting function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The example below is taken directly from the boral help file

example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")

## Not run: 
## Example 2d - model with environmental covariates and 
##  two structured latent variables using fake distance matrix
fakedistmat &lt;- as.matrix(dist(1:n))
spiderfit_lvstruc &lt;- boral(y, X = X, family = "negative.binomial", 
    lv.control = list(num.lv = 2, type = "exponential", distmat = fakedistmat), 
     mcmc.control = example_mcmc_control, model.name = testpath)

summary(spiderfit_lvstruc)

## End(Not run)

</code></pre>

<hr>
<h2 id='about.ranefs'>Including response-specific random intercepts in boral</h2><span id='topic+about.ranefs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This help file provides more information regarding the how response-specific random intercepts can be included to account for sampling design, induce correlation betweens observational units that are different to each response etc...</p>


<h3>Details</h3>

<p>As of version 2.0, it is now possible to include response-specific random intercepts in a model. There may be a number of reasons why a user may be to do this, but the most common reasons (at least in community ecology) would be to account sampling design on a response-specific basis, and more generally if there <em>a-priori</em> knowledge of clustering between observational units and so random intercepts are to be included to account for such potential within-cluster correlation. 
</p>
<p>Alternatively, if you are familiar with including random row effects in a model, then one may think of response-specific random intercepts as similar to this, except the row effects are now response-specific specific rather than a common across all responses. In doing so, response-specific random intercepts are more flexible and allow the induced correlations (and thus the standard deviations) to be on a per-response basis, although this comes at the expense of some random intercepts being poorly estimates for responses with relatively little information in their observations e.g., rare species. 
</p>
<p>In for example, the formulation for the correlated response model 
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{ij}) = \alpha_i + \beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{z}^\top_i\bm{b}_j; \quad i = 1,\ldots,n; j = 1,\ldots,p,</code>
</p>

<p>the <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> denote response-specific random intercepts included, with <code class="reqn">bm{b}_j</code> denoting the response-specific random intercepts, and <code class="reqn">\bm{z}\top_i</code> denoting the corresponding design vector for observational unit <code class="reqn">i</code>, and are &quot;constructed&quot; based on the input <code>ranef.ids</code>. 
</p>
<p>Akin to other packages such as <code>lme4</code> or <code>glmmTMB</code>, all random intercepts are assumed to be normally distributed with the corresponding variance components are assumed to be response-specific. In fact, if we consider the simpler independent response model with no row effects 
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{ij}) = \beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{z}^\top_i\bm{b}_j; \quad i = 1,\ldots,n; j = 1,\ldots,p,</code>
</p>

<p>then the above would be equivalent to fitting a generalized linear mixed model (GLMM) to each response separately, for which packages such as <code>lme4</code> and <code>glmmTMB</code> are well suited for. In that sense, <code>boral</code> can fit some models, but can also incorporate row effects and/or latent variables to induce correlation between responses.
</p>
<p>Perhaps not surprisingly, the way response-specific random intercepts are included is very similar to how row effects are included in the model. Specifically, the argument <code>ranef.ids</code> identifies the number of random intercepts to be included and how each observational unit maps to a cluster. <code>ranefs.ids</code> is a matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of random intercepts to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>. Examples of its use are provided in the help file below.
</p>
<p>After the model is fitted, for each set of random intercepts included (i.e., each column of <code>ranef.ids</code>), estimates along with HPD intervals of the response-specific standard deviations of the corresponding random effects distributions, as well of the random intercept predictions are returned. These can then be visualized for example using the <code><a href="#topic+ranefsplot">ranefsplot</a></code> function, or analyzed as appropriately by the user.
</p>


<h3>Warnings</h3>


<ul>
<li><p> It is usually not recommended to have both random row effects and response-specific random intercepts simultaneously in the same model, unless they are were at different levels of of the data)
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the main boral fitting function, 
<code><a href="#topic+ranefsplot">ranefsplot</a></code> for horizontal line or &quot;caterpillar plot&quot; of the response-specific random effects predictons (if applicable).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The example below is taken directly from the boral help file

example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")

## Example 2e - Similar to 2c, but we will species-specific random intercepts
##   for the seven regions (with row effects in the model)
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath) 

spiderfit_nb$ranef.coefs.median
spiderfit_nb$ranef.sigma.median

## End(Not run)
</code></pre>

<hr>
<h2 id='about.ssvs'>
Stochastic search variable selection (SSVS) in boral
</h2><span id='topic+about.ssvs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This help file provides more information regarding the implementation of the stochastic search variable selection (SSVS, George and McCulloch, 1993) as implemented in the boral package.</p>


<h3>Details</h3>

<p>Stochastic search variable selection (SSVS, George and McCulloch, 1993) is a approach for model selection, which is applicable specifically to the Bayesian MCMC framework. As of boral version 1.5, SSVS is implemented in two ways.
</p>
<p><b>SSVS on coefficients in the covariate matrix <code class="reqn">\bm{X}</code>:</b>
SSVS is implemented on the response-specific coefficients <code class="reqn">\bm{\beta}_j</code>. Basically, SSVS works by placing a spike-and-slab priors on these coefficients, such that the spike is a narrow normal distribution concentrated around zero and the spike is a normal distribution with a large variance.
</p>
<p style="text-align: center;"><code class="reqn">\rho(\beta) = I_{\beta = 1}\times\mathcal{N}(0,\sigma^2) + (1-I_{\beta = 1})\times \mathcal{N}(0,g*\sigma^2),</code>
</p>

<p>where <code class="reqn">\sigma^2</code> is determined by <code>prior.control$hypparams[3]</code>, <code class="reqn">g</code> is determined by <code>ssvs.g</code>, and <code class="reqn">I_{\beta = 1} = P(\beta = 1)</code> is an indicator function representing whether coefficient is included in the model. It is given a Bernoulli prior with probability of inclusion 0.5. After fitting, the posterior probability of <code class="reqn">\beta</code> being included in the model is returned based on posterior mean of the indicator function <code class="reqn">I_{\beta = 1}</code>. Note this is NOT the same as a <em>p</em>-value seen in maximum likelihood estimation: a <em>p</em>-value provides an indication of how much evidence there is against the null hypothesis of <code class="reqn">\beta = 0</code>, while the posterior probability provides a measure of how likely it is for <code class="reqn">\beta \ne 0</code> given the data.
</p>
<p>SSVS can be applied at a grouped or individual coefficient level, and this is governed by <br /> <code>prior.control$ssvs.index</code>: 
</p>

<ul>
<li><p> For elements of <code>ssvs.index</code> equal to -1, SSVS is not applied on the corresponding covariate of <code class="reqn">\bm{X}</code>. 
</p>
</li>
<li><p> For elements equal to 0, SSVS is applied to each individual coefficients of the corresponding covariate in <code class="reqn">\bm{X}</code>. That is, the fitted model will return posterior probabilities for this covariate, one for each column of the response matrix.
</p>
</li>
<li><p> For elements taking positive integers 1, 2, and so on, SSVS is applied to each group of coefficients of the corresponding covariate in <code class="reqn">\bm{X}</code>. That is, the fitted model will return a single posterior probability for this covariate, indicating whether this covariate should be included for all columns of the response matrix; see O'Hara and Sillanpaa (2009) and Tenan et al. (2014) among many others for an discussion of Bayesian variable selection methods.
</p>
</li></ul>

<p>Note the last application of SSVS allows multiple covariates to be selected <em>simultaneously</em>. For example, suppose the covariate matrix consists of five columns: the first two columns are environmental covariates, while the last three correspond to quadratic terms of the two covariates as well as their interaction. If we want to &quot;test&quot; whether any quadratic terms are required, then we can set <br /> <code>prior.control$ssvs.index = c(-1,-1,1,1,1)</code>, so a single posterior probability of inclusion is returned for the last three columns of the covariate matrix. 
</p>
<p>Finally, note that summaries such as posterior medians and HPD intervals of the coefficients, as well as performing residual analysis, from a fitted model that has implemented SSVS may be problematic because the posterior distribution is by definition multi-modal. It may be advisable instead to separate out their application of SSVS and posterior inference.
</p>
<p><b>SSVS on trait coefficients:</b>
If traits are included in boral, thereby leading to a fourth corner model (see <code><a href="#topic+about.traits">about.traits</a></code> for more details on this type of model), SSVS can also be performed on the associated trait coefficients. That is, in such model we have
</p>
<p style="text-align: center;"><code class="reqn">\beta_{0j} \sim N(\kappa_{01} + \bm{traits}^\top_j\bm{\kappa}_1, \sigma^2_1)</code>
</p>

<p>for the response-specific intercepts, and 
</p>
<p style="text-align: center;"><code class="reqn">\beta_{jk} \sim N(\kappa_{0k} + \bm{traits}^\top_j\bm{\kappa}_k, \sigma^2_k)</code>
</p>

<p>for <code class="reqn">k = 1,\ldots,d</code> where <code>d = ncol(X)</code>. Then if the a particular index in the argument <br /> <code>prior.control$ssvs.traitsindex</code> is set to 0, SSVS is performed on the corresponding element in <code class="reqn">\bm{\kappa}_1</code> or <code class="reqn">\bm{\kappa}_k</code>. For example, suppose <code>which.traits[[2]] = c(2,3)</code>, meaning that the <code class="reqn">\beta_{j1}</code>'s are drawn from a normal distribution with mean depending only on the second and third columns of the trait matrix. Then <br /> <code>prior.control$ssvs.traitsindex[[2]] = c(0,1)</code>, then a spike-and-slab prior is placed on the first coefficent in <code class="reqn">\bm{\kappa}_2</code>, while the second coefficient is assigned the &ldquo;standard&quot; prior governed by the <code>prior.control$hypparams</code>. That is, SSVS is performed on the first but not the second coefficient in <code class="reqn">\bm{\kappa}_2</code>. 
</p>
<p>Please keep in mind that because boral allows the user to manually decide which traits drive which covariates in <code class="reqn">\bm{X}</code>, then care must be taken when setting up both <code>which.traits</code> and <br /> <code>prior.control$ssvs.traitsindex</code>. That is, when supplied then both objects should be lists of have the same length, and the length of the corresponding vectors comprising each element in the two lists should match as well e.g., <code>which.traits[[2]]</code> and <br /> <code>prior.control$ssvs.traitsindex[[2]]</code> should be of the same length.
</p>


<h3>Warnings</h3>


<ul>
<li><p> Summaries of the coefficients such as posterior medians and HPD intervals may also be problematic when SSVS is being used, since the posterior distribution will be multi-modal. 
</p>
</li>
<li><p> If <code>save.model = TRUE</code>, the raw jags model is also returned. This can be quite very memory-consuming, since it indirectly saves all the MCMC samples.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> George, E. I. and McCulloch, R. E. (1993). Variable selection via Gibbs sampling. Journal of the American Statistical Association, 85, 398-409.
</p>
</li>
<li><p> O'Hara, B., and Sillianpaa, M.J. (2009). A Review of Bayesian Variable Selection Methods: What, How and Which. Bayesian Analysis, 4, 85-118.
</p>
</li>
<li><p> Tenan et al. (2014). Bayesian model selection: The steepest mountain to climb. Ecological Modelling, 283, 62-69.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the main boral fitting function which implementing SSVS, and <code><a href="#topic+about.traits">about.traits</a></code> for how fourth corner models work before applying SSVS to them.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The two examples below and taken directly from the boral help file

example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


## Not run: 
## Example 3a - Extend example 2 to demonstrate grouped covariate selection
## on the last three covariates. 
example_prior_control &lt;- list(type = c("normal","normal","normal","uniform"), 
     ssvs.index = c(-1,-1,-1,1,2,3))
spiderfit_nb2 &lt;- boral(y, X = X, family = "negative.binomial", 
    mcmc.control = example_mcmc_control, prior.control = example_prior_control,
    model.name = testpath)
     
summary(spiderfit_nb2) 


## Example 3b - Extend example 2 to demonstrate individual covariate selection
## on the last three covariates. 
example_prior_control &lt;- list(type = c("normal","normal","normal","uniform"), 
     ssvs.index = c(-1,-1,-1,0,0,0))
spiderfit_nb3 &lt;- boral(y, X = X, family = "negative.binomial", 
    mcmc.control = example_mcmc_control, prior.control = example_prior_control,
    model.name = testpath)
summary(spiderfit_nb3) 


## Example 5a - model fitted to count data, no site effects, and
## two latent variables, plus traits included to explain environmental responses
data(antTraits)
y &lt;- antTraits$abun
X &lt;- as.matrix(scale(antTraits$env))
## Include only traits 1, 2, and 5
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)
## Just for fun, the regression coefficients for the second column of X,
## corresponding to the third element in the list example_which_traits,
## will be estimated separately and not regressed against traits.
example_which_traits[[3]] &lt;- 0

fit_traits &lt;- boral(y, X = X, traits = traits, 
    which.traits = example_which_traits, family = "negative.binomial", 
    mcmc.control = example_mcmc_control, model.name = testpath,
    save.model = TRUE)

summary(fit_traits)


## Example 5b - perform selection on trait coefficients
ssvs_traitsindex &lt;- vector("list",ncol(X)+1)
for(i in 1:length(ssvs_traitsindex)) 
     ssvs_traitsindex[[i]] &lt;- rep(0,ncol(traits))
ssvs_traitsindex[[3]] &lt;- -1
fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", mcmc.control = example_mcmc_control, 
    save.model = TRUE, prior.control = list(ssvs.traitsindex = ssvs_traitsindex),
    model.name = testpath)

summary(fit_traits)

## End(Not run)

</code></pre>

<hr>
<h2 id='about.traits'>Including species traits in boral</h2><span id='topic+about.traits'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This help file provides more information regarding the how species can be included to help mediate environmental responses, analogous to the so-called fourth corner problem.</p>


<h3>Details</h3>

<p>In the main boral function, when covariates <code class="reqn">\bm{X}</code> are included i.e. both the independent and correlated response models, one has the option of also including traits to help explain differences in species environmental responses to these covariates. Specifically, when a trait matrix is supplied, along with <code>which.traits</code>, then the <code class="reqn">\beta_{0j}</code>'s and <code class="reqn">\bm{\beta}_j</code>'s are then regarded as random effects drawn from a normal distribution. For the response-specific intercepts, we have
</p>
<p style="text-align: center;"><code class="reqn">\beta_{0j} \sim N(\kappa_{01} + \bm{traits}^\top_j\bm{\kappa}_1, \sigma^2_1),</code>
</p>

<p>where <code class="reqn">(\kappa_{01},\bm{\kappa}_1)</code> are the regression coefficients relating to the traits to the intercepts and <code class="reqn">\sigma_1</code> is the error standard deviation. These are now the &quot;parameters&quot; in the model, in the sense that priors are assigned to them and MCMC sampling is used to estimate them (see the next section on estimation). 
</p>
<p>In an analogous manner, each of the elements in <code class="reqn">\bm{\beta}_j = (\beta_{j1},\ldots,\beta_{jd})</code> are now drawn as random effects from a normal distribution. That is, for <code class="reqn">k = 1,\ldots,d</code> where <code>d = ncol(X)</code>, we have,
</p>
<p style="text-align: center;"><code class="reqn">\beta_{jk} \sim N(\kappa_{0k} + \bm{traits}^\top_j\bm{\kappa}_k, \sigma^2_k),</code>
</p>

<p>Which traits are to included (regressed) in the mean of the normal distributions is determined by the list argument <code>which.traits</code> in the main boral function. The first element in the list applies to <code class="reqn">beta_{0j}</code>, while the remaining elements apply to the the <code class="reqn">\bm{\beta}_j</code>. Each element of <code>which.traits</code> is a vector indicating which traits are to be used. For example, if <code>which.traits[[2]] = c(2,3)</code>, then the <code class="reqn">\beta_{j1}</code>'s are drawn from a normal distribution with mean depending only on the second and third columns of the trait matrix. If <code>which.traits[[2]][1] = 0</code>, then the regression coefficients are treated as independent, i.e. the values of <code class="reqn">\beta_{j1}</code> are given their own priors and estimated separately from each other. 
</p>
<p>Including species traits in the model can be regarded as a method of simplifying the model: rather than each to estimates <code class="reqn">p</code> sets of response-specific coefficients, we instead say that these coefficients are linearly related to the corresponding values of their traits (Warton et al., 2015; Ovaskainen et al., 2017). That is, we are using trait data to help explain similarities/differences in species responses to the environment. This idea has close relations to the fourth corner problem in ecology (Brown et al., 2014). Unlike the models of Brown et al. (2014) however, which treat the <code class="reqn">\beta_{0j}</code>'s and <code class="reqn">\beta_{jk}</code>'s are fixed effects and fully explained by the traits, boral adopts a random effects approach similar to Jamil et al. (2013) to &quot;soak up&quot; any additional between species differences in environmental responses not explained by traits.
</p>
<p>Finally, note that from boral version 1.5, stochastic search variable selection (SSVS) can now be applied to the trait coefficients <code class="reqn">\bm{\kappa}_1</code> and <code class="reqn">\bm{\kappa}_k</code>; please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more details.
</p>


<h3>Warnings</h3>


<ul>
<li> <p><em>No</em> intercept column should be included in the trait matrix, as it is included automatically.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Brown et al. (2014). The fourth-corner solution - using predictive models to understand how species traits interact with the environment. Methods in Ecology and Evolution, 5, 344-352.
</p>
</li>
<li><p> Jamil, et al. (2013). Selecting traits that explain species-environment relationships: a generalized linear mixed model approach. Journal of Vegetation Science 24, 988-1000
</p>
</li>
<li><p> Ovaskainen, et al. (2017). How to make more out of community data? A conceptual framework and its implementation as models and software. Ecology Letters, 20, 561-576.
</p>
</li>
<li><p> Warton et al. (2015). So Many Variables: Joint Modeling in Community Ecology. Trends in Ecology and Evolution, 30, 766-779.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the main boral fitting function, and <code><a href="#topic+about.ssvs">about.ssvs</a></code> for implementing SSVS on fourth corner models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The two examples below and taken directly from the boral help file

example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")

## Not run: 
## Example 5a - model fitted to count data, no site effects, and
## two latent variables, plus traits included to explain environmental responses
data(antTraits)
y &lt;- antTraits$abun
X &lt;- as.matrix(scale(antTraits$env))
## Include only traits 1, 2, and 5
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)
## Just for fun, the regression coefficients for the second column of X,
## corresponding to the third element in the list example_which_traits,
## will be estimated separately and not regressed against traits.
example_which_traits[[3]] &lt;- 0

fit_traits &lt;- boral(y, X = X, traits = traits, 
    which.traits = example_which_traits, family = "negative.binomial", 
    mcmc.control = example_mcmc_control, model.name = testpath,
    save.model = TRUE)

summary(fit_traits)


## Example 5b - perform selection on trait coefficients
ssvs_traitsindex &lt;- vector("list",ncol(X)+1)
for(i in 1:length(ssvs_traitsindex)) ssvs_traitsindex[[i]] &lt;- rep(0,ncol(traits))
ssvs_traitsindex[[3]] &lt;- -1
fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", mcmc.control = example_mcmc_control, 
    save.model = TRUE, prior.control = list(ssvs.traitsindex = ssvs_traitsindex),
    model.name = testpath)

summary(fit_traits)


## Example 6 - simulate Bernoulli data, based on a model with two latent variables, 
## no site variables, with two traits and one environmental covariates 
## This example is a proof of concept that traits can used to 
## explain environmental responses 
library(mvtnorm)

n &lt;- 100; s &lt;- 50
X &lt;- as.matrix(scale(1:n))
colnames(X) &lt;- c("elevation")

traits &lt;- cbind(rbinom(s,1,0.5), rnorm(s)) 
## one categorical and one continuous variable
colnames(traits) &lt;- c("thorns-dummy","SLA")

simfit &lt;- list(true.lv = rmvnorm(n, mean = rep(0,2)), 
    lv.coefs = cbind(rnorm(s), rmvnorm(s, mean = rep(0,2))), 
    traits.coefs = matrix(c(0.1,1,-0.5,1,0.5,0,-1,1), 2, byrow = TRUE))
rownames(simfit$traits.coefs) &lt;- c("beta0","elevation")
colnames(simfit$traits.coefs) &lt;- c("kappa0","thorns-dummy","SLA","sigma")

simy = create.life(true.lv = simfit$true.lv, lv.coefs = simfit$lv.coefs, X = X, 
    traits = traits, traits.coefs = simfit$traits.coefs, family = "binomial") 


example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)
fit_traits &lt;- boral(y = simy, X = X, traits = traits, 
    which.traits = example_which_traits, family = "binomial", 
    lv.control = list(num.lv = 2), save.model = TRUE, 
    mcmc.control = example_mcmc_control, model.name = testpath)

## End(Not run)

</code></pre>

<hr>
<h2 id='boral'>Fitting boral (Bayesian Ordination and Regression AnaLysis) models</h2><span id='topic+boral'></span><span id='topic+boral.default'></span><span id='topic+print.boral'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Bayesian ordination and regression models for analyzing multivariate data in ecology. Three &quot;types&quot; of models may be fitted: 1) With covariates and no latent variables, boral fits independent response GLMs; 2) With no covariates, boral fits a pure latent variable model; 3) With covariates and latent variables, boral fits correlated response GLMs.</p>


<h3>Usage</h3>

<pre><code class='language-R'>boral(y, ...)

## Default S3 method:
boral(y, X = NULL, formula.X = NULL, X.ind = NULL, 
     traits = NULL, which.traits = NULL, family, trial.size = 1, 
     lv.control = list(num.lv = 0, type = "independent", distmat = NULL),
     row.eff = "none", row.ids = NULL, ranef.ids = NULL, 
     offset = NULL, save.model = FALSE, calc.ics = FALSE, 
     mcmc.control = list(n.burnin = 10000, n.iteration = 40000, 
     n.thin = 30, seed = NULL), 
     prior.control = list(type = c("normal","normal","normal","uniform"), 
     hypparams = c(10, 10, 10, 30), ssvs.index = -1, ssvs.g = 1e-6, 
     ssvs.traitsindex = -1), do.fit = TRUE, model.name = NULL, num.lv = NULL, ...)

## S3 method for class 'boral'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boral_+3A_y">y</code></td>
<td>
<p>A response matrix of multivariate data e.g., counts, binomial or Bernoulli responses, continuous response, and so on. With multivariate abundance data ecology for instance, rows correspond to sites and columns correspond to species. Any categorical (multinomial) responses <b>must</b> be converted to integer values. For ordinal data, the minimum level of the response matrix must be 1 instead of 0.</p>
</td></tr>
<tr><td><code id="boral_+3A_x">X</code></td>
<td>
<p>Either a model matrix of covariates (otherwise known as the covariate matrix), which is included as part of the model, or a data frame from which the argument <code>formula.X</code> uses to create covariate matrix. Defaults to <code>NULL</code>, in which case no model matrix (and thus covariates) is included in the model. No intercept column should be included.</p>
</td></tr>  
<tr><td><code id="boral_+3A_x.ind">X.ind</code></td>
<td>
<p>An matrix of 1s and 0s, indicating whether a particular covariate should be included (1) or excluded (0) in the mean structure of a particular response. The matrix should the number of rows equal to the number of columns in the response matrix, and the number of columns equal to the number of columns in the covariate matrix Defaults to <code>NULL</code>, in which case it is assumed that all covariates are included in the mean structure of all responses i.e., all 1s.</p>
</td></tr>  
<tr><td><code id="boral_+3A_formula.x">formula.X</code></td>
<td>
<p>an object of class &quot;formula&quot;, which represents a symbolic description of the covariate matrix to be created (based on the this argument along with the <code>X</code>, which will be treated as a data frame). The symbolic description works in the same way that standard regressions functions such as <code>lm</code> and <code>glm</code> work. The &quot;-1&quot; symbolic description, which denotes to not include an intercept, should not be included. Also, there should be nothing on the left hand side of the &quot;~&quot;.
</p>
<p>Note that if this argument is supplied, then after fitting boral will return an <code>X</code> output which is not the original <code>X</code> supplied but the covariate matrix created as a consequence of this argument.</p>
</td></tr>  
<tr><td><code id="boral_+3A_x">x</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="boral_+3A_traits">traits</code></td>
<td>
<p>A model matrix of species traits (otherwise known as the trait matrix), which can be included as part of the model. Defaults to <code>NULL</code>, in which case no matrix was used. No intercept column should be included in the trait matrix, as it is included automatically.</p>
</td></tr>  
<tr><td><code id="boral_+3A_which.traits">which.traits</code></td>
<td>
<p>A list of length equal to (number of predictor variables in the model as implied by <code>X</code> and <code>formula.X</code>, plus 1), informing which columns of the trait matrix the response-specific intercepts and each of the response-specific regression coefficients should be regressed against. The first element in the list applies to the response-specific intercept, while the remaining elements apply to the regression coefficients. Each element of <code>which.traits</code> is a vector indicating which traits are to be used.
</p>
<p>For example, if <code>which.traits[[2]] = c(2,3)</code>, then the regression coefficients corresponding to the first column in the covariate matrix are regressed against the second and third columns of the trait matrix. If <code>which.traits[[2]][1] = 0</code>, then the regression coefficients for each column are treated as independent. Please see <code><a href="#topic+about.traits">about.traits</a></code> for more details.
</p>
<p>Defaults to <code>NULL</code>, and used in conjunction with <code>traits</code> and <br /> <code>prior.control$ssvs.traitsindex</code>.</p>
</td></tr>
<tr><td><code id="boral_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression), &quot;ztpoisson&quot; (zero truncated Poisson with log link), &quot;ztnegative.binomial&quot; (zero truncated negative binomial with log link). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="boral_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="boral_+3A_lv.control">lv.control</code></td>
<td>
<p>A list (currently) with the following arguments:
</p>

<ul>
<li> <p><em>num.lv:</em> which specifies the number of true latent variables to generate. Defaults to 0.
</p>
</li>
<li> <p><em>type:</em> which specifies the type the correlation structure of the latent variables (across sites). Defaults to independence correlation structure.
</p>
</li>
<li> <p><em>distmat:</em> which a distance matrix required to calculate correlations across sites when a non-independence correlation structure on the latent variables is imposed. 
</p>
</li></ul>

<p>Please see <code><a href="#topic+about.lvs">about.lvs</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="boral_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether (multiple) row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and unknown variance, analogous to a random intercept in mixed models. Defaults to &quot;none&quot;.</p>
</td></tr>    
<tr><td><code id="boral_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>. This matrix is useful if one wants to specify more complicated row effect structures beyond a single, row effect unique to each row; please see details below as well as examples below. Whether these row effects are included as fixed or random effects is governed by <code>row.eff</code>. Defaults to <code>NULL</code>, so that if <code>row.eff = "none"</code> then the argument is ignored, otherwise if <code>row.eff = "fixed"</code> or <code>"random"</code>, then <br /> <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row.</p>
</td></tr>
<tr><td><code id="boral_+3A_ranef.ids">ranef.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of random intercepts to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>; please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for details. Defaults to <code>NULL</code>, in which case it is assumed no random intercepts are to be included in the model. If supplied, then response-specific random intercepts are assumed to come from a normal distribution with mean zero and unknown (response-specific) standard deviation.</p>
</td></tr>
<tr><td><code id="boral_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="boral_+3A_save.model">save.model</code></td>
<td>
<p>If <code>save.model = TRUE</code>, then the JAGS model file is saved as a text file (with name given by <code>model.name</code>) in the current working directory as well as the MCMC samples, which themselves can be extracted using the <code>get.mcmcsamples</code> function. Various functions available in the <code>coda</code> package can be applied to the MCMC samples for diagnosing convergence. Note MCMC samples can take up a lot of memory. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="boral_+3A_calc.ics">calc.ics</code></td>
<td>
<p>If <code>calc.ics = TRUE</code>, then various information criteria values are also returned, which could be used to perform model selection (see <code><a href="#topic+get.measures">get.measures</a></code>). Defaults to <code>FALSE</code>. WARNING: As of version 1.6, this function is longer updated!</p>
</td></tr>
<tr><td><code id="boral_+3A_mcmc.control">mcmc.control</code></td>
<td>
<p>A list of parameters for controlling the MCMC sampling. Values not set will assume default values. These include:
</p>

<ul>
<li> <p><em>n.burnin:</em> Length of burnin i.e., the number of iterations to discard at the beginning of the MCMC sampler. Defaults to 10000.
</p>
</li>
<li> <p><em>n.iteration:</em> Number of iterations including burnin. Defaults to 40000.
</p>
</li>
<li> <p><em>n.thin:</em> Thinning rate. Must be a positive integer. Defaults to 30.
</p>
</li>
<li> <p><em>seed:</em> Seed for JAGS sampler. A <code>set.seed(seed)</code> command is run immediately before starting the MCMC sampler. Defaults to the value <code>NULL</code>, so the MCMC estimation is not seeded.
</p>
</li></ul>

</td></tr>
<tr><td><code id="boral_+3A_prior.control">prior.control</code></td>
<td>
<p>A list of parameters for controlling the prior distributions. Values not set will assume default values. These include:
</p>

<ul>
<li> <p><em>type:</em> Vector of four strings indicating the type of prior distributions to use. In order, these are: 1) priors for all response-specific intercepts, row effects, and cutoff points for ordinal data; 2) priors for the latent variable coefficients. This is ignored if <code>num.lv = 0</code>; 3) priors for all response-specific coefficients relating to the covariate matrix (ignored if <code>X = NULL</code>). When traits are included in the model, this is also the prior for the trait regression coefficients (please see <code><a href="#topic+about.traits">about.traits</a></code> for more information); 4) priors for any dispersion parameters and variance (standard deviation, to be precise) parameters in the model.
</p>
<p>For elements 1-3, the prior distributions currently available include: I) &ldquo;normal&quot;, which is a normal prior with the variance controlled by elements 1-3 in <code>hypparams</code>; II) &ldquo;cauchy&quot;, which is a Cauchy prior with variance controlled by elements 1-3 in <code>hypparams</code>. Gelman, et al. (2008) considers using Cauchy priors with variance <code class="reqn">2.5^2</code> as weakly informative priors for coefficients in logistic and potentially other generalized linear models; III) &ldquo;uniform&quot;, which is a symmetric uniform prior with minimum and maximum values controlled by element 1-3 in <code>hypparams</code>. 
</p>
<p>For element 4, the prior distributions currently available include: I) &ldquo;uniform&quot;, which is uniform prior with minimum zero and maximum controlled by element 4 in <code>hypparmas</code>; II) &ldquo;halfnormal&quot;, which is half-normal prior with variance controlled by <code>hypparams</code>; III) &ldquo;halfcauchy&quot;, which is a half-Cauchy prior with variance controlled by element 4 in <code>hypparams</code>.
</p>
<p>Defaults to the vector <code>c("normal","normal","normal","uniform")</code>. 
</p>
</li>
<li> <p><em>hypparams:</em> Vector of four hyperparameters used in the set up of prior distributions. In order, these are: 1) affects the prior distribution for all response-specific intercepts, row effects, and cutoff points for ordinal data; 2) affects the prior distribution for all latent variable coefficients. This is ignored if <code>num.lv = 0</code>; 3) affects the prior distribution for response-specific coefficients relating to the covariate matrix (ignored if <code>X = NULL</code>). When traits are included in the model, it also affects the prior distribution for the trait regression coefficients; 4) affects the prior distribution for any dispersion parameters, as well as the prior distributions for the standard deviation of the random effects normal distribution if <code>row.eff = "random"</code>, the standard deviation of the response-specific random intercepts for these columns if more than two of the columns are ordinal, and the standard deviation of the random effects normal distribution for trait regression coefficients when traits are included in the model.
</p>
<p>Defaults to the vector <code>c(10, 10, 10, 30)</code>. The use of normal distributions with mean zero and variance 10 as priors is seen as one type of (very) weakly informative prior, according to <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Prior choice recommendations</a>.
</p>
</li>
<li> <p><em>ssvs.index:</em> Indices to be used for stochastic search variable selection (SSVS, George and McCulloch, 1993). Either a single element or a vector with length equal to the number of columns in the covariate matrix. Each element can take values of -1 (no SSVS is performed on this covariate), 0 (SSVS is performed on individual coefficients for this covariate), or any integer greater than 0 (SSVS is performed on collectively all coefficients on this covariate.) 
</p>
<p>Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to -1, in which case SSVS is not performed on the covariates. 
</p>
</li>
<li> <p><em>ssvs.g:</em> Multiplicative, shrinkage factor for SSVS, which controls the strength of the &quot;spike&quot; in the SSVS mixture prior. In summary, if the coefficient is included in the model, the &quot;slab&quot; prior is a normal distribution with mean zero and variance given by element 3 in <code>hypparams</code>, while if the coefficient is not included in the model, the &quot;spike&quot; prior is normal distribution with mean zero and variance given by element 3 in <code>hypparams</code> multiplied by <code>ssvs.g</code>. Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to 1e-6.  		
</p>
</li>
<li> <p><em>ssvs.traitsindex:</em> Used in conjunction with <code>traits</code> and <code>which.traits</code>, this is a list of indices to be used 
for performing SSVS on the trait coefficients. Should be a list with the same length as <code>which.traits</code>, and with each element a vector of indices with the same length as the corresponding element in <code>which.traits</code>. Each index either can take values of -1 (no SSVS on this trait coefficient) or 0 (no SSVS on this trait coefficient). 
</p>
<p>Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to -1, in which case SSVS is not performed on any of the trait coefficients, if they are included in the model.
</p>
</li></ul>

</td></tr>
<tr><td><code id="boral_+3A_do.fit">do.fit</code></td>
<td>
<p>If <code>do.fit = FALSE</code>, then only the JAGS model file is written to the current working directly (as text file with name based on <code>model.name</code>). No MCMC sampling is performed, and <em>nothing else</em> is returned. Defaults to <code>TRUE</code>.</p>
</td></tr>    
<tr><td><code id="boral_+3A_model.name">model.name</code></td>
<td>
<p>Name of the text file that the JAGS script is written to. Defaults to <code>NULL</code>, in which case the default of &quot;jagsboralmodel.txt&quot; is used.</p>
</td></tr>

<tr><td><code id="boral_+3A_num.lv">num.lv</code></td>
<td>
<p>Old argument superceded by <code>lv.control</code>. Defaults to <code>NULL</code> and ignored.</p>
</td></tr> 
<tr><td><code id="boral_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The boral package is designed to fit three types of models which may be useful in ecology (and probably outside of ecology as well =D). 
</p>
<p><b>Independent response models:</b> boral allows explanatory variables to be entered into the model via the covariate matrix <code class="reqn">\bm{X}</code>. If factors are to be included, then they should be parameterized using dummy variables. It should NOT include an intercept column. Alternatively, users can make use of the <code>formula.X</code> function to create the covariate model. 
</p>
<p>Without latent variables, i.e. <code>lv.control$num.lv = 0</code>, boral fits separate GLMs to each column of the <code class="reqn">n \times p</code> response matrix <code class="reqn">\bm{Y}</code>, where the columns are assumed to be independent. 
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{ij}) = \alpha_i + \beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{z}^\top_i\bm{b}_j; \quad i = 1,\ldots,n; j = 1,\ldots,p,</code>
</p>

<p>where the mean response for element (i,j), denoted as <code class="reqn">mu_{ij}</code>, is regressed against the covariates <code class="reqn">\bm{x}_i</code> via a link function <code class="reqn">g(\cdot)</code>. The quantities <code class="reqn">beta_{0j}</code> and <code class="reqn">\bm{beta}_j</code> denote the response-specific intercepts and coefficients respectively, while <code>alpha_i</code> is an optional row effect that may be treated as a fixed or random effect, and <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> denote an optional set of response-specific random intercepts. Not all of these components may be included in the model, and the above is just representing the general case. If the included row effects are assumed to be fixed, then the first row effect is constrained to be zero for parameter identifiability reasons. If the include row effects are assumed to be random then they are drawn from a normal distribution with unknown variance <code class="reqn">\phi^2</code>. One reason we might want to include row effects is to account differences in sampling intensity between sites: these can lead to differences in site total abundance, and so by including fixed effects they play the same role as an offset to account for these differences. 
</p>
<p>boral can also handle multiple, hierarchical row effects, which may be useful to account for sampling design. This is controlled using the <code>row.ids</code> argument. For example, if the first five rows of <code class="reqn">y</code> correspond to replications from site 1, the next five rows correspond to replications from site 2, and so on, then one can set <code>row.ids = matrix(c(1,1,1,1,1,2,2,2,2,2,...), ncol = 1)</code> to take this in account. While this way of coding row effects via the <code>row.ids</code> argument takes some getting used to, it has been done this way partly to force the user to think more carefully about exactly the structure of the data i.e., with great power comes great responsibility...
</p>
<p>Aside from row effects, and another more flexible way to account for sampling design but on a response-specific basis, boral allows users to include response-specific random intercepts. Please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for more information on this. Note response-specific random intercepts are permitted for all three types of models discussed. Akin to other packages such as <code>lme4</code> or <code>glmmTMB</code>, all random intercepts are assumed to be normally distributed with the corresponding variance components are assumed to be response-specific. 
</p>
<p>If <code>offset</code> is supplied, then it will be included in the linear predictor below (and all linear predictors below where appropriate).
</p>
<p>Without row effects, the above independent response model is basically a Bayesian analog of the <code>manyglm</code> function in the <code>mvabund</code> package (Wang et al., 2013). Note that <code>X.ind</code> argument can be optionally used to manually force certain covariates to be included in (1) or excluded from (0) from the mean structure of specific responses.
</p>
<p><b>Pure latent variable models:</b> If no explanatory variables are included and <code>lv.control$num.lv</code> &gt; 0, boral fits a pure latent variable model to perform model-based unconstrained ordination (Hui et al., 2014),
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{ij}) = \alpha_i + \beta_{0j} + \bm{z}^\top_i\bm{b}_j + \bm{u}\top_i\bm{\theta}_j,</code>
</p>

<p>where instead of measured covariates, we now have a vector of latent variables <code class="reqn">\bm{u}_i</code> with <code class="reqn">\bm{\theta}_j</code> being the response-specific coefficients relating to these latent variables. The response-specific intercept, <code class="reqn">\beta_{0j}</code>, accounts for differences between species prevalence, while the row effect, <code class="reqn">alpha_i</code>, is included to account for differences in site total abundance (typically assuming a fixed effect, <code>row.eff = "fixed"</code>, although see Jamil and ter Braak, 2013, for a motivation for using random site effects), so that the ordination is then in terms of species composition. If <code class="reqn">\alpha_i</code> is omitted from the model i.e., <code>row.eff = FALSE</code>, then the ordination will be in terms of relative species abundance. As mentioned previously, one reason for including fixed row effects is to account of any potential differences in sampling intensity between sites.
</p>
<p>As with the other types of models, <code class="reqn">\alpha_i</code> can be replaced with more sophisticated multiple, hierarchical row effects, and/or response-specific random intercepts given by <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> are optional.
</p>
<p>Unconstrained ordination is used for visualizing multivariate data in a low-dimensional space, without reference to covariates (Chapter 9, Legendre and Legendre, 2012). Typically, <code>lv.control$num.lv</code> = 1 to 3 latent variables is used, allowing the latent variables to plotted (using <code><a href="#topic+lvsplot">lvsplot</a></code>, for instance). The resulting plot can be interpreted in the same manner as plots from Nonmetric Multi-dimensional Scaling (NMDS, Kruskal, 1964) and Correspondence Analysis (CA, Hill, 1974), for example. A biplot can also be constructed by setting <code>biplot = TRUE</code> when using <code><a href="#topic+lvsplot">lvsplot</a></code>, so that both the latent variables and their corresponding coefficients are plotted. For instance, with multivariate abundance data, biplots are used to visualize the relationships between sites in terms of species abundance or composition, as well as the indicator species for the sites. 
</p>
<p>Finally, boral offers a small number of options for allowing the latent variables to be correlated across rows of the responses. This may be useful when one has <em>a-priori</em> information about correlation between sites e.g., spatial correlation, which cannot be systematically accounted for by the inclusion of random effects (Thorson et al., 2015, 2016; Ovaskainen et al., 2016, 2017).. Please see the help file <code><a href="#topic+about.lvs">about.lvs</a></code> for more information on this. By default, boral assumes the latent variables are independent standard normally distributed across rows. Note the use of a non-independence correlation structure massively increases computation time!
</p>
<p><b>Correlated response models:</b> When one or more latent variables are included in conjunction with covariates i.e., a covariate matrix is supplied and <code>lv.control$num.lv</code> &gt; 1, boral fits separate GLMs to each column of the response matrix <code class="reqn">\bm{Y}</code> while allowing for residual correlation between columns via the latent variables. This is quite useful for multivariate abundance data in ecology, where a separate GLM is fitted to species (modeling its response against environmental covariates), while accounting for the fact species at a site are likely to be correlated for reason other than similarities in environmental responses, e.g. biotic interaction, phylogeny, and so on. Correlated response model take the following form,
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{ij}) = \alpha_i + \beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{z}^\top_i\bm{b}_j + \bm{u}^\top_i\bm{\theta}_j.</code>
</p>

<p>This model is thus a combinaton of the first two types of models. The linear predictor <code class="reqn">\bm{u}^\top_i\bm{\theta}_j</code> induces a residual covariance between the columns of the response matrix <code class="reqn">\bm{y}</code> (which is of rank <code>lv.control$num.lv</code>). For multivariate abundance data, this leads to a parsimonious method of accounting for correlation between species not due to the shared environmental responses. After fitting the model, the residual correlation matrix then can be obtained via the <code><a href="#topic+get.residual.cor">get.residual.cor</a></code> function. Note <code>lv.control$num.lv</code> &gt; 1 is necessarily in order to flexibly model the residual correlations; see Pollock et al. (2014) for residual correlation matrices in the context of Joint Species Distribution Models, Ovaskainen et al., (2017), and Warton et al. (2015, 2016) for an overview of latent variable models in multivariate ecology.
</p>
<p>As with the other types of models, <code class="reqn">\alpha_i</code> can be replaced with more sophisticated multiple, hierarchical row effects, and/or response-specific random intercepts given by <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> are optional.
</p>
<p><b>Distributions:</b> A variety of families are available in boral, designed to handle multivariate abundance data of varying response types. Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for more information on this.
</p>
<p><b>Including species traits:</b> When covariates are included i.e. both the independent and correlated response models, one has the option of also including traits to help explain differences in species environmental responses to these covariates. Please see <code><a href="#topic+about.traits">about.traits</a></code> for more information on this.
</p>
<p><b>Including response-specific random intercepts:</b> For some types of data e.g. nested designs, it may be appropriate to include response-specific random intercepts. This can be considered as like row effects, but now the effects are specific to each response rather than the same across all responses. Please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for more information on this. Note as a consequence, it is usually not recommended to have both random row effects and response-specific random intercepts simultaneously in the same model (unless they are were at different levels of of the data).
</p>
<p><b>Estimation:</b> Estimation for all models is performed using Bayesian Markov Chain Monte Carlo (MCMC) methods via JAGS (Plummer, 2003). Please note that only <em>one</em> MCMC chain in run: this point is discussed later in this help file. Regarding prior distributions, the default settings, based on the <code>prior.control</code> argument, are as follows: 
</p>

<ul>
<li><p> Normal priors with mean zero and variance given by element 1 in <code>hypparams</code> are assigned to all intercepts, cutoffs for ordinal responses, and row effects. 
</p>
</li>
<li><p> Normal priors with mean zero and variance given by element 2 in <code>hypparams</code> are assigned coefficients relating to latent variables, <code class="reqn">\bm{\theta}_j</code>.
</p>
</li>
<li><p> Normal priors with mean zero and variance given by element 3 <code>hypparams</code> are assigned to all coefficients relating to covariates in <code class="reqn">\bm{\beta}_j</code>. If traits are included, the same normal priors are assigned to the <code class="reqn">\kappa</code>'s, and the standard deviation <code class="reqn">\sigma_k</code> are assigned uniform priors with maximum equal to element 4 in <code>hypparams</code>.
</p>
</li>
<li><p> For the negative binomial, normal, lognormal, and tweedie distributions, uniform priors with maximum equal to element 4 in <code>hypparams</code> are used on the dispersion parameters. Please note that for the normal and lognormal distributions, these uniform priors are assigned to the standard deviations <code class="reqn">\phi</code> (see Gelman, 2006). If there are any variance (standard deviation, to be precise) parameters in the model, then these are also assigned uniform priors with maximum equal to element 4 in <code>hypparams</code> e.g., standard deviation of the normal random effects if the row effects are assumed to random, the standard deviation of the normal random response-specific intercepts if more than two columns are ordinal responses, and the standard deviation of the normal random response-specific random intercepts when <code>ranef.ids</code> is supplied etc...
</p>
</li></ul>

<p><b>Using information criteria at your own risk:</b> Using information criterion from <code>calc.ics = TRUE</code> for model selection should be done with extreme caution, for two reasons: 1) The implementation of some of these criteria is heuristic and experimental, 2) Deciding what model to fit should also be driven by the science and questions of interest. For example, it may be the case that a criterion suggests a model with 3 or 4 latent variables is more appropriate. However, if we are interested in visualizing the data for ordination purposes, then models with 1 or 2 latent variables are more appropriate. As another example, whether or not we include row effects when ordinating multivariate abundance data depends on if we are interested in differences between sites in terms of relative species abundance (<code>row.eff = "none"</code>) or species composition (<code>row.eff = "fixed"</code>). From version 1.6, the calculation of all information criteria is being gradually phased out! 
</p>
<p><b>SSVS:</b> Stochastic search variable selection (SSVS, George and McCulloch, 1993) is also implemented for the response-specific coefficients <code class="reqn">\bm{\beta}_j</code>. Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information on this approach.
</p>


<h3>Value</h3>

<p>An object of class &quot;boral&quot; is returned, being a list containing (but not limited to) the following components where applicable:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>lv.coefs.mean/median/sd/iqr</code></td>
<td>
<p>Matrices containing the mean/median/standard deviation/interquartile range of the posterior distributions of the latent variable coefficients. This also includes the response-specific intercepts, and dispersion parameters if appropriate.</p>
</td></tr>
<tr><td><code>lv.mean/median/sd/iqr</code></td>
<td>
<p>A matrix containing the mean/median/standard deviation/interquartile range of the posterior distributions of the latent variables.</p>
</td></tr>
<tr><td><code>lv.covparams.mean/median/sd/iqr</code></td>
<td>
<p>A matrix containing the mean/median/standard deviation/interquartile range of the posterior distributions for the parameters characterizing the correlation structure of the latent variables when they are assumed to be non-independent across rows.</p>
</td></tr>
<tr><td><code>X.coefs.mean/median/sd/iqr</code></td>
<td>
<p>Matrices containing the mean/median/standard deviation/interquartile range of the posterior distributions of the response-specific coefficients relating to the covariate matrix.</p>
</td></tr>
<tr><td><code>traits.coefs.mean/median/sd/iqr</code></td>
<td>
<p>Matrices containing the mean/median/standard deviation/interquartile range of the posterior distributions of the coefficients and standard deviation relating to the species traits; please see <code><a href="#topic+about.traits">about.traits</a></code>.</p>
</td></tr>
<tr><td><code>cutoffs.mean/median/sd/iqr</code></td>
<td>
<p>Vectors containing the mean/median/standard deviation/interquartile range of the posterior distributions of the common cutoffs for ordinal responses (please see the not-so-brief tangent on distributions above).</p>
</td></tr>
<tr><td><code>ordinal.sigma.mean/median/sd/iqr</code></td>
<td>
<p>Scalars containing the mean/median/standard deviation/interquartile range of the posterior distributions of the standard deviation for the random intercept normal distribution corresponding to the ordinal response columns.</p>
</td></tr>
<tr><td><code>powerparam.mean/median/sd/iqr</code></td>
<td>
<p>Scalars for the mean/median/standard deviation/interquartile range of the posterior distributions of the common power parameter for tweedie responses (please see the not-so-brief tangent on distributions above).</p>
</td></tr>
<tr><td><code>row.coefs.mean/median/sd/iq</code></td>
<td>
<p>A list with each element containing the vectors of the mean/median/standard deviation/interquartile range of the posterior distributions of the row effects. The length of the list is equal to the number of row effects included i.e., <code>ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>row.sigma.mean/median/sd/iqr</code></td>
<td>
<p>A list with each element containing the mean/median/standard deviation/interquartile range of the posterior distributions of the standard deviation for the row random effects normal distribution. The length of the list is equal to the number of row effects included i.e., <code>ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>ranef.coefs.mean/median/sd/iq</code></td>
<td>
<p>A list with each element containing the matrices of the mean/median/standard deviation/interquartile range of the posterior distributions of the response-specific random intercepts. The length of the list is equal to the number of random intercepts included i.e., <code>ncol(ranef.ids)</code>.</p>
</td></tr>
<tr><td><code>ranef.sigma.mean/median/sd/iqr</code></td>
<td>
<p>A matrix containing the mean/median/standard deviation/interquartile range of the posterior distributions of the standard deviation for the response-specific random intercept normal distribution. The number of columns of the matrix is equal to number of random intercepts included i.e., <code>ncol(ranef.ids)</code>.</p>
</td></tr>
<tr><td><code>ssvs.indcoefs.mean/ssvs.indcoefs.sd</code></td>
<td>
<p>Matrices containing posterior probabilities and associated standard deviation for individual SSVS of coefficients in the covariate matrix.</p>
</td></tr>
<tr><td><code>ssvs.gpcoefs.mean/ssvs.gpcoefs.sd</code></td>
<td>
<p>Matrices containing posterior probabilities and associated standard deviation for group SSVS of coefficients in the covariate matrix.</p>
</td></tr>
<tr><td><code>ssvs.traitscoefs.mean/ssvs.traitscoefs.sd</code></td>
<td>
<p>Matrices containing posterior probabilities and associated standard deviation for individual SSVS of coefficients relating to species traits.</p>
</td></tr>
<tr><td><code>hpdintervals</code></td>
<td>
<p>A list containing components which correspond to the lower and upper bounds of highest posterior density (HPD) intervals for all the parameters indicated above. Please see <code><a href="#topic+get.hpdintervals">get.hpdintervals</a></code> for more details.</p>
</td></tr>
<tr><td><code>ics</code></td>
<td>
<p>If <code>calc.ics = TRUE</code>, then a list of different information criteria values for the model calculated using <code><a href="#topic+get.measures">get.measures</a></code> is run. Please see <code><a href="#topic+get.measures">get.measures</a></code> for details regarding the criteria. Also, please note the ics returned are based on <code><a href="#topic+get.measures">get.measures</a></code> with <code>more.measures = FALSE</code>.</p>
</td></tr>
<tr><td><code>jags.model</code></td>
<td>
<p>If <code>save.model = TRUE</code>, the raw jags model fitted is returned. This can be quite large!</p>
</td></tr>
<tr><td><code>geweke.diag</code></td>
<td>
<p>A list with two elements. The first element is itself a list containing the Geweke convergence diagnostic (Z-scores) for all appropriate parameters in the model. The second element contains the proportion of Z-scores that whose corresponding p-value is less than 0.05. No adjustment is made for multiple comparison on the p-values. Please see the section <em>Why is only one MCMC chain run?</em> for more information on this diagnostic.</p>
</td></tr>
<tr><td><code>n</code>, <code>p</code>, <code>family</code>, <code>trial.size</code>, <code>num.lv</code>, <code>...</code></td>
<td>
<p>Various attributes of the model fitted, including the dimension of the response matrix, the response and model matrix used, distributional assumptions and trial sizes, number of latent variables, the number of covariates and traits, hyperparameters used in the Bayesian estimation, indices for SSVS, the number of levels for ordinal responses, and n.burnin, n.iteration and n.thin.</p>
</td></tr>
</table>


<h3>Why is only one MCMC chain run?</h3>

<p>Much like the <code>MCMCfactanal</code> function in the <code>MCMCpack</code> package (Martin et al., 2011) for conducting factor analysis, which is a special case of the pure latent variable model with Gaussian responses, boral deliberately runs only one MCMC chain. This runs contrary to the recommendation of most Bayesian analyses, where the advice is to run multiple MCMC chains and check convergence using (most commonly) the Gelman-Rubin statistic (Gelman et al., 2013). The main reason for this is that, in the context of MCMC sampling, the latent variable model is invariant to a switch of the sign, i.e. <code class="reqn">\bm{u}^\top_i\bm{\theta}_j = (-\bm{u}^\top_i(-\bm{\theta}_j)</code>, and so is actually unidentifiable. 
</p>
<p>As a result of sign-switching, different MCMC chains can produce latent variables and corresponding coefficients values that, while having similar magnitudes, will be different in sign. Consequently, combining MCMC chains and checking Rhats, computing posterior means and medians etc...becomes complicated (in principle, one way to resolve this problem would be to post-process the MCMC chains and deal with sign switching, but this is really hard!). Therefore, to alleviate this issue together, boral chooses to only run one MCMC chain.
</p>
<p>What does this mean for the user? 
</p>

<ul>
<li><p> boral automatically calculates the Geweke convergence diagnostic (Geweke, 1992), which is a diagnostic applicable with only one MCMC chain; please see the help file <code>geweke.diag</code> in the <code>coda</code> package for more information. The output is a list containing Z-scores for the appropriate parameters in the model, and each score can be interpreted in the same manner as the test statistic from conducting a Z-test i.e., if the score exeeds roughly 1.96 then the p-value is less than 0.05, and there is evidence the MCMC chain (for this particular parameter) has not converged. 
</p>
<p>The output from boral also provides the proportion of Z-scores whose corresponding p-values are less than 0.05. Of course, because there are a large number of parameters in the model, then there are large number of Z-scores, and boral does not make any multiple comparison adjustment for this when calculating the number of &ldquo;significant&quot; Z-scores. If you do indeed want to use this diagnostic to formally check for convergence, then we recommend you conduct some adjustment e.g., using Holm's method, by doing something such as <br /> <code>gew.pvals &lt;- 2*pnorm(abs(unlist(fit$geweke.diag[[1]])), lower.tail = FALSE)</code> and then <code>p.adjust(gew.pvals, method = "holm")</code>.
</p>
</li>
<li><p> For checking convergence, we recommend you look at trace plots of the MCMC chains. Using the <code>coda</code> package, which is automatically loaded when the <code>boral</code> package is loaded, try something like <code>plot(get.mcmcsamples(fit))</code>. 
</p>
</li>
<li><p> If you have a lot of data, e.g. lots of sites compared to species, sign-switching tends to be less of problem and pops up less often.
</p>

</li></ul>



<h3>Warnings</h3>


<ul>
<li> <p><em>No</em> intercept column should be included in the covariate matrix. Column-specific intercepts are estimated automatically and given by the first column of <code>lv.coefs</code>. Similarly, <em>no</em> intercept column should be included in the trait matrix, as it is included automatically.
</p>
</li>
<li><p> As of version 1.6, functions to calculate information criteria along with <code><a href="#topic+calc.marglogLik">calc.marglogLik</a></code> are no longer updated, and being phrased out!
</p>
</li>
<li><p> MCMC with a non-independence correlation structure for the latent variables takes an especially long time to run! Likewise, MCMC with lots of ordinal columns take an especially long time to run! Moreover, estimates for the cutoffs in cumulative probit regression may be poor for levels with little data. Major apologies for this advance =(
</p>
</li>
<li><p> Summaries of the coefficients such as posterior medians and HPD intervals may also be problematic when SSVS is being used, since the posterior distribution will be multi-modal. 
</p>
</li>
<li><p> If <code>save.model = TRUE</code>, the raw jags model is also returned. This can be quite very memory-consuming, since it indirectly saves all the MCMC samples.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Gelman A. (2006) Prior distributions for variance parameters in hierarchical models. Bayesian Analysis 1, 515-533.
</p>
</li>
<li><p> Gelman et al. (2008). A weakly informative default prior distribution for logistic and other regression models. The Annals of Applied Statistics, 2, 1360-1383.
</p>
</li>
<li><p> Gelman et al. (2013) Bayesian Data Analysis. CRC Press.
</p>
</li>
<li><p> George, E. I. and McCulloch, R. E. (1993). Variable selection via Gibbs sampling. Journal of the American Statistical Association, 85, 398-409.
</p>
</li>
<li><p> Geweke, J. (1992) Evaluating the accuracy of sampling-based approaches to calculating posterior moments. In Bayesian Statistics 4 (editors JM Bernado, JO Berger, AP Dawid and AFM Smith). Clarendon Press.
</p>
</li>
<li><p> Hui et al. (2014). Model-based approaches to unconstrained ordination. Methods in Ecology and Evolution, 6, 399-411.
</p>
</li>
<li><p> Hill, M. O. (1974). Correspondence analysis: a neglected multivariate method. Applied statistics, 23, 340-354.
</p>
</li>
<li><p> Jamil, T., and ter Braak, C.J.F. (2013). Generalized linear mixed models can detect unimodal species-environment relationships. PeerJ 1: e95.
</p>
</li>
<li><p> Kruskal, J. B. (1964). Nonmetric multidimensional scaling: a numerical method. Psychometrika, 29, 115-129.
</p>
</li>
<li><p> Legendre, P. and Legendre, L. (2012). Numerical ecology, Volume 20. Elsevier.
</p>
</li>
<li><p> Martin et al. (2011). MCMCpack: Markov Chain Monte Carlo in R. Journal of Statistical Software, 42, 1-21. URL: http://www.jstatsoft.org/v42/i09/.
</p>
</li>
<li><p> McLachlan, G., and Peel, D. (2004). Finite Mixture Models. Wiley.
</p>
</li>
<li><p> Ovaskainen, et al. (2016). Uncovering hidden spatial structure in species communities with spatially explicit joint species distribution models. Methods in Ecology and Evolution, 7, 428-436.
</p>
</li>
<li><p> Ovaskainen, et al. (2017). How to make more out of community data? A conceptual framework and its implementation as models and software. Ecology Letters, 20, 561-576.
</p>
</li>
<li><p> Plummer, M. (2003). JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling. In Proceedings of the 3rd International Workshop on Distributed Statistical Computing. March (pp. 20-22).
</p>
</li>
<li><p> Pollock, et al. (2014). Understanding co-occurrence by modelling species simultaneously with a Joint Species Distribution Model (JSDM). Methods in Ecology and Evolution, 5, 397-406.
</p>
</li>
<li><p> Skrondal, A., and Rabe-Hesketh, S. (2004). Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models. CRC Press.
</p>
</li>
<li><p> Thorson, et al. (2016). Joint dynamic species distribution models: a tool for community ordination and spatio-temporal monitoring. Global Ecology and Biogeography, 25, 1144-1158
</p>
</li>
<li><p> Thorson, et al. (2015). Spatial factor analysis: a new tool for estimating joint species distributions and correlations in species range. Methods in Ecology and Evolution, 6, 627-63
</p>
</li>
<li><p> Warton et al. (2012). Distance-based multivariate analyses confound location and dispersion effects. Methods in Ecology and Evolution, 3, 89-101.
</p>
</li>
<li><p> Warton et al. (2015). So Many Variables: Joint Modeling in Community Ecology. Trends in Ecology and Evolution, 30, 766-779.
</p>
</li>
<li><p> Warton et al. (2016). Extending joint models in community ecology: A response to Beissinger et al. Trends in ecology &amp; evolution, 31, 737-738.
</p>
</li>
<li><p> Wang et al. (2013). <code>mvabund</code>: statistical methods for analysing multivariate abundance data. R package version 3.8.4.</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+calc.varpart">calc.varpart</a></code> to calculate variance partitioning of the covariates, 
<code><a href="#topic+coefsplot">coefsplot</a></code> for horizontal line or &quot;caterpillar plot&quot; of the regression coefficients corresponding to the covariate matrix (if applicable),
<code><a href="#topic+get.enviro.cor">get.enviro.cor</a></code> and <code><a href="#topic+get.residual.cor">get.residual.cor</a></code> for calculating the correlation matrix between the explanatory variables in the covariate matrix and the residual correlation matrix respectively, 
<code><a href="#topic+lvsplot">lvsplot</a></code> for a scatter plot of the latent variables (and their coefficients if applicable),
<code><a href="#topic+predict.boral">predict.boral</a></code> for calculating predictions from a fitted model.
<code><a href="#topic+ranefsplot">ranefsplot</a></code> for horizontal line or &quot;caterpillar plot&quot; of the response-specific random effects predictons (if applicable),
<code><a href="#topic+summary.boral">summary.boral</a></code> for a summary of the fitted model, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")
 
 
## Example 1 - model with two latent variables, site effects, 
## 	and no environmental covariates
spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
    lv.control = list(num.lv = 2), row.eff = "fixed", 
    mcmc.control = example_mcmc_control, model.name = testpath)

summary(spiderfit_nb)

par(mfrow = c(2,2))
plot(spiderfit_nb) ## Plots used in residual analysis, 
## Used to check if assumptions such an mean-variance relationship 
## are adequately satisfied.

lvsplot(spiderfit_nb) ## Biplot of the latent variables, 
## which can be interpreted in the same manner as an ordination plot.


## Not run: 
## Example 2a - model with no latent variables, no site effects, 
##      and environmental covariates
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
     mcmc.control = example_mcmc_control, model.name = testpath)
## Alternatively, you can use the formula.X argument for more custom
##   creation of a covariate matrix. For example, for have a covariate
##   including all predictors except bare sand:
# spiderfit_nb &lt;- boral(y, X = X, formula.X = ~ . - bare.sand, 
#     family = "negative.binomial", mcmc.control = example_mcmc_control, 
#     model.name = testpath)
    
summary(spiderfit_nb) 
## The results can be compared with the default example from 
## the manyglm() function in mvabund. 

## Caterpillar plots for the coefficients
par(mfrow=c(2,3), mar = c(5,6,1,1))
sapply(colnames(spiderfit_nb$X), coefsplot, object = spiderfit_nb)


## Example 2b - suppose now, for some reason, the 28 rows were
## 	sampled such into four replications of seven sites
## Let us account for this as a fixed effect
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    row.eff = "fixed", row.ids = matrix(rep(1:7,each=4),ncol=1),
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$row.coefs


## Example 2c - suppose now, for some reason, the 28 rows reflected
## 	a nested design with seven regions, each with four sub-regions
## We can account for this nesting as a random effect
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    row.eff = "random", 
    row.ids = cbind(1:n, rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$row.coef.median


## Example 2d - model with environmental covariates and 
##  two structured latent variables using fake distance matrix
fakedistmat &lt;- as.matrix(dist(1:n))
spiderfit_lvstruc &lt;- boral(y, X = X, family = "negative.binomial", 
    lv.control = list(num.lv = 2, type = "exponential", distmat = fakedistmat), 
     mcmc.control = example_mcmc_control, model.name = testpath)

summary(spiderfit_lvstruc)


## Example 2e - Similar to 2c, but we will species-specific random intercepts
##   for the seven regions (with row effects in the model)
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath) 

spiderfit_nb$ranef.coefs.median
spiderfit_nb$ranef.sigma.median


## Example 3a - Extend example 2 to demonstrate grouped covariate selection
## on the last three covariates. 
example_prior_control &lt;- list(type = c("normal","normal","normal","uniform"), 
     ssvs.index = c(-1,-1,-1,1,2,3))
spiderfit_nb2 &lt;- boral(y, X = X, family = "negative.binomial", 
    mcmc.control = example_mcmc_control,
    prior.control = example_prior_control, model.name = testpath)
     
summary(spiderfit_nb2) 


## Example 3b - Extend example 2 to demonstrate individual covariate selection
## on the last three covariates. 
example_prior_control &lt;- list(type = c("normal","normal","normal","uniform"), 
    ssvs.index = c(-1,-1,-1,0,0,0))
spiderfit_nb3 &lt;- boral(y, X = X, family = "negative.binomial", 
    mcmc.control = example_mcmc_control, prior.control = example_prior_control, 
    model.name = testpath)
summary(spiderfit_nb3) 

	
## Example 4 - model fitted to presence-absence data, no site effects, and
## two latent variables
data(tikus)
y &lt;- tikus$abun
y[y &gt; 0] &lt;- 1
y &lt;- y[1:20,] ## Consider only years 1981 and 1983
y &lt;- y[,apply(y &gt; 0,2,sum) &gt; 2] ## Consider only spp with more than 2 presences
     
tikusfit &lt;- boral(y, family = "binomial", 
    lv.control = list(num.lv = 2), mcmc.control = example_mcmc_control,
    model.name = testpath)
     
lvsplot(tikusfit, biplot = FALSE) 
## A strong location between the two sampling years 


## Example 5a - model fitted to count data, no site effects, and
## two latent variables, plus traits included to explain environmental responses
data(antTraits)
y &lt;- antTraits$abun
X &lt;- as.matrix(scale(antTraits$env))
## Include only traits 1, 2, and 5
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
    example_which_traits[[i]] &lt;- 1:ncol(traits)
## Just for fun, the regression coefficients for the second column of X,
## corresponding to the third element in the list example_which_traits,
## will be estimated separately and not regressed against traits.
example_which_traits[[3]] &lt;- 0

fit_traits &lt;- boral(y, X = X, traits = traits, 
    lv.control = list(num.lv = 2),
    which.traits = example_which_traits, family = "negative.binomial",
    mcmc.control = example_mcmc_control, model.name = testpath,
    save.model = TRUE)

summary(fit_traits)


## Example 5b - perform selection on trait coefficients
ssvs_traitsindex &lt;- vector("list",ncol(X)+1)
for(i in 1:length(ssvs_traitsindex)) 
     ssvs_traitsindex[[i]] &lt;- rep(0,ncol(traits))
ssvs_traitsindex[[3]] &lt;- -1
fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", 
    lv.control = list(num.lv = 2), mcmc.control = example_mcmc_control, 
    save.model = TRUE, prior.control = list(ssvs.traitsindex = ssvs_traitsindex),
    model.name = testpath)

summary(fit_traits)


## Example 6 - simulate Bernoulli data, based on a model with two latent variables, 
## no site variables, with two traits and one environmental covariates 
## This example is a proof of concept that traits can used to 
## explain environmental responses 
library(mvtnorm)

n &lt;- 100; s &lt;- 50
X &lt;- as.matrix(scale(1:n))
colnames(X) &lt;- c("elevation")

traits &lt;- cbind(rbinom(s,1,0.5), rnorm(s)) 
## one categorical and one continuous variable
colnames(traits) &lt;- c("thorns-dummy","SLA")

simfit &lt;- list(true.lv = rmvnorm(n, mean = rep(0,2)), 
    lv.coefs = cbind(rnorm(s), rmvnorm(s, mean = rep(0,2))), 
    traits.coefs = matrix(c(0.1,1,-0.5,1,0.5,0,-1,1), 2, byrow = TRUE))
rownames(simfit$traits.coefs) &lt;- c("beta0","elevation")
colnames(simfit$traits.coefs) &lt;- c("kappa0","thorns-dummy","SLA","sigma")

simy = create.life(true.lv = simfit$true.lv, lv.coefs = simfit$lv.coefs, X = X, 
    traits = traits, traits.coefs = simfit$traits.coefs, family = "binomial") 


example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
    example_which_traits[[i]] &lt;- 1:ncol(traits)
fit_traits &lt;- boral(y = simy, X = X, traits = traits, 
    which.traits = example_which_traits, family = "binomial", 
    lv.control = list(num.lv = 2), save.model = TRUE, 
    mcmc.control = example_mcmc_control, model.name = testpath)


## End(Not run)

</code></pre>

<hr>
<h2 id='boral-package'>Bayesian Ordination and Regression AnaLysis (boral)</h2><span id='topic+boral-package'></span>

<h3>Description</h3>

<p>Bayesian approaches for analyzing multivariate data in ecology. Estimation is performed using Markov Chain Monte Carlo (MCMC) methods via Three. JAGS types of models may be fitted: 1) With explanatory variables only, boral fits independent column Generalized Linear Models (GLMs) to each column of the response matrix; 2) With latent variables only, boral fits a purely latent variable model for model-based unconstrained ordination; 3) With explanatory and latent variables, boral fits correlated column GLMs with latent variables to account for any residual correlation between the columns of the response matrix. 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> boral</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.6</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2014-12-12</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Hui et al. (2014). Model-based approaches to unconstrained ordination. Methods in Ecology and Evolution, 6, 399-411.
</p>
</li>
<li><p> Plummer, M. (2003). JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling. In Proceedings of the 3rd International Workshop on Distributed Statistical Computing. March (pp. 20-22).
</p>
</li>
<li><p> Skrondal, A., and Rabe-Hesketh, S. (2004). Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models. CRC Press.
</p>
</li>
<li><p> Warton et al. (2015). So Many Variables: Joint Modeling in Community Ecology. Trends in Ecology and Evolution, 30, 766-779.
</p>
</li>
<li><p> Yi W. et al. (2013). <code>mvabund</code>: statistical methods for analysing multivariate abundance data. R package version 3.8.4. </p>
</li></ul>
 


<h3>Examples</h3>

<pre><code class='language-R'>## Please see main boral function for examples. 
</code></pre>

<hr>
<h2 id='calc.condlogLik'>Conditional log-likelihood for a fitted model</h2><span id='topic+calc.condlogLik'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p>Calculates the conditional log-likelihood for a set of parameter estimates from a fitted model, where everything is treated as &quot;fixed effects&quot; including latent variables, row effects, and so on. WARNING: As of version 1.9, this function is no longer being maintained (and probably does not work properly, if at all)!</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.condlogLik(y, X = NULL, family, trial.size = 1, lv.coefs, 
	X.coefs = NULL, row.coefs = NULL, row.ids = NULL,
	offset = NULL, lv = NULL, cutoffs = NULL, powerparam = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.condlogLik_+3A_y">y</code></td>
<td>
<p>The response matrix the model was fitted to.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_x">X</code></td>
<td>
<p>The covariate matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no model matrix was used.</p>
</td></tr>  
<tr><td><code id="calc.condlogLik_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_lv.coefs">lv.coefs</code></td>
<td>
<p>The response-specific intercept, coefficient estimates relating to the latent variables, and dispersion parameters from the fitted model.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_x.coefs">X.coefs</code></td>
<td>
<p>The coefficients estimates relating to the covariate matrix from the fitted model. Defaults to <code>NULL</code>, in which it is assumed there are no covariates in the model.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_row.coefs">row.coefs</code></td>
<td>
<p>Row effect estimates for the fitted model. The conditional likelihood is defined conditional on these estimates i.e., they are also treated as &ldquo;fixed effects&quot;. Defaults to <code>NULL</code>, in which case it is assumed there are no row effects in the model.</p>
</td></tr> 
<tr><td><code id="calc.condlogLik_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see the <code><a href="#topic+boral">boral</a></code> function for details. Defaults to <code>NULL</code>, so that if <code>row.coefs = NULL</code> then the argument is ignored, otherwise if <code>row.coefs</code> is supplied then <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row. An internal check is done to see <code>row.coefs</code> and <code>row.ids</code> are consistent in terms of arguments supplied.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_lv">lv</code></td>
<td>
<p>Latent variables &quot;estimates&quot; from the fitted model, which the conditional likelihood is based on. Defaults to <code>NULL</code>, in which case it is assumed no latent variables were included in the model.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_cutoffs">cutoffs</code></td>
<td>
<p>Common cutoff estimates from the fitted model when any of the columns of the response matrix are ordinal responses. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calc.condlogLik_+3A_powerparam">powerparam</code></td>
<td>
<p>Common power parameter from the fitted model when any of the columns of the response matrix are tweedie responses. Defaults to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For an <code class="reqn">n x p</code> response matrix <code class="reqn">\bm{Y}</code>, suppose we fit a model with one or more latent variables. If we denote the latent variables by <code class="reqn">\bm{u}_i; i = 1,\ldots,n</code>, then the conditional log-likelihood is given by,
</p>
<p style="text-align: center;"><code class="reqn"> \log(f) = \sum_{i=1}^n \sum_{j=1}^p \log \{f(y_{ij} | \bm{u}_i, \bm{\theta}_j, \beta_{0j}, \ldots)\}, </code>
</p>

<p>where <code class="reqn">f(y_{ij}|\cdot)</code> is the assumed distribution for column <code class="reqn">j</code>, <code class="reqn">\bm{u}_i</code> are the latent variables and <code class="reqn">\bm{\theta}_j</code> are the coefficients relating to them, <code class="reqn">\beta_{0j}</code> are response-specific intercepts, and <code class="reqn">\ldots</code> denotes anything else included in the model, such as row effects, regression coefficients related the covariate matrix and the trait matrix, etc...
</p>
<p>The key difference between this and the marginal likelihood (see <code><a href="#topic+calc.marglogLik">calc.marglogLik</a></code>) is that the conditional likelihood treats everything as &quot;fixed effects&quot; i.e., conditions on them. These include the latent variables <code class="reqn">\bm{u}_i</code> and other parameters that were included in the model as random effects e.g., row effects if <code>row.eff = "random"</code>, regression coefficients related to the covariate matrix if traits were included in the model, and so on.
</p>
<p>The conditional DIC, WAIC, EAIC, and EBIC returned from <code><a href="#topic+get.measures">get.measures</a></code> are based on the conditional likelihood calculated from this function. Additionally, <code><a href="#topic+get.measures">get.measures</a></code> returns the conditional likelihood evaluated at all MCMC samples of a fitted model.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the conditional log-likelihood.</p>
</td></tr>
<tr><td><code>logLik.comp</code></td>
<td>
<p>A matrix of the log-likelihood values for each element in the response matrix, <br /> such that <code>sum(logLik.comp) = logLik</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calc.logLik.lv0">calc.logLik.lv0</a></code> to calculate the conditional/marginal log-likelihood for a model with no latent variables; <code><a href="#topic+calc.marglogLik">calc.marglogLik</a></code> for calculation of the marginal log-likelihood; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

## Example 1 - model with 2 latent variables, site effects, 
## 	and no environmental covariates
spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
    lv.control = list(num.lv = 2), row.eff = "fixed", 
    save.model = TRUE, mcmc.control = example_mcmc_control,
    model.name = testpath)

## Extract all MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb) 
mcmc_names &lt;- colnames(fit_mcmc)

## Find the posterior medians
coef_mat &lt;- matrix(apply(fit_mcmc[,grep("lv.coefs",mcmc_names)],
    2,median),nrow=p)
site_coef &lt;- list(ID1 = apply(fit_mcmc[,grep("row.coefs.ID1", mcmc_names)],
    2,median))
lvs_mat &lt;- matrix(apply(fit_mcmc[,grep("lvs",mcmc_names)],2,median),nrow=n)

## Calculate the conditional log-likelihood at the posterior median
calc.condlogLik(y, family = "negative.binomial", 
    lv.coefs = coef_mat, row.coefs = site_coef, lv = lvs_mat)


## Example 2 - model with no latent variables and environmental covariates
X &lt;- scale(spider$x)
spiderfit_nb2 &lt;- boral(y, X = X, family = "negative.binomial", 
    save.model = TRUE, mcmc.control = example_mcmc_control, 
    model.name = testpath)

## Extract all MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb2) 
mcmc_names &lt;- colnames(fit_mcmc)

## Find the posterior medians
coef_mat &lt;- matrix(apply(fit_mcmc[,grep("lv.coefs",mcmc_names)],
    2,median),nrow=p)
X_coef_mat &lt;- matrix(apply(fit_mcmc[,grep("X.coefs",mcmc_names)],
    2,median),nrow=p)

## Calculate the log-likelihood at the posterior median
calc.condlogLik(y, X = X, family = "negative.binomial", 
    lv.coefs =  coef_mat, X.coefs = X_coef_mat)

## End(Not run)
</code></pre>

<hr>
<h2 id='calc.logLik.lv0'>Log-likelihood for a model fitted with no latent variables</h2><span id='topic+calc.logLik.lv0'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p>Calculates the log-likelihood for a set of parameter estimates from a model with no latent variables. If the row effects are assumed to be random, they are integrated over using Monte Carlo integration. WARNING: As of version 1.9, this function is no longer being maintained (and probably does not work properly, if at all)!</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.logLik.lv0(y, X = NULL, family, trial.size = 1, lv.coefs, 
	X.coefs = NULL, row.eff = "none", row.params = NULL, 
	row.ids = NULL, offset = NULL, cutoffs = NULL,
	powerparam = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.logLik.lv0_+3A_y">y</code></td>
<td>
<p>The response matrix the model was fitted to.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_x">X</code></td>
<td>
<p>The covariate matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no model matrix was used.</p>
</td></tr>  
<tr><td><code id="calc.logLik.lv0_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_lv.coefs">lv.coefs</code></td>
<td>
<p>The response-specific intercept, coefficient estimates relating to the latent variables, and dispersion parameters from the fitted model.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_x.coefs">X.coefs</code></td>
<td>
<p>The coefficients estimates relating to the covariate matrix from the fitted model. Defaults to <code>NULL</code>, in which it is assumed there are no covariates in the model.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and standard deviation given by <code>row.params</code>. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="calc.logLik.lv0_+3A_row.params">row.params</code></td>
<td>
<p>Parameters corresponding to the row effect from the fitted model. If <br /> <code>row.eff = "fixed"</code>, then these are the fixed effects and should have length equal to the number of columns in the response matrix. If <code>row.eff = "random"</code>, then this is the standard deviation for the random effects normal distribution. If <code>row.eff = "none"</code>, then this argument is ignored.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, so that if <code>row.params = NULL</code> then the argument is ignored, otherwise if <code>row.params</code> is supplied then <br /> <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row. An internal check is done to see <code>row.params</code> and <code>row.ids</code> are consistent in terms of arguments supplied.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_cutoffs">cutoffs</code></td>
<td>
<p>Common cutoff estimates from the fitted model when any of the columns of the response matrix are ordinal responses. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calc.logLik.lv0_+3A_powerparam">powerparam</code></td>
<td>
<p>Common power parameter from the fitted model when any of the columns of the response matrix are tweedie responses. Defaults to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For an <code class="reqn">n x p</code> response matrix <code class="reqn">\bm{y}</code>, the log-likelihood for a model with no latent variables included is given by,
</p>
<p style="text-align: center;"><code class="reqn"> \log(f) = \sum_{i=1}^n \sum_{j=1}^p \log \{f(y_{ij} | \beta_{0j}, \alpha_i, \ldots)\}, </code>
</p>

<p>where <code class="reqn">f(y_{ij}|\cdot)</code> is the assumed distribution for column <code class="reqn">j</code>, <code class="reqn">\beta_{0j}</code> is the response-specific intercepts, <code class="reqn">\alpha_i</code> is the row effect, and <code class="reqn">\ldots</code> generically denotes anything else included in the model, e.g. row effects, dispersion parameters etc...
</p>
<p>Please note the function is written conditional on all regression coefficients. Therefore, if traits are included in the model, in which case the regression coefficients <code class="reqn">\beta_{0j}, \bm{\beta}_j</code> become random effects instead (please see <code><a href="#topic+about.traits">about.traits</a></code>), then the calculation of the log-likelihood does NOT take this into account, i.e. does not marginalize over them!
</p>
<p>Likewise if more than two columns are ordinal responses, then the regression coefficients <code class="reqn">\beta_{0j}</code> corresponding to these columns become random effects, and the calculation of the log-likelihood also does NOT take this into account, i.e. does not marginalize over them!
</p>
<p>When a single <code class="reqn">\alpha_i</code> random row effect is inclued, then the log-likelihood is calculated by integrating over this,
</p>
<p style="text-align: center;"><code class="reqn"> \log(f) = \sum_{i=1}^n \log ( \int \prod_{j=1}^p \{f(y_{ij} | \beta_{0j}, \alpha_i, \ldots)\}f(\alpha_i) d\alpha_i ), </code>
</p>
 
<p>where <code class="reqn">f(\alpha_i)</code> is the random effects distribution with mean zero and standard deviation given by the <code>row.params</code>. The integration is performed using standard Monte Carlo integration. This naturally extends to multiple random row effects structures.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the log-likelihood</p>
</td></tr>
<tr><td><code>logLik.comp</code></td>
<td>
<p>A vector of the log-likelihood values for each row of the response matrix, <br /> such that <code>sum(logLik.comp) = logLik</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calc.marglogLik">calc.marglogLik</a></code> for calculation of the log-likelihood marginalizing over one or more latent variables, and <code><a href="#topic+calc.condlogLik">calc.condlogLik</a></code> for calculation of the conditional log-likelihood for models where everything is treated as &quot;fixed effects&quot;, including latent variables, row effects, and so on.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

## Example 1 - NULL model with site effects only
spiderfit_nb &lt;- boral(y, family = "negative.binomial", row.eff = "fixed", 
    save.model = TRUE, mcmc.control = example_mcmc_control,
    model.name = testpath)

## Extract all MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb) 
mcmc_names &lt;- colnames(fit_mcmc)

## Find the posterior medians
coef_mat &lt;- matrix(apply(fit_mcmc[,grep("lv.coefs",mcmc_names)],
    2,median),nrow=p)
site_coef &lt;- list(ID1 = apply(fit_mcmc[,grep("row.coefs.ID1", mcmc_names)],
    2,median))

## Calculate the log-likelihood at the posterior median
calc.logLik.lv0(y, family = "negative.binomial",
    lv.coefs =  coef_mat, row.eff = "fixed", row.params = site_coef)


## Example 2 - Model with environmental covariates and random row effects
X &lt;- scale(spider$x)
spiderfit_nb2 &lt;- boral(y, X = X, family = "negative.binomial", row.eff = "random",
    save.model = TRUE, mcmc.control = example_mcmc_control, 
    model.name = testpath)

## Extract all MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb2) 
mcmc_names &lt;- colnames(fit_mcmc)

## Find the posterior medians
coef_mat &lt;- matrix(apply(fit_mcmc[,grep("lv.coefs",mcmc_names)],
    2,median),nrow=p)
X_coef_mat &lt;- matrix(apply(fit_mcmc[,grep("X.coefs",mcmc_names)],
    2,median),nrow=p)
site.sigma &lt;- list(ID1 = 
    median(fit_mcmc[,grep("row.sigma.ID1", mcmc_names)]))

	
## Calculate the log-likelihood at the posterior median
calc.logLik.lv0(y, X = spider$x, family = "negative.binomial", 
    row.eff = "random",lv.coefs =  coef_mat, X.coefs = X_coef_mat, 
    row.params = site.sigma)

## End(Not run)
</code></pre>

<hr>
<h2 id='calc.marglogLik'>Marginal log-likelihood for a fitted model</h2><span id='topic+calc.marglogLik'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p>Calculates the marginal log-likelihood for a set of parameter estimates from a fitted model, whereby the latent variables and random effects (if applicable) are integrated out. The integration is performed using Monte Carlo integration. WARNING: As of version 1.9, this function is no longer being maintained (and probably does not work properly, if at all)!</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.marglogLik(y, X = NULL, family, trial.size = 1, lv.coefs, 
     X.coefs = NULL, row.eff = "none", row.params = NULL, 
     row.ids = NULL,offset = NULL, num.lv, lv.mc = NULL, 
     cutoffs = NULL, powerparam = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.marglogLik_+3A_y">y</code></td>
<td>
<p>The response matrix that the model was fitted to.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_x">X</code></td>
<td>
<p>The covariate matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no model matrix was used.</p>
</td></tr>  
<tr><td><code id="calc.marglogLik_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_lv.coefs">lv.coefs</code></td>
<td>
<p>The response-specific intercept, coefficient estimates relating to the latent variables, and dispersion parameters from the fitted model.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_x.coefs">X.coefs</code></td>
<td>
<p>The coefficients estimates relating to the covariate matrix from the fitted model. Defaults to <code>NULL</code>, in which it is assumed there are no covariates in the model.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and standard deviation given by <code>row.params</code>. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="calc.marglogLik_+3A_row.params">row.params</code></td>
<td>
<p>Parameters corresponding to the row effect from the fitted model. If <br /> <code>row.eff = "fixed"</code>, then these are the fixed effects and should have length equal to the number of columns in the response matrix. If <code>row.eff = "random"</code>, then this is standard deviation for the random effects normal distribution. If <code>row.eff = "none"</code>, then this argument is ignored.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, so that if <code>row.params = NULL</code> then the argument is ignored, otherwise if <code>row.params</code> is supplied then <br /> <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row. An internal check is done to see <code>row.params</code> and <code>row.ids</code> are consistent in terms of arguments supplied.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_num.lv">num.lv</code></td>
<td>
<p>The number of latent variables used in the fitted model. For models with no latent variables, please use <code><a href="#topic+calc.logLik.lv0">calc.logLik.lv0</a></code> to calculate the log-likelihood.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_lv.mc">lv.mc</code></td>
<td>
<p>A matrix used for performing the Monte Carlo integration. Defaults to <code>NULL</code>, in which case a matrix is generated within the function.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_cutoffs">cutoffs</code></td>
<td>
<p>Common cutoff estimates from the fitted model when any of the columns of the response matrix are ordinal responses. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calc.marglogLik_+3A_powerparam">powerparam</code></td>
<td>
<p>Common power parameter from the fitted model when any of the columns of the response matrix are tweedie responses. Defaults to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For an <code class="reqn">n x p</code> response matrix <code class="reqn">\bm{Y}</code>, suppose we fit a model with one or more latent variables. If we denote the latent variables by <code class="reqn">\bm{u}_i; i = 1,\ldots,n</code>, then the marginal log-likelihood is given by
</p>
<p style="text-align: center;"><code class="reqn"> \log(f) = \sum_{i=1}^n \log ( \int \prod_{j=1}^p \{f(y_{ij} | \bm{u}_i, \beta_{0j}, \bm{\theta}_j, \ldots) \} f(\bm{u}_i) d\bm{u}_i), </code>
</p>

<p>where <code class="reqn">f(y_{ij}|\cdot)</code> is the assumed distribution for column <code class="reqn">j</code>, <code class="reqn">\beta_{0j}</code> are the response-specific intercepts, <code class="reqn">\bm{\theta}_j</code> are the response-specific latent variable coefficients, and <code class="reqn">\ldots</code> generically denotes anything else included in the model, e.g. row effects, dispersion parameters etc... The quantity <code class="reqn">f(\bm{u}_i)</code> denotes the distribution of the latent variable, which is assumed to be standard multivariate Gaussian. Standard Monte Carlo integration is used for calculating the marginal likelihood. If <code>lv.mc = NULL</code>, the function automatically generates a matrix as <br /> <code>lv.mc &lt;- rmvnorm(1000, rep(0,num.lv))</code>. If there is a need to apply this function numerous times, we recommend a matrix be inserted into <code>lv.mc</code> to speed up computation.
</p>
<p>The key difference between this and the conditional likelihood (see <code>calc.condlogLik</code>) is that the marginal likelihood treats the latent variables as &quot;random effects&quot; and integrates over them, whereas the conditional likelihood treats the latent variables as &quot;fixed effects&quot;. 
</p>
<p>Please note the function is written conditional on all regression coefficients. Therefore, if traits are included in the model, in which case the regression coefficients <code class="reqn">\beta_{0j}, \bm{\beta}_j</code> become random effects instead (please see <code><a href="#topic+about.traits">about.traits</a></code>), then the calculation of the log-likelihood does NOT take this into account, i.e. does not marginalize over them! Likewise if more than two columns are ordinal responses, then the regression coefficients <code class="reqn">\beta_{0j}</code> corresponding to these columns become random effects, and the calculation of the log-likelihood also does NOT take this into account, i.e. does not marginalize over them!
</p>
<p>When a single <code class="reqn">\alpha_i</code> random row effect is inclued, then the log-likelihood is calculated by integrating over this,
</p>
<p style="text-align: center;"><code class="reqn"> \log(f) = \sum_{i=1}^n \log ( \int \prod_{j=1}^p \{f(y_{ij} | \bm{u}_i, \beta_{0j}, \alpha_i, \ldots)\} f(\bm{u}_i) f(\alpha_i) d\alpha_i ), </code>
</p>
 
<p>where <code class="reqn">f(\alpha_i)</code> is the random effects distribution with mean zero and standard deviation given by the <code>row.params</code>. The integration is again performed using standard Monte Carlo integration. This naturally extends to multiple random row effects structures.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the marginal log-likelihood.</p>
</td></tr>
<tr><td><code>logLik.comp</code></td>
<td>
<p>A vector of the log-likelihood values for each row of the response matrix, <br /> such that <code>sum(logLik.comp) = logLik</code>.</p>
</td></tr>
</table>


<h3>Warnings</h3>

<p>As of version 1.6, this function is longer updated!</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calc.condlogLik">calc.condlogLik</a></code> for calculation of the conditional log-likelihood; 
<code><a href="#topic+calc.logLik.lv0">calc.logLik.lv0</a></code> to calculate the conditional/marginal log-likelihood for a model with no latent variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)
    
## Example 1 - model with two latent variables, site effects, 
## 	and no environmental covariates
spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
    lv.control = list(num.lv = 2), row.eff = "fixed", save.model = TRUE, 
    mcmc.control = example_mcmc_control, model.name = testpath)

## Extract all MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb) 
mcmc_names &lt;- colnames(fit_mcmc)

## Find the posterior medians
coef_mat &lt;- matrix(apply(fit_mcmc[,grep("lv.coefs",mcmc_names)],
    2,median),nrow=p)
site_coef &lt;- list(ID1 = apply(fit_mcmc[,grep("row.coefs.ID1", mcmc_names)],
    2,median))
     
## Calculate the marginal log-likelihood at the posterior median
calc.marglogLik(y, family = "negative.binomial",
    lv.coefs = coef_mat, row.eff = "fixed", row.params = site_coef, 
    num.lv = 2)

	
## Example 2 - model with one latent variable, no site effects, 
## 	and environmental covariates
spiderfit_nb2 &lt;- boral(y, X = spider$x, family = "negative.binomial", 
     lv.control = list(num.lv = 2), save.model = TRUE, 
     mcmc.control = example_mcmc_control, model.name = testpath)

## Extract all MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb2) 
mcmc_names &lt;- colnames(fit_mcmc)

## Find the posterior medians
coef_mat &lt;- matrix(apply(fit_mcmc[,grep("lv.coefs",mcmc_names)],
    2,median),nrow=p)
X_coef_mat &lt;- matrix(apply(fit_mcmc[,grep("X.coefs",mcmc_names)],
    2,median),nrow=p)

## Calculate the log-likelihood at the posterior median
calc.marglogLik(y, X = spider$x, family = "negative.binomial", 
    lv.coefs = coef_mat, X.coefs = X_coef_mat, num.lv = 2)	

## End(Not run)
</code></pre>

<hr>
<h2 id='calc.varpart'>Variance partitioning for a latent variable model</h2><span id='topic+calc.varpart'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>For each response (species), partition the variance of the linear predictor into components associated with (groups of) the covariates, the latent variables, and any row effects and response-specific random intercepts. If traits are also included in the model, then it also calculates an R-squared value for the proportion of the variance in the environmental response (due to the covariates) which can be explained by traits.</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.varpart(object, groupX = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.varpart_+3A_object">object</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="calc.varpart_+3A_groupx">groupX</code></td>
<td>
<p>A vector of group indicator variables, which allows the variance partitioning to be done for groups of covariates (including the intercept) i.e., how much of the total variation does a certain subset of the covariates explain. Defaults to <code>NULL</code>, in whih case all the covariates are treated as single group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As an alternative to looking at differences in trace of the residual covariance matrix (Hui et al., 2014; Warton et al., 2015), an alternative way to quantify the amount of variance explained by covariates, traits, row effects, response-specific random intercepts, is to perform a variance decomposition of the linear predictor of a latent variable model (Ovaskainen et al., 2017). In particular, for a general model the linear predictor for response <code class="reqn">j = 1,\ldots,p</code> at row <code class="reqn">i = 1,\ldots,n</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">\eta_{ij} = \alpha_i + \beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{z}^\top_i\bm{b}_j + \bm{u}^\top_i\bm{\theta}_j,</code>
</p>

<p>where <code class="reqn">\beta_{0j} + \bm{x}^\top_i\bm{\beta}_j</code> is the component of the linear predictor due to the covariates <code class="reqn">\bm{X}</code> plus an intercept, <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> is the component due to response-specific random intercept, <code class="reqn">\bm{u}^\top_i\bm{\theta}_j</code> is the component due to the latent variables, and <code class="reqn">\alpha_i</code> is the component due to one or more fixed or random row effects. Not all of these components may be included in the model, and the above is just representing the general case. The regression coefficients <code class="reqn">\bm{\beta}_j</code> may be further as random effects and regressed against traits; please see <code><a href="#topic+about.traits">about.traits</a></code> for further information on this. 
</p>
<p>For the response, a variation partitioning of the linear predictor is performed by calculating the variance due to the components in <code class="reqn">\eta_{ij}</code> and then rescaling them to ensure that they sum to one. The general details of this type of variation partitioning is given in Ovaskainen et al., (2017); see also Nakagawa and Schielzeth (2013) for R-squared and proportion of variance explained in the case of generalized linear mixed model. In brief, for response <code class="reqn">j = 1,\ldots,p</code>: 
</p>

<ul>
<li><p> the variance due to the covariates and intercept is given by the variance of <code class="reqn">\beta_{0j} + \bm{x}^\top_i\bm{\beta}_j</code> calculated across the <code class="reqn">n</code> rows;
</p>
</li>
<li><p> the variance due to (all) the response-respecific random intercepts is given by the (sum of the) variances for each of the elements of <code class="reqn">b_{j}</code>
</p>
</li>
<li><p> the variance due to (all) the random row effects is given by variance of <code class="reqn">\alpha_i</code> calculated across the <code class="reqn">n</code> rows for fixed row effects (<code>row.eff = "fixed"</code>), and given by the (sum of the) variance <code class="reqn">\sigma^2_{\alpha}</code> for random row effects (<code>row.eff = "random"</code>);
</p>
</li>
<li><p> the variance due the latent variables is given by the diagonal elements of <code class="reqn">\bm{\theta}^\top_j\bm{\theta}_j</code>.
</p>
</li></ul>

<p>After scaling, we can then obtain the proportion of variance for each response which is explained by the variance components. These proportions are calculated for each MCMC sample and then average acrossed them to calculate a posterior mean variance partitioning. 
</p>
<p>If <code>groupX</code> is supplied, the variance due to the covariates is done based on subsets of the covariates (including the intercept) as identified by  <code>groupX</code>, and then rescaled correspondingly. This is useful if one was to, for example, quantify the proportion of variation in each response which is explained by each covariate.
</p>
<p>If a fitted model also containing traits, which are included to help explain/mediate differences in species environmental responses, then the function calculates <code class="reqn">R^2</code> value for the proportion of variance in the covariates which is explained by the traits. In brief, this is calculated based the correlation between <code class="reqn">\beta_{0j} + \bm{x}^\top_i\bm{\beta}_j</code> and <code class="reqn">\tau_{0j} + \bm{x}^\top_i\bm{\tau}_j</code>, where <code class="reqn">\tau_{0j}</code> and <code class="reqn">\bm{\tau}_j</code> are the &ldquo;predicted&quot; values of the species coefficients based on values i.e., <code class="reqn">\tau_{0j} = \kappa_{01} + \bm{traits}^\top_j\bm{\kappa}_1</code> and <code class="reqn">\tau_{jk} = \kappa_{0k} + \bm{traits}^\top_j\bm{\kappa}_k</code> for element <code class="reqn">k</code> in <code class="reqn">\bm{\tau}_j</code>. 
</p>


<h3>Value</h3>

<p>A list containing the following components, if applicable:
</p>
<table>
<tr><td><code>varpart.X</code></td>
<td>
<p>Vector containing the proportion of variance (in the linear predictor) for each response, which is explained by the covariate matrix.</p>
</td></tr>
<tr><td><code>varpart.lv</code></td>
<td>
<p>Vector containing the proportion of variance (in the linear predictor) for each response, which is explained by the latent variables.</p>
</td></tr>
<tr><td><code>varpart.row</code></td>
<td>
<p>Vector containing the proportion of variance (in the linear predictor) for each response, which is explained by the row effects.</p>
</td></tr>
<tr><td><code>varpart.ranef</code></td>
<td>
<p>Vector containing the proportion of variance (in the linear predictor) for each response, which is explained by the response-specific random intercepts.</p>
</td></tr>
<tr><td><code>R2.traits</code></td>
<td>
<p>Vector containing the proportion of variance due to the covariates for each response, which can be explained by traits for each response.</p>
</td></tr>
</table>


<h3>Warnings</h3>

<p>There is considerable controversy over exactly what quantities such as R-squared and proportion of variance explained are in the case mixed models and latent variable models, and how they can interpreted e.g., what is considered a high value for the proportion of variance by the covariates, is it consistent with whether the coefficients are significantly different from zero or not; see for instance <a href="https://stats.stackexchange.com/questions/111150/calculating-r2-in-mixed-models-using-nakagawa-schielzeths-2013-r2glmm-me">R2 controversy</a>.
</p>
<p>When reporting these values, researchers should be at least aware of this and that there are multiple ways of manufacturing such quantities, with no single best approach e.g., using relative changes in trace of the residual covariance matrix, relative changes in marginal and conditional log-likelihoods are other possible approaches. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Nakagawa, S., and Schielzeth, H. (2013). A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution 4, 133-142.
</p>
</li>
<li><p> Ovaskainen et al. (2017). How to make more out of community data? A conceptual framework and its implementation as models and software. Ecology Letters 20, 561-576.
</p>
</li>
<li><p> Hui et al. (2014). Model-based approaches to unconstrained ordination. Methods in Ecology and Evolution, 6, 399-411.
</p>
</li>
<li><p> Warton et al. (2015). So Many Variables: Joint Modeling in Community Ecology. Trends in Ecology and Evolution, 30, 766-779.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


## Example 1 - model with X variables, two latent variables, and no row effects
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
     lv.control = list(num.lv = 2), 
     save.model = TRUE, mcmc.control = example_mcmc_control,
     model.name = testpath)

## Partition variance for each species into that explained by covariates 
## and by the latent variables
dovar &lt;- calc.varpart(spiderfit_nb)

## Consider the intercept and first two covariates in X as one group, 
## and remaining four covariates in X as another group, 
## then partition variance for each species based on these groups.
dovar &lt;- calc.varpart(spiderfit_nb, groupX = c(1,1,1,2,2,2,2))


## Example 1b - model with X variables, two latent variables, and 
## species-specific random intercepts at a so-called region level
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    lv.control = list(num.lv = 2),
    ranef.ids = data.frame(subregion = rep(1:7,each=4)), 
    save.model = TRUE, mcmc.control = example_mcmc_control, 
    model.name = testpath) 

## Partition variance for each species into that explained by covariates 
## and by the latent variables
dovar &lt;- calc.varpart(spiderfit_nb)

## Consider the intercept and first two covariates in X as one group, 
## and remaining four covariates in X as another group, 
## then partition variance for each species based on these groups.
dovar &lt;- calc.varpart(spiderfit_nb, groupX = c(1,1,1,2,2,2,2))


## Example 2 - model fitted to count data, no site effects, and
## two latent variables, plus traits included to explain environmental responses
data(antTraits)
y &lt;- antTraits$abun
X &lt;- as.matrix(scale(antTraits$env))
## Include only traits 1, 2, and 5
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)
## Just for fun, the regression coefficients for the second column of X,
## corresponding to the third element in the list example_which_traits,
## will be estimated separately and not regressed against traits.
example_which_traits[[3]] &lt;- 0

fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", mcmc.control = example_mcmc_control, 
    save.model = TRUE, model.name = testpath)

## Partition variance for each species due to covariates in X 
## and latent variables. Also calculate proportion of variance 
## due to the covariates which can be explained by traits 
dovar &lt;- calc.varpart(fit_traits)

## End(Not run)

</code></pre>

<hr>
<h2 id='coefsplot'>Caterpillar plots of the regression coefficients from a fitted model</h2><span id='topic+coefsplot'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Constructs horizontal line plot (point estimate and HPD intervals), otherwise known as &quot;caterpillar plots&quot;, for the response-specific regression coefficients corresponding to the covariate in the fitted model. If a fourth-corner model is fitted, then &quot;caterpillar plots&quot; can optionally be produced for all the fourth-corner regression coefficients.</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefsplot(covname, object, fourthcorner = FALSE, labely = NULL, est = "median", ...) 
	</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefsplot_+3A_covname">covname</code></td>
<td>
<p>The name of one of the covariates in the fitted model. That is, it must be a character vector corresponding to one of the elements in <code>colnames(object$X.coefs.median)</code>. 
</p>
<p>If <code>fourthcorner = TRUE</code>, then this argument is ignored.</p>
</td></tr>
<tr><td><code id="coefsplot_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="coefsplot_+3A_fourthcorner">fourthcorner</code></td>
<td>
<p>If set to <code>TRUE</code>, then a caterpillar plot of the fourth-corner regression coefficients, as given by <code>object$traits.coefs.median</code> say, are plotted instead, assuming a model involving traits is fitted. Defaults to <code>FALSE</code>, in which case the plot is of response-specific regression coefficients. If <code>fourthcorner = TRUE</code>, then both the <code>covname</code> and <code>labely</code> arguments are ignored.</p>
</td></tr>
<tr><td><code id="coefsplot_+3A_labely">labely</code></td>
<td>
<p>Controls the labels on the y-axis for the line plot. If it is not <code>NULL</code>, then it must be a vector either of length 1 or the same length as the number of columns in the response matrix in the fitted boral object. In the former, it is treated as the y-axis label. In the latter, it is used in place of the column names of the response matrix to label each line. Defaults to <code>NULL</code>, in which the each line in the plot is labeled according to the columns of the response matrix, or equivalently <code>rownames(object$X.coefs.median)</code>.
</p>
<p>If <code>fourthcorner = TRUE</code>, then this argument is ignored.</p>
</td></tr>
<tr><td><code id="coefsplot_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then used as the point estimates in the lines. Default is posterior median.</p>
</td></tr>
<tr><td><code id="coefsplot_+3A_...">...</code></td>
<td>
<p>Additional graphical options to be included in. These include values for <br /> <code>cex, cex.lab, cex.axis, cex.main, lwd</code>, and so on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each response (column of the response matrix, the horizontal line or &quot;caterpillar&quot; is constructed by first marking the point estimate (posterior mean or median) with an &quot;x&quot; symbol. Then the line is construed based on the lower and upper limits of the highest posterior density (HPD) intervals as found in <code>object$hpdintervals</code>. By default, these are 95% HPD intervals. To complete the plot, a vertical dotted line is drawn to denote the zero value. All HPD intervals that include zero are colored gray, while HPD intervals that exclude zero are colored black. 
</p>
<p>For plots of fourth-corner regression coefficients, the coefficients are labelled such that on the left vertical axis the names of the covariates includes in the model are given, while on the right vertical axis the names of traits included in the model are given. Please see the <code><a href="#topic+about.traits">about.traits</a></code> for more about fourth-corner models where traits are included to help explain differences in species environmental responses to covariates. 
</p>
<p>The graph is probably better explained by, well, plotting it using the toy example below! Thanks to Robert O'Hara for suggesting and providing the original code for this function.
</p>


<h3>Value</h3>

<p>If SSVS was applied individually to each coefficient of the covariate matrix when fitting the model, then the posterior probabilities of including the specified covariate are printed out i.e., <br /> those from <code>object$ssvs.indcoefs.mean</code>.
</p>
<p>For fourth-corher models, if SSVS was applied individually to fourth-corner coefficients when fitting the model, then the posterior probabilities of including the specified coefficient are printed out i.e., <br /> those from <code>object$ssvs.traitscoefs.mean</code>.
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranefsplot">ranefsplot</a></code> for horizontal line or &quot;caterpillar plot&quot; of the response-specific random effects predictons (if applicable),
<code>caterplot</code> from the <code>mcmcplots</code> package, as well as the <code>ggpubr</code> package, for other, sexier caterpillar plots. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

X &lt;- scale(spider$x)
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    lv.control = list(num.lv = 2), mcmc.control = example_mcmc_control, 
    model.name = testpath)


## Do separate line plots for all the coefficients of X
par(mfrow=c(2,3), mar = c(5,6,1,1))
sapply(colnames(spiderfit_nb$X), coefsplot, 
    spiderfit_nb)
    
        
## Consider a model based on Example 5a in the main boral help file
## The model is fitted to count data, no site effects, two latent variables, 
## plus traits included to explain environmental responses
data(antTraits)
y &lt;- antTraits$abun
X &lt;- as.matrix(scale(antTraits$env))
## Include only traits 1, 2, and 5
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
    example_which_traits[[i]] &lt;- 1:ncol(traits)
## Just for fun, the regression coefficients for the second column of X,
## corresponding to the third element in the list example_which_traits,
## will be estimated separately and not regressed against traits.
example_which_traits[[3]] &lt;- 0

fit_traits &lt;- boral(y, X = X, traits = traits, 
                    which.traits = example_which_traits, family = "negative.binomial", 
                    mcmc.control = example_mcmc_control, model.name = testpath,
                    save.model = TRUE)

summary(fit_traits)

par(mar = c(3,10,2,10))
coefsplot(object = fit_traits, fourthcorner = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='create.life'>
<a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
Simulate a Multivariate response matrix</h2><span id='topic+create.life'></span><span id='topic+simulate.boral'></span>

<h3>Description</h3>

<p>Simulate a multivariate response matrix, given parameters such as but not necessarily all of: family, number of latent variables and related coefficients, an matrix of explanatory variables and related coefficients, row effects, response-specific random intercepts, cutoffs for cumulative probit regression of ordinal responses, and so on.</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
create.life(true.lv = NULL, lv.coefs, 
     lv.control = list(num.lv = 0, type = "independent", 
     lv.covparams = NULL, distmat = NULL),
     X = NULL, X.coefs = NULL, 
     traits = NULL, traits.coefs = NULL, family, 
     row.eff = "none", row.params = NULL, row.ids = NULL, 
     true.ranef = NULL, ranef.params = NULL, ranef.ids = NULL, 
     offset = NULL, trial.size = 1, cutoffs = NULL, powerparam = NULL, 
     manual.dim = NULL, save.params = FALSE)

     
## S3 method for class 'boral'
simulate(object, nsim = 1, seed = NULL, new.lvs = FALSE, new.ranefs = FALSE, 
     distmat = NULL, est = "median", ...)   
 </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.life_+3A_object">object</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="create.life_+3A_nsim">nsim</code></td>
<td>
<p>Number of multivariate response matrices to simulate. Defaults to 1.</p>
</td></tr>
<tr><td><code id="create.life_+3A_seed">seed</code></td>
<td>
<p>Seed for dataset simulation. Defaults to <code>NULL</code>, in which case no seed is set.</p>
</td></tr>
<tr><td><code id="create.life_+3A_new.lvs">new.lvs</code></td>
<td>
<p>If <code>FALSE</code>, then true latent variables are obtained from <code>object</code>. If <code>TRUE</code>, then new true latent variables are generated.</p>
</td></tr>
<tr><td><code id="create.life_+3A_new.ranefs">new.ranefs</code></td>
<td>
<p>If <code>FALSE</code>, then true response-specific random intercepts are obtained from <code>object</code>. If <code>TRUE</code>, then new random intercepts are generated.</p>
</td></tr>
<tr><td><code id="create.life_+3A_distmat">distmat</code></td>
<td>
<p>A distance matrix required to calculate correlations across sites when a non-independent correlation structure on the latent variables is imposed, when <code>new.lvs = TRUE</code> and <code>object$lv.type != "independent"</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then treated as estimates and the fitted values are calculated from. Default is posterior median.</p>
</td></tr>
<tr><td><code id="create.life_+3A_true.lv">true.lv</code></td>
<td>
<p>A matrix of true latent variables. With multivariate abundance data in ecology for instance, each row corresponds to the true site ordination coordinates. If supplied, then simulation is based of these true latent variables. If <code>NULL</code>, then the function looks to the argument <code>lv.control</code> to see what to do. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_lv.coefs">lv.coefs</code></td>
<td>
<p>A matrix containing response-specific intercepts, latent variable coefficients relating to <code>true.lv</code>, and dispersion parameters.</p>
</td></tr>
<tr><td><code id="create.life_+3A_lv.control">lv.control</code></td>
<td>
<p>This argument is utilized if <code>true.lv = NULL</code>, in which case the function uses this argument to determine how to simulate new, true latent variables. A list (currently) with the following arguments:
</p>

<ul>
<li> <p><em>num.lv:</em> which specifies the number of true latent variables to generate. Defaults to 0.
</p>
</li>
<li> <p><em>type:</em> which specifies the type the correlation structure of the latent variables (across sites). Defaults to independence correlation structure.
</p>
</li>
<li> <p><em>lv.covparams:</em> which is a vector containing one or two elements required if parameterizing a non-independence spatial correlation structure of the latent variables.
</p>
</li>
<li> <p><em>distmat:</em> which a distance matrix required to calculate correlations across sites when a non-independence correlation structure on the latent variables is imposed. 
</p>
</li></ul>

<p>Please see <code><a href="#topic+about.lvs">about.lvs</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="create.life_+3A_x">X</code></td>
<td>
<p>A model matrix of covariates (otherwise known as the covariate matrix), which can be included as part of the data generation. Defaults to <code>NULL</code>, in which case no model matrix is used. No intercept column should be included.</p>
</td></tr>  
<tr><td><code id="create.life_+3A_x.coefs">X.coefs</code></td>
<td>
<p>The coefficients relating to the covariate matrix. Defaults to <code>NULL</code>. This argument needs to be supplied if the covariate matrix is supplied and no trait matrix is supplied.</p>
</td></tr>
<tr><td><code id="create.life_+3A_traits">traits</code></td>
<td>
<p>A model matrix of species traits (otherwise known as the covariate matrix), which can be included as part of the model. Defaults to <code>NULL</code>, in which case no matrix was used. No intercept column should be included in the trait matrix, as it is included automatically.</p>
</td></tr>  
<tr><td><code id="create.life_+3A_traits.coefs">traits.coefs</code></td>
<td>
<p>A matrix of coefficients that are used to generate &quot;new&quot; response-specific intercepts and <code>X.coefs</code>. The number of rows should equal to (<code>ncol(X)+1</code>) and the number of columns should equal to (<code>ncol(traits)</code>+2). 
</p>
<p>How this argument works is as follows: when both <code>traits</code> and <code>traits.coefs</code> are supplied, then new response-specific intercepts (i.e. the first column of <code>lv.coefs</code> is overwritten) are generated by simulating from a normal distribution with mean equal to <br /> <code>crossprod(c(1,traits), traits.coefs[1,1:(ncol(traits.coefs)-1)])</code> and standard deviation <br /> <code>traits.coefs[1,ncol(traits.coefs)]</code>. In other words, the last column of <code>trait.coefs</code> provides the standard deviation of the normal distribution, with the other columns being the regression coefficients in the mean of the normal distribution. Analogously, new <code>X.coefs</code> are generated in the same manner using the remaining rows of <code>trait.coefs</code>. Please see <code><a href="#topic+about.traits">about.traits</a></code> for more information.
</p>
<p>It is important that highlight then with in this data generation mechanism, the new response-specific intercepts and <code>X.coefs</code> are now random effects, being drawn from a normal distribution. 
</p>
<p>Defaults to <code>NULL</code>, in conjuction with <code>traits = NULL</code>.</p>
</td></tr>  
<tr><td><code id="create.life_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression), &quot;ztpoisson&quot; (zero truncated Poisson with log link), &quot;ztnegative.binomial&quot; (zero truncated negative binomial with log link). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="create.life_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and standard deviation given by <code>row.params</code>. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="create.life_+3A_row.params">row.params</code></td>
<td>
<p>Parameters corresponding to the row effects. If <br /> <code>row.eff = "fixed"</code>, then these are the fixed effects and should have length equal to the number of columns in the response matrix. If <code>row.eff = "random"</code>, then this is the standard deviation for the random effects normal distribution. <br /> If <code>row.eff = "none"</code>, then this argument is ignored.</p>
</td></tr>
<tr><td><code id="create.life_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, so that if <code>row.params = NULL</code> then the argument is ignored, otherwise if <code>row.params</code> is supplied then <br />  <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row.</p>
</td></tr>
<tr><td><code id="create.life_+3A_true.ranef">true.ranef</code></td>
<td>
<p>A list of true response-specific random intercepts. If supplied, it should be a list of length <code>length(ranef.ids)</code>, where the k-th element is the matrix a matrix where the number of rows is equal to the number of responses, and the number of columns is equal to <code>length(unique(ranef.ids[,k]))</code>. If <code>NULL</code>, then the function looks to the arguments <code>ranef.ids</code> and/or <code>ranef.params</code> to see what to do. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_ranef.params">ranef.params</code></td>
<td>
<p>Parameters corresponding to standard deviation for the the response-specific random intercepts distribution. If supplied, it should be a matrix, where the number of rows is equal to the number of responses, and the number of columns equal to <code>length(ranef.ids)</code>. If <code>NULL</code>, then the function looks to the arguments <code>ranef.ids</code> and/or <code>true.ranef</code> to see what to do. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_ranef.ids">ranef.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of random intercepts to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>; please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for details. Defaults to <code>NULL</code>, in which case it is assumed no random intercepts are to be included in the model. If supplied, then either one of <code>true.ranef</code> or <code>ranef.params</code> must also be supplied. If <code>true.ranef</code> is supplied, then these are used as the true random intercepts; if <code>ranef.params</code> is supplied, then response-specific random intercepts are generated from a normal distribution with mean zero and (response-specific) standard deviation based on the elements of <code>ranef.params</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="create.life_+3A_cutoffs">cutoffs</code></td>
<td>
<p>A vector of common common cutoffs for proportional odds regression when any of <code>family</code> is ordinal. They should be increasing order. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_powerparam">powerparam</code></td>
<td>
<p>A common power parameter for tweedie regression when any of <code>family</code> is tweedie. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_manual.dim">manual.dim</code></td>
<td>
<p>A vector of length 2, containing the number of rows (<code class="reqn">n</code>) and columns (<code class="reqn">p</code>) for the multivariate response matrix. This is a &quot;backup&quot; argument only required when <code>create.life</code> can not determine how many rows or columns the multivariate response matrix should be.</p>
</td></tr>
<tr><td><code id="create.life_+3A_save.params">save.params</code></td>
<td>
<p>If <code>save.params = TRUE</code>, then all parameters provided as input and/or generated are returned, in addition to the simulated multivariate response matrix. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="create.life_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>create.life</code> gives the user flexibility to control the true parameters of the model from which the multivariate responses matrices are generated from. For example, if <code>true.lv</code> is supplied, then the data generation mechanism is based on this set of true latent variables. If <code>true.lv = NULL</code>, then the function looks to <code>lv.control</code> to determine whether and how the true latent variables are to be simulated. 
</p>
<p><code>simulate</code> makes use of the generic function of the same name in <code>R</code>: it takes a fitted model, treats either the posterior medians and mean estimates from the model as the true parameters, and generates response matrices based off that. There is control as to whether the latent variables and/or response-specific random intercepts obtained from the fitted model are used, or new ones are generated.
</p>


<h3>Value</h3>

<p>If <code>create.life</code> is used, then: 1) if <code>save.params</code> = FALSE, a <code class="reqn">n</code> by <code class="reqn">p</code> multivariate response matrix is returned only, 2) if <code>save.params = TRUE</code>, then a list containing the element <code>resp</code> which is a <code class="reqn">n</code> times <code class="reqn">p</code> multivariate response matrix, as well as other elements for the parameters used in the true model are returned.
</p>
<p>If <code>simulate</code> is used, then a three dimensional array of dimension <code class="reqn">n</code> by <code class="reqn">p</code> by <code>nsim</code> is returned. The same latent variables can be used each time (<code>new.lvs = FALSE</code>), or new true latent variables can be generated each time (<code>new.lvs = TRUE</code>).
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the default function for model fitting. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


## Example 1a - Simulate a response matrix of normally distributed data
library(mvtnorm)

## 30 rows (sites) with two latent variables 
true_lv &lt;- rbind(rmvnorm(n=15,mean=c(1,2)),rmvnorm(n=15,mean=c(-3,-1))) 
## 30 columns (species)
true_lv_coefs &lt;- cbind(matrix(runif(30*3),30,3),1)

X &lt;- matrix(rnorm(30*4),30,4) 
## 4 explanatory variables
X.coefs &lt;- matrix(rnorm(30*4),30,4)

simy &lt;- create.life(true.lv = true_lv, lv.coefs = true_lv_coefs, 
    X = X, X.coefs = X.coefs, family = "normal")

## Not run: 
fit_simdata &lt;- boral(simy, X = X, family = "normal", lv.control = list(num.lv = 2),
    mcmc.control = example_mcmc_control, model.name = testpath)

summary(fit_simdata)

## End(Not run)

## Example 1b - Include a nested random row effect
## 30 subregions nested within six regions
example_row_ids &lt;- cbind(1:30, rep(1:6,each=5))
## Subregion has a small std deviation; region has a larger one
true_ranef_sigma &lt;- list(ID1 = 0.5, ID2 = 2)

simy &lt;- create.life(true.lv = true_lv, lv.coefs = true_lv_coefs, 
    X = X, X.coefs = X.coefs, row.eff = "random",
    row.params = true_ranef_sigma, row.ids = example_row_ids, family = "normal",
    save.params = TRUE)
	
	
## Example 1c - Same as example 1b except new, true latent variables are generated
simy &lt;- create.life(true.lv = NULL, lv.coefs = true_lv_coefs, 
    X = X, X.coefs = X.coefs, row.eff = "random",
    row.params = true_ranef_sigma, row.ids = example_row_ids, family = "normal",
    save.params = TRUE)

    
## Example 1d - Same as example 1a except new, true latent variables are generated
##   with a non-independent correlation structure using a fake distance matrix
makedistmat &lt;- as.matrix(dist(1:30))
simy &lt;- create.life(true.lv = NULL, lv.coefs = true_lv_coefs, 
    lv.control = list(num.lv = 2, type = "exponential", lv.covparams = 5, 
          distmat = makedistmat),
    X = X, X.coefs = X.coefs, row.eff = "random",
    row.params = true_ranef_sigma, row.ids = example_row_ids, family = "normal",
    save.params = TRUE)
    
    
## Example 1e - Similar to 1b, except instead of a nested random row effect,
## it includes a species-specific random interept at the region level
example_ranef_ids &lt;- data.frame(region = rep(1:6,each=5))
## Subregion has a small std deviation; region has a larger one
true_ranef_sigma &lt;- matrix(runif(nrow(true_lv_coefs)), 
     nrow = nrow(true_lv_coefs), ncol = 1)

simy &lt;- create.life(true.lv = true_lv, lv.coefs = true_lv_coefs, 
    X = X, X.coefs = X.coefs, ranef.ids = example_ranef_ids,
    ranef.params = true_ranef_sigma, family = "normal",
    save.params = TRUE)

        
## Example 2 - Simulate a response matrix of ordinal data
## 30 rows (sites) with two latent variables 
true_lv &lt;- rbind(rmvnorm(15,mean=c(-2,-2)),rmvnorm(15,mean=c(2,2)))
## 10 columns (species)
true_lv_coefs &lt;- rmvnorm(10,mean = rep(0,3)); 
## Cutoffs for proportional odds regression (must be in increasing order)
true.ordinal.cutoffs &lt;- seq(-2,10,length=10-1)

simy &lt;- create.life(true.lv = true_lv, lv.coefs = true_lv_coefs, 
     family = "ordinal", cutoffs = true.ordinal.cutoffs, save.params = TRUE) 

## Not run: 
fit_simdata &lt;- boral(y = simy$resp, family = "ordinal", lv.control = list(num.lv = 2),
      mcmc.control = example_mcmc_control, model.name = testpath)

## End(Not run)

## Not run: 
## Example 3 - Simulate a response matrix of count data based off
## a fitted model involving traits (ants data from mvabund)
library(mvabund)
data(antTraits)

y &lt;- antTraits$abun
X &lt;- as.matrix(antTraits$env)
## Include only traits 1, 2, and 5, plus an intercept
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
## Please see help file for boral regarding the use of which.traits
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)

fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", lv.control = list(num.lv = 2),
     mcmc.control = example_mcmc_control, model.name = testpath)

## The hard way
simy &lt;- create.life(true.lv = fit_traits$lv.mean, 
     lv.coefs = fit_traits$lv.coefs.median, X = X, 
     X.coefs = fit_traits$X.coefs.median, traits = traits, 
     traits.coefs = fit_traits$traits.coefs.median, family = "negative.binomial")

## The easy way, using the same latent variables as the fitted model
simy &lt;- simulate(object = fit_traits)

## The easy way, generating new latent variables
simy &lt;- simulate(object = fit_traits, new.lvs = TRUE)


## Example 4 - simulate Bernoulli data, based on a model with two latent variables, 
## no site variables, with two traits and one environmental covariates 
## This example is a proof of concept that traits can used 
## to explain environmental responses 
library(mvtnorm)

n &lt;- 100; s &lt;- 50
X &lt;- as.matrix(scale(1:n))
colnames(X) &lt;- c("elevation")

traits &lt;- cbind(rbinom(s,1,0.5), rnorm(s)) 
## one categorical and one continuous variable
colnames(traits) &lt;- c("thorns-dummy","SLA")

simfit &lt;- list(lv.coefs = cbind(rnorm(s), rmvnorm(s, mean = rep(0,2))), 
     lv.control = list(num.lv = 2, type = "independent"),
    traits.coefs = matrix(c(0.1,1,-0.5,1,0.5,0,-1,1), 2, byrow = TRUE))
rownames(simfit$traits.coefs) &lt;- c("beta0","elevation")
colnames(simfit$traits.coefs) &lt;- c("kappa0","thorns-dummy","SLA","sigma")

simy &lt;- create.life(lv.control = simfit$lv.control, lv.coefs = simfit$lv.coefs, 
    X = X, traits = traits, traits.coefs = simfit$traits.coefs, 
    family = "binomial") 


example_which_traits &lt;- vector("list",ncol(X)+1); 
for(i in 1:length(example_which_traits)) 
    example_which_traits[[i]] &lt;- 1:ncol(traits)
fit_traits &lt;- boral(y = simy, X = X, traits = traits, 
    which.traits = example_which_traits, family = "binomial", 
    lv.control = list(num.lv = 2), save.model = TRUE, 
    mcmc.control = example_mcmc_control, model.name = testpath)


## Example 5 -- extend Example 2e in the main boral help file to simulate data from a 
##   fitted model
library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)

spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath) 

simulate(object = spiderfit_nb)

simulate(object = spiderfit_nb, new.ranefs = TRUE)   

## End(Not run)
</code></pre>

<hr>
<h2 id='ds.residuals'>Dunn-Smyth Residuals for a fitted model</h2><span id='topic+ds.residuals'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Calculates the Dunn-Smyth residuals for a fitted model and, if some of the responses are ordinal, a confusion matrix between predicted and true levels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds.residuals(object, est = "median", include.ranef = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds.residuals_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="ds.residuals_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then treated as parameter estimates and the residuals are calculated from. Default is posterior median.</p>
</td></tr>
<tr><td><code id="ds.residuals_+3A_include.ranef">include.ranef</code></td>
<td>
<p>If response-specific random intercepts were included as part of the fitted model, then this determines whether the predicted random effects will be used in the calculated of the fitted values and thus residuals. When set to <code>TRUE</code>, which is the default, then they are included (using either the posterior mean and posterior median predictor). When set to <code>FALSE</code>, they are not included. The former leads to what are sometimes called conditional residuals, while the latter are sometimes called marginal residuals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details regarding Dunn-Smyth residuals, based on the randomized quantile residuals of Dunn and Smyth (1996), can be found in <code>plot.manyglm</code> function in the <code>mvabund</code> package (Wang et al., 2012) where they are implemented in all their glory. Due their inherent stochasticity, Dunn-Smyth residuals will be slightly different each time this function is run. As with other types of residuals, Dunn-Smyth residuals can be used in the context of residual analysis. 
</p>
<p>For ordinal responses, a single confusion matrix between the predicted levels (as based on the class with the highest probability) and true levels is aso returned. The table pools the results over all columns assumed to be ordinal.
</p>
<p>The Dunn-Smyth residuals are calculated based on a point estimate of the parameters, as determined by the argument <code>est</code>. A fully Bayesian approach would calculate the residuals by averaging over the posterior distribution of the parameters i.e., ergodically average over the MCMC samples. In general however, the results (as in the trends seen in residual analysis) from either approach should be very similar.
</p>
<p>Check out also the awesome <code>DHARMa</code> package for calculation of Dunn-Smyth and probability integral transform residuals in other regression models.
</p>


<h3>Value</h3>

<p>A list containing <code>agree.ordinal</code> which is a single confusion matrix for ordinal columns, and <code>residuals</code> which contains Dunn-Smyth residuals.
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Dunn, P. K., and Smyth, G. K. (1996). Randomized quantile residuals. Journal of Computational and Graphical Statistics, 5, 236-244.
</p>
</li>
<li><p> Wang et al. (2012). mvabund-an R package for model-based analysis of multivariate abundance data. Methods in Ecology and Evolution, 3, 471-474.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.boral">plot.boral</a></code> for constructing residual analysis plots directly; <code><a href="#topic+fitted.boral">fitted.boral</a></code> which calculated fitted values from a model.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun

spiderfit_nb &lt;- boral(y, family = "negative.binomial", lv.control = list(num.lv = 2),
     row.eff = "fixed", mcmc.control = example_mcmc_control, model.name = testpath)

ds.residuals(spiderfit_nb) 

## End(Not run)
</code></pre>

<hr>
<h2 id='fitted.boral'>Extract Model Fitted Values for an boral object</h2><span id='topic+fitted.boral'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Calculated the fitted values based on the response or linear predictor scale, by using the posterior medians or means of the parameters.</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
## S3 method for class 'boral'
fitted(object, est = "median", include.ranef = TRUE, linear.predictor = FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.boral_+3A_object">object</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="fitted.boral_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then treated as estimates and the fitted values are calculated from. Default is posterior median.</p>
</td></tr>
<tr><td><code id="fitted.boral_+3A_include.ranef">include.ranef</code></td>
<td>
<p>If response-specific random intercepts were included as part of the fitted model, then this determines whether the predicted random effects will be included in the fitted values. When set to <code>TRUE</code>, which is the default, then they are included (using either the posterior mean and posterior median predictor). When set to <code>FALSE</code>, they are not included. The former are sometimes called conditional fitted values, while the latter are sometimes called marginal fitted values.</p>
</td></tr>
<tr><td><code id="fitted.boral_+3A_linear.predictor">linear.predictor</code></td>
<td>
<p>Determines the scale on which to return the fitted values. When set to <code>TRUE</code>, it returns the fitted values on the linear predictor scale. When set to <code>FALSE</code>, which is the defaul behavior, the fitted values are on the response scale. Note things are slightly more complicated for zero truncated distributions because, the log-link connects the mean of the <em>untruncated</em> distribution to the linear predictor. Therefore if <code>linear.predictor = TRUE</code>, then the linear predictor is returned. But if <code>linear.predictor = FALSE</code>, then actual mean value is returned.</p>
</td></tr>
<tr><td><code id="fitted.boral_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This fitted values here are calculated based on a point estimate of the parameters, as determined by the argument <code>est</code>. A fully Bayesian approach would calculate the fitted values by averaging over the posterior distribution of the parameters i.e., ergodically average over the MCMC samples. For simplicity and speed though (to avoid generation of a large number of predicted values), this is not implemented.
</p>


<h3>Value</h3>

<p>A list containing <code>ordinal.probs</code> which is an array with dimensions (number of rows of the response matrix) x (number of columns of the response matrix) x (no. of levels) containing the predicted probabilities for ordinal columns, and <code>out</code> which is a matrix of the same dimension as the original response matrix containing the fitted values. For ordinal columns, the &quot;fitted values&quot; are defined as the level/class that had the highest fitted probability. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.boral">plot.boral</a></code> which uses the fitted values calculated from this function to construct plots for residual analysis,
<code><a href="#topic+ds.residuals">ds.residuals</a></code> for calculating the Dunn-Smyth residuals for a fitted model. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun

spiderfit_nb &lt;- boral(y, family = "negative.binomial", lv.control = list(num.lv = 2),
     row.eff = "fixed", mcmc.control = example_mcmc_control, model.name = testpath)

fitted(spiderfit_nb)

## End(Not run)
</code></pre>

<hr>
<h2 id='get.dic'>Extract Deviance Information Criterion for a fitted model</h2><span id='topic+get.dic'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#defunct"><img src="../help/figures/lifecycle-defunct.svg" alt='[Defunct]' /></a>
</p>
<p>Calculates the Deviance Information Criterion (DIC) for a model fitted using JAGS. WARNING: As of version 1.6, this function is no longer maintained (and probably doesn't work properly, if at all)!</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.dic(jagsfit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.dic_+3A_jagsfit">jagsfit</code></td>
<td>
<p>The <code>jags.model</code> component of the output, from a model fitted using <code>boral</code> with <code>save.model = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details regarding the Deviance Information Criterion may be found in (Spiegelhalter et al., 2002; Ntzoufras, 2011; Gelman et al., 2013). The DIC here is based on the conditional log-likelihood i.e., the latent variables (and row effects if applicable) are treated as &quot;fixed effects&quot;. A DIC based on the marginal likelihood is obtainable from <code><a href="#topic+get.more.measures">get.more.measures</a></code>, although this requires a much longer time to compute. For models with overdispered count data, conditional DIC may not perform as well as marginal DIC (Millar, 2009)
</p>


<h3>Value</h3>

<p>DIC value for the jags model.
</p>


<h3>Note</h3>

<p>This function and consequently the DIC value is automatically returned when a model is fitted using <code><a href="#topic+boral">boral</a></code> with <code>calc.ics = TRUE</code>. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Gelman et al. (2013). Bayesian data analysis. CRC press.
</p>
</li>
<li><p> Millar, R. B. (2009). Comparison of hierarchical Bayesian models for overdispersed count data using DIC and Bayes' factors. Biometrics, 65, 962-969.
</p>
</li>
<li><p> Ntzoufras, I. (2011). Bayesian modeling using WinBUGS (Vol. 698). John Wiley &amp; Sons.
</p>
</li>
<li><p> Spiegelhalter et al. (2002). Bayesian measures of model complexity and fit. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64, 583-639.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)
    
spiderfit_nb &lt;- boral(y, family = "negative.binomial", lv.control = list(num.lv = 2),
     save.model = TRUE, calc.ics = TRUE, mcmc.control = example_mcmc_control,
     model.name = testpath)

spiderfit_nb$ics ## DIC returned as one of several information criteria.

## End(Not run)
</code></pre>

<hr>
<h2 id='get.enviro.cor'>Extract covariances and correlations due to shared environmental responses</h2><span id='topic+get.enviro.cor'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Calculates the correlation between columns of the response matrix, due to similarities in the response to explanatory variables i.e., shared environmental response.</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.enviro.cor(object, est = "median", prob = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.enviro.cor_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="get.enviro.cor_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then treated as estimates and the fitted values are calculated from. Default is posterior median.</p>
</td></tr>
<tr><td><code id="get.enviro.cor_+3A_prob">prob</code></td>
<td>
<p>A numeric scalar in the interval (0,1) giving the target probability coverage of the intervals, by which to determine whether the correlations are &quot;significant&quot;. Defaults to 0.95.</p>
</td></tr>   
</table>


<h3>Details</h3>

<p>In both independent response and correlated response models, where the each of the columns of the response matrix <code class="reqn">\bm{Y}</code> are fitted to a set of covariates, the covariance and thus between two columns <code class="reqn">j</code> and <code class="reqn">j'</code> due to similarities in their response to the model matrix is calculated based on the linear predictors <code class="reqn">\bm{x}^\top_i\bm{\beta}_j</code> and <code class="reqn">\bm{x}^\top_i\bm{\beta}_{j'})</code>, where <code class="reqn">\bm{\beta}_j</code> are response-specific coefficients relating to the explanatory variables. 
</p>
<p>For multivariate abundance data, the correlation calculated by this function can be interpreted as the correlation attributable to similarities in the environmental response between species. Such correlation matrices are discussed and found in Ovaskainen et al., (2010), Pollock et al., 2014.
</p>
<p>Please note this correlation calculation does not include any row effects or any response-specific random intercepts.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>cor</code>, <code>cor.lower</code>, <code>cor.upper</code></td>
<td>
<p>A set of <code class="reqn">p \times p</code> correlation matrices, containing either the posterior median or mean estimate plus lower and upper limits of the corresponding (100<code class="reqn">\times</code><code>prob</code>) % HPD interval.</p>
</td></tr>
<tr><td><code>sig.cor</code></td>
<td>
<p>A <code class="reqn">p \times p</code> correlation matrix containing only the &ldquo;significant&quot; correlations whose (100<code class="reqn">\times</code><code>prob</code>) % HPD interval does not contain zero. All non-significant correlations are set to zero.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>A <code class="reqn">p \times p</code> covariance matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Ovaskainen et al. (2010). Modeling species co-occurrence by multivariate logistic regression generates new hypotheses on fungal interactions. Ecology, 91, 2514-2521.
</p>
</li>
<li><p> Pollock et al. (2014). Understanding co-occurrence by modelling species simultaneously with a Joint Species Distribution Model (JSDM). Methods in Ecology and Evolution, 5, 397-406.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+get.residual.cor">get.residual.cor</a></code>, which calculates the residual correlation matrix for models involving latent variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
library(corrplot) ## For plotting correlations
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)
    
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
     save.model = TRUE, mcmc.control = example_mcmc_control,
     model.name = testpath)

enviro.cors &lt;- get.enviro.cor(spiderfit_nb)

corrplot(enviro.cors$sig.cor, title = "Shared response correlations", 
	type = "lower", diag = FALSE, mar = c(3,0.5,2,1), tl.srt = 45)

## End(Not run)
</code></pre>

<hr>
<h2 id='get.hpdintervals'>Highest posterior density intervals for a fitted model</h2><span id='topic+get.hpdintervals'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Calculates the lower and upper bounds of the highest posterior density intervals for parameters and latent variables in a fitted model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.hpdintervals(y, X = NULL, traits = NULL, row.ids = NULL, ranef.ids = NULL, 
	fit.mcmc, lv.control, prob = 0.95, num.lv = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.hpdintervals_+3A_y">y</code></td>
<td>
<p>The response matrix that the model was fitted to.</p>
</td></tr>
<tr><td><code id="get.hpdintervals_+3A_x">X</code></td>
<td>
<p>The covariate matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no model matrix was used.</p>
</td></tr>  
<tr><td><code id="get.hpdintervals_+3A_traits">traits</code></td>
<td>
<p>The trait matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no traits were included.</p>
</td></tr>  
<tr><td><code id="get.hpdintervals_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, in which case iti assumed no random effects were included in the model.</p>
</td></tr>
<tr><td><code id="get.hpdintervals_+3A_ranef.ids">ranef.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of random intercepts to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>; please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for details. Defaults to <code>NULL</code>, in which case it is assumed no random intercepts are to be included in the model. If supplied, then response-specific random intercepts are assumed to come from a normal distribution with mean zero and unknown (response-specific) standard deviation.</p>
</td></tr>
<tr><td><code id="get.hpdintervals_+3A_fit.mcmc">fit.mcmc</code></td>
<td>
<p>All MCMC samples for the fitted model. These can be extracted by fitting a model using <code>boral</code> with <code>save.model = TRUE</code>, and then applying <code>get.mcmcsamples(fit)</code>.</p>
</td></tr> 
<tr><td><code id="get.hpdintervals_+3A_lv.control">lv.control</code></td>
<td>
<p>A list (currently) with the following arguments:
</p>

<ul>
<li> <p><em>num.lv:</em> which specifies the number of true latent variables to generate. Defaults to 0.
</p>
</li>
<li> <p><em>type:</em> which specifies the type the correlation structure of the latent variables (across sites). Defaults to independence correlation structure.
</p>
</li>
<li> <p><em>distmat:</em> which a distance matrix required to calculate correlations across sites when a non-independence correlation structure on the latent variables is imposed. 
</p>
</li></ul>

<p>Please see <code><a href="#topic+about.lvs">about.lvs</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="get.hpdintervals_+3A_prob">prob</code></td>
<td>
<p>A numeric scalar in the interval (0,1) giving the target probability coverage of the intervals. Defaults to 0.95.</p>
</td></tr>   
<tr><td><code id="get.hpdintervals_+3A_num.lv">num.lv</code></td>
<td>
<p>Old argument superceded by <code>lv.control</code>. Defaults to <code>NULL</code> and ignored.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function uses the <code>HPDinterval</code> function from the <code>coda</code> package to obtain the HPD intervals. See <code>HPDinterval</code> for details regarding the definition of the HPD interval. For interpreting the results, please check the dimension names of each of the components below to better ascertain what is being printed.
</p>


<h3>Value</h3>

<p>A list containing the following components, where applicable:
</p>
<table>
<tr><td><code>lv.coefs</code></td>
<td>
<p>An array giving the lower and upper bounds of the HPD intervals for the response-specific intercepts, latent variable coefficients, and dispersion parameters if appropriate.</p>
</td></tr>
<tr><td><code>lv</code></td>
<td>
<p>An array giving the and upper bounds of the HPD intervals for the latent variables.</p>
</td></tr>
<tr><td><code>lv.covparams</code></td>
<td>
<p>A matrix giving the lower and upper bounds of the HPD intervals for the parameters characterizing the correlation structure of the latent variables when they are assumed to be non-independent across rows.</p>
</td></tr>
<tr><td><code>row.coefs</code></td>
<td>
<p>A list with each element being a matrix giving the lower and upper bounds of the HPD intervals for row effects. The number of elements in the list should equal the number of row effects included in the model i.e., <code>ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>row.sigma</code></td>
<td>
<p>A list with each element being a vector giving the lower and upper bounds of the HPD interval for the standard deviation of the normal distribution for the row effects. The number of elements in the list should equal the number of row effects included in the model i.e., <code>ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>ranef.coefs</code></td>
<td>
<p>A list with each element being a array giving the lower and upper bounds of the HPD intervals for response-specific random intercepts. The number of elements in the list should equal the number of row effects included in the model i.e., <code>ncol(ranef.ids)</code>.</p>
</td></tr>
<tr><td><code>ranef.sigma</code></td>
<td>
<p>An array giving the lower and upper bounds of the HPD interval for the standard deviation of the normal distribution for the response-specific random intercepts. The number of elements in the list should equal the number of row effects included in the model i.e., <code>ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>X.coefs</code></td>
<td>
<p>An array giving the lower and upper bounds of the HPD intervals for coefficients relating to the covariate matrix.</p>
</td></tr>
<tr><td><code>traits.coefs</code></td>
<td>
<p>An array giving the lower and upper of the HPD intervals for coefficients and standard deviation relating to the traits matrix.</p>
</td></tr>
<tr><td><code>cutoffs</code></td>
<td>
<p>A matrix giving the lower and upper bounds of the HPD intervals for common cutoffs in proportional odds regression.</p>
</td></tr>
<tr><td><code>powerparam</code></td>
<td>
<p>A vector giving the lower and upper bounds of the HPD interval for common power parameter in tweedie regression.</p>
</td></tr>
</table>


<h3>Warnings</h3>


<ul>
<li><p> HPD intervals tend to be quite wide, and inference is somewhat tricky with them. This is made more difficult by the multiple comparison problem due to the construction one interval for each parameter!
</p>
</li>
<li><p> Be careful with interpretation of coefficients and HPD intervals if different columns of the response matrix have different distributions!
</p>
</li>
<li><p> HPD intervals for the cutoffs in proportional odds regression may be poorly estimated for levels with few data.
</p>
</li></ul>



<h3>Note</h3>

<p><code><a href="#topic+boral">boral</a></code> fits the model and returns the HPD intervals by default. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")
 
 
## Example 1 - model with two latent variables, site effects, 
## 	and no environmental covariates
spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
    lv.control = list(num.lv = 2), row.eff = "fixed", 
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$hpdintervals

## Example 2a - model with no latent variables, no site effects, 
##      and environmental covariates
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$hpdintervals

## Example 2b - suppose now, for some reason, the 28 rows were
## 	sampled such into four replications of seven sites
## Let us account for this as a fixed effect
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    row.eff = "fixed", row.ids = matrix(rep(1:7,each=4),ncol=1),
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$hpdintervals

## Example 2c - suppose now, for some reason, the 28 rows reflected
## 	a nested design with seven regions, each with four sub-regions
## We can account for this nesting as a random effect
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    row.eff = "random", 
    row.ids = cbind(1:n, rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$hpdintervals

## Example 2d - model with environmental covariates and 
##  two structured latent variables using fake distance matrix
fakedistmat &lt;- as.matrix(dist(1:n))
spiderfit_lvstruc &lt;- boral(y, X = X, family = "negative.binomial", 
    lv.control = list(num.lv = 2, type = "exponential", distmat = fakedistmat), 
     mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$hpdintervals

## Example 2e - Similar to 2d, but we will species-specific random intercepts
##   for the seven regions (with row effects in the model)
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath) 

spiderfit_nb$hpdintervals

## End(Not run)
</code></pre>

<hr>
<h2 id='get.mcmcsamples'>Extract MCMC samples from models</h2><span id='topic+get.mcmcsamples'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Extract the MCMC samples from fitted models, taking into account the burnin period and thinning.</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.mcmcsamples(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.mcmcsamples_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the function to work, the JAGS model file (containing the MCMC samples from the call to JAGS) has to have been saved when fitting the model, that is, <code>save.model = TRUE</code>. The function will throw an error if it cannot find the the JAGs model file.
</p>


<h3>Value</h3>

<p>A matrix containing the MCMC samples, with the number of rows equal to the number of MCMC samples after accounting the burnin period and thinning (i.e., number of rows = (n.iteration - n.burnin)/n.thin), and the number of columns equal to the number of parameters in the fitted model. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
library(corrplot) ## For plotting correlations
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)
    
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
     mcmc.control = example_mcmc_control, model.name = testpath, 
     save.model = TRUE)

mcmcsamps &lt;- get.mcmcsamples(spiderfit_nb)

## End(Not run)

</code></pre>

<hr>
<h2 id='get.measures'>Information Criteria for models</h2><span id='topic+get.measures'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#defunct"><img src="../help/figures/lifecycle-defunct.svg" alt='[Defunct]' /></a>
</p>
<p>Calculates some information criteria for a fitted model, which could be used for model selection. WARNING: As of version 1.6, this function is no longer maintained (and probably doesn't work properly, if at all)!</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.measures(y, X = NULL, family, trial.size = 1, row.eff = "none", 
	row.ids = NULL, offset = NULL, num.lv, fit.mcmc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.measures_+3A_y">y</code></td>
<td>
<p>The response matrix that the model was fitted to.</p>
</td></tr>
<tr><td><code id="get.measures_+3A_x">X</code></td>
<td>
<p>The covariate matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no model matrix was used.</p>
</td></tr>  
<tr><td><code id="get.measures_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression), &quot;ztpoisson&quot; (zero truncated Poisson with log link), &quot;ztnegative.binomial&quot; (zero truncated negative binomial with log link). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="get.measures_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="get.measures_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and estimated standard deviation. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="get.measures_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, so that if <code>row.eff = "none"</code> then the argument is ignored, otherwise if <br /> <code>row.eff = "fixed"</code> or <code>"random"</code>, <br /> then <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row.</p>
</td></tr>
<tr><td><code id="get.measures_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="get.measures_+3A_num.lv">num.lv</code></td>
<td>
<p>The number of latent variables used in the model.</p>
</td></tr>
<tr><td><code id="get.measures_+3A_fit.mcmc">fit.mcmc</code></td>
<td>
<p>All MCMC samples for the fitted model. These can be extracted by fitting a model using <code><a href="#topic+boral">boral</a></code> with <code>save.model = TRUE</code>, and then applying <code>get.mcmcsamples(fit)</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The following information criteria are currently calculated, when permitted: 1) Widely Applicable Information Criterion (WAIC, Watanabe, 2010) based on the conditional log-likelihood; 2) expected AIC (EAIC, Carlin and Louis, 2011); 3) expected BIC (EBIC, Carlin and Louis, 2011); 4) AIC (using the marginal likelihood) evaluated at the posterior median; 5) BIC (using the marginal likelihood) evaluated at the posterior median.
</p>
<p>1) WAIC has been argued to be more natural and extension of AIC to the Bayesian and hierarchical modeling context (Gelman et al., 2013), and is based on the conditional log-likelihood calculated at each of the MCMC samples. 
</p>
<p>2 &amp; 3) EAIC and EBIC were suggested by (Carlin and Louis, 2011). Both criteria are of the form -2*mean(conditional log-likelihood) + penalty*(no. of parameters in the model), where the mean is averaged all the MCMC samples. EAIC applies a penalty of 2, while EBIC applies a penalty of <code class="reqn">log(n)</code>.
</p>
<p>4 &amp; 5) AIC and BIC take the form -2*(marginal log-likelihood) + penalty*(no. of parameters in the model), where the log-likelihood is evaluated at the posterior median. If the parameter-wise posterior distributions are unimodal and approximately symmetric, these will produce similar results to an AIC and BIC where the log-likelihood is evaluated at the posterior mode. EAIC applies a penalty of 2, while EBIC applies a penalty of <code class="reqn">log(n)</code>.
</p>
<p>Intuitively, comparing models with and without latent variables (using information criteria such as those returned) amounts to testing whether the columns of the response matrix are correlated. With multivariate abundance data for example, where the response matrix comprises of <code class="reqn">n</code> sites and <code class="reqn">p</code> species, comparing models with and without latent variables tests whether there is any evidence of correlation between species.
</p>
<p>Please note that criteria 4 and 5 are not calculated all the time. In models where traits are included in the model (such that the regression coefficients <code class="reqn">\beta_{0j}, \bm{\beta}_j</code> are random effects), or more than two columns are ordinal responses (such that the intercepts <code class="reqn">\beta_{0j}</code> for these columns are random effects), then criteria 4 and 5 are will not calculated. This is because the calculation of the marginal log-likelihood in such cases currently fail to marginalize over such random effects; please see the details in <code>calc.logLik.lv0</code> and <code>calc.marglogLik</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>waic</code></td>
<td>
<p>WAIC based on the conditional log-likelihood.</p>
</td></tr>
<tr><td><code>eaic</code></td>
<td>
<p>EAIC based on the mean of the conditional log-likelihood.</p>
</td></tr>
<tr><td><code>ebic</code></td>
<td>
<p>EBIC based on the mean of the conditional log-likelihood.</p>
</td></tr>
<tr><td><code>all.cond.logLik</code></td>
<td>
<p>The conditional log-likelihood evaluated at all MCMC samples. This is done via repeated application of <code><a href="#topic+calc.condlogLik">calc.condlogLik</a></code>.</p>
</td></tr>
<tr><td><code>cond.num.params</code></td>
<td>
<p>Number of estimated parameters used in the fitted model, when all parameters are treated as &quot;fixed&quot; effects.</p>
</td></tr>
<tr><td><code>do.marglik.ics</code></td>
<td>
<p>A boolean indicating whether marginal log-likelihood based information criteria are calculated.</p>
</td></tr>
</table>
<p>If <code>do.marglik.ics = TRUE</code>, then we also have:
</p>
<table>
<tr><td><code>median.logLik</code></td>
<td>
<p>The marginal log-likelihood evaluated at the posterior median.</p>
</td></tr>
<tr><td><code>marg.num.params</code></td>
<td>
<p>Number of estimated parameters used in the fitted model, when all parameters are treated as &quot;fixed&quot; effects.</p>
</td></tr>
<tr><td><code>aic.median</code></td>
<td>
<p>AIC (using the marginal log-likelihood) evaluated at the posterior median.</p>
</td></tr>
<tr><td><code>bic.median</code></td>
<td>
<p>BIC (using the marginal log-likelihood) evaluated at the posterior median.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>As of version 1.6, this function is no longer maintained (and probably doesn't work properly, if at all)!
</p>
<p>Using information criterion for variable selection should be done with extreme caution, for two reasons: 1) The implementation of these criteria are both <em>heuristic</em> and experimental. 2) Deciding what model to fit for ordination purposes should be driven by the science. For example, it may be the case that a criterion suggests a model with 3 or 4 latent variables. However, if we interested in visualizing the data for ordination purposes, then models with 1 or 2 latent variables are far more appropriate. As an another example, whether or not we include row effects when ordinating multivariate abundance data depends on if we are interested in differences between sites in terms of relative species abundance (<code>row.eff = FALSE</code>) or in terms of species composition (<code>row.eff = "fixed"</code>).  
</p>
<p>Also, the use of information criterion in the presence of variable selection using SSVS is questionable.
</p>


<h3>Note</h3>

<p>When a model is fitted using <code><a href="#topic+boral">boral</a></code> with <code>calc.ics = TRUE</code>, then this function is applied and the information criteria are returned as part of the model output. 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Carlin, B. P., and Louis, T. A. (2011). Bayesian methods for data analysis. CRC Press.
</p>
</li>
<li><p> Gelman et al. (2013). Understanding predictive information criteria for Bayesian models. Statistics and Computing, 1-20.
</p>
</li>
<li><p> Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. The Journal of Machine Learning Research, 11, 3571-3594.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+get.dic">get.dic</a></code> for calculating the Deviance Information Criterion (DIC) based on the conditional log-likelihood; <code><a href="#topic+get.more.measures">get.more.measures</a></code> for even more information criteria.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

spiderfit_pois &lt;- boral(y, family = "poisson", 
    lv.control = list(num.lv = 2), row.eff = "random",
    mcmc.control = example_mcmc_control)

spiderfit_pois$ics ## Returns information criteria

spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
    lv.control = list(num.lv = 2), row.eff = "random",
    mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb$ics ## Returns the information criteria 

## End(Not run)
</code></pre>

<hr>
<h2 id='get.more.measures'>Additional Information Criteria for models</h2><span id='topic+get.more.measures'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#defunct"><img src="../help/figures/lifecycle-defunct.svg" alt='[Defunct]' /></a>
</p>
<p>Calculates some information criteria beyond those from <code><a href="#topic+get.measures">get.measures</a></code> for a fitted model, although this set of criteria takes much longer to compute! WARNING: As of version 1.6, this function is no longer maintained (and probably doesn't work properly, if at all)!</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.more.measures(y, X = NULL, family, trial.size = 1, 
	row.eff = "none", row.ids = NULL, offset = NULL,
	num.lv, fit.mcmc, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.more.measures_+3A_y">y</code></td>
<td>
<p>The response matrix that the model was fitted to.</p>
</td></tr>
<tr><td><code id="get.more.measures_+3A_x">X</code></td>
<td>
<p>The covariate matrix used in the model. Defaults to <code>NULL</code>, in which case it is assumed no model matrix was used.</p>
</td></tr>  
<tr><td><code id="get.more.measures_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression), &quot;ztpoisson&quot; (zero truncated Poisson with log link), &quot;ztnegative.binomial&quot; (zero truncated negative binomial with log link). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="get.more.measures_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="get.more.measures_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and estimated standard deviation. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="get.more.measures_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, so that if <code>row.eff = "none"</code> then the argument is ignored, otherwise if <br /> <code>row.eff = "fixed"</code> or <code>"random"</code>, <br /> then <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row.</p>
</td></tr>
<tr><td><code id="get.more.measures_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="get.more.measures_+3A_num.lv">num.lv</code></td>
<td>
<p>The number of latent variables used in the fitted model.</p>
</td></tr>
<tr><td><code id="get.more.measures_+3A_fit.mcmc">fit.mcmc</code></td>
<td>
<p>All MCMC samples for the fitted model. These can be extracted by fitting a model using <code><a href="#topic+boral">boral</a></code> with <code>save.model = TRUE</code>, and then applying <code>get.mcmcsamples(fit)</code>.</p>
</td></tr> 
<tr><td><code id="get.more.measures_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, a notice is printed every 100 samples indicating progress in calculation of the marginal log-likelihood. Defaults to <code>TRUE</code>.</p>
</td></tr>    
</table>


<h3>Details</h3>

<p>Currently, four information criteria are calculated using this function, when permitted: 1) AIC (using the marginal likelihood) evaluated at the posterior mode; 2) BIC (using the marginal likelihood) evaluated at the posterior mode; 3) Deviance information criterion (DIC) based on the marginal log-likelihood; 4) Widely Applicable Information Criterion (WAIC, Watanabe, 2010) based on the marginal log-likelihood. When uninformative priors are used in fitting models, then the posterior mode should be approximately equal to the maximum likelihood estimates.
</p>
<p>All four criteria require computing the marginal log-likelihood across all MCMC samples. This takes a very long time to run, since Monte Carlo integration needs to be performed for all MCMC samples. Consequently, this function is currently not implemented as an argument in main <code><a href="#topic+boral">boral</a></code> fitting function, unlike <code><a href="#topic+get.measures">get.measures</a></code> which is available via the <code>calc.ics = TRUE</code> argument.  
</p>
<p>Moreover, note these criteria are not calculated all the time. In models where traits are included in the model (such that the regression coefficients <code class="reqn">\beta_{0j}, \bm{\beta}_j</code> are random effects), or more than two columns are ordinal responses (such that the intercepts <code class="reqn">\beta_{0j}</code> for these columns are random effects), then these extra information criteria are will not calculated, and the function returns nothing except a simple message. This is because the calculation of the marginal log-likelihood in such cases currently fail to marginalize over such random effects; please see the details in <code>calc.logLik.lv0</code> and <code>calc.marglogLik</code>. 
</p>
<p>The two main differences between the criteria and those returned from <code><a href="#topic+get.measures">get.measures</a></code> are:
</p>

<ul>
<li><p> The AIC and BIC computed here are based on the log-likelihood evaluated at the posterior mode, whereas the AIC and BIC from <code><a href="#topic+get.measures">get.measures</a></code> are evaluated at the posterior median. The posterior mode and median will be quite close to one another if the component-wise posterior distributions are unimodal and symmetric. Furthermore, given uninformative priors are used, then both will be approximate maximum likelihood estimators. 
</p>
</li>
<li><p> The DIC and WAIC computed here are based on the marginal log-likelihood, whereas the DIC and WAIC from <code><a href="#topic+get.measures">get.measures</a></code> are based on the conditional log-likelihood. Criteria based on the two types of log-likelihood are equally valid, and to a certain extent, which one to use depends on the question being answered i.e., whether to condition on the latent variables or treat them as &quot;random effects&quot; (see discussions in Spiegelhalter et al. 2002, and Vaida and Blanchard, 2005). 
</p>
</li></ul>



<h3>Value</h3>

<p>If calculated, then a list with the following components:
</p>
<table>
<tr><td><code>marg.aic</code></td>
<td>
<p>AIC (using on the marginal log-likelihood) evaluated at posterior mode.</p>
</td></tr>
<tr><td><code>marg.bic</code></td>
<td>
<p>BIC (using on the marginal log-likelihood) evaluated at posterior mode.</p>
</td></tr>
<tr><td><code>marg.dic</code></td>
<td>
<p>DIC based on the marginal log-likelihood.</p>
</td></tr>
<tr><td><code>marg.waic</code></td>
<td>
<p>WAIC based on the marginal log-likelihood.</p>
</td></tr>
<tr><td><code>all.marg.logLik</code></td>
<td>
<p>The marginal log-likelihood evaluated at all MCMC samples. This is done via repeated application of <code><a href="#topic+calc.marglogLik">calc.marglogLik</a></code>.</p>
</td></tr>
<tr><td><code>num.params</code></td>
<td>
<p>Number of estimated parameters used in the fitted model.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>As of version 1.6, this function is no longer maintained (and probably doesn't work)!
</p>
<p>Using information criterion for variable selection should be done with extreme caution, for two reasons: 1) The implementation of these criteria are both <em>heuristic</em> and experimental. 2) Deciding what model to fit for ordination purposes should be driven by the science. For example, it may be the case that a criterion suggests a model with 3 or 4 latent variables. However, if we interested in visualizing the data for ordination purposes, then models with 1 or 2 latent variables are far more appropriate. As an another example, whether or not we include row effects when ordinating multivariate abundance data depends on if we are interested in differences between sites in terms of relative species abundance (<code>row.eff = FALSE</code>) or in terms of species composition (<code>row.eff = "fixed"</code>).  
</p>
<p>Also, the use of information criterion in the presence of variable selection using SSVS is questionable.
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Spiegelhalter et al. (2002). Bayesian measures of model complexity and fit. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64, 583-639.
</p>
</li>
<li><p> Vaida, F., and Blanchard, S. (2005). Conditional Akaike information for mixed-effects models. Biometrika, 92, 351-370.
</p>
</li>
<li><p> Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. The Journal of Machine Learning Research, 11, 3571-3594.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+get.measures">get.measures</a></code> for several information criteria which take considerably less time to compute, and are automatically implemented in <code><a href="#topic+boral">boral</a></code> with <code>calc.ics = TRUE</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
    n.thin = 1)
     
testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

spiderfit_nb &lt;- boral(y, family = "negative.binomial", lv.control = list(num.lv = 2),
    row.eff = "fixed", save.model = TRUE, calc.ics = TRUE,
    mcmc.control = example_mcmc_control, model.name = testpath)

## Extract MCMC samples
fit_mcmc &lt;- get.mcmcsamples(spiderfit_nb)

## NOTE: The following takes a long time to run!
get.more.measures(y, family = "negative.binomial", 
    num.lv = spiderfit_nb$num.lv, fit.mcmc = fit_mcmc, 
    row.eff = "fixed", row.ids = spiderfit_nb$row.ids)		

     
## Illustrating what happens in a case where these criteria will 
## 	not be calculated.
data(antTraits)
y &lt;- antTraits$abun
X &lt;- as.matrix(scale(antTraits$env))
## Include only traits 1, 2, and 5
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits))
    example_which_traits[[i]] &lt;- 1:ncol(traits)

fit_traits &lt;- boral(y, X = X, traits = traits, lv.control = list(num.lv = 2), 
    which.traits = example_which_traits, family = "negative.binomial", 
    save.model = TRUE, mcmc.control = example_mcmc_control,
    model.name = testpath)
     
## Extract MCMC samples
fit_mcmc &lt;- get.mcmcsamples(fit_traits)

get.more.measures(y, X = X, family = "negative.binomial", 
    num.lv = fit_traits$num.lv, fit.mcmc = fit_mcmc)	

## End(Not run)
</code></pre>

<hr>
<h2 id='get.residual.cor'>Extract residual correlations and precisions from models</h2><span id='topic+get.residual.cor'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Calculates the residual correlation and precision matrices from models that include latent variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.residual.cor(object, est = "median", prob = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.residual.cor_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="get.residual.cor_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then treated as estimates and the fitted values are calculated from. Default is posterior median.</p>
</td></tr>
<tr><td><code id="get.residual.cor_+3A_prob">prob</code></td>
<td>
<p>A numeric scalar in the interval (0,1) giving the target probability coverage of the intervals, by which to determine whether the correlations and precisions are &quot;significant&quot;. Defaults to 0.95.</p>
</td></tr>   
</table>


<h3>Details</h3>

<p>In models with latent variables, the residual covariance matrix is calculated based on the matrix of latent variables regression coefficients formed by stacking the rows of <code class="reqn">\bm{\theta}_j</code>. That is, if we denote <code class="reqn">\bm{\Theta} = (\bm{\theta}_1 \ldots \bm{\theta}_p)'</code>, then the residual covariance and hence residual correlation matrix is calculated based on <code class="reqn">\bm{\Theta}\bm{\Theta}'</code>.
</p>
<p>For multivariate abundance data, the inclusion of latent variables provides a parsimonious method of accounting for correlation between species. Specifically, the linear predictor,
</p>
<p style="text-align: center;"><code class="reqn">\beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{u}^\top_i\bm{\theta}_j</code>
</p>

<p>is normally distributed with a residual covariance matrix given by <code class="reqn">\bm{\Theta}\bm{\Theta}'</code>. A strong residual covariance/correlation matrix between two species can then be interpreted as evidence of species interaction (e.g., facilitation or competition), missing covariates, as well as any additional species correlation not accounted for by shared environmental responses (see also Pollock et al., 2014, for residual correlation matrices in the context of Joint Species Distribution Models). If random effects <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> are also included in the model, then the latent variables induce a residual covariance/correlation between responses than is conditional on this.
</p>
<p>The residual precision matrix (also known as partial correlation matrix, Ovaskainen et al., 2016) is defined as the inverse of the residual correlation matrix. The precision matrix is often used to identify direct or causal relationships between two species e.g., two species can have a zero precision but still be correlated, which can be interpreted as saying that two species do not directly interact, but they are still correlated through other species. In other words, they are conditionally independent given the other species. It is important that the precision matrix does not exhibit the exact same properties of the correlation e.g., the diagonal elements are not equal to 1. Nevertheless, relatively larger values of precision imply a stronger direct relationships between two species. 
</p>
<p>In addition to the residual correlation and precision matrices, the median or mean point estimator of trace of the residual covariance matrix is returned, <code class="reqn">\sum\limits_{j=1}^p [\bm{\Theta}\bm{\Theta}']_{jj}</code>. Often used in other areas of multivariate statistics, the trace may be interpreted as the amount of covariation explained by the latent variables. One situation where the trace may be useful is when comparing a pure LVM versus a model with latent variables and some predictors (correlated response models) &ndash; the proportional difference in trace between these two models may be interpreted as the proportion of covariation between species explained by the predictors. Of course, the trace itself is random due to the MCMC sampling, and so it is not always guranteed to produce sensible answers!
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>cor</code>, <code>cor.lower</code>, <code>cor.upper</code></td>
<td>
<p>A set of <code class="reqn">p \times p</code> correlation matrices, containing either the posterior median or mean estimate plus lower and upper limits of the corresponding (100<code class="reqn">\times</code><code>prob</code>) % HPD interval.</p>
</td></tr>
<tr><td><code>sig.cor</code></td>
<td>
<p>A <code class="reqn">p \times p</code> correlation matrix containing only the &ldquo;significant&quot; correlations whose (100<code class="reqn">\times</code><code>prob</code>) % HPD interval does not contain zero. All non-significant correlations are set to zero.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>A <code class="reqn">p \times p</code> covariance matrix.</p>
</td></tr>
<tr><td><code>prec</code>, <code>prec.lower</code>, <code>prec.upper</code></td>
<td>
<p>A set of <code class="reqn">p \times p</code> precision matrices, containing either the posterior median or mean estimate plus lower and upper limits of the corresponding (100<code class="reqn">\times</code><code>prob</code>) % HPD interval.</p>
</td></tr>
<tr><td><code>sig.prec</code></td>
<td>
<p>A <code class="reqn">p \times p</code> residual precision matrix containing only the &ldquo;significant&quot; precisions whose (100<code class="reqn">\times</code><code>prob</code>) % HPD interval does not contain zero. All non-significant precision are set to zero.</p>
</td></tr>
<tr><td><code>trace</code></td>
<td>
<p>The median/mean point estimator of the trace (sum of the diagonal elements) of the residual covariance matrix.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Residual correlation and precision matrices are reliably modeled only with two or more latent variables i.e., <code>num.lv &gt; 1</code> when fitting the model using <code>boral</code>.  
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Ovaskainen et al. (2016). Using latent variable models to identify large networks of species-to-species associations at different spatial scales. Methods in Ecology and Evolution, 7, 549-555.
</p>
</li>
<li><p> Pollock et al. (2014). Understanding co-occurrence by modelling species simultaneously with a Joint Species Distribution Model (JSDM). Methods in Ecology and Evolution, 5, 397-406.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+get.enviro.cor">get.enviro.cor</a></code>, which calculates the correlation matrix due to similarities in the response to the explanatory variables (i.e., similarities due to a shared environmental response). 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
library(corrplot) ## For plotting correlations
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)
    
spiderfit_nb &lt;- boral(y, X = spider$x, family = "negative.binomial", 
    lv.control = list(num.lv = 2), save.model = TRUE, 
    mcmc.control = example_mcmc_control, model.name = testpath)

res.cors &lt;- get.residual.cor(spiderfit_nb)

corrplot(res.cors$sig.cor, title = "Residual correlations", 
    type = "lower", diag = FALSE, mar = c(3,0.5,2,1), tl.srt = 45)

## End(Not run)
</code></pre>

<hr>
<h2 id='lvsplot'>Plot the latent variables from a fitted model</h2><span id='topic+lvsplot'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Construct a 1-D index plot or 2-D scatterplot of the latent variables, and their corresponding coefficients i.e., a biplot, from a fitted model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lvsplot(object, jitter = FALSE, biplot = TRUE, ind.spp = NULL, alpha = 0.5, 
	main = NULL, est = "median", which.lvs = c(1,2), return.vals = FALSE, ...) 
	</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lvsplot_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_jitter">jitter</code></td>
<td>
<p>If <code>jitter = TRUE</code>, then some jittering is applied so that points on the plots do not overlap exactly (which can often occur with discrete data, small sample sizes, and if some sites are identical in terms species co-occurence). Please see <code><a href="base.html#topic+jitter">jitter</a></code> for its implementation. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_biplot">biplot</code></td>
<td>
<p>If <code>biplot = TRUE</code>, then a biplot is construct such that both the latent variables <em>and</em> their corresponding coefficients are plotted. Otherwise, only the latent variable scores are plotted. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_ind.spp">ind.spp</code></td>
<td>
<p>Controls the number of latent variable coefficients to plot if <code>biplot = TRUE</code>. If <code>ind.spp</code> is an integer, then only the first <code>ind.spp</code> &quot;most important&quot; latent variable coefficients are included in the biplot, where &quot;most important&quot; means the latent variable coefficients with the largests L2-norms. Defaults to <code>NULL</code>, in which case all latent variable coefficients are included in the biplot.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_alpha">alpha</code></td>
<td>
<p>A numeric scalar between 0 and 1 that is used to control the relative scaling of the latent variables and their coefficients, when constructing a biplot. Defaults to 0.5, and we typically recommend between 0.45 to 0.55 so that the latent variables and their coefficients are on roughly the same scale.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_main">main</code></td>
<td>
<p>Title for resulting ordination plot. Defaults to <code>NULL</code>, in which case a &quot;standard&quot; title is used.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then treated as estimates and the ordinations based off. Default is posterior median.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_which.lvs">which.lvs</code></td>
<td>
<p>A vector of length two, indicating which latent variables (ordination axes) to plot which <code>object</code> is an object with two or more latent variables. The argument is ignored is <code>object</code> only contains one latent variables. Defaults to <code>which.lvs = c(1,2)</code>.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_return.vals">return.vals</code></td>
<td>
<p>If <code>TRUE</code>, then the <em>scaled</em> latent variables scores and corresponding scaled coefficients are returned (based on the value of <code>alpha</code> used). This is useful if the user wants to construct their own custom model-based ordinations. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lvsplot_+3A_...">...</code></td>
<td>
<p>Additional graphical options to be included in. These include values for <br /> <code>cex, cex.lab, cex.axis, cex.main, lwd</code>, and so on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows an ordination plot to be constructed, based on either the posterior medians and posterior means of the latent variables respectively depending on the choice of <code>est</code>. The latent variables are labeled using the row index of the response matrix. If the fitted model contains more than two latent variables, then one can specify which latent variables i.e., ordination axes, to plot based on the <code>which.lvs</code> argument. This can prove useful (to check) if certain sites are outliers on one particular ordination axes.
</p>
<p>If the fitted model did not contain any covariates, the ordination plot can be interpreted in the exactly same manner as unconstrained ordination plots constructed from methods such as Nonmetric Multi-dimensional Scaling (NMDS, Kruskal, 1964) and Correspondence Analysis (CA, Hill, 1974). With multivariate abundance data for instance, where the response matrix comprises of <code class="reqn">n</code> sites and <code class="reqn">p</code> species, the ordination plots can be studied to look for possible clustering of sites, location and/or dispersion effects, an arch pattern indicative of some sort species succession over an environmental gradient, and so on.
</p>
<p>If the fitted model did include covariates, then a &ldquo;residual ordination&quot; plot is produced, which can be interpreted can offering a graphical representation of the (main patterns of) residual covarations, i.e. covariations after accounting for the covariates. With multivariate abundance data for instance, these residual ordination plots represent could represent residual species co-occurrence due to phylogency, species competition and facilitation, missing covariates, and so on (Warton et al., 2015)
</p>
<p>If <code>biplot = TRUE</code>, then a biplot is constructed so that both the latent variables and their corresponding coefficients are included in their plot (Gabriel, 1971). The latent variable coefficients are shown in red, and are indexed by the column names of the response matrix. The number of latent variable coefficients to plot is controlled by <code>ind.spp</code>. In ecology for example, often we are only be interested in the &quot;indicator&quot; species, e.g. the species with most represent a particular set of sites or species with the strongest covariation (see Chapter 9, Legendre and Legendre, 2012, for additional discussion). In such case, we can then biplot only the <code>ind.spp</code> &quot;most important&quot; species, as indicated by the the L2-norm of their latent variable coefficients. 
</p>
<p>As with correspondence analysis, the relative scaling of the latent variables and the coefficients in a biplot is essentially arbitrary, and could be adjusted to focus on the sites, species, or put even weight on both (see Section 9.4, Legendre and Legendre, 2012). In <code>lvsplot</code>, this relative scaling is controlled by the <code>alpha</code> argument, which basically works by taking the latent variables to a power <code>alpha</code> and the latent variable coefficients to a power <code>1-alpha</code>. 
</p>
<p>For latent variable models, we are generally interested in &quot;symmetric plots&quot; that place the latent variables and their coefficients on the same scale. In principle, this is achieved by setting <code>alpha = 0.5</code>, the default value, although sometimes this needs to be tweaked slighlty to a value between 0.45 and 0.55 (see also the <code>corresp</code> function in the <code>MASS</code> package that also produces symmetric plots, as well as Section 5.4, Borcard et al., 2011 for more details on scaling).
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Borcard et al. (2011). Numerical Ecology with R. Springer.
</p>
</li>
<li><p> Gabriel, K. R. (1971). The biplot graphic display of matrices with application to principal component analysis. Biometrika, 58, 453-467.
</p>
</li>
<li><p> Hill, M. O. (1974). Correspondence analysis: a neglected multivariate method. Applied statistics, 23, 340-354.
</p>
</li>
<li><p> Kruskal, J. B. (1964). Nonmetric multidimensional scaling: a numerical method. Psychometrika, 29, 115-129.
</p>
</li>
<li><p> Legendre, P. and Legendre, L. (2012). Numerical ecology, Volume 20. Elsevier.
</p>
</li>
<li><p> Warton et al. (2015). So Many Variables: Joint Modeling in Community Ecology. Trends in Ecology and Evolution, to appear
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)
     
spiderfit_nb &lt;- boral(y, family = "negative.binomial", lv.control = list(num.lv = 2),
    row.eff = "fixed", mcmc.control = example_mcmc_control, model.name = testpath)

lvsplot(spiderfit_nb) 
</code></pre>

<hr>
<h2 id='make.jagsboralmodel'>Write a text file containing a model for use into JAGS</h2><span id='topic+make.jagsboralmodel'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This function is designed to write models with one or more latent variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.jagsboralmodel(family, num.X = 0, X.ind =  NULL, num.traits = 0, 
     which.traits = NULL, lv.control = list(num.lv = 2, type = "independent"), 
     row.eff = "none", row.ids = NULL, ranef.ids = NULL,
     offset = NULL, trial.size = 1, n, p, model.name = NULL, 
     prior.control = list(type = c("normal","normal","normal","uniform"), 
     hypparams = c(10, 10, 10, 30), ssvs.index = -1, ssvs.g = 1e-6,
	ssvs.traitsindex = -1),
     num.lv = NULL)
	</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.jagsboralmodel_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression), &quot;ztpoisson&quot; (zero truncated Poisson with log link), &quot;ztnegative.binomial&quot; (zero truncated negative binomial with log link). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_num.x">num.X</code></td>
<td>
<p>Number of columns in the covariate matrix. Defaults to 0, in which case it is assumed that no covariates are included in the model. Recall that no intercept is included in the covariate matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_x.ind">X.ind</code></td>
<td>
<p>An matrix of 1s and 0s, indicating whether a particular covariate should be included (1) or excluded (0) in the mean structure of a particular response. The matrix should the number of rows equal to the number of columns in the response matrix, and the number of columns equal to the number of columns in the covariate matrix. Defaults to <code>NULL</code>, in which case it is assumed that all covariates are included in the mean structure of all responses i.e., all 1s.</p>
</td></tr>  
<tr><td><code id="make.jagsboralmodel_+3A_num.traits">num.traits</code></td>
<td>
<p>Number of columns in the trait matrix. Defaults to 0, in which case it is assumed no traits are included in model. Recall that no intercept should is included in the trait matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_which.traits">which.traits</code></td>
<td>
<p>A list of length equal to (number of columns in the covariate matrix + 1), informing which columns of the trait matrix the response-specific intercepts and each of the response-specific regression coefficients should be regressed against. The first element in the list applies to the response-specific intercept, while the remaining elements apply to the regression coefficients. Each element of <code>which.traits</code> is a vector indicating which traits are to be used. 
</p>
<p>For example, if <code>which.traits[[2]] = c(2,3)</code>, then the regression coefficients corresponding to the first column in the covariate matrix are regressed against the second and third columns of the trait matrix. If <code>which.traits[[2]][1] = 0</code>, then the regression coefficients for each column are treated as independent. Please see <code><a href="#topic+about.traits">about.traits</a></code> for more details.
</p>
<p>Defaults to <code>NULL</code>, and used in conjunction with <code>traits</code> and <br /> <code>prior.control$ssvs.traitsindex</code>.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_lv.control">lv.control</code></td>
<td>
<p>A list (currently) with the following arguments:
</p>

<ul>
<li> <p><em>num.lv:</em> which specifies the number of true latent variables to generate. Defaults to 0.
</p>
</li>
<li> <p><em>type:</em> which specifies the type the correlation structure of the latent variables (across sites). Defaults to independence correlation structure.        
</p>
</li></ul>

<p>Please see <code><a href="#topic+about.lvs">about.lvs</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and unknown standard deviation. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="make.jagsboralmodel_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for details. Defaults to <code>NULL</code>, so that if <code>row.eff = "none"</code> then the argument is ignored, otherwise if <br /> <code>row.eff = "fixed"</code> or <code>"random"</code>, <br /> then <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_ranef.ids">ranef.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of random intercepts to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>; please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for details. Defaults to <code>NULL</code>, in which case it is assumed no random intercepts are to be included in the model. If supplied, then response-specific random intercepts are assumed to come from a normal distribution with mean zero and unknown (response-specific) standard deviation.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_n">n</code></td>
<td>
<p>The number of rows in the response matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_p">p</code></td>
<td>
<p>The number of columns in the response matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_model.name">model.name</code></td>
<td>
<p>Name of the text file that the JAGS script is written to. Defaults to <code>NULL</code>, in which case the default of &quot;jagsboralmodel.txt&quot; is used.</p>
</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_prior.control">prior.control</code></td>
<td>
<p>A list of parameters for controlling the prior distributions. These include:
</p>

<ul>
<li> <p><em>type:</em> Vector of four strings indicating the type of prior distributions to use. In order, these are: 1) priors for all response-specific intercepts, row effects, and cutoff points for ordinal data; 2) priors for the latent variable coefficients and covariance parameters. This is ignored if <code>lv.control$num.lv = 0</code>; 3) priors for all response-specific coefficients relating to the covariate matrix (ignored if <code>X = NULL</code>). When traits are included in the model, this is also the prior for the trait regression coefficients (please see <code><a href="#topic+about.traits">about.traits</a></code> for more information); 4) priors for any dispersion parameters and variance (standard deviation, to be precise) parameters in the model.
</p>
<p>For elements 1-3, the prior distributions currently available include: I) &ldquo;normal&quot;, which is a normal prior with the variance controlled by elements 1-3 in <code>hypparams</code>; II) &ldquo;cauchy&quot;, which is a Cauchy prior with variance controlled by elements 1-3 in <code>hypparams</code>. Gelman, et al. (2008) considers using Cauchy priors with variance <code class="reqn">2.5^2</code> as weakly informative priors for coefficients in logistic and potentially other generalized linear models; III) &ldquo;uniform&quot;, which is a symmetric uniform prior with minimum and maximum values controlled by element 1-3 in <code>hypparams</code>. 
</p>
<p>For element 4, the prior distributions currently available include: I) &ldquo;uniform&quot;, which is uniform prior with minimum zero and maximum controlled by element 4 in <code>hypparmas</code>; II) &ldquo;halfnormal&quot;, which is half-normal prior with variance controlled by <code>hypparams</code>; III) &ldquo;halfcauchy&quot;, which is a half-Cauchy prior with variance controlled by element 4 in <code>hypparams</code>.
</p>
<p>Defaults to the vector <code>c("normal","normal","normal","uniform")</code>. 
</p>
</li>
<li> <p><em>hypparams:</em> Vector of four hyperparameters used in the set up of prior distributions. In order, these are: 1) affects the prior distribution for all response-specific intercepts, row effects, and cutoff points for ordinal data; 2) affects the prior distribution for all latent variable coefficients and correlation parameters. This is ignored if <code>lv.control$num.lv = 0</code>; 3) affects the prior distribution for response-specific coefficients relating to the covariate matrix (ignored if <code>X = NULL</code>). When traits are included in the model, it also affects the prior distribution for the trait regression coefficients; 4) affects the prior distribution for any dispersion parameters, as well as the prior distributions for the standard deviation of the random effects normal distribution if <code>row.eff = "random"</code>, the standard deviation of the response-specific random intercepts for these columns if more than two of the columns are ordinal, and the standard deviation of the random effects normal distribution for trait regression coefficients when traits are included in the model.
</p>
<p>Defaults to the vector <code>c(10, 10, 10, 30)</code>. The use of normal distributions with mean zero and variance 10 as priors is seen as one type of (very) weakly informative prior, according to <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Prior choice recommendations</a>.
</p>
</li>
<li> <p><em>ssvs.index:</em> Indices to be used for stochastic search variable selection (SSVS, George and McCulloch, 1993). Either a single element or a vector with length equal to the number of columns in covariate matrix. Each element can take values of -1 (no SSVS is performed on this covariate), 0 (SSVS is performed on individual coefficients for this covariate), or any integer greater than 0 (SSVS is performed on collectively all coefficients on this covariate/s.) 
</p>
<p>Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to -1, in which case SSVS is not performed on the covariates. 
</p>
</li>
<li> <p><em>ssvs.g:</em> Multiplicative, shrinkage factor for SSVS, which controls the strength of the &quot;spike&quot; in the SSVS mixture prior. In summary, if the coefficient is included in the model, the &quot;slab&quot; prior is a normal distribution with mean zero and variance given by element 3 in <code>hypparams</code>, while if the coefficient is not included in the model, the &quot;spike&quot; prior is normal distribution with mean zero and variance given by element 3 in <code>hypparams</code> multiplied by <code>ssvs.g</code>. Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to 1e-6.  		
</p>
</li>
<li> <p><em>ssvs.traitsindex:</em> Used in conjunction with <code>traits</code> and <code>which.traits</code>, this is a list of indices to be used 
for performing SSVS on the trait coefficients. Should be a list with the same length as <code>which.traits</code>, and with each element a vector of indices with the same length as the corresponding element in <code>which.traits</code>. Each index either can take values of -1 (no SSVS on this trait coefficient) or 0 (no SSVS on this trait coefficient). 
</p>
<p>Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to -1, in which case SSVS is not performed on any of the trait coefficients, if they are included in the model.
</p>
</li></ul>

</td></tr>
<tr><td><code id="make.jagsboralmodel_+3A_num.lv">num.lv</code></td>
<td>
<p>Old argument superceded by <code>lv.control</code>. Defaults to <code>NULL</code> and ignored.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This function is automatically executed inside <code><a href="#topic+boral">boral</a></code>, and therefore does not need to be run separately before fitting the model. It can however be run independently if one is: 1) interested in what the actual JAGS file for a particular model looks like, 2) wanting to modify a basic JAGS model file to construct more complex model e.g., include environmental variables. 
</p>
<p>Please note that <code><a href="#topic+boral">boral</a></code> currently does not allow the user to manually enter a script to be run. 
</p>
<p>When running the main function <code><a href="#topic+boral">boral</a></code>, setting <code>save.model = TRUE</code> which automatically save the JAGS model file as a text file (with name based on the <code>model.name</code>) in the current working directory.
</p>


<h3>Value</h3>

<p>A text file is created, containing the model to be called by the boral function for entering into JAGS. This file is automatically deleted once boral has finished running <code>save.model = TRUE</code>.</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Gelman et al. (2008). A weakly informative default prior distribution for logistic and other regression models. The Annals of Applied Statistics, 2, 1360-1383.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+make.jagsboralnullmodel">make.jagsboralnullmodel</a></code> for writing JAGS scripts for models with no latent variables i.e., so-called &quot;null models&quot;.</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvtnorm)
library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


## Example 1 - Create a JAGS model file, where distributions alternative 
## between Poisson and negative binomial distributions 
##   across the rows of y.
make.jagsboralmodel(family = rep(c("poisson","negative.binomial"),length=p), 
    row.eff = "fixed", num.X = 0, n = n, p = p, model.name = testpath)

    
## Example 2 - Create a JAGS model file, where distributions are all 
##	negative binomial distributions and covariates will be included.
make.jagsboralmodel(family = "negative.binomial", num.X = ncol(spider$x),
    n = n, p = p, model.name = testpath)

	
## Example 3 - Simulate some ordinal data and create a JAGS model file
## 30 rows (sites) with two latent variables 
true.lv &lt;- rbind(rmvnorm(15,mean=c(-2,-2)),rmvnorm(15,mean=c(2,2)))
## 10 columns (species)
true.lv.coefs &lt;- rmvnorm(10,mean = rep(0,3)); 
true.lv.coefs[nrow(true.lv.coefs),1] &lt;- -sum(true.lv.coefs[-nrow(true.lv.coefs),1])
## Impose a sum-to-zero constraint on the column effects
true.ordinal.cutoffs &lt;- seq(-2,10,length=10-1)

simy &lt;- create.life(true.lv = true.lv, lv.coefs = true.lv.coefs, 
    family = "ordinal", cutoffs = true.ordinal.cutoffs) 

make.jagsboralmodel(family = "ordinal", num.X = 0, 
    row.eff = FALSE, n=30, p=10, model.name = testpath)


## Have a look at the JAGS model file for a model involving traits,
## based on the ants data from mvabund.
library(mvabund)
data(antTraits)

y &lt;- antTraits$abun
X &lt;- as.matrix(antTraits$env)
## Include only traits 1, 2, and 5, plus an intercept
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
## Please see help file for boral regarding the use of which.traits
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
    example_which_traits[[i]] &lt;- 1:ncol(traits)

## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
    n.thin = 1)

fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", lv.control = list(num.lv = 2), 
    model.name = testpath, mcmc.control = example_mcmc_control,
    do.fit = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='make.jagsboralnullmodel'>Write a text file containing a model for use into JAGS</h2><span id='topic+make.jagsboralnullmodel'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>This function is designed to write models with no latent variables i.e., so-called &quot;null&quot; models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.jagsboralnullmodel(family, num.X = 0, X.ind = NULL, num.traits = 0, 
     which.traits = NULL, row.eff = "none", row.ids = NULL, ranef.ids = NULL,
     offset = NULL, trial.size = 1, n, p, model.name = NULL, 
     prior.control = list(type = c("normal","normal","normal","uniform"), 
	hypparams = c(10, 10, 10, 30), ssvs.index = -1, ssvs.g = 1e-6,
	ssvs.traitsindex = -1))
	</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.jagsboralnullmodel_+3A_family">family</code></td>
<td>
<p>Either a single element, or a vector of length equal to the number of columns in the response matrix. The former assumes all columns of the response matrix come from this distribution. The latter option allows for different distributions for each column of the response matrix. Elements can be one of &quot;binomial&quot; (with probit link), &quot;poisson&quot; (with log link), &quot;negative.binomial&quot; (with log link), &quot;normal&quot; (with identity link), &quot;lnormal&quot; for lognormal (with log link), &quot;tweedie&quot; (with log link), &quot;exponential&quot; (with log link), &quot;gamma&quot; (with log link), &quot;beta&quot; (with logit link), &quot;ordinal&quot; (cumulative probit regression), &quot;ztpoisson&quot; (zero truncated Poisson with log link), &quot;ztnegative.binomial&quot; (zero truncated negative binomial with log link). 
</p>
<p>Please see <code><a href="#topic+about.distributions">about.distributions</a></code> for information on distributions available in boral overall.
</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_num.x">num.X</code></td>
<td>
<p>Number of columns in the covariate matrix. Defaults to 0, in which case it is assumed that no covariates are included in the model. Recall that no intercept is included in the covariate matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_x.ind">X.ind</code></td>
<td>
<p>An matrix of 1s and 0s, indicating whether a particular covariate should be included (1) or excluded (0) in the mean structure of a particular response. The matrix should the number of rows equal to the number of columns in the response matrix, and the number of columns equal to the number of columns in the covariate matrix. Defaults to <code>NULL</code>, in which case it is assumed that all covariates are included in the mean structure of all responses i.e., all 1s.</p>
</td></tr>  
<tr><td><code id="make.jagsboralnullmodel_+3A_num.traits">num.traits</code></td>
<td>
<p>Number of columns in the trait matrix. Defaults to 0, in which case it is assumed no traits are included in model. Recall that no intercept is included in the trait matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_which.traits">which.traits</code></td>
<td>
<p>A list of length equal to (number of columns in the covariate matrix + 1), informing which columns of the trait matrix the response-specific intercepts and each of the response-specific regression coefficients should be regressed against. The first element in the list applies to the response-specific intercept, while the remaining elements apply to the regression coefficients. Each element of <code>which.traits</code> is a vector indicating which traits are to be used. 
</p>
<p>For example, if <code>which.traits[[2]] = c(2,3)</code>, then the regression coefficients corresponding to the first column in the covariate matrix are regressed against the second and third columns of the trait matrix. If <code>which.traits[[2]][1] = 0</code>, then the regression coefficients for each column are treated as independent. Please see <code><a href="#topic+about.traits">about.traits</a></code> for more details.
</p>
<p>Defaults to <code>NULL</code>, and used in conjunction with <code>traits</code> and <br /> <code>prior.control$ssvs.traitsindex</code>.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_row.eff">row.eff</code></td>
<td>
<p>Single element indicating whether row effects are included as fixed effects (&quot;fixed&quot;), random effects (&quot;random&quot;) or not included (&quot;none&quot;) in the fitted model. If fixed effects, then for parameter identifiability the first row effect is set to zero, which analogous to acting as a reference level when dummy variables are used. If random effects, they are drawn from a normal distribution with mean zero and unknown standard deviation. Defaults to &quot;none&quot;. </p>
</td></tr> 
<tr><td><code id="make.jagsboralnullmodel_+3A_row.ids">row.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of row effects to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>; please see <code><a href="#topic+boral">boral</a></code> for more details. for details. Defaults to <code>NULL</code>, so that if <code>row.eff = "none"</code> then the argument is ignored, otherwise if <br /> <code>row.eff = "fixed"</code> or <code>"random"</code>, <br /> then <code>row.ids = matrix(1:nrow(y), ncol = 1)</code> i.e., a single, row effect unique to each row.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_ranef.ids">ranef.ids</code></td>
<td>
<p>A matrix with the number of rows equal to the number of rows in the response matrix, and the number of columns equal to the number of random intercepts to be included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>; please see <code><a href="#topic+about.ranefs">about.ranefs</a></code> for details. Defaults to <code>NULL</code>, in which case it is assumed no random intercepts are to be included in the model. If supplied, then response-specific random intercepts are assumed to come from a normal distribution with mean zero and unknown (response-specific) standard deviation.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_offset">offset</code></td>
<td>
<p>A matrix with the same dimensions as the response matrix, specifying an a-priori known component to be included in the linear predictor during fitting. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_trial.size">trial.size</code></td>
<td>
<p>Either equal to a single element, or a vector of length equal to the number of columns in y. If a single element, then all columns assumed to be binomially distributed will have trial size set to this. If a vector, different trial sizes are allowed in each column of y. The argument is ignored for all columns not assumed to be binomially distributed. Defaults to 1, i.e. Bernoulli distribution.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_n">n</code></td>
<td>
<p>The number of rows in the response matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_p">p</code></td>
<td>
<p>The number of columns in the response matrix.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_model.name">model.name</code></td>
<td>
<p>Name of the text file that the JAGS model is written to. Defaults to <code>NULL</code>, in which case the default of &quot;jagsboralmodel.txt&quot; is used.</p>
</td></tr>
<tr><td><code id="make.jagsboralnullmodel_+3A_prior.control">prior.control</code></td>
<td>
<p>A list of parameters for controlling the prior distributions. These include:
</p>

<ul>
<li> <p><em>type:</em> Vector of four strings indicating the type of prior distributions to use. In order, these are: 1) priors for all response-specific intercepts, row effects, and cutoff points for ordinal data; 2) priors for the latent variable coefficients and correlation parameters. This is ignored for this function; 3) priors for all response-specific coefficients relating to the covariate matrix (ignored if <code>X = NULL</code>). When traits are included in the model, this is also the prior for the trait regression coefficients (please see <code><a href="#topic+about.traits">about.traits</a></code> for more information); 4) priors for any dispersion parameters and variance (standard deviation, to be precise) parameters in the model.
</p>
<p>For elements 1-3, the prior distributions currently available include: I) &ldquo;normal&quot;, which is a normal prior with the variance controlled by elements 1-3 in <code>hypparams</code>; II) &ldquo;cauchy&quot;, which is a Cauchy prior with variance controlled by elements 1-3 in <code>hypparams</code>. Gelman, et al. (2008) considers using Cauchy priors with variance <code class="reqn">2.5^2</code> as weakly informative priors for coefficients in logistic and potentially other generalized linear models; III) &ldquo;uniform&quot;, which is a symmetric uniform prior with minimum and maximum values controlled by element 1-3 in <code>hypparams</code>. 
</p>
<p>For element 4, the prior distributions currently available include: I) &ldquo;uniform&quot;, which is uniform prior with minimum zero and maximum controlled by element 4 in <code>hypparmas</code>; II) &ldquo;halfnormal&quot;, which is half-normal prior with variance controlled by <code>hypparams</code>; III) &ldquo;halfcauchy&quot;, which is a half-Cauchy prior with variance controlled by element 4 in <code>hypparams</code>.
</p>
<p>Defaults to the vector <code>c("normal","normal","normal","uniform")</code>. 
</p>
</li>
<li> <p><em>hypparams</em> Vector of four hyperparameters used in the set up of prior distributions. In order, these are: 1) affects the prior distribution for all response-specific intercepts, row effects, and cutoff points for ordinal data; 2) affects the prior distribution for all latent variable coefficients and correlation parameters. This is ignored for this function; 3) affects the prior distribution for response-specific coefficients relating to the covariate matrix (ignored if <code>X = NULL</code>). When traits are included in the model, it also affects the prior distribution for the trait regression coefficients; 4) affects the prior distribution for any dispersion parameters, as well as the prior distributions for the standard deviation of the random effects normal distribution if <code>row.eff = "random"</code>, the standard deviation of the response-specific random intercepts for these columns if more than two of the columns are ordinal, and the standard deviation of the random effects normal distribution for trait regression coefficients when traits are included in the model.
</p>
<p>Defaults to the vector <code>c(10, 10, 10, 30)</code>. The use of normal distributions with mean zero and variance 10 as priors is seen as one type of (very) weakly informative prior, according to <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Prior choice recommendations</a>.
</p>
</li>
<li> <p><em>ssvs.index:</em> Indices to be used for stochastic search variable selection (SSVS, George and McCulloch, 1993). Either a single element or a vector with length equal to the number of columns in the covariate matrix. Each element can take values of -1 (no SSVS is performed on this covariate), 0 (SSVS is performed on individual coefficients for this covariate), or any integer greater than 0 (SSVS is performed on collectively all coefficients on this covariate/s.) 
</p>
<p>Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to -1, in which case SSVS is not performed on the covariates. 
</p>
</li>
<li> <p><em>ssvs.g:</em> Multiplicative, shrinkage factor for SSVS, which controls the strength of the &quot;spike&quot; in the SSVS mixture prior. In summary, if the coefficient is included in the model, the &quot;slab&quot; prior is a normal distribution with mean zero and variance given by element 3 in <code>hypparams</code>, while if the coefficient is not included in the model, the &quot;spike&quot; prior is normal distribution with mean zero and variance given by element 3 in <code>hypparams</code> multiplied by <code>ssvs.g</code>. Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to 1e-6.  		
</p>
</li>
<li> <p><em>ssvs.traitsindex:</em> Used in conjunction with <code>traits</code> and <code>which.traits</code>, this is a list of indices to be used 
for performing SSVS on the trait coefficients. Should be a list with the same length as <code>which.traits</code>, and with each element a vector of indices with the same length as the corresponding element in <code>which.traits</code>. Each index either can take values of -1 (no SSVS on this trait coefficient) or 0 (no SSVS on this trait coefficient). 
</p>
<p>Please see <code><a href="#topic+about.ssvs">about.ssvs</a></code> for more information regarding the implementation of SSVS. Defaults to -1, in which case SSVS is not performed on any of the trait coefficients, if they are included in the model.
</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>This function is automatically executed inside <code><a href="#topic+boral">boral</a></code>, and therefore does not need to be run separately before fitting the model. It can however be run independently if one is: 1) interested in what the actual JAGS file for a particular model looks like, 2) wanting to modify a basic JAGS model file to construct more complex model e.g., include environmental variables. 
</p>
<p>Please note that <code><a href="#topic+boral">boral</a></code> currently does not allow the user to manually enter a script to be run. 
</p>
<p>When running the main function <code><a href="#topic+boral">boral</a></code>, setting <code>save.model = TRUE</code> which automatically save the JAGS model file as a text file (with name based on the <code>model.name</code>) in the current working directory.
</p>


<h3>Value</h3>

<p>A text file is created, containing the JAGS model to be called by the boral function for entering into jags. This file is automatically deleted once boral has finished running unless <code>save.model = TRUE</code>.</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Gelman et al. (2008). A weakly informative default prior distribution for logistic and other regression models. The Annals of Applied Statistics, 2, 1360-1383.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+make.jagsboralmodel">make.jagsboralmodel</a></code> for writing JAGS scripts for models with one or more latent variables.</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
n &lt;- nrow(y)
p &lt;- ncol(y)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


## Create a "null" model JAGS script, where distributions alternative 
## between Poisson and negative distributions 
##   across the rows of y.
make.jagsboralnullmodel(family = rep(c("poisson","negative.binomial"),length=p), 
    num.X = ncol(spider$x), row.eff = "fixed", n = n, p = p,
    model.name = testpath)

     
## Create a "null" model JAGS script, where distributions are all negative 
## 	binomial distributions and covariates will be included!
make.jagsboralnullmodel(family = "negative.binomial", 
    num.X = ncol(spider$x), n = n, p = p, 
    model.name = testpath)

     
## Have a look at the JAGS model file for a model involving traits,
## based on the ants data from mvabund.
library(mvabund)
data(antTraits)

y &lt;- antTraits$abun
X &lt;- as.matrix(antTraits$env)
## Include only traits 1, 2, and 5, plus an intercept
traits &lt;- as.matrix(antTraits$traits[,c(1,2,5)])
## Please see help file for boral regarding the use of which.traits
example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)

## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

fit_traits &lt;- boral(y, X = X, traits = traits, which.traits = example_which_traits, 
    family = "negative.binomial", model.name = testpath, 
     mcmc.control = example_mcmc_control, do.fit = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.boral'>Plots of a fitted boral object</h2><span id='topic+plot.boral'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Produces a set of four plots relating to the fitted boral object, which can be used for (some basic0 residual analysis. If some of the columns are ordinal, then a single confusion matrix is also produced.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boral'
plot(x, est = "median", include.ranef = TRUE, jitter = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.boral_+3A_x">x</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="plot.boral_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>) of the parameters, which are then treated as parameter estimates and the fitted values/residuals used in the plots are calculated from. Default is posterior median.</p>
</td></tr>
<tr><td><code id="plot.boral_+3A_jitter">jitter</code></td>
<td>
<p>If <code>jitter = TRUE</code>, then some jittering is applied so that points on the plots do not overlap exactly (which can often occur with discrete data). Please see <code><a href="base.html#topic+jitter">jitter</a></code> for its implementation.</p>
</td></tr>
<tr><td><code id="plot.boral_+3A_include.ranef">include.ranef</code></td>
<td>
<p>If response-specific random intercepts were included as part of the fitted model, then this determines whether the predicted random effects will be used in the calculated of the fitted values and Dunn-Smyth residuals. When set to <code>TRUE</code>, which is the default, then they are included (using either the posterior mean and posterior median predictor). When set to <code>FALSE</code>, they are not included. The former leads to what are sometimes called conditional fitted values/residuals, while the latter are sometimes called marginal fitted values/residuals.</p>
</td></tr>
<tr><td><code id="plot.boral_+3A_...">...</code></td>
<td>
<p>Additional graphical options to be included in. These include values for <br /> <code>cex, cex.lab, cex.axis, cex.main, lwd</code>, and so on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A set of four plots are provided:
</p>

<ol>
<li><p> Plot of Dunn-Smyth residuals against the linear predictors. For ordinal responses, things are more ambiguous due to the lack of single definition for &quot;linear predictor&quot;. Therefore, instead of linear predictors the Dunn-Smyth residuals are plotted against the fitted values (defined as the level with the highest fitted probability). It is fully acknowledged that this makes things hard to interpret if only some of your columns are ordinal. 
</p>
</li>
<li><p> Plot of Dunn-Smyth residuals against the row index/names of the response matrix.  
</p>
</li>
<li><p> Plot of Dunn-Smyth residuals against the column index/names of the response matrix. 
</p>
</li>
<li><p> A normal quantile-quantile plot of the Dunn-Smyth residuals.  
</p>
</li></ol>

<p>For ordinal responses, a single confusion matrix between the predicted levels (as based on the class with the highest probability) and true levels is aso returned. The table pools the results over all columns assumed to be ordinal.
</p>


<h3>Note</h3>

<p>Due the inherent stochasticity, Dunn-Smyth residuals and consequently the plots will be slightly different time this function is run. Note also the fitted values and residuals are calculated from point estimates of the parameters, as opposed to a fully Bayesian approach (please see details in <code><a href="#topic+fitted.boral">fitted.boral</a></code> and <code><a href="#topic+ds.residuals">ds.residuals</a></code>). Consequently, it is recommended that this function is run several times to ensure that any trends observed in the plots are consistent throughout the runs.
</p>
<p>As mentioned above, for ordinal responses things are much more challenging as there is no single definition for &quot;linear predictor&quot;. Instead of linear predictors then, for the first plot the Dunn-Smyth residuals are plotted against the fitted values, defined as the level with the highest fitted probability. It is fully acknowledged that this makes things VERY hard to interpret if only some of your columns are ordinal though. Suggestions to improve this are welcome!!!
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitted.boral">fitted.boral</a></code> to obtain the fitted values, <code><a href="#topic+ds.residuals">ds.residuals</a></code> to obtain Dunn-Smyth residuals and details as to what they are.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
    n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun

spiderfit_pois &lt;- boral(y, family = "poisson", lv.control = list(num.lv = 2),
    row.eff = "fixed", mcmc.control = example_mcmc_control
    model.name = testpath)

par(mfrow = c(2,2))
plot(spiderfit_pois) 
## A distinct fan pattern is observed in the plot of residuals 
## versus linear predictors plot. 


spiderfit_nb &lt;- boral(y, family = "negative.binomial", lv.control = list(num.lv = 2), 
    row.eff = "fixed", mcmc.control = example_mcmc_control, 
    model.name = testpath)

par(mfrow = c(2,2))
plot(spiderfit_nb) 
## The fan shape is not as clear now, 
## and the normal quantile plot also suggests a better fit to the data 

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.boral'>Predict using a model</h2><span id='topic+predict.boral'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Construct predictions and associated intervals (lower and upper limits) from a fitted boral object. Predictions can be made either conditionally on the predicted latent variables and any random row effects/response-specific random intercepts included in the model, or marginally (averaged) on the latent variables and these other effects (note integration is done on the linear predictor scale).</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boral'
predict(object, newX = NULL, newrow.ids = NULL, newranef.ids = NULL,
     distmat =  NULL, predict.type = "conditional", scale = "link", 
     est = "median", prob = 0.95, lv.mc = 1000, return.alllinpred = FALSE, 
     ...)
     </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.boral_+3A_object">object</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="predict.boral_+3A_newx">newX</code></td>
<td>
<p>An optional model matrix of covariates for extrapolation to the same sites (under different environmental conditions) or extrapolation to new sites. No intercept column should be included in <code>newX</code>. Defaults to <code>NULL</code>, in which case the model matrix of covariates is taken from the fitted boral object if found.</p>
</td></tr>  
<tr><td><code id="predict.boral_+3A_newrow.ids">newrow.ids</code></td>
<td>
<p>An optional matrix with the number of columns equal to the number of row effects included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random effect <code class="reqn">j</code>. Defaults to <code>NULL</code>, in which case row IDs are taken from the fitted boral object itself, if appropriate, i.e., from <code>object$row.ids</code>.</p>
</td></tr>  
<tr><td><code id="predict.boral_+3A_newranef.ids">newranef.ids</code></td>
<td>
<p>An optional matrix with the number of columns equal to the number of response-specific random intercepts included in the model. Element <code class="reqn">(i,j)</code> indicates the cluster ID of row <code class="reqn">i</code> in the response matrix for random intercept <code class="reqn">j</code>. Defaults to <code>NULL</code>, in which case random intercept IDs are taken from the fitted boral object itself, if appropriate, i.e., from <code>object$ranef.ids</code>.</p>
</td></tr>  
<tr><td><code id="predict.boral_+3A_distmat">distmat</code></td>
<td>
<p>A distance matrix required to calculate correlations across sites when a non-independence correlation structure on the latent variables is imposed.</p>
</td></tr> 
<tr><td><code id="predict.boral_+3A_predict.type">predict.type</code></td>
<td>
<p>The type of prediction to be made. Either takes value <code>"conditional"</code> in which case the prediction is made conditionally on the predicted latent variables and any random row effects in the model, or <code>"marginal"</code> in which case the prediction marginalizes (averages) over the latent variables and random row effects in the model. Defaults to <code>"conditional"</code>.</p>
</td></tr>  
<tr><td><code id="predict.boral_+3A_scale">scale</code></td>
<td>
<p>The type of prediction required. The default is on the scale of the linear predictors; the alternative <code>scale = "response"</code> is on the scale of the response variable. For example, if the binomial family is used, then the default predictions (and associated uncertainty intervals) provide probabilities on linear predictor scale, while <code>scale = "response"</code> gives the predicted probabilities between 0 and 1. 
</p>
<p>Note things are slightly more complicated for zero truncated distributions because the log-link connects the mean of the <em>untruncated</em> distribution to the linear predictor. Therefore if <code>scale = "link"</code>, then the linear predictor is returned. But if <code>scale = "response"</code>, then actual predicted mean is returned.</p>
</td></tr>
<tr><td><code id="predict.boral_+3A_est">est</code></td>
<td>
<p>A choice of either whether to print the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>) of the parameters.</p>
</td></tr>
<tr><td><code id="predict.boral_+3A_prob">prob</code></td>
<td>
<p>A numeric scalar in the interval (0,1) giving the target probability coverage of the intervals. Defaults to 0.95.</p>
</td></tr>   
<tr><td><code id="predict.boral_+3A_lv.mc">lv.mc</code></td>
<td>
<p>If the predictions are made marginalizing over the latent variables, then number of Monte-Carlo samples to take when performing the relevant integration.</p>
</td></tr>
<tr><td><code id="predict.boral_+3A_return.alllinpred">return.alllinpred</code></td>
<td>
<p>If <code>TRUE</code>, then the full array of predictions, on the linear predictor scale, across all MCMC samples is predicted. This is useful if the user wants to transform the predictions onto a different scale or for further manipulation, say. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predict.boral_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the Bayesian MCMC framework, predictions are based around the posterior predictive distribution, which is the integral of the quantity one wants to predict on, integrated or averaged over the posterior distribution of the parameters and latent variables. For example, on the linear predictor scale, predictions are made as,
</p>
<p style="text-align: center;"><code class="reqn">\eta_{ij} = \alpha_i + \beta_{0j} + \bm{x}^\top_i\bm{\beta}_j + \bm{z}^\top_i\bm{b}_j + \bm{u}^\top_i\bm{\theta}_j; \quad i = 1,\ldots,n; j = 1,\ldots,p,</code>
</p>

<p>where <code class="reqn">\beta_{0j} + \bm{x}^\top_i\bm{\beta}_j</code> is the component of the linear predictor due to the covariates <code class="reqn">\bm{X}</code> plus an intercept, <code class="reqn">\bm{z}^\top_i\bm{b}_j</code> is the component due to response-specific random intercept, <code class="reqn">\bm{u}^\top_i\bm{\theta}_j</code> is the component due to the latent variables, and <code class="reqn">\alpha_i</code> is the component due to one or more fixed or random row effects. Not all of these components may be included in the model, and the above is just representing the general case. 
</p>
<p>Note that for the above to work, one must have saved the MCMC samples in the fitted boral object, that is, set <code>save.model = TRUE</code> when fitting. 
</p>
<p>Two types of predictions are possible using this function:
</p>

<ul>
<li><p> The first type is <code>predict.type = "conditional"</code>, meaning predictions are made conditionally on the predicted latent variables and any (random) row effects and response-specific random intercepts included in the model. This is mainly used when predictions are made onto the <em>same</em> set of sites that the model was fitted to, although a <code>newX</code> can be supplied in this case if we want to extrapolate on to the same set of sites but under different environmental conditions. 
</p>
</li>
<li><p> The second type of prediction is <code>predict.type = "marginal"</code>, meaning predictions are made marginally or averaging over the latent variables and any (random) row effects and response-specific random intercepts included in the model. This is mainly used when predictions are made onto a <em>new</em> set of sites where the latent variables/row effects/response-specific random intercepts are unknown. Consequently, arguments <code>newX</code>, <code>newrow.ids</code> and <code>newranef.ids</code> are often supplied in such a setting since we are extrapolating to new observational units. The integration over the latent variables and random row effects is done via Monte-Carlo integration. Please note however that the integration is done on the linear predictor scale. 
</p>
</li></ul>

<p>More information on conditional versus marginal predictions in latent variable models can be found in Warton et al., (2015). In both cases, and if <code>return.alllinpred = FALSE</code>, the function returns a point prediction (either the posterior mean or median depending on <code>est</code>) and the lower and upper bounds of a (100<code class="reqn">\times</code><code>prob</code>) % interval of the posterior prediction. All of these quantities are calculated empirically based across the MCMC samples.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>linpred</code></td>
<td>
<p>A matrix containing posterior point predictions (either posterior mean or median depending on <code>est</code>), on the linear predictor scale.</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>A matrix containing the lower bound of the (100<code class="reqn">\times</code><code>prob</code>) % interval of the posterior predictions, on the linear predictor scale.</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>A matrix containing the upper bound of the (100<code class="reqn">\times</code><code>prob</code>) % interval of the posterior predictions, on the linear predictor scale.</p>
</td></tr>
<tr><td><code>all.linpred</code></td>
<td>
<p>If <code>return.alllinpred = TRUE</code>, then only an array of predicted linear predictions across all MCMC samples.</p>
</td></tr>
</table>


<h3>Warnings</h3>


<ul>
<li><p> Marginal predictions can take quite a while to construct due to the need to perform Monte-Carlo integration to marginalize over the latent variables and any random row effects in the model.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Gelman et al. (2013) Bayesian Data Analysis. CRC Press.
</p>
</li>
<li><p> Warton et al. (2015). So Many Variables: Joint Modeling in Community Ecology. Trends in Ecology and Evolution, 30, 766-779.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mvabund) ## Load a dataset from the mvabund package
library(mvtnorm) 
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


## Example 1 - model with two latent variables, random site effects, 
## 	and environmental covariates
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    row.eff = "random", lv.control = list(num.lv = 2), 
    mcmc.control = example_mcmc_control, save.model = TRUE,
    model.name = testpath)

## Predictions conditional on predicted latent variables
getcondpreds &lt;- predict(spiderfit_nb)

## Predictions marginal on latent variables, random row effects
## The intervals for these will generally be wider than the
##   conditional intervals.
getmargpreds &lt;- predict(spiderfit_nb, predict.type = "marginal")


## Now suppose you extrpolate to new sites
newX &lt;- rmvnorm(100, mean = rep(0,ncol(X)))

## Below won't work since conditional predictions are made to the same sites
#getcondpreds &lt;- predict(spiderfit_nb, newX = newX)

## Marginal predictions will work though, provided newrow.ids is set up 
## properly. For example,
new_row_ids &lt;- matrix(sample(1:28,100,replace=TRUE), 100, 1)
while(length(table(new_row_ids)) != 28) { 
    new_row_ids &lt;- matrix(sample(1:28,100,replace=TRUE), 100, 1)
    }
getmargpreds &lt;- predict(spiderfit_nb, newX = newX, predict.type = "marginal", 
     newrow.ids = new_row_ids)

     
## Example 1b - Similar to 1 except with no random site effects, 
## 	and a non-independence correlation structure for the latent variables
##      based on a fake distance matrix
fakedistmat &lt;- as.matrix(dist(1:n))
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
     lv.control = list(type = "squared.exponential", num.lv = 2, 
          distmat = fakedistmat), model.name = testpath, 
     mcmc.control = example_mcmc_control, save.model = TRUE)

getmargpreds &lt;- predict(spiderfit_nb, predict.type = "marginal", 
     distmat = fakedistmat)

## Now suppose you extrpolate to new sites
newfakedistmat &lt;- as.matrix(dist(1:100))

getmargpreds &lt;- predict(spiderfit_nb, newX = newX, 
     predict.type = "marginal", distmat = newfakedistmat)


## Example 1c - similar to 1 except instead of random site effects,
##   there are species-specific random intercepts at a so-called
##   "region" level
y &lt;- spider$abun
X &lt;- scale(spider$x)
spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    lv.control = list(num.lv = 2), 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath, 
    save.model = TRUE) 

## Predictions conditional on predicted latent variables and 
##   random intercepts
getcondpreds &lt;- predict(spiderfit_nb)

## Predictions marginal on latent variables, random intercepts
## The intervals for these will generally be wider than the
##   conditional intervals.
getmargpreds &lt;- predict(spiderfit_nb, predict.type = "marginal")

## Now suppose you extrpolate to new sites
newX &lt;- rmvnorm(100, mean = rep(0,ncol(X)))

## Marginal predictions will work though, provided newranef.ids is set up 
## properly. For example,
new_ranef_ids &lt;- matrix(sample(1:7,100,replace=TRUE), 100, 1)
getmargpreds &lt;- predict(spiderfit_nb, newX = newX, predict.type = "marginal",
     newranef.ids = new_ranef_ids)

     
## Example 2 - simulate count data, based on a model with two latent variables, 
## no site variables, with two traits and one environmental covariates 
library(mvtnorm)

n &lt;- 100; s &lt;- 50
X &lt;- as.matrix(scale(1:n))
colnames(X) &lt;- c("elevation")

traits &lt;- cbind(rbinom(s,1,0.5), rnorm(s)) 
## one categorical and one continuous variable
colnames(traits) &lt;- c("thorns-dummy","SLA")

simfit &lt;- list(true.lv = rmvnorm(n, mean = rep(0,2)), 
	lv.coefs = cbind(rnorm(s), rmvnorm(s, mean = rep(0,2)), 1), 
	traits.coefs = matrix(c(0.1,1,-0.5,0.1,0.5,0,-1,0.1), 2, byrow = TRUE))
rownames(simfit$traits.coefs) &lt;- c("beta0","elevation")
colnames(simfit$traits.coefs) &lt;- c("kappa0","thorns-dummy","SLA","sigma")

simy = create.life(true.lv = simfit$true.lv, lv.coefs = simfit$lv.coefs, X = X, 
	traits = traits, traits.coefs = simfit$traits.coefs, family = "normal") 


example_which_traits &lt;- vector("list",ncol(X)+1)
for(i in 1:length(example_which_traits)) 
     example_which_traits[[i]] &lt;- 1:ncol(traits)
fit_traits &lt;- boral(y = simy, X = X, traits = traits, 
     which.traits = example_which_traits, family = "normal", 
     lv.control = list(num.lv = 2), save.model = TRUE, 
     mcmc.control = example_mcmc_control,
     model.name = testpath)

     
## Predictions conditional on predicted latent variables   
getcondpreds &lt;- predict(fit_traits)     
     
## Predictions marginal on latent variables
## The intervals for these will generally be wider than the
##   conditional intervals.
getmargpreds &lt;- predict(fit_traits, predict.type = "marginal")

## End(Not run)

</code></pre>

<hr>
<h2 id='ranefsplot'>Caterpillar plots of response-specific random effects from a fitted model</h2><span id='topic+ranefsplot'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Constructs horizontal line plot (point estimate and HPD intervals), otherwise known as &quot;caterpillar plots&quot;, for the response-specific random intercept predictions in the fitted model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranefsplot(sel.spp, object, ordered = FALSE, est = "median", ...) 
	</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ranefsplot_+3A_sel.spp">sel.spp</code></td>
<td>
<p>A vector selecting which response' random intercept predictions are to be plotted. It can either be a numeric vector indexing the columns of <code>object$y</code> to be plotted, or a character vector with each being an element in <code>colnames(object$y)</code> indexing the names of the responses of the plotted. Default is <code>NULL</code>, in which case plots are done for all responses, one response at a time.</p>
</td></tr>
<tr><td><code id="ranefsplot_+3A_object">object</code></td>
<td>
<p>An object for class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="ranefsplot_+3A_ordered">ordered</code></td>
<td>
<p>If set to <code>TRUE</code>, then the random intercept predictions in each caterpillar plot are plotted from smallest to largest. Defaults to <code>FALSE</code>, in which case the caterpillar plot is simply ordered as per the rows of <code>object$ranef.ids</code>.</p>
</td></tr>
<tr><td><code id="ranefsplot_+3A_est">est</code></td>
<td>
<p>A choice of either the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>), which are then used as the point estimates in the lines. Default is posterior median.</p>
</td></tr>
<tr><td><code id="ranefsplot_+3A_...">...</code></td>
<td>
<p>Additional graphical options to be included in. These include values for <br /> <code>cex, cex.lab, cex.axis, cex.main, lwd</code>, and so on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each response (column of the response matrix) and random intercept, the horizontal line or &quot;caterpillar&quot; is constructed by first marking the point prediction (posterior mean or median) with an &quot;x&quot; symbol. Then the line is construed based on the lower and upper limits of the highest posterior density (HPD) intervals as found in <code>object$hpdintervals</code>. By default, these are 95% HPD intervals. To complete the plot, a vertical dotted line is drawn to denote the zero value. All HPD intervals that include zero are colored gray, while HPD intervals that exclude zero are colored black.
</p>
<p>By defaults, the plots are constructed one response at a time. That is, for a particular response, caterpillar plots of all the random intercepts (noting the number of plots is detemined by the number of random intercepts included in the model i.e., <code>ncol(object$ranef.ids</code>) are constructed on a single page. Then it moves onto the next response, and so on. If the user is only interested in plots from a subset of responses, then please make use of the <code>sel.spp</code> argument. This may be recommended especially since, in community ecology for example, the number of responses may be very large and so plotting all graphs may take a lot time.
</p>
<p>The graph is probably better explained by, well, plotting it using the toy example below! 
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coefsplot">coefsplot</a></code> for horizontal line or &quot;caterpillar plot&quot; of the regression coefficients corresponding to the covariate matrix (if applicable),
the help file for <code>ranef</code> function in the <code>lme4</code> package, for other examples of caterpillar plots of random effect predictions,
<code>caterplot</code> from the <code>mcmcplots</code> package, as well as the <code>ggpubr</code> package, for other, sexier caterpillar plots. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- scale(spider$x)
n &lt;- nrow(y)
p &lt;- ncol(y)

## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
     n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")

spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath) 

ranefsplot(sel.spp = 1:5, object = spiderfit_nb) 

ranefsplot(sel.spp = 1:5, object = spiderfit_nb, ordered = TRUE) 

ranefsplot(sel.spp = c("Alopacce","Zoraspin"), object = spiderfit_nb, ordered = TRUE) 

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.boral'>Summary of fitted boral object</h2><span id='topic+summary.boral'></span><span id='topic+print.summary.boral'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>A summary of the fitted boral objects including the type of model fitted e.g., error distribution, number of latent variables parameter estimates, and so on.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boral'
summary(object, est = "median", ...)

## S3 method for class 'summary.boral'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.boral_+3A_object">object</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="summary.boral_+3A_x">x</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
<tr><td><code id="summary.boral_+3A_est">est</code></td>
<td>
<p>A choice of either whether to print the posterior median (<code>est = "median"</code>) or posterior mean (<code>est = "mean"</code>) of the parameters.</p>
</td></tr>
<tr><td><code id="summary.boral_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Attributes of the model fitted, parameter estimates, and posterior probabilities of including individual and/or grouped coefficients in the model based on SSVS if appropriate.
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the fitting function on which <code>summary</code> is applied.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
    n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun

spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
     lv.control = list(num.lv = 2), row.eff = "fixed", 
     mcmc.control = example_mcmc_control, model.name = testpath)

summary(spiderfit_nb)

## End(Not run)
</code></pre>

<hr>
<h2 id='tidyboral'>Reformats output from a boral fit</h2><span id='topic+tidyboral'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Reformats estimates from a fitted boral model to be in a slightly tidier format, meaning everything is presented as a long data frame.</p>


<h3>Usage</h3>

<pre><code class='language-R'>tidyboral(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tidyboral_+3A_object">object</code></td>
<td>
<p>An object of class &quot;boral&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Formatting the output into a long data frame maybe useful if one wishes to take the estimated parameters (namely the posterior mean/median/interquartile range/standard deviation, and the lower and upper limits of the HPD intervals), and subsequently wrangle them for presentation purposes using packages from the <code>tidyverse</code> package e.g., Wickham and Henry (2018), construct plots from them using the <code>ggplot2</code> package (Wickham, 2016), and so on.
</p>
<p>It is important to note that this function is solely designed to format output from a fitted boral model relating to the estimated parameters. It does not an additional information like model call and MCMC samples. Please do NOT erase the original fitted model in place of this!
</p>


<h3>Value</h3>

<p>A a list containing the following components, where applicable:
</p>
<table>
<tr><td><code>lv.coefs</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the latent variable coefficients. This also includes the response-specific intercepts, and dispersion parameters if appropriate.</p>
</td></tr>
<tr><td><code>lv</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the latent variables.</p>
</td></tr>
<tr><td><code>lv.covparams</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions for the parameters characterizing the correlation structure of the latent variables when they are assumed to be non-independent across rows.</p>
</td></tr>
<tr><td><code>X.coefs</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the response-specific coefficients relating to the covariate matrix.</p>
</td></tr>
<tr><td><code>traits.coefs</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the coefficients and standard deviation relating to the species traits; please see <code><a href="#topic+about.traits">about.traits</a></code>.</p>
</td></tr>
<tr><td><code>cutoffs</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the common cutoffs for ordinal responses (please see the not-so-brief tangent on distributions above).</p>
</td></tr>
<tr><td><code>ordinal.sigma</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the standard deviation for the random intercept normal distribution corresponding to the ordinal response columns.</p>
</td></tr>
<tr><td><code>powerparam</code></td>
<td>
<p>A long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the common power parameter for tweedie responses (please see the not-so-brief tangent on distributions above).</p>
</td></tr>
<tr><td><code>row.coefs</code></td>
<td>
<p>A list with each element being a long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the row effects. The length of the list is equal to the number of row effects included i.e., <code>object$ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>row.sigma</code></td>
<td>
<p>A list with each element being a long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the standard deviation for the row random effects normal distribution. The length of the list is equal to the number of row effects included i.e., <code>object$ncol(row.ids)</code>.</p>
</td></tr>
<tr><td><code>ranef.coefs</code></td>
<td>
<p>A list with each element being a long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the response-specific random intercepts. The length of the list is equal to the number of row effects included i.e., <code>ncol(object$ranef.ids)</code>.</p>
</td></tr>
<tr><td><code>ranef.sigma</code></td>
<td>
<p>A list with each element being a long format data frame containing the mean/median/standard deviation/interquartile range of the posterior distributions of the standard deviation for the response-specific random intercept normal distributions. The length of the list is equal to the number of row effects included i.e., <code>object$ncol(ranef.ids)</code>.</p>
</td></tr>
<tr><td><code>ssvs.indcoefs</code></td>
<td>
<p>A long format data frame containing posterior probabilities and associated standard deviation for individual SSVS of coefficients in the covariate matrix.</p>
</td></tr>
<tr><td><code>ssvs.gpcoefs</code></td>
<td>
<p>A long format data frame containing posterior probabilities and associated standard deviation for group SSVS of coefficients in the covariate matrix.</p>
</td></tr>
<tr><td><code>ssvs.traitscoefs</code></td>
<td>
<p>A long format data frame containing posterior probabilities and associated standard deviation for individual SSVS of coefficients relating to species traits.</p>
</td></tr>
<tr><td><code>hpdintervals</code></td>
<td>
<p>A list containing long format data frames corresponding to the lower and upper bounds of highest posterior density (HPD) intervals for all the parameters indicated above. Please see <code><a href="#topic+get.hpdintervals">get.hpdintervals</a></code> for more details.</p>
</td></tr>
</table>


<h3>Warnings</h3>


<ul>
<li><p> This function is solely designed to format output from a fitted boral model relating to the estimated parameters. It does not an additional information like model call and MCMC samples. Please do NOT erase the original fitted model in place of this!
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui [aut, cre], 
     Wade Blanchard [aut]
</p>
<p>Maintainer: Francis K.C. Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Wickham, H. (2016). ggplot2: elegant graphics for data analysis. Springer.
</p>
</li>
<li><p> Wickham, H., &amp; Henry, L. (2017). Tidyr: Easily tidy data with &lsquo;spread ()&rsquo; and &lsquo;gather ()&rsquo; functions.</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+boral">boral</a></code> for the fitting function on which <code>tidyboral</code> can be applied.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## NOTE: The values below MUST NOT be used in a real application;
## they are only used here to make the examples run quick!!!
example_mcmc_control &lt;- list(n.burnin = 10, n.iteration = 100, 
    n.thin = 1)

testpath &lt;- file.path(tempdir(), "jagsboralmodel.txt")


library(mvabund) ## Load a dataset from the mvabund package
data(spider)
y &lt;- spider$abun
X &lt;- spider$x

spiderfit_nb &lt;- boral(y, family = "negative.binomial", 
     lv.control = list(num.lv = 2), row.eff = "fixed", 
     mcmc.control = example_mcmc_control, model.name = testpath)

spiderfit_nb_tidy &lt;- tidyboral(spiderfit_nb)


spiderfit_nb &lt;- boral(y, X = X, family = "negative.binomial", 
    ranef.ids = data.frame(region = rep(1:7,each=4)), 
    mcmc.control = example_mcmc_control, model.name = testpath) 

spiderfit_nb_tidy &lt;- tidyboral(spiderfit_nb)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
