<!DOCTYPE html><html><head><title>Help for package bigdatadist</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bigdatadist}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Ausmale'><p>Australian Male Mortality Rates</p></a></li>
<li><a href='#entropy'><p>Entropy Computation</p></a></li>
<li><a href='#entropy.fd'><p>Functional Entropy Measures</p></a></li>
<li><a href='#fdframe'><p>Functional Data Frame</p></a></li>
<li><a href='#gmdepth'><p>Generalized Mahalanobis Depth and Distance</p></a></li>
<li><a href='#gmdepth.fd'><p>Generalized Mahalanobis Kernel Depth and Distance for Functional Data</p></a></li>
<li><a href='#kmdepth.fd'><p>Kernel Mahalanobis Depth for Functional Data</p></a></li>
<li><a href='#levelsetdist'><p>Level Set Distances</p></a></li>
<li><a href='#merval'><p>Merval Index</p></a></li>
<li><a href='#rkhs'><p>RKHS Representation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-09-23</td>
</tr>
<tr>
<td>Title:</td>
<td>Distances for Machine Learning and Statistics in the Context of
Big Data</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to compute distances between probability measures or any other data object than can be posed in this way, entropy measures for samples of curves, distances and depth measures for functional data, and the Generalized Mahalanobis Kernel distance for high dimensional data. For further details about the metrics please refer to Martos et al (2014) &lt;<a href="https://doi.org/10.3233%2FIDA-140706">doi:10.3233/IDA-140706</a>&gt;; Martos et al (2018) &lt;<a href="https://doi.org/10.3390%2Fe20010033">doi:10.3390/e20010033</a>&gt;; Hernandez et al (2018, submitted); Martos et al (2018, submitted).</td>
</tr>
<tr>
<td>Author:</td>
<td>Gabriel Martos [aut, cre],
  Nicolas Hernandez [aut]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gabriel Martos &lt;gmartos@utdt.edu&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, FNN, rrcov, pdist</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-09-24 13:14:03 UTC; gmartos</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-09-24 13:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='Ausmale'>Australian Male Mortality Rates</h2><span id='topic+Ausmale'></span>

<h3>Description</h3>

<p>The data consist of set of measurements across years of male mortality rates 
in Australia from package <code>fds</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ausmale</code></pre>


<h3>Format</h3>

<p>A list with years in the first component and a 101 times 103 matrix, 
years in rows and cohorts in columns, in the second component.</p>


<h3>Source</h3>

<p>fds</p>

<hr>
<h2 id='entropy'>Entropy Computation</h2><span id='topic+entropy'></span>

<h3>Description</h3>

<p>This function allows you to compute the family of alpha entropy 
as stated in Martos et al (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy(X,alpha=2,k.neighbor,scale=FALSE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="entropy_+3A_x">X</code></td>
<td>
<p>data in a matrix where variables are in columns and observations are in rows.</p>
</td></tr>
<tr><td><code id="entropy_+3A_alpha">alpha</code></td>
<td>
<p>a parameter defining the entropy function.</p>
</td></tr>
<tr><td><code id="entropy_+3A_k.neighbor">k.neighbor</code></td>
<td>
<p>number of neighbour points to consider in the computation of entropy.</p>
</td></tr>
<tr><td><code id="entropy_+3A_scale">scale</code></td>
<td>
<p>logical variable indicating if scaling is required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the alpha entropy and the local alpha entropy 
(see reference for further details) of a data set using a non parametric 
density estimator.
</p>


<h3>Value</h3>

<table>
<tr><td><code>local.entropy</code></td>
<td>
<p>local entropy relative to each point in the sample.</p>
</td></tr>
<tr><td><code>entropy</code></td>
<td>
<p>estimated entropy.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Martos, G. et al (2018): Entropy Measures for Stochastic Processes with 
Applications in Functional Anomaly Detection. Entropy 20(1): 33 (2018).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(MASS);
data = mvrnorm(100,c(0,0),diag(2));
entropy(data, alpha = 2, k.neighbor = 10, scale = FALSE)
</code></pre>

<hr>
<h2 id='entropy.fd'>Functional Entropy Measures</h2><span id='topic+entropy.fd'></span>

<h3>Description</h3>

<p>This function allows you to compute the family of alpha-Entropy for 
functional data as stated in Martos et al (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy.fd(fdframe, gamma = 1, kerfunc="rbf",
       kerpar = list(sigma = 1, bias=0,degree=2), 
       alpha=2,d=2,resol,k.neighbor) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="entropy.fd_+3A_fdframe">fdframe</code></td>
<td>
<p>functional data frame <code>fdframe</code> object.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_gamma">gamma</code></td>
<td>
<p>regularization parameter.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_kerfunc">kerfunc</code></td>
<td>
<p>kernel function (<code>rbf</code> or <code>poly</code>) to be used.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_kerpar">kerpar</code></td>
<td>
<p>a list of kernel parameters where sigma is the scale with both kernels.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_alpha">alpha</code></td>
<td>
<p>Entropy parameter.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_d">d</code></td>
<td>
<p>Dimension truncation in the Reproducing Kernel Hilbert Space representation.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_resol">resol</code></td>
<td>
<p>number of level sets used to compute the functional entropy.</p>
</td></tr>
<tr><td><code id="entropy.fd_+3A_k.neighbor">k.neighbor</code></td>
<td>
<p>number of points to estimate the support of the distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the entropy of a stochastic process. To this aim,
the raw functional data is projected onto a Reproducing Kernel Hilbert Space,
and the entropy is estimated using the coefficient of these functions. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>local.entropy</code></td>
<td>
<p>local entropy relative to each curve in the sample.</p>
</td></tr>
<tr><td><code>entropy</code></td>
<td>
<p>estimated entropy of the the set of functions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hernandez and Martos</p>


<h3>References</h3>

<p>Martos, G. et al (2018). Entropy Measures for Stochastic Processes with 
Applications in Functional Anomaly Detection. Entropy 20(1), 33 (2018).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ausmale); t &lt;- Ausmale[[1]]
t &lt;- as.numeric(( t - min(t) ) / length(t))
raw.data &lt;- fdframe(t=t, Y=Ausmale[[2]])

entropy.fd(raw.data,gamma=0.0001,kerfunc="rbf",kerpar=c(10), 
                        alpha=2, k.neighbor=15)
</code></pre>

<hr>
<h2 id='fdframe'>Functional Data Frame</h2><span id='topic+fdframe'></span><span id='topic+fdframe.default'></span>

<h3>Description</h3>

<p>This function is used to create multivariate functional data frame
objects to be used in combination with the functions in the package
<code>bigdatadist</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdframe(t, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fdframe_+3A_t">t</code></td>
<td>
<p>abscissa values at which observations took place.</p>
</td></tr>
<tr><td><code id="fdframe_+3A_y">Y</code></td>
<td>
<p>matrix with functions in columns and observations in rows.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>t = 1:10; Y = cbind(sin(t),cos(t))
fdata = fdframe(t,Y)
plot(fdata, xlab='Time', ylab='')
</code></pre>

<hr>
<h2 id='gmdepth'>Generalized Mahalanobis Depth and Distance</h2><span id='topic+gmdepth'></span>

<h3>Description</h3>

<p>This function allows you to compute the Generalized Kernel Mahalanobis depth
measure as stated in Hernandez et al (2018, submitted) and the Generalized 
Mahalanobis distance in Martos et al (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmdepth(A,b,resol,k.neighbor) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmdepth_+3A_a">A</code></td>
<td>
<p>data matrix where variables in columns, observations in rows.</p>
</td></tr>
<tr><td><code id="gmdepth_+3A_b">b</code></td>
<td>
<p>a new point in the support of the distribution to evaluate the depth. 
If omitted, the function compute the distances and depth between all 
points in the sample.</p>
</td></tr>
<tr><td><code id="gmdepth_+3A_resol">resol</code></td>
<td>
<p>resolution level, i.e. number of density level sets to consider.</p>
</td></tr>
<tr><td><code id="gmdepth_+3A_k.neighbor">k.neighbor</code></td>
<td>
<p>number of local neighbours to estimate the support.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>depth</code></td>
<td>
<p>the generalized Mahalanobis depth measure.</p>
</td></tr>
<tr><td><code>distance</code></td>
<td>
<p>the generalized Mahalanobis distance measure.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hernandez and Martos</p>


<h3>References</h3>

<p>Hernandez N. et al (2018). Generalized Mahalanobis depth functions (submitted).
Martos, G. et al (2014). Generalizing the Mahalanobis distance via density
kernels. Inteligent Data Anal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(MASS)
set.seed(1)
A=mvrnorm(450,c(0,0),Sigma=diag(2))
b=mvrnorm(50,c(10,10),Sigma=diag(c(0.1,0.1)))
C=rbind(A,b)
plot(C, pch=20, col=c(rep('black',450),rep('red',50)),
                      xlab='x1',ylab='x2')

gmd.fit = gmdepth(A=C)
depth    = gmd.fit$depth
distance = gmd.fit$distance
plot(depth,distance, pch=20, 
           col=c(rep('black',450),rep('red',50)))
gmdepth(A=A,b=mvrnorm(1,c(0,0),Sigma=diag(2))) 

</code></pre>

<hr>
<h2 id='gmdepth.fd'>Generalized Mahalanobis Kernel Depth and Distance for Functional Data</h2><span id='topic+gmdepth.fd'></span>

<h3>Description</h3>

<p>This function allows you to compute the Generalized Kernel Mahalanobis 
depth measure as stated in Hernandez et al (2018, submitted) and the 
Generalized Mahalanobis distance in Martos et al (2014), for functional
data represented in a Reproducing Kernel Hilbert Space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmdepth.fd(fdframe, gamma = 1,kerfunc="rbf" , 
   kerpar=list(sigma=1,bias=0,degree=2),d=2,resol,k.neighbor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmdepth.fd_+3A_fdframe">fdframe</code></td>
<td>
<p>an <code>fdframe</code> object storing raw functional data.</p>
</td></tr>
<tr><td><code id="gmdepth.fd_+3A_gamma">gamma</code></td>
<td>
<p>regularization parameter.</p>
</td></tr>
<tr><td><code id="gmdepth.fd_+3A_kerfunc">kerfunc</code></td>
<td>
<p>kernel function to be used. </p>
</td></tr>
<tr><td><code id="gmdepth.fd_+3A_kerpar">kerpar</code></td>
<td>
<p>a list of kernel parameters where sigma is the scale 
with both kernels.</p>
</td></tr>
<tr><td><code id="gmdepth.fd_+3A_d">d</code></td>
<td>
<p>truncation parameter in the Reproducing Kernel Hilbert Space representation.</p>
</td></tr>
<tr><td><code id="gmdepth.fd_+3A_resol">resol</code></td>
<td>
<p>resolution level to estimate the generalized 
Mahalanobis distance.</p>
</td></tr>
<tr><td><code id="gmdepth.fd_+3A_k.neighbor">k.neighbor</code></td>
<td>
<p>number of neighbours to estimate the support 
of the disitribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>depth</code></td>
<td>
<p>the generalized Mahalanobis depth measure for the 
curves in the sample.</p>
</td></tr>
<tr><td><code>distance</code></td>
<td>
<p>the generalized Mahalanobis distance for the 
curves in the sample.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hernandez and Martos</p>


<h3>References</h3>

<p>Hernandez N. et al (2018, submitted). Generalized Mahalanobis depth functions.
Martos, G. et al (2014). Generalizing the Mahalanobis distance via density 
kernels. Inteligent Data Anal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ausmale); t &lt;- Ausmale[[1]]
t = as.numeric(( t - min(t) ) / length(t))
raw.data = fdframe(t=t, Y=Ausmale[[2]])

gmd.fit.fd = gmdepth.fd(raw.data,gamma=0.001,
            kerfunc="rbf",kerpar=list(sigma = 10))

gmd.fit.fd$distance
gmd.fit.fd$depth

rbPal &lt;- colorRampPalette(c('red','black'))
color = rbPal(5)[as.numeric(cut(gmd.fit.fd$depth,breaks = 5))]
plot(rkhs(raw.data,gamma=0.0001,kerfunc="rbf",kerpar=list(sigma = 10)),
 col = color, xlab='time',ylab='')
</code></pre>

<hr>
<h2 id='kmdepth.fd'>Kernel Mahalanobis Depth for Functional Data</h2><span id='topic+kmdepth.fd'></span>

<h3>Description</h3>

<p>This function allows you to compute the Generalized Kernel Mahalanobis depth measure for a sample of functional data as stated in  Hernandez et al (2018, submitted).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kmdepth.fd(fdframe, gamma = 1, kerfunc = "rbf" ,
                        kerpar = list(sigma = 1, bias = 0, degree = 2) ,
                        d = 2 , robust=TRUE , h=0.1 , nsamp=250)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kmdepth.fd_+3A_fdframe">fdframe</code></td>
<td>
<p>an <code>fdframe</code> object storing raw functional data.</p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_gamma">gamma</code></td>
<td>
<p>regularization parameter.</p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_kerfunc">kerfunc</code></td>
<td>
<p>kernel function to be used. </p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_kerpar">kerpar</code></td>
<td>
<p>a list of kernel parameters where sigma is the scale 
with both kernels.</p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_d">d</code></td>
<td>
<p>truncation parameter in the Reproducing Kernel Hilbert Space representation.</p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_robust">robust</code></td>
<td>
<p>TRUE if the covariance matrix is estimated through Robust Maximum Likelihood method.</p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_h">h</code></td>
<td>
<p>numeric parameter controlling the a-prioir precentage 
of outliers in the sample (value between 0 and 1, by def = 0.1).</p>
</td></tr>
<tr><td><code id="kmdepth.fd_+3A_nsamp">nsamp</code></td>
<td>
<p>number of subsets used for initial estimates (by def = 250).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>depth</code></td>
<td>
<p>the kernel-mahalanobis depth measure for the 
curves in the sample.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hernandez and Martos</p>


<h3>References</h3>

<p>Hernandez N. et al (2018, submitted). Generalized Mahalanobis depth functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ausmale); t &lt;- Ausmale[[1]]
t = as.numeric(( t - min(t) ) / length(t))
raw.data = fdframe(t=t, Y=Ausmale[[2]])

kmd.fit.fd = kmdepth.fd(raw.data, gamma = 0.0001, kerfunc = "rbf" ,
                        kerpar = list(sigma = 10) , d = 2 , robust=TRUE)  

kmd.fit.fd$depth

rbPal &lt;- colorRampPalette(c('red','black'))
color = rbPal(5)[as.numeric(cut(kmd.fit.fd$depth,breaks = 5))]
plot(rkhs(raw.data,gamma=0.0001,kerfunc="rbf",kerpar=list(sigma = 10)),
 col = color, xlab='time',ylab='')
</code></pre>

<hr>
<h2 id='levelsetdist'>Level Set Distances</h2><span id='topic+levelsetdist'></span>

<h3>Description</h3>

<p>This function allows you to compute the alpha level set distances as proposed
in Martos et al. Nomparametric distances for probability measures with 
applications, 2018 (submitted).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>levelsetdist(A,B,n.level=10,k.neighbor=10) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="levelsetdist_+3A_a">A</code></td>
<td>
<p>data set in a matrix where variables are in columns and 
observations are in rows.</p>
</td></tr>
<tr><td><code id="levelsetdist_+3A_b">B</code></td>
<td>
<p>data set in a matrix where variables are in columns and 
observations are in rows.</p>
</td></tr>
<tr><td><code id="levelsetdist_+3A_n.level">n.level</code></td>
<td>
<p>the number of level sets to consider for distance computation.</p>
</td></tr>
<tr><td><code id="levelsetdist_+3A_k.neighbor">k.neighbor</code></td>
<td>
<p>number of neighbour points to consider in the estimation 
of the support of the distribution on each class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the alpha level set distance between two (samples from)
different probability measures. Details about the distance and the criterion
to fix its hyperparameter can be found in Martos et al (2018, submitted).
</p>


<h3>Value</h3>

<table>
<tr><td><code>distance</code></td>
<td>
<p>distance estimation between the two data sets or distributions.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Martos, G. et al (2018): Nomparametric distances for probability measures
with applications in classification. J. of Calssification, 2018 (submitted).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(MASS);
set.seed(1)
A = mvrnorm(100,c(0,0),diag(2));  B = mvrnorm(150,c(1,1),diag(2)); 
levelsetdist(A, B)
</code></pre>

<hr>
<h2 id='merval'>Merval Index</h2><span id='topic+merval'></span>

<h3>Description</h3>

<p>The data consist of an low and high values of the Merval Index stock market 
from Argentina; the data were gathered from Yahoo Finance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merval</code></pre>


<h3>Format</h3>

<p>A dataframe with 5269 observations with daily minimum, maximum, 
open and close index values.</p>


<h3>Source</h3>

<p>Yahoo Finance</p>

<hr>
<h2 id='rkhs'>RKHS Representation</h2><span id='topic+rkhs'></span>

<h3>Description</h3>

<p>This function allows you to fit discrete functional data (fdframe) as 
functions in RKHS solving a regularization problem as stated in Munoz (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rkhs(fdframe, gamma=1, kerfunc='rbf', 
            kerpar=list(sigma=1, bias=0, degree=2))</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rkhs_+3A_fdframe">fdframe</code></td>
<td>
<p>functional data <code>fdframe</code> object.</p>
</td></tr>
<tr><td><code id="rkhs_+3A_gamma">gamma</code></td>
<td>
<p>regularization parameter.</p>
</td></tr>
<tr><td><code id="rkhs_+3A_kerfunc">kerfunc</code></td>
<td>
<p>kernel function rbf or poly to be used.</p>
</td></tr>
<tr><td><code id="rkhs_+3A_kerpar">kerpar</code></td>
<td>
<p>a list of kernel parameters where sigma is the scale with both kernels.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>fdframe</code></td>
<td>
<p>raw data in an fdframe object.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>estimated functional data</p>
</td></tr> 
<tr><td><code>alpha</code></td>
<td>
<p>coefficients for the linear combination.</p>
</td></tr>
<tr><td><code>lambda.star</code></td>
<td>
<p>reduced coefficients for the linear combination.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hernandez and Martos</p>


<h3>References</h3>

<p>Munoz A. et al (2010). Representing functional data using support vector 
machines. Pattern recognition letters, 31(6). 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(merval); t &lt;- as.Date(merval[1:100,1])
t &lt;- as.numeric(( t - min(t) ) / 154)
raw.data &lt;-fdframe(t = t, Y = merval[1:100,2:5])
plot(raw.data, xlab='time', ylab='Merval raw data')

f.data &lt;- rkhs(raw.data, gamma = 0.001, kerpar = list(sigma = 8))

print(f.data)

plot(f.data, xlab='time', ylab='Merval data')

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
