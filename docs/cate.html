<!DOCTYPE html><html><head><title>Help for package cate</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cate}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjust.latent'><p>Adjust for latent factors, after rotationn</p></a></li>
<li><a href='#cate'><p>The main function for confounder adjusted testing</p></a></li>
<li><a href='#cate-package'><p>High dimensional factor analysis and confounder adjusted testing and estimation (CATE)</p></a></li>
<li><a href='#check.rank'><p>Check linear dependence</p></a></li>
<li><a href='#EigenDiff'><p>the ed method to estimate the number of factors proposed by Onatski(2010)</p></a></li>
<li><a href='#est.confounder.num'><p>Estimate the number of confounders</p></a></li>
<li><a href='#fa.em'><p>Factor analysis via EM algorithm to maximize likelihood</p></a></li>
<li><a href='#fa.pc'><p>Factor analysis via principal components</p></a></li>
<li><a href='#factor.analysis'><p>Factor analysis</p></a></li>
<li><a href='#gen.sim.data'><p>Generate simulation data set</p></a></li>
<li><a href='#gender.sm'><p>Gender study dataset</p></a></li>
<li><a href='#IPOD'><p>changed IPOD function</p></a></li>
<li><a href='#leapp'><p>original leapp function only added the resOpt.scale(beta.t) return</p></a></li>
<li><a href='#parse.cate.formula'><p>Parse the formula in <code>cate</code>, and return a matrix of primary variables and a matrix of nuisance variables.</p></a></li>
<li><a href='#rlm.cate'><p>Robust linear regression</p></a></li>
<li><a href='#wrapper'><p>Wrapper functions for some previous methods</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>High Dimensional Factor Analysis and Confounder Adjusted Testing
and Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-06-22</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides several methods for factor analysis in high dimension (both n,p &gt;&gt; 1) and methods to adjust for possible confounders in multiple hypothesis testing.</td>
</tr>
<tr>
<td>biocViews:</td>
<td>sva</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, MASS, esaBcv, ruv, sva, corpcor, leapp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, ggplot2, gridExtra</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-06-23 09:36:43 UTC; qyzhao</td>
</tr>
<tr>
<td>Author:</td>
<td>Jingshu Wang [aut],
  Qingyuan Zhao [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Qingyuan Zhao &lt;qz280@cam.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-23 10:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjust.latent'>Adjust for latent factors, after rotationn</h2><span id='topic+adjust.latent'></span>

<h3>Description</h3>

<p>Adjust for latent factors, after rotationn
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust.latent(
  corr.margin,
  n,
  X.cov,
  Gamma,
  Sigma,
  method = c("rr", "nc", "lqs"),
  psi = psi.huber,
  nc = NULL,
  nc.var.correction = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust.latent_+3A_corr.margin">corr.margin</code></td>
<td>
<p>marginal correlations, p*d1 matrix</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_x.cov">X.cov</code></td>
<td>
<p>estimated second moment of X, d*d matrix</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_gamma">Gamma</code></td>
<td>
<p>estimated confounding effects, p*r matrix</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_sigma">Sigma</code></td>
<td>
<p>diagonal of the estimated noise covariance, p*1 vector</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_method">method</code></td>
<td>
<p>adjustment method</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_psi">psi</code></td>
<td>
<p>derivative of the loss function in robust regression, choices are
<code>psi.huber</code>, <code>psi.bisquare</code>and <code>psi.hampel</code></p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_nc">nc</code></td>
<td>
<p>position of the negative controls</p>
</td></tr>
<tr><td><code id="adjust.latent_+3A_nc.var.correction">nc.var.correction</code></td>
<td>
<p>correct asymptotic variance based on our formula</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function essentially runs a regression of <code>corr.margin</code> ~ <code>Gamma</code>.
The sample size <code>n</code> is needed to have the right scale.
</p>
<p>This function should only be called if you know what you are doing.
Most of the time you want to use the main function <code><a href="#topic+cate">cate</a></code> to adjust for confounders.
</p>


<h3>Value</h3>

<p>a list of objects
</p>

<dl>
<dt>alpha</dt><dd><p>estimated alpha, r*d1 matrix</p>
</dd>
<dt>beta</dt><dd><p>estimated beta, p*d1 matrix</p>
</dd>
<dt>beta.cov.row</dt><dd><p>estimated row covariance of <code>beta</code>, a length p vector</p>
</dd>
<dt>beta.cov.col</dt><dd><p>estimated column covariance of <code>beta</code>, a d1*d1 matrix</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+cate">cate</a></code>
</p>

<hr>
<h2 id='cate'>The main function for confounder adjusted testing</h2><span id='topic+cate'></span><span id='topic+cate.fit'></span>

<h3>Description</h3>

<p>The main function for confounder adjusted testing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cate(
  formula,
  X.data = NULL,
  Y,
  r,
  fa.method = c("ml", "pc", "esa"),
  adj.method = c("rr", "nc", "lqs", "naive"),
  psi = psi.huber,
  nc = NULL,
  nc.var.correction = TRUE,
  calibrate = TRUE
)

cate.fit(
  X.primary,
  X.nuis = NULL,
  Y,
  r,
  fa.method = c("ml", "pc", "esa"),
  adj.method = c("rr", "nc", "lqs", "naive"),
  psi = psi.huber,
  nc = NULL,
  nc.var.correction = TRUE,
  calibrate = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cate_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the known covariates including both primary variables and nuisance variables, which are seperated by <code>|</code>. The variables before <code>|</code> are primary variables and the variables after <code>|</code> are nuisance variables. It's OK if there is no nuisance variables, then <code>|</code> is not needed and <code>formula</code> becomes a typical formula with all the covariates considered primary. When there is confusion about where the intercept should be put, <code>cate</code> will include it in X.nuis.</p>
</td></tr>
<tr><td><code id="cate_+3A_x.data">X.data</code></td>
<td>
<p>the data frame used for <code>formula</code></p>
</td></tr>
<tr><td><code id="cate_+3A_y">Y</code></td>
<td>
<p>outcome, n*p matrix</p>
</td></tr>
<tr><td><code id="cate_+3A_r">r</code></td>
<td>
<p>number of latent factors, can be estimated using the function <code>est.confounder.num</code></p>
</td></tr>
<tr><td><code id="cate_+3A_fa.method">fa.method</code></td>
<td>
<p>factor analysis method</p>
</td></tr>
<tr><td><code id="cate_+3A_adj.method">adj.method</code></td>
<td>
<p>adjustment method</p>
</td></tr>
<tr><td><code id="cate_+3A_psi">psi</code></td>
<td>
<p>derivative of the loss function in robust regression</p>
</td></tr>
<tr><td><code id="cate_+3A_nc">nc</code></td>
<td>
<p>position of the negative controls,
if d0 &gt; 1, this should be a matrix with 2 columns</p>
</td></tr>
<tr><td><code id="cate_+3A_nc.var.correction">nc.var.correction</code></td>
<td>
<p>correct asymptotic variance based on our formula</p>
</td></tr>
<tr><td><code id="cate_+3A_calibrate">calibrate</code></td>
<td>
<p>if TRUE, use the Median and the Mean Absolute Deviation(MAD) to calibrate the test statistics</p>
</td></tr>
<tr><td><code id="cate_+3A_x.primary">X.primary</code></td>
<td>
<p>primary variables, n*d0 matrix or data frame</p>
</td></tr>
<tr><td><code id="cate_+3A_x.nuis">X.nuis</code></td>
<td>
<p>nuisance covarites, n*d1 matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ideally <code>nc</code> can either be a vector of numbers between 1 and p, if d0 = 1 or the negative controls are the same for every treatment variable, or a 2-column matrix specifying which positions of beta are known to be zero. But this is yet implemented.
</p>


<h3>Value</h3>

<p>a list of objects
</p>

<dl>
<dt>alpha</dt><dd><p>estimated alpha, r*d1 matrix</p>
</dd>
<dt>alpha.p.value</dt><dd><p>asymptotic p-value for the global chi squared test of alpha, a vector of length d1</p>
</dd>
<dt>beta</dt><dd><p>estimated beta, p*d1 matrix</p>
</dd>
<dt>beta.cov.row</dt><dd><p>estimated row covariance of <code>beta</code>, a length p vector</p>
</dd>
<dt>beta.cov.col</dt><dd><p>estimated column covariance of <code>beta</code>, a d1*d1 matrix</p>
</dd>
<dt>beta.t</dt><dd><p>asymptotic z statistics for <code>beta</code></p>
</dd>
<dt>beta.p.value</dt><dd><p>asymptotic p-values for beta, based on <code>beta.t</code></p>
</dd>
<dt>Y.tilde</dt><dd><p>the transformed outcome matrix, an n*p matrix</p>
</dd>
<dt>Gamma</dt><dd><p>estimated factor loadings, p*r matrix</p>
</dd>
<dt>Z</dt><dd><p>estimated latent factors</p>
</dd>
<dt>Sigma</dt><dd><p>estimated noise variance matrix, a length p vector</p>
</dd>
</dl>



<h3>Functions</h3>


<ul>
<li> <p><code>cate.fit</code>: Basic computing function called by <code>cate</code>
</p>
</li></ul>


<h3>References</h3>


<p>J. Wang, Q. Zhao, T. Hastie, and A. B. Owen (2017). Confounder adjustment in multiple testing. Annals of Statistics, 45(5), 1863&ndash;1894.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrapper">wrapper</a></code> for wrapper functions of some existing methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## simulate a dataset with 100 observations, 1000 variables and 5 confounders
data &lt;- gen.sim.data(n = 100, p = 1000, r = 5)
X.data &lt;- data.frame(X1 = data$X1)

## linear regression without any adjustment
output.naive &lt;- cate(~ X1 | 1, X.data, Y = data$Y, r = 0, adj.method = "naive")
## confounder adjusted linear regression
output &lt;- cate(~ X1 | 1, X.data, Y = data$Y, r = 5)
## plot the histograms of unadjusted and adjusted regression statistics
par(mfrow = c(1, 2))
hist(output.naive$beta.t)
hist(output$beta.t)

## simulate a dataset with 100 observations, 1000 variables and 5 confounders
data &lt;- gen.sim.data(n = 100, p = 1000, r = 5)
## linear regression without any adjustment
output.naive &lt;- cate.fit(X.primary = data$X1, X.nuis = NULL, Y = data$Y,
                         r = 0, adj.method = "naive")
## confounder adjusted linear regression
output &lt;- cate.fit(X.primary = data$X1, X.nuis = NULL, Y = data$Y, r = 5)
## plot the histograms of unadjusted and adjusted regression statistics
par(mfrow = c(1, 2))
hist(output.naive$beta.t)
hist(output$beta.t)

</code></pre>

<hr>
<h2 id='cate-package'>High dimensional factor analysis and confounder adjusted testing and estimation (CATE)</h2><span id='topic+cate-package'></span>

<h3>Description</h3>

<p>Provides several methods for factor analysis in high dimension (both n,p &gt;&gt; 1) and methods to adjust for possible confounders in multiple hypothesis testing.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+factor.analysis">factor.analysis</a></code>, <code><a href="#topic+cate">cate</a></code>
</p>

<hr>
<h2 id='check.rank'>Check linear dependence</h2><span id='topic+check.rank'></span>

<h3>Description</h3>

<p>Checks if <code>X.primary</code> has full rank and is linearly independent of <code>x.nuis</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.rank(X.primary, X.nuis)
</code></pre>


<h3>Details</h3>

<p>X.nuis is allowed to not have full rank.
</p>

<hr>
<h2 id='EigenDiff'>the ed method to estimate the number of factors proposed by Onatski(2010)</h2><span id='topic+EigenDiff'></span>

<h3>Description</h3>

<p>the ed method to estimate the number of factors proposed by Onatski(2010)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EigenDiff(Y, rmax = 20, niter = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EigenDiff_+3A_y">Y</code></td>
<td>
<p>outcome, n*p matrix</p>
</td></tr>
<tr><td><code id="EigenDiff_+3A_rmax">rmax</code></td>
<td>
<p>the maximum number of factors to consider. If the estimated number of factors is rmax,
then users are encouraged to increase rmax and run again. Default is 20.</p>
</td></tr>
</table>

<hr>
<h2 id='est.confounder.num'>Estimate the number of confounders</h2><span id='topic+est.confounder.num'></span><span id='topic+est.factor.num'></span>

<h3>Description</h3>

<p>Estimate the number of confounders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est.confounder.num(
  formula,
  X.data = NULL,
  Y,
  method = c("bcv", "ed"),
  rmax = 20,
  nRepeat = 20,
  bcv.plot = TRUE,
  log = ""
)

est.factor.num(
  Y,
  method = c("bcv", "ed"),
  rmax = 20,
  nRepeat = 12,
  bcv.plot = TRUE,
  log = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est.confounder.num_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the known covariates including both primary variables and nuisance variables, which are seperated by <code>|</code>. The variables before <code>|</code> are primary variables and the variables after <code>|</code> are nuisance variables. It's OK if there is no nuisance variables, then <code>|</code> is not needed and <code>formula</code> becomes a typical formula with all the covariates considered primary. When there is confusion about where the intercept should be put, <code>cate</code> will include it in X.nuis.</p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_x.data">X.data</code></td>
<td>
<p>the data frame used for <code>formula</code></p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_y">Y</code></td>
<td>
<p>outcome, n*p matrix</p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_method">method</code></td>
<td>
<p>method to estimate the number of factors. There are currently two choices,
&quot;ed&quot; is the eigenvalue difference method proposed by Onatski (2010) and &quot;bcv&quot; is the
bi-cross-validation method proposed by Owen and Wang (2015). &quot;bcv&quot; tends to estimate more
weak factors and takes longer time</p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_rmax">rmax</code></td>
<td>
<p>the maximum number of factors to consider. If the estimated number of factors is rmax,
then users are encouraged to increase rmax and run again. Default is 20.</p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_nrepeat">nRepeat</code></td>
<td>
<p>the number of repeats of bi-cross-validation. A larger nRepeat will result in a
more accurate estimate of the bcv error, but will need longer time to run.</p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_bcv.plot">bcv.plot</code></td>
<td>
<p>whether to plot the relative bcv error versus the number of estimated
ranks. The relative bcv error is the entrywise mean square error devided by the average of
the estimated noise variance.</p>
</td></tr>
<tr><td><code id="est.confounder.num_+3A_log">log</code></td>
<td>
<p>if <code>log = "y"</code>, then the y-axis of the bcv plot is in log scale.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>method</code> is &quot;ed&quot;, then return the estimated number of confounders/factors.
If <code>method</code> is &quot;bcv&quot;, then return the a list of objects
</p>

<dl>
<dt>r</dt><dd><p>estimated number of confounders/factors</p>
</dd>
<dt>errors</dt><dd><p>the relative bcv errors of length <code>1 + rmax</code></p>
</dd>
</dl>



<h3>Functions</h3>


<ul>
<li> <p><code>est.factor.num</code>: Estimate the number of factors
</p>
</li></ul>


<h3>References</h3>


<p>A. B. Owen and J. Wang (2015), Bi-cross-validation for factor analysis. Statistical Science, 31(1), 119&ndash;139.
</p>
<p>A. Onatski (2010), Determining the number of factors from empirical distribution of eigenvalues.
<em>The Review of Economics and Statistics</em> 92(4).

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example for est.confounder.num
data &lt;- gen.sim.data(n = 50, p = 50, r = 5)
X.data &lt;- data.frame(X1 = data$X1)
est.confounder.num(~ X1 | 1, X.data, data$Y, method = "ed")
est.confounder.num(~ X1 | 1, X.data, data$Y, method = "bcv")

## example for est.factor.num
n &lt;- 50
p &lt;- 100
r &lt;- 5
Z &lt;- matrix(rnorm(n * r), n, r)
Gamma &lt;- matrix(rnorm(p * r), p, r)
Y &lt;- Z %*% t(Gamma) + rnorm(n * p)

est.factor.num(Y, method = "ed")
est.factor.num(Y, method = "bcv")

</code></pre>

<hr>
<h2 id='fa.em'>Factor analysis via EM algorithm to maximize likelihood</h2><span id='topic+fa.em'></span>

<h3>Description</h3>

<p>Factor analysis via EM algorithm to maximize likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fa.em(Y, r, tol = 1e-06, maxiter = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fa.em_+3A_y">Y</code></td>
<td>
<p>data matrix, a n*p matrix</p>
</td></tr>
<tr><td><code id="fa.em_+3A_r">r</code></td>
<td>
<p>number of factors</p>
</td></tr>
<tr><td><code id="fa.em_+3A_tol">tol</code></td>
<td>
<p>a tolerance scale of change of log-likelihood for convergence in the EM iterations</p>
</td></tr>
<tr><td><code id="fa.em_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum iterations</p>
</td></tr>
</table>


<h3>References</h3>


<p>Bai, J. and Li, K. (2012). Statistical analysis of factor models of high dimension. <em>The Annals of Statistics 40</em>, 436-465.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+factor.analysis">factor.analysis</a></code> for the main function.
</p>

<hr>
<h2 id='fa.pc'>Factor analysis via principal components</h2><span id='topic+fa.pc'></span>

<h3>Description</h3>

<p>Factor analysis via principal components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fa.pc(Y, r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fa.pc_+3A_y">Y</code></td>
<td>
<p>data matrix, a n*p matrix</p>
</td></tr>
<tr><td><code id="fa.pc_+3A_r">r</code></td>
<td>
<p>number of factors</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+factor.analysis">factor.analysis</a></code> for the main function.
</p>

<hr>
<h2 id='factor.analysis'>Factor analysis</h2><span id='topic+factor.analysis'></span>

<h3>Description</h3>

<p>The main function for factor analysis with potentially high dimensional variables.
Here we implement some recent algorithms that is optimized for the high dimensional problem where
the number of samples n is less than the number of variables p.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factor.analysis(Y, r, method = c("ml", "pc", "esa"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factor.analysis_+3A_y">Y</code></td>
<td>
<p>data matrix, a n*p matrix</p>
</td></tr>
<tr><td><code id="factor.analysis_+3A_r">r</code></td>
<td>
<p>number of factors</p>
</td></tr>
<tr><td><code id="factor.analysis_+3A_method">method</code></td>
<td>
<p>algorithm to be used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three methods are quasi-maximum likelihood (ml),
principal component analysis (pc),
and factor analysis using an early stopping criterion (esa).
</p>
<p>The ml is iteratively solved the Expectation-Maximization algorithm
using the PCA solution as the initial value.
See Bai and Li (2012) and for more details. For the esa method, see
Owen and Wang (2015) for more details.
</p>


<h3>Value</h3>

<p>a list of objects
</p>

<dl>
<dt>Gamma</dt><dd><p>estimated factor loadings</p>
</dd>
<dt>Z</dt><dd><p>estimated latent factors</p>
</dd>
<dt>Sigma</dt><dd><p>estimated noise variance matrix</p>
</dd>
</dl>



<h3>References</h3>


<p>Bai, J. and Li, K. (2012). Statistical analysis of factor models of high dimension. <em>The Annals of Statistics 40</em>, 436-465.
Owen, A. B. and Wang, J. (2015). Bi-cross-validation for factor analysis. <em>arXiv:1503.03515</em>.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+fa.pc">fa.pc</a></code>, <code><a href="#topic+fa.em">fa.em</a></code>, <code><a href="esaBcv.html#topic+ESA">ESA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a factor model
n &lt;- 100
p &lt;- 1000
r &lt;- 5
Z &lt;- matrix(rnorm(n * r), n, r)
Gamma &lt;- matrix(rnorm(p * r), p, r)
Y &lt;- Z %*% t(Gamma) + rnorm(n * p)

## to check the results, verify the true factors are in the linear span of the estimated factors.
pc.results &lt;- factor.analysis(Y, r = 5, "pc")
sapply(summary(lm(Z ~ pc.results$Z)), function(x) x$r.squared)

ml.results &lt;- factor.analysis(Y, r = 5, "ml")
sapply(summary(lm(Z ~ ml.results$Z)), function(x) x$r.squared)

esa.results &lt;- factor.analysis(Y, r = 5, "esa")
sapply(summary(lm(Z ~ esa.results$Z)), function(x) x$r.squared)

</code></pre>

<hr>
<h2 id='gen.sim.data'>Generate simulation data set</h2><span id='topic+gen.sim.data'></span>

<h3>Description</h3>

<p><code>gen.sim.data</code> generates data from the following model
Y = X_0 Beta_0^T + X_1 Beta_1^T + Z Gamma^T + E Sigma^1/2,
Z|X_0, X_1 = X_0 Alpha_0^T + X_1 Alpha_1^T + D,
cov(X_0, X_1) ~ Sigma_X
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.sim.data(
  n,
  p,
  r,
  d0 = 0,
  d1 = 1,
  X.dist = c("binary", "normal"),
  alpha = matrix(0.5, r, d0 + d1),
  beta = NULL,
  beta.strength = 1,
  beta.nonzero.frac = 0.05,
  Gamma = NULL,
  Gamma.strength = sqrt(p),
  Gamma.beta.cor = 0,
  Sigma = 1,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.sim.data_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_p">p</code></td>
<td>
<p>number of observed variables</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_r">r</code></td>
<td>
<p>number of confounders</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_d0">d0</code></td>
<td>
<p>number of nuisance regression covariates</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_d1">d1</code></td>
<td>
<p>number of primary regression covariates</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_x.dist">X.dist</code></td>
<td>
<p>the distribution of X, either &quot;binary&quot; or &quot;normal&quot;</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_alpha">alpha</code></td>
<td>
<p>association of X and Z, a r*d vector (d = d0 + d1)</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_beta">beta</code></td>
<td>
<p>treatment effects, a p*d vector</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_beta.strength">beta.strength</code></td>
<td>
<p>strength of beta</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_beta.nonzero.frac">beta.nonzero.frac</code></td>
<td>
<p>if beta is not specified, fraction of nonzeros in beta</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_gamma">Gamma</code></td>
<td>
<p>confounding effects, a p*r matrix</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_gamma.strength">Gamma.strength</code></td>
<td>
<p>strength of Gamma, more precisely the mean of square entries of Gamma * alpha</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_gamma.beta.cor">Gamma.beta.cor</code></td>
<td>
<p>the &quot;correlation&quot; (proportion of variance explained) of beta and Gamma</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_sigma">Sigma</code></td>
<td>
<p>noise variance, a p*p matrix or p*1 vector or a single real number</p>
</td></tr>
<tr><td><code id="gen.sim.data_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of objects
</p>

<dl>
<dt>X0</dt><dd><p>matrix of nuisance covariates</p>
</dd>
<dt>X1</dt><dd><p>matrix of primary covariates</p>
</dd>
<dt>Y</dt><dd><p>matrix Y</p>
</dd>
<dt>Z</dt><dd><p>matrix of confounders</p>
</dd>
<dt>alpha</dt><dd><p>regression coefficients between X and Z</p>
</dd>
<dt>beta</dt><dd><p>regression coefficients between X and Y</p>
</dd>
<dt>Gamma</dt><dd><p>coefficients between Z and Y</p>
</dd>
<dt>Sigma</dt><dd><p>noise variance</p>
</dd>
<dt>beta.nonzero.pos</dt><dd><p>the nonzero positions in beta</p>
</dd>
<dt>r</dt><dd><p>number of confounders</p>
</dd>
</dl>


<hr>
<h2 id='gender.sm'>Gender study dataset</h2><span id='topic+gender.sm'></span>

<h3>Description</h3>

<p>This genetics dataset is used to demonstrate the usage of <code>cate</code> in the vignette. It was originally extracted by Gagnon-Bartsch and Speed (2012) as an example of confounded multiple testing.
The data included in this package contains only 500 genes that are sampled from the original 12600 genes, besides keeping all the spike-in controls.
</p>


<h3>References</h3>

<p><a href="http://www-personal.umich.edu/~johanngb/ruv/">http://www-personal.umich.edu/~johanngb/ruv/</a>
Vawter, M. P., S. Evans, P. Choudary, H. Tomita, J. Meador-Woodruff, M. Molnar, J. Li, J. F. Lopez, R. Myers, D. Cox, et al. (2004). Gender-specific gene expression in post-mortem human brain: localization to sex chromosomes. Neuropsychopharmacology 29(2), 373-384.
Gagnon-Bartsch, J. A. and T. P. Speed (2012). Using control genes to correct for unwanted variation in microarray data. Biostatistics 13(3), 539-552.
</p>

<hr>
<h2 id='IPOD'>changed IPOD function</h2><span id='topic+IPOD'></span>

<h3>Description</h3>

<p>changed IPOD function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IPOD(X, Y, H, method = "hard", TOL = 1e-04, length.out = 50)
</code></pre>

<hr>
<h2 id='leapp'>original leapp function only added the resOpt.scale(beta.t) return</h2><span id='topic+leapp'></span>

<h3>Description</h3>

<p>original leapp function only added the resOpt.scale(beta.t) return
</p>


<h3>Usage</h3>

<pre><code class='language-R'>leapp(
  data,
  pred.prim,
  pred.covar = NULL,
  O = NULL,
  num.fac = "buja",
  method = "hard",
  sparse = TRUE,
  centered = FALSE,
  verbose = FALSE,
  perm.num = 50,
  TOL = 1e-04,
  length.out = 50
)
</code></pre>

<hr>
<h2 id='parse.cate.formula'>Parse the formula in <code>cate</code>, and return a matrix of primary variables and a matrix of nuisance variables.</h2><span id='topic+parse.cate.formula'></span>

<h3>Description</h3>

<p>Parse the formula in <code>cate</code>, and return a matrix of primary variables and a matrix of nuisance variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse.cate.formula(formula, X.data = NULL)
</code></pre>

<hr>
<h2 id='rlm.cate'>Robust linear regression</h2><span id='topic+rlm.cate'></span>

<h3>Description</h3>

<p>This function is slightly modified from rlm.default in the package MASS.
The only difference is an option of &quot;known.scale&quot;, which is an input vector of the same length of y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cate'
rlm(
  x,
  y,
  weights,
  ...,
  w = rep(1, nrow(x)),
  init = "ls",
  psi = psi.huber,
  scale.est = c("MAD", "Huber", "proposal 2"),
  k2 = 1.345,
  method = c("M", "MM"),
  wt.method = c("inv.var", "case"),
  maxit = 100,
  acc = 1e-04,
  test.vec = "resid",
  lqs.control = NULL,
  known.scale = NULL
)
</code></pre>

<hr>
<h2 id='wrapper'>Wrapper functions for some previous methods</h2><span id='topic+wrapper'></span><span id='topic+sva.wrapper'></span><span id='topic+ruv.wrapper'></span><span id='topic+leapp.wrapper'></span>

<h3>Description</h3>

<p>These functions provide an uniform interface to three existing methods: SVA, RUV, LEAPP
The wrapper functions transform the data into desired forms and call the corresponding functions in the package
sva, <a href="ruv.html#topic+ruv">ruv</a>, <a href="#topic+leapp">leapp</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sva.wrapper(
  formula,
  X.data = NULL,
  Y,
  r,
  sva.method = c("irw", "two-step"),
  B = 5
)

ruv.wrapper(
  formula,
  X.data = NULL,
  Y,
  r,
  nc,
  lambda = 1,
  ruv.method = c("RUV2", "RUV4", "RUVinv")
)

leapp.wrapper(
  formula,
  X.data = NULL,
  Y,
  r,
  search.tuning = F,
  ipod.method = c("hard", "soft")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrapper_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the known covariates including both primary variables and nuisance variables, which are seperated by <code>|</code>. The variables before <code>|</code> are primary variables and the variables after <code>|</code> are nuisance variables. It's OK if there is no nuisance variables, then <code>|</code> is not needed and <code>formula</code> becomes a typical formula with all the covariates considered primary. When there is confusion about where the intercept should be put, <code>cate</code> will include it in X.nuis.</p>
</td></tr>
<tr><td><code id="wrapper_+3A_x.data">X.data</code></td>
<td>
<p>the data frame used for <code>formula</code></p>
</td></tr>
<tr><td><code id="wrapper_+3A_y">Y</code></td>
<td>
<p>outcome, n*p matrix</p>
</td></tr>
<tr><td><code id="wrapper_+3A_r">r</code></td>
<td>
<p>number of latent factors, can be estimated using the function <code>est.confounder.num</code></p>
</td></tr>
<tr><td><code id="wrapper_+3A_sva.method">sva.method</code></td>
<td>
<p>parameter for <code><a href="sva.html#topic+sva">sva</a></code>.
whether to use an iterative reweighted algorithm (irw) or a two-step algorithm (two-step).</p>
</td></tr>
<tr><td><code id="wrapper_+3A_b">B</code></td>
<td>
<p>parameter for <code><a href="sva.html#topic+sva">sva</a></code>. the number of iterations of the irwsva algorithm</p>
</td></tr>
<tr><td><code id="wrapper_+3A_nc">nc</code></td>
<td>
<p>parameter for <a href="ruv.html#topic+ruv">ruv</a> functions: position of the negative controls</p>
</td></tr>
<tr><td><code id="wrapper_+3A_lambda">lambda</code></td>
<td>
<p>parameter for <code><a href="ruv.html#topic+RUVinv">RUVinv</a></code></p>
</td></tr>
<tr><td><code id="wrapper_+3A_ruv.method">ruv.method</code></td>
<td>
<p>either using <code><a href="ruv.html#topic+RUV2">RUV2</a></code>, <code><a href="ruv.html#topic+RUV4">RUV4</a></code> or
<code><a href="ruv.html#topic+RUVinv">RUVinv</a></code> functions</p>
</td></tr>
<tr><td><code id="wrapper_+3A_search.tuning">search.tuning</code></td>
<td>
<p>logical parameter for <code><a href="leapp.html#topic+leapp">leapp</a></code>, whether using BIC to search for tuning parameter of IPOD.</p>
</td></tr>
<tr><td><code id="wrapper_+3A_ipod.method">ipod.method</code></td>
<td>
<p>parameter for <code><a href="leapp.html#topic+leapp">leapp</a></code>. &quot;hard&quot;: hard thresholding in the IPOD algorithm;
&quot;soft&quot;: soft thresholding in the IPOD algorithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>beta.p.values</code> returned is a length <code>p</code> vector, each for the overall effects of all the primary variables.
</p>
<p>Only 1 variable of interest is allowed for <code>leapp.wrapper</code>. The method can be slow.
</p>


<h3>Value</h3>

<p>All functions return <code>beta.p.value</code> which are the p-values after adjustment.
For the other returned objects, refer to <a href="#topic+cate">cate</a> for their meaning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## this is the simulation example in Wang et al. (2015).
n &lt;- 100
p &lt;- 1000
r &lt;- 2
set.seed(1)
data &lt;- gen.sim.data(n = n, p = p, r = r,
                     alpha = rep(1 / sqrt(r), r),
                     beta.strength = 3 * sqrt(1 + 1) / sqrt(n),
                     Gamma.strength = c(seq(3, 1, length = r)) * sqrt(p),
                     Sigma = 1 / rgamma(p, 3, rate = 2),
                     beta.nonzero.frac = 0.05)
X.data &lt;- data.frame(X1 = data$X1)
sva.results &lt;- sva.wrapper(~ X1 | 1, X.data, data$Y,
                           r = r, sva.method = "irw")
ruv.results &lt;- ruv.wrapper(~ X1 | 1, X.data, data$Y, r = r,
                           nc = sample(data$beta.zero.pos, 30), ruv.method = "RUV4")
leapp.results &lt;- leapp.wrapper(~ X1 | 1, X.data, data$Y, r = r)
cate.results &lt;- cate(~ X1 | 1, X.data, data$Y, r = r)

## p-values after adjustment
par(mfrow = c(2, 2))
hist(sva.results$beta.p.value)
hist(ruv.results$beta.p.value)
hist(leapp.results$beta.p.value)
hist(cate.results$beta.p.value)

## type I error
mean(sva.results$beta.p.value[data$beta.zero.pos] &lt; 0.05)

## power
mean(sva.results$beta.p.value[data$beta.nonzero.pos] &lt; 0.05)

## false discovery proportion for sva
discoveries.sva &lt;- which(p.adjust(sva.results$beta.p.value, "BH") &lt; 0.2)
fdp.sva &lt;- length(setdiff(discoveries.sva, data$beta.nonzero.pos)) / max(length(discoveries.sva), 1)
fdp.sva

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
