<!DOCTYPE html><html><head><title>Help for package monmlp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {monmlp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gam.style'>
<p>GAM-style effects plots for interpreting MLP and MONMLP models</p></a></li>
<li><a href='#linear'>
<p>Identity function</p></a></li>
<li><a href='#linear.prime'>
<p>Derivative of the linear function</p></a></li>
<li><a href='#logistic'>
<p>Logistic sigmoid function</p></a></li>
<li><a href='#logistic.prime'>
<p>Derivative of the logistic sigmoid function</p></a></li>
<li><a href='#monmlp-package'>
<p>Monotone Multi-Layer Perceptron Neural Network</p></a></li>
<li><a href='#monmlp.fit'>
<p>Fit one or more MLP or MONMLP models</p></a></li>
<li><a href='#monmlp.predict'>
<p>Make predictions from a fitted MLP or MONMLP model</p></a></li>
<li><a href='#tansig'>
<p>Hyperbolic tangent sigmoid function</p></a></li>
<li><a href='#tansig.prime'>
<p>Derivative of the hyperbolic tangent function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multi-Layer Perceptron Neural Network with Optional Monotonicity
Constraints</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.5</td>
</tr>
<tr>
<td>Author:</td>
<td>Alex J. Cannon</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alex J. Cannon &lt;alex.cannon@canada.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Train and make predictions from a multi-layer perceptron neural
        network with optional partial monotonicity constraints.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Depends:</td>
<td>optimx</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-12-04 22:55:46 UTC; ECPACIFIC+cannona</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-12-05 00:05:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='gam.style'>
GAM-style effects plots for interpreting MLP and MONMLP models
</h2><span id='topic+gam.style'></span>

<h3>Description</h3>

<p>GAM-style effects plots provide a graphical means of interpreting
fitted covariate/response relationships. From Plate et al. (2000):
The effect of the <code>i</code>th input variable at a particular input point 
<code>Delta.i.x</code> is the change in <code>f</code> resulting from changing <code>X1</code>
to <code>x1</code> from <code>b1</code> (the baseline value [...]) while keeping the
other inputs constant. The effects are plotted as short line segments,
centered at (<code>x.i</code>, <code>Delta.i.x</code>), where the slope of the segment
is given by the partial derivative. Variables that strongly influence
the function value have a large total vertical range of effects.
Functions without interactions appear as possibly broken straight lines
(linear functions) or curves (nonlinear functions). Interactions show up as
vertical spread at a particular horizontal location, that is, a vertical
scattering of segments. Interactions are present when the effect of
a variable depends on the values of other variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gam.style(x, weights, column, baseline = mean(x[,column]),
         epsilon = 1e-5, seg.len = 0.02, seg.cols = "black",
         plot = TRUE, return.results = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gam.style_+3A_x">x</code></td>
<td>

<p>matrix with number of rows equal to the number of samples and number of columns equal to the number of covariate variables.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_weights">weights</code></td>
<td>

<p>list returned by <code><a href="#topic+monmlp.fit">monmlp.fit</a></code>.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_column">column</code></td>
<td>

<p>column of <code>x</code> for which effects plots should be returned.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_baseline">baseline</code></td>
<td>

<p>value of <code>x[,column]</code> to be used as the baseline for calculation of covariate effects; defaults to <code>mean(x[,column])</code>.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_epsilon">epsilon</code></td>
<td>

<p>step-size used in the finite difference calculation of the partial derivatives.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_seg.len">seg.len</code></td>
<td>

<p>length of effects line segments expressed as a fraction of the range of <code>x[,column]</code>.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_seg.cols">seg.cols</code></td>
<td>

<p>colors of effects line segments.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_plot">plot</code></td>
<td>

<p>if <code>TRUE</code> (the default) then an effects plots for each response variable is produced.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_return.results">return.results</code></td>
<td>

<p>if <code>TRUE</code> then values of effects and partial derivatives for each response variable are returned.
</p>
</td></tr>
<tr><td><code id="gam.style_+3A_...">...</code></td>
<td>

<p>further arguments to be passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements:
</p>
<table>
<tr><td><code>effects</code></td>
<td>
<p>a matrix of covariate effects.</p>
</td></tr>
<tr><td><code>partials</code></td>
<td>
<p>a matrix of covariate partial derivatives.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cannon, A.J. and I.G. McKendry, 2002. A graphical sensitivity analysis
for interpreting statistical climate models: Application to Indian
monsoon rainfall prediction by artificial neural networks and
multiple linear regression models. International Journal of
Climatology, 22:1687-1708.
</p>
<p>Plate, T., J. Bert, J. Grace, and P. Band, 2000. Visualizing the function
computed by a feedforward neural network. Neural Computation,
12(6): 1337-1354.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+monmlp.fit">monmlp.fit</a></code>, <code><a href="#topic+monmlp.predict">monmlp.predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(runif(350*6), ncol=6)
y &lt;- as.matrix(5*sin(10*x[,1]*x[,2]) + 20*(x[,3]-0.5)^2 -
               10*x[,4] + 20*x[,5]*x[,6])

w &lt;- monmlp.fit(x = x, y = y, hidden1 = 4, n.trials = 1,
                iter.max = 500)

for (i in seq(ncol(x))) gam.style(x, weights = w, column = i)
</code></pre>

<hr>
<h2 id='linear'>
Identity function
</h2><span id='topic+linear'></span>

<h3>Description</h3>

<p>Computes a trivial identity function. Used as the hidden layer transfer function for linear MLP or MONMLP models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linear_+3A_x">x</code></td>
<td>

<p>numeric vector.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+linear.prime">linear.prime</a></code>
</p>

<hr>
<h2 id='linear.prime'>
Derivative of the linear function
</h2><span id='topic+linear.prime'></span>

<h3>Description</h3>

<p>Derivative of the linear function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear.prime(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linear.prime_+3A_x">x</code></td>
<td>

<p>numeric vector.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+linear">linear</a></code></p>

<hr>
<h2 id='logistic'>
Logistic sigmoid function
</h2><span id='topic+logistic'></span>

<h3>Description</h3>

<p>Computes the logistic sigmoid function. Used as a hidden layer transfer function for nonlinear MLP or MONMLP models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistic_+3A_x">x</code></td>
<td>

<p>numeric vector.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+logistic.prime">logistic.prime</a></code>
</p>

<hr>
<h2 id='logistic.prime'>
Derivative of the logistic sigmoid function
</h2><span id='topic+logistic.prime'></span>

<h3>Description</h3>

<p>Derivative of the logistic sigmoid function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic.prime(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistic.prime_+3A_x">x</code></td>
<td>

<p>numeric vector.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+logistic">logistic</a></code></p>

<hr>
<h2 id='monmlp-package'>
Monotone Multi-Layer Perceptron Neural Network
</h2><span id='topic+monmlp-package'></span><span id='topic+monmlp'></span>

<h3>Description</h3>

<p>The monmlp package implements one and two hidden-layer multi-layer
perceptron neural network (MLP) models. An optional monotone constraint,
which guarantees monotonically increasing behaviour
of model outputs with respect to specified covariates, can be added
to the MLP. The resulting monotone MLP (MONMLP) regression model
is based on Zhang and Zhang (1999).
</p>
<p>Early stopping can be combined with bootstrap aggregation to
control overfitting. The model reduces to a standard  MLP
neural network if the monotone constraint is not invoked.
</p>
<p>MLP and MONMLP models are fit using the <code><a href="#topic+monmlp.fit">monmlp.fit</a></code> function. 
Predictions from a fitted model are made using the 
<code><a href="#topic+monmlp.predict">monmlp.predict</a></code> function. The <code><a href="#topic+gam.style">gam.style</a></code>
function can be used to investigate fitted covariate/response relationships.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> monmlp</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>References</h3>

<p>Lang, B., 2005. Monotonic multi-layer perceptron networks as 
universal approximators. In: W. Duch et al. (eds.): ICANN 2005, 
Lecture Notes in Computer Science, 3697:31-37. <br /> doi:10.1007/11550907
</p>
<p>Minin, A., Velikova, M., Lang, B., and Daniels, H., 2010. Comparison 
of universal approximators incorporating partial monotonicity by 
structure. Neural Networks, 23:471-475. <br /> doi:10.1016/j.neunet.2009.09.002
</p>
<p>Zhang, H. and Zhang, Z., 1999. Feedforward networks with monotone 
constraints. In: International Joint Conference on Neural Networks, 
vol. 3, p. 1820-1823. doi:10.1109/IJCNN.1999.832655
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- as.matrix(seq(-10, 10, length = 100))
y &lt;- logistic(x) + rnorm(100, sd = 0.2)

dev.new()
plot(x, y)
lines(x, logistic(x), lwd = 10, col = "gray")

## MLP w/ 2 hidden nodes
w.mlp &lt;- monmlp.fit(x = x, y = y, hidden1 = 2, iter.max = 500)
lines(x, attr(w.mlp, "y.pred"), col = "red", lwd = 3)

## MLP w/ 2 hidden-layers (2 nodes each) and early stopping
w.stp &lt;- monmlp.fit(x = x, y = y, hidden1 = 2, hidden2 = 2,
                    bag = TRUE, iter.max = 500, iter.stopped = 10)
lines(x, attr(w.stp, "y.pred"), col = "orange", lwd = 3)

## MONMLP w/ 2 hidden nodes
w.mon &lt;- monmlp.fit(x = x, y = y, hidden1 = 2, monotone = 1,
                    iter.max = 500)
lines(x, attr(w.mon, "y.pred"), col = "blue", lwd = 3)
</code></pre>

<hr>
<h2 id='monmlp.fit'>
Fit one or more MLP or MONMLP models
</h2><span id='topic+monmlp.fit'></span>

<h3>Description</h3>

<p>Fit an individual model or ensemble of MLP or MONMLP regression models
using <code><a href="optimx.html#topic+optimx">optimx</a></code> optimization routines to minimize a least
squares cost function. Optional stopped training and bootstrap
aggregation (bagging) can be used to help avoid overfitting.
</p>
<p>If invoked, the <code>monotone</code> argument enforces increasing behaviour
between specified columns of <code>x</code> and model outputs. In this case, the
<code>exp</code> function is applied to the relevant weights following
initialization and during optimization; manual adjustment of <code>init.weights</code>
may be needed.
</p>
<p>Note: <code>x</code> and <code>y</code> are automatically standardized prior to
fitting and predictions are automatically rescaled by
<code><a href="#topic+monmlp.predict">monmlp.predict</a></code>. This behaviour can be suppressed for
<code>y</code> by the <code>scale.y</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>monmlp.fit(x, y, hidden1, hidden2 = 0, iter.max = 5000,
           n.trials = 1, n.ensemble = 1, bag = FALSE,
           cases.specified = NULL, iter.stopped = NULL,
           scale.y = TRUE, Th = tansig, To = linear,
           Th.prime = tansig.prime, To.prime = linear.prime,
           monotone = NULL, init.weights = NULL,
           max.exceptions = 10, silent = FALSE, method = "BFGS",
           control = list(trace = 0))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="monmlp.fit_+3A_x">x</code></td>
<td>

<p>covariate matrix with number of rows equal to the number of samples and number of columns equal to the number of covariates.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_y">y</code></td>
<td>

<p>response matrix with number of rows equal to the number of samples and number of columns equal to the number of response variables.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_hidden1">hidden1</code></td>
<td>

<p>number of hidden nodes in the first hidden layer.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_hidden2">hidden2</code></td>
<td>

<p>number of hidden nodes in the second hidden layer.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_iter.max">iter.max</code></td>
<td>

<p>maximum number of iterations of the optimization algorithm.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_n.trials">n.trials</code></td>
<td>

<p>number of repeated trials used to avoid local minima.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_n.ensemble">n.ensemble</code></td>
<td>

<p>number of ensemble members to fit.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_bag">bag</code></td>
<td>

<p>logical variable indicating whether or not bootstrap aggregation (bagging) should be used.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_cases.specified">cases.specified</code></td>
<td>

<p>if <code>bag = TRUE</code>, a list that specifies the bootstrapped cases to be used in each ensemble member.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_iter.stopped">iter.stopped</code></td>
<td>

<p>if <code>bag = TRUE</code>, specifies the number of stopped training iterations between calculation of the cost function on the out-of-bootstrap cases.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_scale.y">scale.y</code></td>
<td>

<p>logical determining if columns of the response matrix should be scaled to zero mean and unit variance prior to fitting. Set this to <code>FALSE</code> if using an output layer transfer function that limits the range of predictions.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_th">Th</code></td>
<td>

<p>hidden layer transfer function.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_to">To</code></td>
<td>

<p>output layer transfer function.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_th.prime">Th.prime</code></td>
<td>

<p>derivative of the hidden layer transfer function.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_to.prime">To.prime</code></td>
<td>

<p>derivative of the output layer transfer function.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_monotone">monotone</code></td>
<td>

<p>column indices of covariates for which the monotonicity constraint should hold.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_init.weights">init.weights</code></td>
<td>

<p>either a vector giving the minimum and maximum allowable values of the random weights, an initial weight vector, or NULL to calculate based on fan-in.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_max.exceptions">max.exceptions</code></td>
<td>

<p>maximum number of exceptions of the optimization routine before fitting is terminated with an error.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_silent">silent</code></td>
<td>

<p>logical determining if diagnostic messages should be suppressed.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_method">method</code></td>
<td>

<p><code><a href="optimx.html#topic+optimx">optimx</a></code> optimization method.
</p>
</td></tr>
<tr><td><code id="monmlp.fit_+3A_control">control</code></td>
<td>

<p><code>list of <a href="optimx.html#topic+optimx">optimx</a></code> control parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing fitted weight matrices with attributes
including called values of <code>x</code>, <code>y</code>, <code>Th</code>, <code>To</code>,
<code>Th.prime</code>, <code>To.prime</code>, <code>monotone</code>, <code>bag</code>,
<code>iter.max</code>, and <code>iter.stopped</code>, along with values of
covariate/response column means and standard deviations
(<code>x.center</code>, <code>x.scale</code>, <code>y.center</code>,
<code>y.scale</code>), out-of-bootstrap cases <code>oob</code>,
predicted values <code>y.pred</code>, and, if stopped training is
switched on, the iteration <code>iter.best</code> and value of
the cost function <code>cost.best</code> that minimized the
out-of-bootstrap validation error.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+monmlp.predict">monmlp.predict</a></code>, <code><a href="#topic+gam.style">gam.style</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- as.matrix(seq(-10, 10, length = 100))
y &lt;- logistic(x) + rnorm(100, sd = 0.2)

dev.new()
plot(x, y)
lines(x, logistic(x), lwd = 10, col = "gray")

## MLP w/ 2 hidden nodes
w.mlp &lt;- monmlp.fit(x = x, y = y, hidden1 = 2, iter.max = 500)
lines(x, attr(w.mlp, "y.pred"), col = "red", lwd = 3)

## MLP w/ 2 hidden nodes and stopped training
w.stp &lt;- monmlp.fit(x = x, y = y, hidden1 = 2, bag = TRUE,
                    iter.max = 500, iter.stopped = 10)
lines(x, attr(w.stp, "y.pred"), col = "orange", lwd = 3)

## MONMLP w/ 2 hidden nodes
w.mon &lt;- monmlp.fit(x = x, y = y, hidden1 = 2, monotone = 1,
                    iter.max = 500)
lines(x, attr(w.mon, "y.pred"), col = "blue", lwd = 3)
</code></pre>

<hr>
<h2 id='monmlp.predict'>
Make predictions from a fitted MLP or MONMLP model
</h2><span id='topic+monmlp.predict'></span>

<h3>Description</h3>

<p>Make predictions from a fitted model or ensemble of MLP or MONMLP models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>monmlp.predict(x, weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="monmlp.predict_+3A_x">x</code></td>
<td>

<p>covariate matrix with number of rows equal to the number of samples and number of columns equal to the number of covariates.
</p>
</td></tr>
<tr><td><code id="monmlp.predict_+3A_weights">weights</code></td>
<td>

<p>list containing weight matrices and other parameters from <code><a href="#topic+monmlp.fit">monmlp.fit</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with number of rows equal to the number of samples and number of columns equal to the number of response variables. If <code>weights</code> is from an ensemble of models, the matrix is the ensemble mean and the attribute <code>ensemble</code> contains a list with predictions for each ensemble member.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+monmlp.fit">monmlp.fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- as.matrix(seq(-10, 10, length = 100))
y &lt;- logistic(x) + rnorm(100, sd = 0.2)

dev.new()
plot(x, y)
lines(x, logistic(x), lwd = 10, col = "gray")

## Ensemble of MONMLP models w/ 3 hidden nodes
w.mon &lt;- monmlp.fit(x = x, y = y, hidden1 = 3, monotone = 1,
                    n.ensemble = 15, bag = TRUE, iter.max = 500,
                    control = list(trace = 0))
p.mon &lt;- monmlp.predict(x = x, weights = w.mon)

## Plot predictions from ensemble members
matlines(x = x, y = do.call(cbind, attr(p.mon, "ensemble")),
         col = "cyan", lty = 2)

## Plot ensemble mean
lines(x, p.mon, col = "blue", lwd = 3)
</code></pre>

<hr>
<h2 id='tansig'>
Hyperbolic tangent sigmoid function
</h2><span id='topic+tansig'></span>

<h3>Description</h3>

<p>Computes the hyperbolic tangent sigmoid function. Used as a hidden layer transfer function for nonlinear MLP or MONMLP models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tansig(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tansig_+3A_x">x</code></td>
<td>

<p>numeric vector.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+tansig.prime">tansig.prime</a></code>
</p>

<hr>
<h2 id='tansig.prime'>
Derivative of the hyperbolic tangent function
</h2><span id='topic+tansig.prime'></span>

<h3>Description</h3>

<p>Derivative of the hyperbolic tangent function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tansig.prime(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tansig.prime_+3A_x">x</code></td>
<td>

<p>numeric vector.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+tansig">tansig</a></code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
