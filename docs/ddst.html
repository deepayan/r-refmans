<!DOCTYPE html><html><head><title>Help for package ddst</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ddst}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ddst-package'>
<p>Data Driven Smooth Tests</p></a></li>
<li><a href='#ddst.exp.test'><p> Data Driven Smooth Test for Exponentiality</p></a></li>
<li><a href='#ddst.extr.test'><p> Data Driven Smooth Test for Extreme Value Distribution</p></a></li>
<li><a href='#ddst.norm.test'><p> Data Driven Smooth Test for Normality</p></a></li>
<li><a href='#ddst.uniform.test'><p> Data Driven Smooth Test for Uniformity</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Driven Smooth Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-05-26</td>
</tr>
<tr>
<td>Author:</td>
<td>Przemyslaw Biecek (R code), Teresa Ledwina (support,
    descriptions)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Przemyslaw Biecek &lt;przemyslaw.biecek@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Smooth testing of goodness of fit. These tests are data
    driven (alternative hypothesis is dynamically selected based on data). In this
    package you will find various tests for exponent, Gaussian, Gumbel and uniform
    distribution.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.7.0), orthopolynom, evd</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-05-26 16:31:17 UTC; pbiecek</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-05-26 18:51:49</td>
</tr>
</table>
<hr>
<h2 id='ddst-package'>
Data Driven Smooth Tests
</h2><span id='topic+ddst-package'></span><span id='topic+ddst.base.cos'></span><span id='topic+ddst.base.legendre'></span><span id='topic+ddst.IIC'></span><span id='topic+ddst.phi'></span><span id='topic+ddst'></span><span id='topic+Nmax'></span>

<h3>Description</h3>

<p>Set of Data Driven Smooth Tests for Goodness of Fit
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ddst</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2008-07-01</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>General Description</h3>

<p>Smooth test was introduced by Neyman (1937) to verify simple null hypothesis asserting that observations obey completely known continuous distribution function <em>F</em>. Smooth test statistic (with <em>k</em> components) can be interpreted as score statistic in an appropriate class of auxiliary models indexed by a vector of parameters <em>$theta in R^k, k &gt;= 1$.</em> 
</p>
<p>Pertaining auxilary null hypothesis asserts <em>$theta=theta_0=0$</em>. Therefore, in this case, the smooth test statistic based on <em>n</em> i.i.d. observations <em>$Z_1,...,Z_n$</em> has the form
<em>$W_k=[1/sqrt(n) sum_i=1^n l(Z_i)]I^-1[1/sqrt(n) sum_i=1^n l(Z_i)]'$</em>,
</p>
<p>where <em>$l(Z_i)$</em>, i=1,...,n, is <em>k</em>-dimensional (row) score vector, the symbol <em>'</em> denotes transposition while <em>$I=Cov_theta_0[l(Z_1)]'[l(Z_1)]$</em>. Following Neyman's idea of modelling underlying distributions one gets <em>$l(Z_i)=(phi_1(F(Z_i)),...,phi_k(F(Z_i)))$</em> and <em>I</em> being the identity matrix, where <em>$phi_j$</em>'s, j &gt;= 1,  are zero mean orthonormal functions on [0,1], while <em>F</em> is the completely specified null distribution function.
</p>
<p>In case of composite null hypothesis there is also unspecified vector of nuisance parameters <em>$gamma$</em> defining the distribution of observations. Smooth statistic (with <em>k</em> components) in such applications is understood as efficient score statistic for some class of models indexed by an auxiliary parmeter <em>$theta in R^k$</em>, k &gt;= 1. Pertaining efficient score vector <em>$l^*(Z_i;gamma)$</em> is defined as the residual from projection the score vector for <em>$theta$</em> onto the space spanned by score vector for <em>$gamma$</em>. As such, smooth test is alternative name for <em>$C(alpha)$</em> Neyman's test. See Neyman (1959), Buhler and Puri (1966) as well as Javitz (1975) for details. Hence, smooth test, based on <em>n</em> i.i.d. variables <em>$Z_1,...,Z_n$</em> rejects hypothesis <em>$theta=theta_0=0$</em> for large values of 
</p>
<p><em>$W_k^*(tilde gamma)=[1/sqrt(n) sum_i=1^n l^*(Z_i;tilde gamma)][I^*(tilde gamma)]^-1[1/sqrt(n) sum_i=1^n l^*(Z_i;tilde gamma)]'$</em>,
where <em>$tilde gamma$</em> is an appropriate estimator of <em>$gamma$</em> while <em>$I^*(gamma)=Cov_theta_0[l^*(Z_1;gamma)]'[l^*(Z_1;gamma)]$</em>. More details can be found in Janic and Ledwina (2008), Kallenberg and Ledwina (1997 a,b) as well as Inglot and Ledwina (2006 a,b). 
</p>
<p>Auxiliary models, mentioned above, aim to mimic the unknown underlying model for the data at hand. To choose the dimension <em>k</em> of the auxilary model we apply some model selection criteria. Among several solutions already considered, we decided to implement two following ones, pertaining to the two above described problems and resulting <em>$W_k$</em> and <em>$W_k^*(tilde gamma)$</em>. The selection rules in the two cases are briefly denoted by <em>T</em> and <em>$T^*$</em>, respectively, and given by
</p>
<p><em>$T = min1 &lt;= k &lt;= d: W_k-pi(k,n,c) &gt;= W_j-pi(j,n,c), j=1,...,d$</em>
</p>
<p>and
</p>
<p><em>
$T^* = min1 &lt;= k &lt;= d: W_k^*(tilde gamma)-pi^*(k,n,c) &gt;= W_j^*(tilde gamma)-pi^*(j,n,c), j=1,...,d$</em>.
</p>
<p>Both criteria are based on approximations of penalized loglikelihoods, where loglikelihoods are replaced by <em>$W_k$</em> and <em>$W_k^*(tilde gamma)$</em>, respectively.  The penalties for the dimension <em>j</em> in case of simple and composite null hypothesis are defined as follows
</p>
<p><em>$pi(j,n,c)=jlog n,  if  max1 &lt;= k &lt;= d|Y_k| &lt;= sqrt(c log(n)), 2j,  if max1 &lt;= k &lt;= d|Y_k|&gt;sqrt(c log(n)). $</em>
</p>
<p>and
</p>
<p><em>
$pi^*(j,n,c)=jlog n,  if max1 &lt;= k &lt;= d|Y_k^*| &lt;= sqrt(c log(n)),2j  if max(1 &lt;= k &lt;= d)|Y_k^*| &gt; sqrt(c log(n))$</em>.
</p>
<p>respectively, where <em>c</em> is some calibrating constant, <em>d</em> is maximal dimension taken into account, 
</p>
<p><em>$(Y_1,...,Y_k)=[1/sqrt(n) sum_i=1^n l(Z_i)]I^-1/2$</em> 
</p>
<p>while  
</p>
<p><em>$(Y_1^*,...,Y_k^*)=[1/sqrt(n) sum_i=1^n l^*(Z_i; tilde gamma)][I^*(tilde gamma)]^-1/2$</em>.
</p>
<p>In consequence, data driven smooth tests for the simple and composite null hypothesis reject for large values of <em>$W_T$</em>
and <em>$W_T^* = W_T^*(tilde gamma)$</em>, respectively. For details see Inglot and Ledwina (2006 a,b,c). 
</p>
<p>The choice of <em>c</em> in <em>T</em> and <em>$T^*$</em> is decisive to finite sample behaviour of the selection rules and pertaining statistics <em>$W_T$</em> and <em>$W_T^*(tilde gamma)$</em>. In particular, under large <em>c</em>'s the rules behave similarly as Schwarz's (1978) BIC while for <em>c=0</em> they mimic Akaike's (1973) AIC. For moderate sample sizes, values <em>c in (2,2.5)</em> guarantee, under &lsquo;smooth&rsquo; departures, only slightly smaller power as in case BIC were used and simultaneously give much higher power than BIC under multimodal alternatives. In genral, large <em>c's</em> are recommended if changes in location, scale, skewness and kurtosis are in principle aimed to be detected. For evidence and discussion see Inglot and Ledwina (2006 c). 
</p>
<p>It <em>c&gt;0</em> then the limiting null distribution of <em>$W_T$</em> and <em>$W_T^*(tilde gamma)$</em> is central chi-squared with one degree of freedom. In our implementation, for given <em>n</em>, both critical values and <em>p</em>-values are computed by MC method.
</p>
<p>Empirical distributions of <em>T</em> and <em>$T^*$</em> as well as <em>$W_T$</em> and <em>$W_T^*(tilde gamma)$</em> are not essentially influenced by the choice of reasonably large <em>d</em>'s, provided that sample size is at least moderate.
</p>
<p>For more details see: <a href="http://www.biecek.pl/R/ddst/description.pdf">http://www.biecek.pl/R/ddst/description.pdf</a>.
</p>


<h3>Author(s)</h3>

<p>Przemyslaw Biecek and Teresa Ledwina
</p>
<p>Maintainer: You should complain to Przemyslaw Biecek  &lt;przemyslaw.biecek@gmail.com&gt;
</p>


<h3>References</h3>

<p>Akaike, H. (1973). Information theory and the maximum likelihood principle. In: <em> 2nd International Symposium on Information Theory</em>, (eds. B. N. Petrov and F. Csaki), 267-281. Akademiai Kiado, Budapest.
</p>
<p>Buhler, W.J., Puri, P.S. (1966). On optimal asymptotic tests of composite hypotheses with several constraints. <em> Z. Wahrsch. verw. Geb.</em> <b> 5</b>, 71&ndash;88.
</p>
<p>Inglot, T., Ledwina, T. (2006 a). Data-driven score tests for homoscedastic linear regression model: asymptotic results. <em> Probab. Math. Statist.</em> <b> 26</b>, 41&ndash;61.
</p>
<p>Inglot, T., Ledwina, T. (2006 b). Data-driven score tests for homoscedastic linear regression model: the construction and simulations. In <em> Prague Stochastics 2006. Proceedings</em>, (eds. M. Huskova, M. Janzura), 124&ndash;137. Matfyzpress, Prague.
</p>
<p>Inglot, T., Ledwina, T. (2006 c). Towards data driven selection of a penalty function for data driven Neyman tests. <em> Linear Algebra and its Appl.</em> <b> 417</b>, 579&ndash;590. 
</p>
<p>Javitz, H.S. (1975). Generalized smooth tests of goodness of fit, independence and equality of distributions. Ph.D. thesis at University of California, Berkeley.
</p>
<p>Janic, A. and Ledwina, T. (2008). Data-driven tests for a location-scale family revisited. <em> J. Statist. Theory. Pract. Special issue on Modern Goodness of Fit Methods. accepted.</em>.
</p>
<p>Kallenberg, W.C.M., Ledwina, T. (1997 a). Data driven smooth tests for composite hypotheses: Comparison of powers. <em> J. Statist. Comput. Simul.</em> <b> 59</b>, 101&ndash;121.
</p>
<p>Kallenberg, W.C.M.,  Ledwina, T. (1997 b). Data driven smooth tests when the hypothesis is composite. <em> J. Amer. Statist. Assoc.</em> <b> 92</b>, 1094&ndash;1104.
</p>
<p>Neyman, J. (1937). &lsquo;Smooth test&rsquo; for goodness of fit. <em> Skand. Aktuarietidskr.</em> <b> 20</b>, 149-199.
</p>
<p>Neyman, J. (1959). Optimal asymptotic tests of composite statistical hypotheses. In <em> Probability and Statistics</em>, (ed. U. Grenander), Harald Cramer Volume, 212&ndash;234. Wiley, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data Driven Smooth Test for Uniformity
#
# H0 is true
z = runif(80)
ddst.uniform.test(z, compute.p=TRUE)

# H0 is false
z = rbeta(80,4,2)
(t = ddst.uniform.test(z, compute.p=TRUE))
t$p.value

# Data Driven Smooth Test for Normality
#
# H0 is true
z = rnorm(80)
ddst.norm.test(z, compute.p=TRUE)

# H0 is false
z = rexp(80,4)
ddst.norm.test(z, B=5000, compute.p=TRUE)

# Data Driven Smooth Test for Extreme Value Distribution
#
# H0 is true
#library(evd)
#z = -qgumbel(runif(100),-1,1)
#ddst.extr.test (z, compute.p = TRUE)

# H0 is false
z = rexp(80,4)
ddst.extr.test (z, compute.p = TRUE)

# Data Driven Smooth Test for Exponentiality
#
# H0 is true
z = rexp(80,4)
ddst.exp.test (z, compute.p = TRUE)

# H0 is false
z = rchisq(80,4)
ddst.exp.test (z, compute.p = TRUE)

</code></pre>

<hr>
<h2 id='ddst.exp.test'> Data Driven Smooth Test for Exponentiality</h2><span id='topic+ddst.exp.test'></span><span id='topic+ddst.exp.Nk'></span>

<h3>Description</h3>

<p>Performs data driven smooth test for composite hypothesis of exponentiality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddst.exp.test(x, base = ddst.base.legendre, c = 100, B = 1000, compute.p = F, 
    Dmax = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddst.exp.test_+3A_x">x</code></td>
<td>
<p>  a (non-empty) numeric vector of data values. </p>
</td></tr>
<tr><td><code id="ddst.exp.test_+3A_base">base</code></td>
<td>
<p> a function which returns orthogonal system, might be <code>ddst.base.legendre</code> for Legendre polynomials or <code>ddst.base.cos</code> for cosine system, see package description. </p>
</td></tr>
<tr><td><code id="ddst.exp.test_+3A_c">c</code></td>
<td>
<p> a parameter for model selection rule, see package description. </p>
</td></tr>
<tr><td><code id="ddst.exp.test_+3A_b">B</code></td>
<td>
<p> an integer specifying the number of replicates used in p-value computation. </p>
</td></tr>
<tr><td><code id="ddst.exp.test_+3A_compute.p">compute.p</code></td>
<td>
<p>  a logical value indicating whether to compute a p-value. </p>
</td></tr>
<tr><td><code id="ddst.exp.test_+3A_dmax">Dmax</code></td>
<td>
<p> an integer specifying the maximum number of coordinates, only for advanced users. </p>
</td></tr>
<tr><td><code id="ddst.exp.test_+3A_...">...</code></td>
<td>
<p> further arguments. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Null density is given by <em>$f(z;gamma) = exp(-z/gamma)$</em>  for z &gt;= 0 and 0 otherwise.  
</p>
<p>Modelling alternatives similarly as in Kallenberg and Ledwina (1997 a,b), e.g., and estimating <em>$gamma$</em> by <em>$tilde gamma= 1/n sum_i=1^n Z_i$</em> yields the efficient score 
vector <em>$l^*(Z_i;tilde gamma)=(phi_1(F(Z_i;tilde gamma)),...,phi_k(F(Z_i;tilde gamma)))$</em>, where <em>$phi_j$</em>'s are	<em>j</em>th degree orthonormal Legendre polynomials on [0,1] or cosine functions <em>$sqrt(2) cos(pi j x), j&gt;=1$,</em> while <em>$F(z;gamma)$</em> is the distribution function pertaining to <em>$f(z;gamma)$</em>. 
</p>
<p>The matrix <em>$[I^*(tilde gamma)]^-1$</em> does not  depend on <em>$tilde gamma$</em> and is calculated for succeding dimensions <em>k</em> using some recurrent relations for Legendre's polynomials and computed in a numerical way in case of cosine basis. In the implementation the default value of <em>c</em> in <em>$T^*$</em> is set to be 100. 
</p>
<p>Therefore, <em>$T^*$</em> practically coincides with S1 considered in Kallenberg and Ledwina (1997 a).
</p>
<p>For more details see: <a href="http://www.biecek.pl/R/ddst/description.pdf">http://www.biecek.pl/R/ddst/description.pdf</a>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code>
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number of choosen coordinates (k).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the parameters of performed test. </p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data. </p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test, computed only if <code>compute.p=T</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Przemyslaw Biecek and Teresa Ledwina </p>


<h3>References</h3>

 
<p>Kallenberg, W.C.M., Ledwina, T. (1997 a). Data driven smooth tests for
composite hypotheses: Comparison of powers. <em> J. Statist. Comput. Simul.</em>
<b> 59</b>, 101&ndash;121.
</p>
<p>Kallenberg, W.C.M.,  Ledwina, T. (1997 b). Data driven smooth tests when
the hypothesis is composite. <em> J. Amer. Statist. Assoc.</em> <b> 92</b>,
1094&ndash;1104.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# H0 is true
z = rexp(80,4)
ddst.exp.test (z, compute.p = TRUE)

# H0 is false
z = rchisq(80,4)
(t = ddst.exp.test (z, compute.p = TRUE))
t$p.value

</code></pre>

<hr>
<h2 id='ddst.extr.test'> Data Driven Smooth Test for Extreme Value Distribution </h2><span id='topic+ddst.extr.test'></span><span id='topic+ddst.extr.Nk'></span>

<h3>Description</h3>

<p>Performs data driven smooth test for composite hypothesis of extreme value distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddst.extr.test(x, base = ddst.base.legendre, c = 100, B = 1000, compute.p = F, 
    Dmax = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddst.extr.test_+3A_x">x</code></td>
<td>
<p>  a (non-empty) numeric vector of data values. </p>
</td></tr>
<tr><td><code id="ddst.extr.test_+3A_base">base</code></td>
<td>
<p> a function which returns orthogonal system, might be <code>ddst.base.legendre</code> for Legendre polynomials or <code>ddst.base.cos</code> for cosine system, see package description. </p>
</td></tr>
<tr><td><code id="ddst.extr.test_+3A_c">c</code></td>
<td>
<p> a parameter for model selection rule, see package description. </p>
</td></tr>
<tr><td><code id="ddst.extr.test_+3A_b">B</code></td>
<td>
<p> an integer specifying the number of replicates used in p-value computation. </p>
</td></tr>
<tr><td><code id="ddst.extr.test_+3A_compute.p">compute.p</code></td>
<td>
<p>  a logical value indicating whether to compute a p-value. </p>
</td></tr>
<tr><td><code id="ddst.extr.test_+3A_dmax">Dmax</code></td>
<td>
<p> an integer specifying the maximum number of coordinates, only for advanced users. </p>
</td></tr>
<tr><td><code id="ddst.extr.test_+3A_...">...</code></td>
<td>
<p> further arguments. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Null density is given by 
<em>
$f(z;gamma)=1/gamma_2 exp((z-gamma_1)/gamma_2- exp((z-gamma_1)/gamma_2))$</em>, z in R.
</p>
<p>We model alternatives similarly as in Kallenberg and Ledwina (1997) and Janic-Wroblewska (2004) using Legendre's polynomials or cosines. The parameter 
<em>$gamma=(gamma_1,gamma_2)$</em> is estimated by <em>$tilde gamma=(tilde gamma_1,tilde gamma_2)$</em>, where <em>$tilde gamma_1=-1/n sum_i=1^n Z_i + varepsilon  G$</em>, where <em>$varepsilon approx 0.577216 $</em> is the Euler constant and <em>$ G = tilde gamma_2 = [n(n-1) ln2]^-1sum_1&lt;= j &lt; i &lt;= n(Z_n:i^o - Z_n:j^o) $</em> while <em>$Z_n:1^o &lt;= ... &lt;= Z_n:n^o$</em>
are ordered variables <em>$-Z_1,...,-Z_n$</em>, cf Hosking et al. (1985). 
The above yields auxiliary test statistic <em>$W_k^*(tilde gamma)$</em> described in details in Janic and Ledwina (2008), in case when Legendre's basis is applied. 
</p>
<p>The related matrix <em>$[I^*(tilde gamma)]^-1$</em> does not  depend on <em>$tilde gamma$</em> and is calculated for succeding dimensions <em>k</em> using some recurrent relations for Legendre's polynomials and numerical methods for cosine functions. In the implementation the default value of <em>c</em> in <em>$T^*$</em> was fixed to be 100. Hence, <em>$T^*$</em> is Schwarz-type model selection rule. The resulting data driven test statistic for extreme value distribution is <em>$W_T^*=W_T^*(tilde gamma)$</em>.
</p>
<p>For more details see: <a href="http://www.biecek.pl/R/ddst/description.pdf">http://www.biecek.pl/R/ddst/description.pdf</a>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code>
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number of choosen coordinates (k).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the parameters of performed test. </p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data. </p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test, computed only if <code>compute.p=T</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Przemyslaw Biecek and Teresa Ledwina </p>


<h3>References</h3>

 
<p>Hosking, J.R.M., Wallis, J.R., Wood, E.F. (1985). Estimation of the generalized extreme-value distribution by the method of probability-weighted moments. <em> Technometrics</em> 27, 251&ndash;261.
</p>
<p>Janic-Wroblewska, A. (2004). Data-driven smooth test for extreme  value distribution. <em> Statistics</em> 38, 413&ndash;426.
</p>
<p>Janic, A. and Ledwina, T. (2008). Data-driven tests for a location-scale family revisited. <em> J. Statist. Theory. Pract. Special issue on Modern Goodness of Fit Methods. accepted.</em>.
</p>
<p>Kallenberg, W.C.M., Ledwina, T. (1997). Data driven smooth tests for composite hypotheses: Comparison of powers. <em> J. Statist. Comput. Simul.</em> <b> 59</b>, 101&ndash;121. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(evd)

# for given vector of 19 numbers
z = c(13.41, 6.04, 1.26, 3.67, -4.54, 2.92, 0.44, 12.93, 6.77, 10.09, 
   4.10, 4.04, -1.97, 2.17, -5.38, -7.30, 4.75, 5.63, 8.84)
ddst.extr.test(z, compute.p=TRUE)

# H0 is true
x = -qgumbel(runif(100),-1,1)
ddst.extr.test (x, compute.p = TRUE)

# H0 is false
x = rexp(80,4)
ddst.extr.test (x, compute.p = TRUE)

</code></pre>

<hr>
<h2 id='ddst.norm.test'> Data Driven Smooth Test for Normality </h2><span id='topic+ddst.norm.test'></span><span id='topic+tabNorm'></span><span id='topic+ddst.norm.Nk'></span>

<h3>Description</h3>

<p>Performs data driven smooth test for composite hypothesis of normality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddst.norm.test(x, base = ddst.base.legendre, c = 100, B = 1000, compute.p = F, 
    Dmax = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddst.norm.test_+3A_x">x</code></td>
<td>
<p>  a (non-empty) numeric vector of data values. </p>
</td></tr>
<tr><td><code id="ddst.norm.test_+3A_base">base</code></td>
<td>
<p> a function which returns orthogonal system, might be <code>ddst.base.legendre</code> for Legendre polynomials or <code>ddst.base.cos</code> for cosine system, see package description. </p>
</td></tr>
<tr><td><code id="ddst.norm.test_+3A_c">c</code></td>
<td>
<p> a parameter for model selection rule, see package description. </p>
</td></tr>
<tr><td><code id="ddst.norm.test_+3A_b">B</code></td>
<td>
<p> an integer specifying the number of replicates used in p-value computation. </p>
</td></tr>
<tr><td><code id="ddst.norm.test_+3A_compute.p">compute.p</code></td>
<td>
<p>  a logical value indicating whether to compute a p-value. </p>
</td></tr>
<tr><td><code id="ddst.norm.test_+3A_dmax">Dmax</code></td>
<td>
<p> an integer specifying the maximum number of coordinates, only for advanced users. </p>
</td></tr>
<tr><td><code id="ddst.norm.test_+3A_...">...</code></td>
<td>
<p> further arguments. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Null density is given by 
<em>
$f(z;gamma)=1/(sqrt(2 pi)gamma_2) exp(-(z-gamma_1)^2/(2 gamma_2^2))$</em> for z in R.
</p>
<p>We model alternatives similarly as in Kallenberg and Ledwina (1997 a,b) using Legendre's polynomials or cosine basis. The parameter 
<em>$gamma=(gamma_1,gamma_2)$</em> is estimated by <em>$tilde gamma=(tilde gamma_1,tilde gamma_2)$</em>, where <em>$tilde gamma_1=1/n sum_i=1^n Z_i$</em> and 
<em>$tilde gamma_2 = 1/(n-1) sum_i=1^n-1(Z_n:i+1-Z_n:i)(H_i+1-H_i)$</em>,
while <em>$Z_n:1&lt;= ... &lt;= Z_n:n$</em> are ordered values of <em>$Z_1, ..., Z_n$</em> and <em>$H_i= phi^-1((i-3/8)(n+1/4))$</em>, cf. Chen and Shapiro (1995). 
</p>
<p>The above yields auxiliary test statistic <em>$W_k^*(tilde gamma)$</em> described in details in Janic and Ledwina (2008), in case when Legendre's basis is applied. 
The pertaining matrix <em>$[I^*(tilde gamma)]^-1$</em> does not  depend on <em>$tilde gamma$</em> and is calculated for succeding dimensions <em>k</em> using some recurrent relations for Legendre's polynomials and is computed in a numerical way in case of cosine basis. In the implementation of <em>$T^*$</em> the default value of <em>c</em> is set  to be 100. Therefore, in practice, <em>$T^*$</em> is Schwarz-type criterion. See Inglot and Ledwina (2006) as well as Janic and Ledwina (2008) for comments. The resulting data driven test statistic for normality is <em>$W_T^*=W_T^*(tilde gamma)$</em>.
</p>
<p>For more details see: <a href="http://www.biecek.pl/R/ddst/description.pdf">http://www.biecek.pl/R/ddst/description.pdf</a>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code>
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number of choosen coordinates (k).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the parameters of performed test. </p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data. </p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test, computed only if <code>compute.p=T</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Przemyslaw Biecek and Teresa Ledwina </p>


<h3>References</h3>

 
<p>Chen, L., Shapiro, S.S. (1995). An alternative test for normality based on normalized spacings. <em> J. Statist. Comput. Simulation</em> 53, 269&ndash;288.
</p>
<p>Inglot, T., Ledwina, T. (2006). Towards data driven selection of a penalty function for data driven Neyman tests. <em> Linear Algebra and its Appl.</em> <b> 417</b>, 579&ndash;590. 
</p>
<p>Janic, A. and Ledwina, T. (2008). Data-driven tests for a location-scale family revisited. <em> J. Statist. Theory. Pract. Special issue on Modern Goodness of Fit Methods. accepted.</em>.
</p>
<p>Kallenberg, W.C.M., Ledwina, T. (1997 a). Data driven smooth tests for composite hypotheses: Comparison of powers. <em> J. Statist. Comput. Simul.</em> <b> 59</b>, 101&ndash;121.
</p>
<p>Kallenberg, W.C.M.,  Ledwina, T. (1997 b). Data driven smooth tests when the hypothesis is composite. <em> J. Amer. Statist. Assoc.</em> <b> 92</b>, 1094&ndash;1104.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# for given vector of 19 numbers
z = c(13.41, 6.04, 1.26, 3.67, -4.54, 2.92, 0.44, 12.93, 6.77, 10.09, 
   4.10, 4.04, -1.97, 2.17, -5.38, -7.30, 4.75, 5.63, 8.84)
ddst.norm.test(z, compute.p=TRUE)

# H0 is true
z = rnorm(80)
ddst.norm.test(z, compute.p=TRUE)

# H0 is false
z = rexp(80,4)
ddst.norm.test(z, B=5000, compute.p=TRUE)

</code></pre>

<hr>
<h2 id='ddst.uniform.test'> Data Driven Smooth Test for Uniformity </h2><span id='topic+ddst.uniform.test'></span><span id='topic+ddst.uniform.Nk'></span>

<h3>Description</h3>

<p>Performs data driven smooth tests for simple hypothesis of uniformity on [0,1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddst.uniform.test(x, base = ddst.base.legendre, c = 2.4, B = 1000, compute.p = F,
    Dmax = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddst.uniform.test_+3A_x">x</code></td>
<td>
<p>  a (non-empty) numeric vector of data values. </p>
</td></tr>
<tr><td><code id="ddst.uniform.test_+3A_base">base</code></td>
<td>
<p> a function which returns orthogonal system, might be <code>ddst.base.legendre</code> for Legendre polynomials or <code>ddst.base.cos</code> for cosine system, see package description. </p>
</td></tr>
<tr><td><code id="ddst.uniform.test_+3A_c">c</code></td>
<td>
<p> a parameter for model selection rule, see package description. </p>
</td></tr>
<tr><td><code id="ddst.uniform.test_+3A_b">B</code></td>
<td>
<p> an integer specifying the number of replicates used in p-value computation. </p>
</td></tr>
<tr><td><code id="ddst.uniform.test_+3A_compute.p">compute.p</code></td>
<td>
<p>  a logical value indicating whether to compute a p-value. </p>
</td></tr>
<tr><td><code id="ddst.uniform.test_+3A_dmax">Dmax</code></td>
<td>
<p> an integer specifying the maximum number of coordinates, only for advanced users. </p>
</td></tr>
<tr><td><code id="ddst.uniform.test_+3A_...">...</code></td>
<td>
<p> further arguments. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Embeding null model into the original exponential family introduced by Neyman (1937) leads to the information matrix <em> I</em> being identity and smooth test statistic with <em>k</em> components
<em>
$W_k=[1/sqrt(n) sum_j=1^k sum_i=1^n phi_j(Z_i)]^2$</em>,
where <em>$phi_j$</em> is <em>j</em>th degree normalized Legendre polynomial on [0,1] (default value of parameter base = &lsquo;ddst.base.legendre&rsquo;). Alternatively, in our implementation, cosine system can be selected (base = &lsquo;ddst.base.cos&rsquo;). For details see Ledwina (1994) and Inglot and Ledwina (2006).
</p>
<p>An application of the pertaining selection rule <em>T</em> for choosing <em>k</em> gives related &lsquo;ddst.uniform.test()&rsquo; based on statistic <em>$W_T$</em>.
</p>
<p>Similar approach applies to testing goodness-of-fit to any fully specified continuous distribution function <em>F</em>. For this purpose it is enough to apply the above solution to transformed observations <em>$F(z_1),...,F(z_n)$</em>.
</p>
<p>For more details see: <a href="http://www.biecek.pl/R/ddst/description.pdf">http://www.biecek.pl/R/ddst/description.pdf</a>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code>
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number of choosen coordinates (k).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the parameters of performed test. </p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data. </p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test, computed only if <code>compute.p=T</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Przemyslaw Biecek and Teresa Ledwina </p>


<h3>References</h3>

<p>Inglot, T., Ledwina, T. (2006). Towards data driven selection of a penalty function for data driven Neyman tests. <em> Linear Algebra and its Appl.</em> <b> 417</b>, 579&ndash;590.
</p>
<p>Ledwina, T. (1994). Data driven version of Neyman's smooth test of fit. <em> J. Amer. Statist. Assoc.</em> <b> 89</b> 1000-1005.
</p>
<p>Neyman, J. (1937). &lsquo;Smooth test&rsquo; for goodness of fit. <em>Skand. Aktuarietidskr.</em> <b> 20</b>, 149-199.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# H0 is true
z = runif(80)
ddst.uniform.test(z, compute.p=TRUE)

# known fixed alternative
z = rnorm(80,10,16)
ddst.uniform.test(pnorm(z, 10, 16), compute.p=TRUE)


# H0 is false
z = rbeta(80,4,2)
(t = ddst.uniform.test(z, compute.p=TRUE))
t$p.value

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
