<!DOCTYPE html><html><head><title>Help for package imptree</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {imptree}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#imptree-package'><p>imptree: Classification Trees with Imprecise Probabilities</p></a></li>
<li><a href='#carEvaluation'><p>Car Evaluation Database</p></a></li>
<li><a href='#imptree'><p>Classification Trees with Imprecise Probabilities</p></a></li>
<li><a href='#imptree_control'><p>Control parameters for generating</p>
imptree objects</a></li>
<li><a href='#imptree_params'><p>Method parameters for generating imptree objects</p></a></li>
<li><a href='#node_imptree'><p>Classification with Imprecise Probabilities</p></a></li>
<li><a href='#predict.imptree'><p>Classification with Imprecise Probabilities</p></a></li>
<li><a href='#print.imptree'><p>Classification with Imprecise Probabilities</p></a></li>
<li><a href='#probInterval'><p>Various method around IPIntervals</p></a></li>
<li><a href='#summary.imptree'><p>Classification with Imprecise Probabilities</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Classification Trees with Imprecise Probabilities</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-08-16</td>
</tr>
<tr>
<td>Description:</td>
<td>Creation of imprecise classification trees. They rely on
    probability estimation within each node by means of either the
    imprecise Dirichlet model or the nonparametric predictive
    inference approach. The splitting variable is selected by the
    strategy presented in Fink and Crossman (2013)
    <a href="http://www.sipta.org/isipta13/index.php?id=paper&amp;amp;paper=014.html">http://www.sipta.org/isipta13/index.php?id=paper&amp;paper=014.html</a>,
    but also the original imprecise information gain of Abellan and
    Moral (2003) &lt;<a href="https://doi.org/10.1002%2Fint.10143">doi:10.1002/int.10143</a>&gt; is covered.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.5)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-08-16 17:52:30 UTC; paulus</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul Fink [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul Fink &lt;paul.fink@stat.uni-muenchen.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-08-17 08:50:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='imptree-package'>imptree: Classification Trees with Imprecise Probabilities</h2><span id='topic+imptree-package'></span>

<h3>Description</h3>

<p>The <code>imptree</code> package implements the creation of 
imprecise classification trees based on algorithm developed by 
Abellan and Moral. 
The credal sets of the classification variable within each node
are estimated by either the imprecise Dirichlet model (IDM) or the 
nonparametric predictive inference (NPI).
As split possible split criteria serve the 'information gain', 
based on the maximal entropy distribution, and the adaptable 
entropy-range based criterion propsed by Fink and Crossman.
It also implements different correction terms for the entropy.
</p>
<p>The performance of the tree can be evaluated with respect to the
common criteria in the context of imprecise classification trees.
</p>
<p>It also provides the functionality for estimating credal sets via 
IDM or NPI and obtain their minimal/maximal entropy (distribution) 
to be used outside the tree growing process.
</p>


<h3>References</h3>

<p>Abell&aacute;n,
J. and Moral, S. (2005), Upper entropy of credal sets. Applications to 
credal classification, <em>International Journal of Approximate Reasoning</em>
<b>39</b>, pp. 235&ndash;255.
</p>
<p>Baker, R. M. (2010), <em>Multinomial Nonparametric Predictive Inference:
Selection, Classification and Subcategory Data</em>, PhD thesis. Durham University, GB.
</p>
<p>Strobl, C. (2005), Variable Selection in Classification Trees Based on
Imprecise Probabilities, <em>ISIPTA '05: Proceedings of the Fourth
International Symposium on Imprecise Probabilities and Their Applications</em>,
339&ndash;348.
</p>
<p>Fink, P. and Crossman, R.J. (2013), Entropy based classification trees,
<em>ISIPTA '13: Proceedings of the Eighth International Symposium on Imprecise
Probability: Theories and Applications</em>, pp. 139&ndash;147.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code> for tree creation, <code><a href="#topic+probInterval">probInterval</a></code> for the credal set
and entropy estimation functionality
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")

## create a tree with IDM (s=1) to full size
## carEvaluation, leaving the first 10 observations out
ip &lt;- imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  control = list(depth = NULL, minbucket = 1))

## summarize the tree and show performance on training data
summary(ip)

## predict the first 10 observations
## Note: The result of the prediction is return invisibly
pp &lt;- predict(ip, dominance = "max", data = carEvaluation[(1:10),])
## print the general evaluation statistics
print(pp)
## display the predicted class labels
pp$classes

</code></pre>

<hr>
<h2 id='carEvaluation'>Car Evaluation Database</h2><span id='topic+carEvaluation'></span>

<h3>Description</h3>

<p>This data.frame contains the 'Car Evaluation' data set from 
the UCI Machine Learning Repository.
<br />
The 'Car Evaluation data' set gives the acceptance 
of a car directly related to the six input attributes:
buying, maint, doors, persons, lug_boot, safety.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(carEvaluation)
</code></pre>


<h3>Format</h3>

<p>A data frame with 1728 observations on the following 7 variables,
where each row contains information on one car.
All variables are factor variables.
</p>

<dl>
<dt><code>buying</code></dt><dd><p>Buying price of the car
(Levels: <code>high</code>, <code>low</code>, <code>med</code> ,<code>vhigh</code>)</p>
</dd>
<dt><code>maint</code></dt><dd><p>Price of the maintenance
(Levels: <code>high</code>, <code>low</code>, <code>med</code>, <code>vhigh</code>)</p>
</dd>
<dt><code>doors</code></dt><dd><p>Number of doors
(Levels: <code>2</code>, <code>3</code>, <code>4</code>, <code>5more</code>)</p>
</dd>
<dt><code>persons</code></dt><dd><p>Capacity in terms of persons to carry
(Levels: <code>2</code>, <code>4</code>, <code>more</code>)</p>
</dd>
<dt><code>lug_boot</code></dt><dd><p>Size of luggage boot
(Levels: <code>big</code>, <code>med</code>, <code>small</code>)</p>
</dd>
<dt><code>safety</code></dt><dd><p>Estimated safety of the car
(Levels: <code>high</code>, <code>low</code>, <code>med</code>)</p>
</dd>
<dt><code>acceptance</code></dt><dd><p>Acceptance of the car (target variable)
(Levels: <code>acc</code>, <code>good</code>, <code>unacc</code>, <code>vgood</code>)</p>
</dd>
</dl>


<h3>Details</h3>

<p>Car Evaluation Database was derived from a simple hierarchical
decision model originally developed for the demonstration of DEX. 
</p>
<p>The model evaluates cars according to the following concept structure:
</p>

<table>
<tr>
 <td style="text-align: left;">
 CAR                 </td><td style="text-align: left;"> car acceptability</td>
</tr>
<tr>
 <td style="text-align: left;">
 . PRICE             </td><td style="text-align: left;"> overall price</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . buying          </td><td style="text-align: left;"> buying price</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . maint           </td><td style="text-align: left;"> price of the maintenance</td>
</tr>
<tr>
 <td style="text-align: left;">
 . TECH              </td><td style="text-align: left;"> technical characteristics</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . COMFORT         </td><td style="text-align: left;"> comfort</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . . doors         </td><td style="text-align: left;"> number of doors</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . . persons       </td><td style="text-align: left;"> capacity in terms of persons to carry</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . . lug_boot      </td><td style="text-align: left;"> the size of luggage boot</td>
</tr>
<tr>
 <td style="text-align: left;">
 . . safety          </td><td style="text-align: left;"> estimated safety of the car
 </td>
</tr>

</table>

<p>Input attributes are printed in lowercase. Besides the target
concept (CAR), the model includes three intermediate concepts:
PRICE, TECH, COMFORT. 
</p>
<p>The Car Evaluation Database contains examples with the structural 
information removed, i.e., directly relates CAR to the six input 
attributes: buying, maint, doors, persons, lug_boot, safety.
</p>


<h3>Source</h3>

<p>The original data were taken from the UCI Machine Learning repository 
(<a href="https://archive.ics.uci.edu/ml/datasets/Car+Evaluation">https://archive.ics.uci.edu/ml/datasets/Car+Evaluation</a>) and were 
converted into R format by Paul Fink.
</p>


<h3>References</h3>

<p>M. Bohanec and V. Rajkovic (1988), Knowledge acquisition and explanation for 
multi-attribute decision making, <em>8th Intl. Workshop on Expert 
Systems and their Applications</em>, Avignon, France, 59&ndash;78.
</p>
<p>D. Dua and E. Karra Taniskidou (2017), UCI Machine Learning Repository 
<a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>. Irvine, CA: University of California, 
School of Information and Computer Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")
summary(carEvaluation)

</code></pre>

<hr>
<h2 id='imptree'>Classification Trees with Imprecise Probabilities</h2><span id='topic+imptree'></span><span id='topic+imptree.formula'></span><span id='topic+imptree.default'></span>

<h3>Description</h3>

<p><code>imptree</code> implements Abellan and Moral's tree 
algorithm (based on Quinlans ID3) for classification. It
employes either the imprecise Dirichlet model (IDM) or
nonparametric predictive inference (NPI) to generate the
imprecise probability distribution of the classification variable
within a node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
imptree(formula, data = NULL, weights, control,
  method = c("IDM", "NPI", "NPIapprox"), method.param, ...)

## Default S3 method:
imptree(x, y, ...)

imptree(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imptree_+3A_formula">formula</code></td>
<td>
<p>Formula describing the strucutre
(class variable ~ featutre variables).
Any interaction terms trigger an error.</p>
</td></tr>
<tr><td><code id="imptree_+3A_data">data</code></td>
<td>
<p>Data.frame to evaluate supplied formula on.
If not provided the the formula is evaluated 
on the calling environment</p>
</td></tr>
<tr><td><code id="imptree_+3A_weights">weights</code></td>
<td>
<p>Individual weight of the observations
(default: 1 to each).
<em>This argument is ignored at the moment.</em></p>
</td></tr>
<tr><td><code id="imptree_+3A_control">control</code></td>
<td>
<p>A named (partial) list according to the result of
<code><a href="#topic+imptree_control">imptree_control</a></code>.</p>
</td></tr>
<tr><td><code id="imptree_+3A_method">method</code></td>
<td>
<p>Method applied for calculating the probability
intervals of the class probability. <code>"IDM"</code> for the imprecise
Dirichlet model (default), <code>"NPI"</code> for use of the 
nonparametric predictive inference approach and <code>"NPIapprox"</code>
for use of the approximate algorithm obtaining maximal entropy of
NPI generated probability intervals.</p>
</td></tr>
<tr><td><code id="imptree_+3A_method.param">method.param</code></td>
<td>
<p>Named list providing the method specific 
parameters. See <code><a href="#topic+imptree_params">imptree_params</a></code>.</p>
</td></tr>
<tr><td><code id="imptree_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to the main function
<code>imptree.formula</code> or to the call of
<code><a href="#topic+imptree_control">imptree_control</a></code>.</p>
</td></tr>
<tr><td><code id="imptree_+3A_x">x</code></td>
<td>
<p>A data.frame or a matrix of feature variables.
The columns are required to be named.</p>
</td></tr>
<tr><td><code id="imptree_+3A_y">y</code></td>
<td>
<p>The classification variable as a factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>imptree</code>, which is a list
with the following components:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>Original call to <code>imptree</code></p>
</td></tr>
<tr><td><code>tree</code></td>
<td>
<p>Object reference to the underlying C++ tree object.</p>
</td></tr>
<tr><td><code>train</code></td>
<td>
<p>Training data in the form required by the 
workhorse C++ function.<br />
It is an integer matrix containing the internal factor
representations, adjusted for the C++ specific indexing
starting at 0 and not at 1 as in R.
Further attributes of the matrix, hold the names of the variables,
the C++ adjusted index of the classification variabe, as well as
the levels and number of levels for each variable.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>The formula describing the data structure</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>,
based on algorithms by 
J. Abell&aacute;n
and S. Moral for the IDM and R. M. Baker for the NPI approach.
</p>


<h3>References</h3>

<p>Abell&aacute;n,
J. and Moral, S. (2005), Upper entropy of credal sets. Applications to 
credal classification, <em>International Journal of Approximate Reasoning</em>
<b>39</b>, 235&ndash;255.
</p>
<p>Strobl, C. (2005), Variable Selection in Classification Trees Based on
Imprecise Probabilities, <em>ISIPTA'05: Proceedings of the Fourth
International Symposium on Imprecise Probabilities and Their Applications</em>,
339&ndash;348.
</p>
<p>Baker, R. M. (2010), <em>Multinomial Nonparametric Predictive Inference:
Selection, Classification and Subcategory Data</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.imptree">predict.imptree</a></code> for prediction,
<code><a href="#topic+summary.imptree">summary.imptree</a></code> for summary information, 
<code><a href="#topic+imptree_params">imptree_params</a></code> and <code><a href="#topic+imptree_control">imptree_control</a></code> for
arguments controlling the creation, <code><a href="#topic+node_imptree">node_imptree</a></code> for
accessing a specific node in the tree
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")

## create a tree with IDM (s=1) to full size on
## carEvaluation, leaving the first 10 observations out
imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  control = list(depth = NULL, minbucket = 1)) # control args as list

## same setting as above, now passing control args in '...'
imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  depth = NULL, minbucket = 1)

</code></pre>

<hr>
<h2 id='imptree_control'>Control parameters for generating
imptree objects</h2><span id='topic+imptree_control'></span>

<h3>Description</h3>

<p>Initializing and validating 
the tree generation parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imptree_control(splitmetric, controlList = NULL, tbase = 1,
  gamma = 1, depth = NULL, minbucket = 1L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imptree_control_+3A_splitmetric">splitmetric</code></td>
<td>
<p>Choosen split metric as integer:
<code>0</code> means <code>"globalmax"</code> and <code>1L</code> <code>"range"</code>, 
repectively. See <code><a href="#topic+imptree_params">imptree_params</a></code></p>
</td></tr>
<tr><td><code id="imptree_control_+3A_controllist">controlList</code></td>
<td>
<p>Named list containing the processed arguments.
See details.</p>
</td></tr>
<tr><td><code id="imptree_control_+3A_tbase">tbase</code></td>
<td>
<p>Value that needs to be at least attained to qualify
for splitting (default: 1)</p>
</td></tr>
<tr><td><code id="imptree_control_+3A_gamma">gamma</code></td>
<td>
<p>Weighting factor of the maximum entropy
(default: 1)</p>
</td></tr>
<tr><td><code id="imptree_control_+3A_depth">depth</code></td>
<td>
<p>Integer limiting the tree to the given depth, with
<code>0</code> indicating to perform no splitting at all.
If not supplied, <code>NULL</code> (default) or negative the
tree is grown to maximal size, the latter triggering a warning.</p>
</td></tr>
<tr><td><code id="imptree_control_+3A_minbucket">minbucket</code></td>
<td>
<p>Positive integer as minimal leaf size
(default: 1)</p>
</td></tr>
<tr><td><code id="imptree_control_+3A_...">...</code></td>
<td>
<p>Argument gobbling; is not processed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>controlList</code> may be a named list with names in
<code>c("tbase", "gamma", "depth", "minbucket")</code>
Any values in this list will overwrite those supplied in 
named arguments.
When <code>controlList = NULL</code> (default) only the supplied 
arguments are checked.
</p>
<p>In case <code>controlList</code> contains an argument named
<code>splitmetric</code>, this will be ignored.
If <code>splitmetric</code> is <code>0L</code>, i.e. <code>"globalmax"</code>, 
the values for <code>gamma</code> and <code>tbase</code> are set to their 
default values, even if the user supplied different values.
</p>


<h3>Value</h3>

<p>A list containing the options. Missing options are set
to their default value.
</p>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code>, <code><a href="#topic+imptree_params">imptree_params</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Check performed for splitmetric 'globalmax',
## tbase' is default generated and 'gamma' is overwritten
## (see Details), tree is grown to full depth and 
## at least 5 observations are needed to be within each node
imptree_control(splitmetric = 0, gamma = 0.5,
                depth = NULL, minbucket = 5)

## Passing some control arguments in a list
## As splitmetric is 'range', gamma is respected
imptree_control(splitmetric = 1, minbucket = 5,
                controlList = list(gamma = 0.5, depth = NULL))

</code></pre>

<hr>
<h2 id='imptree_params'>Method parameters for generating imptree objects</h2><span id='topic+imptree_params'></span>

<h3>Description</h3>

<p>Initializing and validating the essential probability method specific parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imptree_params(args, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imptree_params_+3A_args">args</code></td>
<td>
<p>Named list containing the arguments to be processed.
May be <code>NULL</code> for default values. See details.</p>
</td></tr>
<tr><td><code id="imptree_params_+3A_method">method</code></td>
<td>
<p>Probability method as character, as supplied to <code><a href="#topic+imptree">imptree</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>imptree_params()</code> is not exported into the user's namespace.
</p>
<p>For all methods <code>args</code> takes the following inputs:
</p>

<ul>
<li><p>s: Hyperparamter of the imprecise Dirichlet model
(<code>s &gt;= 0</code>), see below.
</p>
</li>
<li><p>correction: Entropy correction to be carried out
(Default <code>"no"</code>), see below.
</p>
</li>
<li><p>splitmetric: Split criterion to use
(Default <code>"globalmax"</code>), see below.
</p>
</li></ul>

<p>The hyperparamter <code>s</code> of the imprecise Dirchlet model (IDM) may
be given as any non-negative value.  It defines the impression the locally
applied IDMs introduce. With increasing values of <code>s</code> more impression is
added. For <code>s=0</code> the IDM collapses to a precise Dirichlet model.
This value is ignored for <code>method = "NPI"</code>.
</p>
<p>To account for a varying number of categories of the splitting candidates
Strobl proposed the use of a correction based on the Miller-entropy
correction: <code>correction = "strobl"</code>.
In their work Abellan and Moral favoured for the IDM the use of a
generalized Hartley measure such that the final measure may be viewed as
measure of total uncertainty: <code>correction = "abellan"</code>.
This correction method is not available for <code>method = "NPI"</code>.
</p>
<p>When deciding for split canditates a split criterion is applied.
<code>"globalmax"</code> splits on maximal entropy of local models (with a
global IDM parameter <code>s</code>).
For <code>"range"</code> the splitting variable is found by taking the whole
entropy interval into account.
<code>localmax</code> is only available for IDM and split on maximal entropy,
however with <code>s</code> dependent on the number of missing values in the class
variable in the node
</p>


<h3>Value</h3>

<p>A list containing the sanitized and validated parameters.
</p>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code>, <code><a href="#topic+imptree_control">imptree_control</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Note: 
## The function is used internally by imptree (not exported).

## default constructed for method IDM
imptree:::imptree_params(NULL, method = "IDM")

## passing arguments as list ('s' is not required for 'NPI')
imptree:::imptree_params(args = list(correction = "strobl", 
                                     splitmetric = "globalmax"),
                         method = "NPI")

</code></pre>

<hr>
<h2 id='node_imptree'>Classification with Imprecise Probabilities</h2><span id='topic+node_imptree'></span><span id='topic+print.node_imptree'></span>

<h3>Description</h3>

<p>Access probability information of nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>node_imptree(x, idx = NULL)

## S3 method for class 'node_imptree'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="node_imptree_+3A_x">x</code></td>
<td>
<p>An object of class <code>imptree</code> or <code>node_imptree</code>,
respectively. See details.</p>
</td></tr>
<tr><td><code id="node_imptree_+3A_idx">idx</code></td>
<td>
<p>numeric or integer vector of indices specifying
the sequential node access from the root node.
Numeric values are coerced to integer as
by <code><a href="base.html#topic+as.integer">as.integer</a></code>
(and hence truncated towards zero). <br />
If <code>NULL</code> the probability information of 
the root node are accessed.</p>
</td></tr>
<tr><td><code id="node_imptree_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>print</code> methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function acceses the properties of a specific node 
of an imprecise tree. 
An existence check on the stored C++ object reference is 
carried out at first. If the reference is not valid the 
original call for <code>"x"</code> is printed as error.
</p>


<h3>Value</h3>

<p>An object of class <code>node_imptree</code> containing 
information on the properties of the node as a list:
</p>
<table>
<tr><td><code>probint</code></td>
<td>
<p>matrix containing the bounds of the imprecise
probability distribution and the absolute observed frequencies
of the classification variable within the node.</p>
</td></tr>
<tr><td><code>depth</code></td>
<td>
<p>The depth of the node with the tree.</p>
</td></tr>
<tr><td><code>splitter</code></td>
<td>
<p>The name of the variable used for splitting
as character; <code>NA</code> if node is a leaf.</p>
</td></tr>
<tr><td><code>children</code></td>
<td>
<p>The number of children of the node.</p>
</td></tr>
<tr><td><code>traindataIdx</code></td>
<td>
<p>Vector giving the indexes of the 
training data contained within the node</p>
</td></tr>
<tr><td><code>ipmodel</code></td>
<td>
<p>List giving details about the used 
imprecise probability model to obatin the credal set:
</p>

<dl>
<dt>iptype</dt><dd><p>used IP model:
<code>"IDM"</code>, <code>"NPI"</code> or <code>"NPIapprox"</code></p>
</dd>
<dt>s</dt><dd><p>If <code>iptpye == "IDM"</code> the IDM's parameter 's',
otherwise this list entry is missing</p>
</dd>
</dl>
</td></tr>
</table>
<p>The printing function returns the
<code>node_imptree</code> object invisibly.
</p>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code>, for global information on 
the generated tree <code><a href="#topic+summary.imptree">summary.imptree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")

## create a tree with IDM (s=1) to full size
## carEvaluation, leaving the first 10 observations out
ip &lt;- imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  control = list(depth = NULL, minbucket = 1))

## obtain information on the root node
node_imptree(x = ip, idx = NULL)

## obtain information on the 2nd note in the 1st level
node_imptree(x = ip, idx = c(1, 2))

## reference to an invalid index and/or level generates error
## Not run: 
node_imptree(x = ip, idx = c(1,10))  # no 10th node on 1st level

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.imptree'>Classification with Imprecise Probabilities</h2><span id='topic+predict.imptree'></span><span id='topic+print.evaluation_imptree'></span>

<h3>Description</h3>

<p>Prediction of <code>imptree</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imptree'
predict(object, data, dominance = c("strong", "max"),
  utility = 0.65, ...)

## S3 method for class 'evaluation_imptree'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.imptree_+3A_object">object</code></td>
<td>
<p>An object of class <code>imptree</code>. See details.</p>
</td></tr>
<tr><td><code id="predict.imptree_+3A_data">data</code></td>
<td>
<p>Data.frame containing observations to be predicted.
If <code>NULL</code> the observations in the training set of <code>"object"</code>
are employed.</p>
</td></tr>
<tr><td><code id="predict.imptree_+3A_dominance">dominance</code></td>
<td>
<p>Dominace criterion to be applied when predicting
classes. This may either be <code>"strong"</code> (default) or <code>"max"</code>.
See details.</p>
</td></tr>
<tr><td><code id="predict.imptree_+3A_utility">utility</code></td>
<td>
<p>Utility for the utility based accuracy measure for a 
vacuous prediction result (default: 0.65).</p>
</td></tr>
<tr><td><code id="predict.imptree_+3A_...">...</code></td>
<td>
<p>Additional arguments for data. May be <code>"weights"</code>,
<code>"subset"</code>, <code>"na.action"</code>, any further are discarded.</p>
</td></tr>
<tr><td><code id="predict.imptree_+3A_x">x</code></td>
<td>
<p>an object of class <code>evaluation_imptree</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function carries out the prediction of an imprecise tree. 
An existence check on the stored C++ object reference is carried out 
at first. If the reference is not valid the original call
for <code>"object"</code> is printed as error.
</p>
<p>There are currently 2 different dominance criteria available:
</p>

<dl>
<dt>max</dt><dd><p>Maximum frequency criterion. Dominance is decided only
by the upper bound of the probability interval, ie. a state <code class="reqn">C_i</code> is 
dominated if there exists any <code class="reqn">j \neq i</code> with
<code class="reqn">u(C_i) &lt; u(C_j)</code></p>
</dd>
<dt>strong</dt><dd><p>Interval dominance criterion. For the IDM it
coincides with the strong dominance criterion. Here a state
<code class="reqn">C_i</code> is dominated if there exists any <code class="reqn">j \neq i</code> 
with <code class="reqn">u(C_i) &lt; l(C_j)</code></p>
</dd>
</dl>



<h3>Value</h3>

<p><code>predict.imptree()</code> return an object of class 
<code>evaluation_imptree</code>, which is a named list containing 
predicted classes, predicted probability distribution and  accuracy 
evaluation
</p>
<table>
<tr><td><code>probintlist</code></td>
<td>
<p>List of the imprecise probability distributions of the
class variable. One matrix per observation in the test data.</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>Predicted class(es) of the observations as boolean matrix</p>
</td></tr>
<tr><td><code>evaluation</code></td>
<td>
<p>Result of accuracy evaluation
</p>

<ul>
<li><p>nObs: Number of observations
</p>
</li>
<li><p>deter: Determinacy
</p>
</li>
<li><p>nObsIndet: Number of observations with indeterminate prediction
</p>
</li>
<li><p>indetSize: Average number of classes when predicting 
indeterminate (<code>NA</code> when no indeterminate observation)
</p>
</li>
<li><p>acc_single: Single-set accuracy (<code>NA</code> when no determinate 
observation)
</p>
</li>
<li><p>acc_set: Set-accuracy (<code>NA</code> when no indeterminate observation)
</p>
</li>
<li><p>acc_disc: Discounted-accuracy
</p>
</li>
<li><p>acc_util: Utility based (discounted) accuracy
</p>
</li></ul>
</td></tr>
</table>
<p>The printing function returns the
<code>evaluation_imptree</code> object invisibly.
</p>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code>, <code><a href="#topic+node_imptree">node_imptree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")

## create a tree with IDM (s=1) to full size
## carEvaluation, leaving the first 10 observations out
ip &lt;- imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  control = list(depth = NULL, minbucket = 1))

## predict the first 10 observations with 'max' dominance
pp &lt;- predict(ip, dominance = "max", data = carEvaluation[(1:10),])
print(pp)
pp$classes                ## predicted classes as logical matrix

## predict the first 10 observations with 'strong' dominance and
## use a different level of utility
predict(ip, dominance = "strong", data = carEvaluation[(1:10),],
        utility = 0.5)

</code></pre>

<hr>
<h2 id='print.imptree'>Classification with Imprecise Probabilities</h2><span id='topic+print.imptree'></span>

<h3>Description</h3>

<p>Printing the <code>imptree</code> object to console
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imptree'
print(x, digits = getOption("digits"), sep = "\t",
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.imptree_+3A_x">x</code></td>
<td>
<p>Object of class <code>imptree</code>. See details.</p>
</td></tr>
<tr><td><code id="print.imptree_+3A_digits">digits</code></td>
<td>
<p>a non-null value for digits specifies the minimum number
of significant digits to be printed in values. The default uses 
<code><a href="base.html#topic+getOption">getOption</a>("digits")</code>. Non-integer values will be rounded down,
and only values greater than or equal to 1 and 
no greater than 17 are accepted.</p>
</td></tr>
<tr><td><code id="print.imptree_+3A_sep">sep</code></td>
<td>
<p>Separator between the displayed IPDistribution objects.
(Default: <code>'\t'</code>)</p>
</td></tr>
<tr><td><code id="print.imptree_+3A_...">...</code></td>
<td>
<p>Additional arguments; ignored at the moment</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An existence check on the stored C++ object reference is carried out 
at first. If the reference is not valid the original call
for <code>"object"</code> is printed as error.
</p>
<p>For a more detailed summary of the tree <code><a href="#topic+summary.imptree">summary.imptree</a></code>.
</p>


<h3>Value</h3>

<p>Returns the calling object invisible.
</p>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code>, <code><a href="#topic+summary.imptree">summary.imptree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")

## create a tree with IDM (s=1) to full size
## carEvaluation, leaving the first 10 observations out
ip &lt;- imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  control = list(depth = NULL, minbucket = 1))

ip                        ## standard printing; same as 'print(ip)'
print(ip, sep = ";")      ## probability intervals are separated by ';'

</code></pre>

<hr>
<h2 id='probInterval'>Various method around IPIntervals</h2><span id='topic+probInterval'></span>

<h3>Description</h3>

<p>Calculation of probability intervals, 
and their maximal and minimal entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probInterval(table, iptype = c("IDM", "NPI", "NPIapprox"),
  entropymin = TRUE, entropymax = TRUE, correction = c("no",
  "strobl", "abellan"), s = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probInterval_+3A_table">table</code></td>
<td>
<p>integer vector of absolute frequencies</p>
</td></tr>
<tr><td><code id="probInterval_+3A_iptype">iptype</code></td>
<td>
<p>method for calculating the probability
intervals of <code>table</code>. <code>"IDM"</code> for the imprecise
Dirichlet model (default), <code>"NPI"</code> for use of the 
nonparametric predictive inference approach and <code>"NPIapprox"</code>
for use of the approximate algorithm obtaining maximal entropy of
NPI generated probability intervals.</p>
</td></tr>
<tr><td><code id="probInterval_+3A_entropymin">entropymin</code></td>
<td>
<p>Calculation of one distribution with minimal 
entropy, including the actual value of the minimal entropy
(default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="probInterval_+3A_entropymax">entropymax</code></td>
<td>
<p>Calculation of the distribution with maximal 
entropy, including the actual value of the maximal entropy
(default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="probInterval_+3A_correction">correction</code></td>
<td>
<p>Entropy correction to be carried out,
ignorned if <code>(entropymin || entropymax) == FALSE</code>
(default <code>"no"</code>), see <code><a href="#topic+imptree_params">imptree_params</a></code></p>
</td></tr>
<tr><td><code id="probInterval_+3A_s">s</code></td>
<td>
<p>Hyperparamter of the IDM (<code>s &gt;= 0</code>),
see <code><a href="#topic+imptree_params">imptree_params</a></code> 
(ignored for <code>iptype == "NPI"</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with 5 named entries:
</p>
<table>
<tr><td><code>probint</code></td>
<td>
<p>matrix with 3 rows and <code>length(table)</code>
columns: in the rows are the abosulte frequencies, the lower 
bound (<code>"lower"</code>) and the upper bound (<code>"upper"</code>) 
of the event-wise probabilities.</p>
</td></tr>
<tr><td><code>maxEntDist</code></td>
<td>
<p>The (unique) probability distribution with
maximal entropy</p>
</td></tr>
<tr><td><code>maxEntCorr</code></td>
<td>
<p>The value of the (corrected) maximal entropy</p>
</td></tr>
<tr><td><code>minEntDist</code></td>
<td>
<p>A probability distribution with minimal
entropy, as it is not necessarily unqiue there may be others</p>
</td></tr>
<tr><td><code>minEntCorr</code></td>
<td>
<p>The value of the (corrected) minimal entropy</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree_params">imptree_params</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Artificial vector of absolute frequencies
obs &lt;- c(a = 1,b = 2, c = 10, d = 30, e = 5)

## probability interval by NPI, including only information on the
## mininum entropy distribution, using no entropy correction
probInterval(obs, iptype = "NPI", entropymax = FALSE)

## probability interval by IDM, including information on the
## minimum and maximum entropy distribution with s = 2 and correction
## according to 'strobl'
probInterval(obs, iptype = "IDM", correction = "strobl", s = 2)

</code></pre>

<hr>
<h2 id='summary.imptree'>Classification with Imprecise Probabilities</h2><span id='topic+summary.imptree'></span><span id='topic+print.summary.imptree'></span>

<h3>Description</h3>

<p>Summary function for an imptree object, assesses 
accuracy achieved on training data and further tree properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imptree'
summary(object, utility = 0.65,
  dominance = c("strong", "max"), ...)

## S3 method for class 'summary.imptree'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.imptree_+3A_object">object</code></td>
<td>
<p>An object of class <code>imptree</code>. See details.</p>
</td></tr>
<tr><td><code id="summary.imptree_+3A_utility">utility</code></td>
<td>
<p>Utility for the utility based accuracy measure for
a vacuous prediction result (default: 0.65).</p>
</td></tr>
<tr><td><code id="summary.imptree_+3A_dominance">dominance</code></td>
<td>
<p>Dominace criterion to be applied when predicting
classes. This may either be <code>"strong"</code> (default) or
<code>"max"</code>. See details at <code><a href="#topic+predict.imptree">predict.imptree</a></code>.</p>
</td></tr>
<tr><td><code id="summary.imptree_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored at the moment.</p>
</td></tr>
<tr><td><code id="summary.imptree_+3A_x">x</code></td>
<td>
<p>an object of class <code>summary.imptree</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>An existence check on the stored C++ object reference is carried
out at first. If the reference is not valid the original call
for <code>"object"</code> is printed as error.
</p>


<h3>Value</h3>

<p>A named list of class <code>summary.imptree</code> containing
the tree creation call, accuracy on the training data, meta data
and supplied the utility and dominance criterion for evaluation.
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>Call to create the tree</p>
</td></tr>
<tr><td><code>utility</code></td>
<td>
<p>Supplied utility, or its default value</p>
</td></tr>
<tr><td><code>dominance</code></td>
<td>
<p>Supplied dominace criterion, or its 
default value</p>
</td></tr>
<tr><td><code>sizes</code></td>
<td>
<p>List containing the overall number and number of 
indeterminate predictions on training data</p>
</td></tr>
<tr><td><code>acc</code></td>
<td>
<p>named vector containing the accuracy measures 
on training data with nicer names (without size information)
(see <code><a href="#topic+predict.imptree">predict.imptree</a></code>)</p>
</td></tr>
<tr><td><code>meta</code></td>
<td>
<p>named vector containing the tree's depth, 
number of leaves and number of nodes</p>
</td></tr>
</table>
<p>The printing function returns the
<code>summary.imptree</code> object invisibly.
</p>


<h3>Author(s)</h3>

<p>Paul Fink <a href="mailto:Paul.Fink@stat.uni-muenchen.de">Paul.Fink@stat.uni-muenchen.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imptree">imptree</a></code>, <code><a href="#topic+predict.imptree">predict.imptree</a></code>,
for information on a single node <code><a href="#topic+node_imptree">node_imptree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carEvaluation")

## create a tree with IDM (s=1) to full size
## carEvaluation, leaving the first 10 observations out
ip &lt;- imptree(acceptance~., data = carEvaluation[-(1:10),], 
  method="IDM", method.param = list(splitmetric = "globalmax", s = 1), 
  control = list(depth = NULL, minbucket = 1))

## summary including prediction on training data
summary(ip)                       # default prediction
summary(ip, dominance = "max")    # different prediction parameter

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
