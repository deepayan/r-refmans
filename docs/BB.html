<!DOCTYPE html><html><head><title>Help for package BB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BB-package'><p>Solving and Optimizing Large-Scale Nonlinear Systems</p></a></li>
<li><a href='#BBoptim'><p>Large=Scale Nonlinear Optimization - A Wrapper for spg()</p></a></li>
<li><a href='#BBsolve'><p>Solving Nonlinear System of Equations - A Wrapper for dfsane()</p></a></li>
<li><a href='#dfsane'><p> Solving Large-Scale Nonlinear System of Equations</p></a></li>
<li><a href='#multiStart'><p>Nonlinear Optimization or Root-Finding with Multiple Starting Values</p></a></li>
<li><a href='#project'><p>spg Projection Functions</p></a></li>
<li><a href='#sane'><p> Solving Large-Scale Nonlinear System of Equations</p></a></li>
<li><a href='#spg'><p>Large-Scale Optimization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2019.10-1</td>
</tr>
<tr>
<td>Title:</td>
<td>Solving and Optimizing Large-Scale Nonlinear Systems</td>
</tr>
<tr>
<td>Description:</td>
<td>Barzilai-Borwein spectral methods for solving nonlinear
        system of equations, and for optimizing nonlinear objective
        functions subject to simple constraints. A tutorial style
        introduction to this package is available in a vignette on the
        CRAN download page or, when the package is loaded in an R
        session, with vignette("BB").</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.6.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, quadprog</td>
</tr>
<tr>
<td>Suggests:</td>
<td>setRNG, survival, Hmisc, numDeriv</td>
</tr>
<tr>
<td>BuildVignettes:</td>
<td>true</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Copyright:</td>
<td>2008-2020, Ravi Varadhan</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.jhsph.edu/agingandhealth/People/Faculty_personal_pages/Varadhan.html">http://www.jhsph.edu/agingandhealth/People/Faculty_personal_pages/Varadhan.html</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-10-05 18:13:35 UTC; paul</td>
</tr>
<tr>
<td>Author:</td>
<td>Ravi Varadhan [aut, cph, trl],
  Paul Gilbert [aut, cre],
  Marcos Raydan [ctb] (with co-authors, wrote original algorithms in
    fortran. These provided some guidance for implementing R code in
    the BB package.),
  JM Martinez [ctb] (with co-authors, wrote original algorithms in
    fortran. These provided some guidance for implementing R code in
    the BB package.),
  EG Birgin [ctb] (with co-authors, wrote original algorithms in fortran.
    These provided some guidance for implementing R code in the BB
    package.),
  W LaCruz [ctb] (with co-authors, wrote original algorithms in fortran.
    These provided some guidance for implementing R code in the BB
    package.)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul Gilbert &lt;pgilbert.ttv9z@ncf.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-10-18 04:50:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='BB-package'>Solving and Optimizing Large-Scale Nonlinear Systems</h2><span id='topic+BB-package'></span><span id='topic+BB.Intro'></span>

<h3>Description</h3>

<p>Non-monotone Barzilai-Borwein spectral methods for the solution 
and optimization of large-scale nonlinear systems.  </p>


<h3>Details</h3>

<p>A tutorial style introduction to this package is available in a vignette, which
can be viewed with vignette(&quot;BB&quot;).
</p>
<p>The main functions in this package are:
</p>
<pre>

BBsolve A wrapper function to provide a robust stategy for solving large 
        systems of nonlinear equations. It calls dfsane with different 
	algorithm control settings, until a successfully converged solution
	is obtained.

BBoptim A wrapper function to provide a robust stategy for real valued function 
        optimization. It calls spg with different algorithm control settings, 
	until a successfully converged solution is obtained.

dfsane  function for solving large systems of nonlinear equations using a 
        derivative-free spectral approach 

sane	function for solving large systems of nonlinear equations using 
        spectral approach

spg	function for spectral projected gradient method for large-scale 
        optimization with simple constraints
</pre>


<h3>Author(s)</h3>

<p>Ravi Varadhan</p>


<h3>References</h3>

<p>J Barzilai, and JM Borwein  (1988),  Two-point step size gradient methods, <em>IMA J Numerical Analysis</em>, 8, 141-148. 
</p>
<p>Birgin EG, Martinez JM, and Raydan M (2000): Nonmonotone spectral projected 
gradient methods on convex sets, <em>SIAM J Optimization</em>, 10, 1196-1211.
</p>
<p>Birgin EG, Martinez JM, and Raydan M (2001): SPG: software for 
convex-constrained optimization, <em>ACM Transactions on Mathematical Software</em>.
</p>
<p>L Grippo, F Lampariello, and S Lucidi (1986),  A nonmonotone line search technique for Newton's method,  <em>SIAM J on Numerical Analysis</em>, 23, 707-716. 
</p>
<p>W LaCruz, and M Raydan (2003),  Nonmonotone spectral methods for large-scale nonlinear systems, <em>Optimization Methods and Software</em>, 18, 583-599. 
</p>
<p>W LaCruz, JM Martinez, and M Raydan (2006),  Spectral residual method without gradient information for solving large-scale nonlinear systems of equations, <em>Mathematics of Computation</em>, 75, 1429-1448. 
</p>
<p>M Raydan (1997),  Barzilai-Borwein gradient method for large-scale unconstrained minimization problem, <em>SIAM J of Optimization</em>, 7, 26-33.
</p>
<p>R Varadhan and C Roland (2008),  Simple and globally-convergent methods for accelerating the convergence of any EM 
algorithm,  <em>Scandinavian J Statistics</em>, doi: 10.1111/j.1467-9469.2007.00585.x. 
</p>
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, <a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>

<hr>
<h2 id='BBoptim'>Large=Scale Nonlinear Optimization - A Wrapper for spg()</h2><span id='topic+BBoptim'></span>

<h3>Description</h3>

<p>A strategy using different Barzilai-Borwein steplengths to 
optimize a nonlinear objective function subject to box constraints.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  BBoptim(par, fn, gr=NULL, method=c(2,3,1), lower=-Inf, upper=Inf, 
  	project=NULL, projectArgs=NULL,
	control=list(), quiet=FALSE, ...) 
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BBoptim_+3A_par">par</code></td>
<td>
<p>A real vector argument to <code>fn</code>, indicating the initial 
guess for the root of the nonliinear system of equations <code>fn</code>.</p>
</td></tr>
<tr><td><code id="BBoptim_+3A_fn">fn</code></td>
<td>
<p>Nonlinear objective function that is to be optimized.  A scalar 
function that takes a real vector as argument and returns a scalar 
that is the value of the function at that point (see details).</p>
</td></tr>
<tr><td><code id="BBoptim_+3A_gr">gr</code></td>
<td>
<p>The gradient of the objective function <code>fn</code> evaluated at the 
argument.  This is a vector-function that takes a real vector as argument 
and returns a real vector of the same length.  It defaults to 
<code>NULL</code>, which means that gradient is evaluated numerically.
Computations are dramatically faster in high-dimensional problems when 
the exact gradient is provided.  See *Example*.</p>
</td></tr> 
<tr><td><code id="BBoptim_+3A_method">method</code></td>
<td>
<p>A vector of integers specifying which Barzilai-Borwein 
steplengths should be used in a consecutive manner.  The methods will 
be used in the order specified.</p>
</td></tr>
<tr><td><code id="BBoptim_+3A_upper">upper</code></td>
<td>
<p>An upper bound for box constraints. See <code>spg</code></p>
</td></tr>
<tr><td><code id="BBoptim_+3A_lower">lower</code></td>
<td>
<p>An lower bound for box constraints. See <code>spg</code></p>
</td></tr>
<tr><td><code id="BBoptim_+3A_project">project</code></td>
<td>
<p>The projection function that takes a point in $R^n$ and 
projects it onto a region that defines the constraints of the problem.
This is a vector-function that takes a real vector as argument and 
returns a real vector of the same length. 
See <code>spg</code> for more details.</p>
</td></tr> 
<tr><td><code id="BBoptim_+3A_projectargs">projectArgs</code></td>
<td>
<p>list of arguments to <code>project</code>. See <code>spg()</code> 
for more details.</p>
</td></tr> 
<tr><td><code id="BBoptim_+3A_control">control</code></td>
<td>
<p>A list of parameters governing the algorithm behaviour.  
This list is the same as that for <code>spg</code> (excepting 
the default for <code>trace</code>).  See <code>details</code> for 
important special features of control parameters.</p>
</td></tr>
<tr><td><code id="BBoptim_+3A_quiet">quiet</code></td>
<td>
<p>logical indicating if messages about convergence success or
failure should be suppressed</p>
</td></tr> 
<tr><td><code id="BBoptim_+3A_...">...</code></td>
<td>
<p>arguments passed fn (via the optimization algorithm).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This wrapper is especially useful in problems where (<code>spg</code> is likely 
to experience convergence difficulties.  When <code>spg()</code> fails, i.e. 
when <code>convergence &gt; 0</code> is obtained, a user might attempt various strategies
to find a local optimizer. The function <code>BBoptim</code> tries the following 
sequential strategy:
</p>

<ol>
<li><p> Try a different BB steplength.  Since the default is <code>method = 2</code> 
for <code>dfsane</code>, BBoptim wrapper tries <code>method = c(2, 3, 1)</code>.
</p>
</li>
<li><p> Try a different non-monotonicity parameter <code>M</code> for each method, 
i.e. BBoptim wrapper tries <code>M = c(50, 10)</code> for each BB steplength.
</p>
</li></ol>

<p>The argument <code>control</code> defaults to a list with values 
<code>maxit = 1500, M = c(50, 10), ftol=1.e-10, gtol = 1e-05, maxfeval = 10000, 
  maximize = FALSE, trace = FALSE, triter = 10, eps = 1e-07, checkGrad=NULL</code>.  
It is recommended that <code>checkGrad</code> be set to FALSE for high-dimensional 
problems, after making sure that the gradient is correctly specified. See 
<code>spg</code> for additional details about the default.
</p>
<p>If <code>control</code> is specified as an argument, only values which are different
need to be given in the list. See <code>spg</code> for more details.
</p>


<h3>Value</h3>

<p>A list with the same elements as returned by <code>spg</code>.  One additional 
element returned is <code>cpar</code> which contains the control parameter settings
used to obtain successful convergence, or to obtain the best solution in 
case of failure.</p>


<h3>References</h3>

 
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large 
System of Nonlinear Equations and for Optimizing a High-Dimensional 
Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, 
<a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BBsolve">BBsolve</a></code>,
<code><a href="#topic+spg">spg</a></code>,
<code><a href="#topic+multiStart">multiStart</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
<code><a href="numDeriv.html#topic+grad">grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use a preset seed so test values are reproducable. 
require("setRNG")
old.seed &lt;- setRNG(list(kind="Mersenne-Twister", normal.kind="Inversion",
    seed=1234))

rosbkext &lt;- function(x){
# Extended Rosenbrock function
n &lt;- length(x)
j &lt;- 2 * (1:(n/2))
jm1 &lt;- j - 1
sum(100 * (x[j] - x[jm1]^2)^2 + (1 - x[jm1])^2)
}

p0 &lt;- rnorm(50)
spg(par=p0, fn=rosbkext)
BBoptim(par=p0, fn=rosbkext)

# compare the improvement in convergence when bounds are specified
BBoptim(par=p0, fn=rosbkext, lower=0) 

# identical to spg() with defaults
BBoptim(par=p0, fn=rosbkext, method=3, control=list(M=10, trace=TRUE))  
</code></pre>

<hr>
<h2 id='BBsolve'>Solving Nonlinear System of Equations - A Wrapper for dfsane()</h2><span id='topic+BBsolve'></span>

<h3>Description</h3>

<p>A strategy using different Barzilai-Borwein steplengths to 
solve a nonlinear system of equations.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  BBsolve(par, fn, method=c(2,3,1), 
	control=list(), quiet=FALSE, ...) 
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BBsolve_+3A_par">par</code></td>
<td>
<p>A real vector argument to <code>fn</code>, indicating the initial guess
for the root of the nonliinear system of equations <code>fn</code>.</p>
</td></tr>
<tr><td><code id="BBsolve_+3A_fn">fn</code></td>
<td>
<p>Nonlinear system of equation that is to be solved. 
A vector function that takes a real vector as argument and 
returns a real vector of the same length.</p>
</td></tr>
<tr><td><code id="BBsolve_+3A_method">method</code></td>
<td>
<p>A vector of integers specifying which Barzilai-Borwein 
steplengths should be used in a consecutive manner.  The methods will 
be used in the order specified.</p>
</td></tr>
<tr><td><code id="BBsolve_+3A_control">control</code></td>
<td>
<p>A list of parameters governing the algorithm behaviour.  
This list is the same as that for <code>dfsane</code> and <code>sane</code> (excepting 
the default for <code>trace</code>).  
See <code>details</code> for important special features of control parameters.</p>
</td></tr>
<tr><td><code id="BBsolve_+3A_quiet">quiet</code></td>
<td>
<p>logical indicating if messages about convergence success or
failure should be suppressed</p>
</td></tr> 
<tr><td><code id="BBsolve_+3A_...">...</code></td>
<td>
<p>arguments passed fn (via the optimization algorithm).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This wrapper is especially useful in problems where the algorithms
(<code>dfsane</code> or <code>sane</code>) are likely to experience difficulties in 
convergence.  When these algorithms with default parameters fail, i.e. 
when <code>convergence &gt; 0</code> is obtained, a user might attempt various 
strategies to find a root of the nonlinear system. The function <code>BBsolve</code> 
tries the following sequential strategy:
</p>

<ol>
<li><p> Try a different BB steplength.  Since the default is <code>method = 2</code> 
for <code>dfsane</code>, the BBsolve wrapper tries <code>method = c(2, 1, 3)</code>. 
</p>
</li>
<li><p> Try a different non-monotonicity parameter <code>M</code> for each method, 
i.e. BBsolve wrapper tries <code>M = c(50, 10)</code> for each BB steplength.
</p>
</li>
<li><p> Try with Nelder-Mead initialization.  Since the default for 
<code>dfsane</code> is <code>NM = FALSE</code>, BBsolve does <code>NM = c(TRUE, FALSE)</code>.
</p>
</li></ol>

<p>The argument <code>control</code> defaults to a list with values 
<code>maxit = 1500, M = c(50, 10), tol = 1e-07, trace = FALSE, 
        triter = 10, noimp = 100, NM = c(TRUE, FALSE)</code>. 
If <code>control</code> is specified as an argument, only values which are different
need to be given in the list. See <code>dfsane</code> for more details.
</p>


<h3>Value</h3>

<p>A list with the same elements as returned by <code>dfsane</code> 
or <code>sane</code>.  One additional element returned is <code>cpar</code> which 
contains the control parameter settings used to obtain successful 
convergence, or to obtain the best solution in case of failure. </p>


<h3>References</h3>

 
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, <a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BBoptim">BBoptim</a></code>,
<code><a href="#topic+dfsane">dfsane</a></code>,
<code><a href="#topic+sane">sane</a></code>
<code><a href="#topic+multiStart">multiStart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use a preset seed so test values are reproducable. 
require("setRNG")
old.seed &lt;- setRNG(list(kind="Mersenne-Twister", normal.kind="Inversion",
    seed=1234))

broydt &lt;- function(x) {
n &lt;- length(x)
f &lt;- rep(NA, n)
h &lt;- 2
f[1] &lt;- ((3 - h*x[1]) * x[1]) - 2*x[2] + 1
tnm1 &lt;- 2:(n-1)
f[tnm1] &lt;- ((3 - h*x[tnm1]) * x[tnm1]) - x[tnm1-1] - 2*x[tnm1+1] + 1
f[n] &lt;- ((3 - h*x[n]) * x[n]) - x[n-1] + 1
f
}

p0 &lt;- rnorm(50)
BBsolve(par=p0, fn=broydt)  # this works 
dfsane(par=p0, fn=broydt) # but this is highly unliikely to work.

# this implements the 3 BB steplengths with M = 50, and without Nelder-Mead initialization
BBsolve(par=p0, fn=broydt, control=list(M=50, NM=FALSE))

# this implements BB steplength 1 with M = 50 and 10, and both with and 
#   without Nelder-Mead initialization  
BBsolve(par=p0, fn=broydt, method=1, control=list(M=c(50, 10))) 

# identical to dfsane() with defaults
BBsolve(par=p0, fn=broydt, method=2, control=list(M=10, NM=FALSE)) 
</code></pre>

<hr>
<h2 id='dfsane'> Solving Large-Scale Nonlinear System of Equations</h2><span id='topic+dfsane'></span>

<h3>Description</h3>

<p>Derivative-Free Spectral Approach for solving nonlinear systems of equations</p>


<h3>Usage</h3>

<pre><code class='language-R'>  dfsane(par, fn, method=2, control=list(),
         quiet=FALSE, alertConvergence=TRUE, ...) 
 </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfsane_+3A_fn">fn</code></td>
<td>
<p>a function that takes a real vector as argument and  returns a real vector of same length (see details).</p>
</td></tr>
<tr><td><code id="dfsane_+3A_par">par</code></td>
<td>
<p>A real vector argument to <code>fn</code>, indicating the 
initial guess for the root of the nonlinear system.</p>
</td></tr>
<tr><td><code id="dfsane_+3A_method">method</code></td>
<td>
<p>An integer (1, 2, or 3) specifying which Barzilai-Borwein steplength to use.  The default is 2.  See *Details*.</p>
</td></tr> 
<tr><td><code id="dfsane_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See *Details*.</p>
</td></tr>
<tr><td><code id="dfsane_+3A_quiet">quiet</code></td>
<td>
<p>A logical variable (TRUE/FALSE). If <code>TRUE</code> warnings 
and some additional information printing are suppressed.  
Default is <code>quiet = FALSE</code>
Note that <code>quiet</code> and the <code>control</code> variable <code>trace</code>
affect different printing, so if <code>trace</code> is not set to <code>FALSE</code> 
there will be considerable printed output.</p>
</td></tr>
<tr><td><code id="dfsane_+3A_alertconvergence">alertConvergence</code></td>
<td>
<p>A logical variable. With the default <code>TRUE</code>
a warning is issued if convergence is not obtained. When set to <code>FALSE</code>
the warning is suppressed.</p>
</td></tr>
<tr><td><code id="dfsane_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>fn</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function <code>dfsane</code> is another algorithm for implementing non-monotone 
spectral residual method for finding a root of nonlinear systems, by working 
without gradient information.  
It stands for &quot;derivative-free spectral approach for nonlinear equations&quot;. 
It differs from the function <code>sane</code> in that <code>sane</code> requires an 
approximation of a directional derivative at every iteration of the merit 
function <code class="reqn">F(x)^t F(x)</code>.
</p>
<p>R adaptation, with significant modifications, by Ravi Varadhan, Johns Hopkins University (March 25, 2008), from the original FORTRAN code of La Cruz, Martinez, and Raydan (2006).  
</p>
<p>A major modification in our R adaptation of the original FORTRAN code is the availability of 3 different options for Barzilai-Borwein (BB) steplengths: <code>method = 1</code> is the BB 
steplength used in LaCruz, Martinez and Raydan (2006);  <code>method = 2</code> is equivalent to the other steplength proposed in Barzilai and Borwein's (1988) original paper.  
Finally, <code>method = 3</code>, is a new steplength, which is equivalent to that first proposed in Varadhan and Roland (2008) for accelerating the EM algorithm.  
In fact, Varadhan and Roland (2008) considered 3 similar steplength schemes in their EM acceleration work.  Here, we have chosen <code>method = 2</code> 
as the &quot;default&quot; method, since it generally performe better than the other schemes in our numerical experiments. 
</p>
<p>Argument <code>control</code> is a list specifing any changes to default values of algorithm control parameters.  Note that the names of these must be 
specified completely.  Partial matching does not work.
</p>

<dl>
<dt>M</dt><dd><p>A positive integer, typically between 5-20, that controls the monotonicity of the algorithm.  <code>M=1</code> would enforce strict monotonicity 
in the reduction of L2-norm of <code>fn</code>, whereas larger values allow for more non-monotonicity.  Global convergence under non-monotonicity is ensured by 
enforcing the Grippo-Lampariello-Lucidi condition (Grippo et al. 1986) in a non-monotone line-search algorithm.  Values of <code>M</code> 
between 5 to 20 are generally good, although some problems may require a much
larger M.  The default is <code>M = 10</code>.</p>
</dd>  
<dt>maxit</dt><dd><p>The maximum number of iterations.  The default is 
<code>maxit = 1500</code>.</p>
</dd>
<dt>tol</dt><dd><p>The absolute convergence tolerance on the residual L2-norm of 
<code>fn</code>.  Convergence is declared 
when <code class="reqn">\|F(x)\| / \sqrt(npar) &lt; \mbox{tol}</code>.  
Default is <code>tol = 1.e-07</code>.</p>
</dd>
<dt>trace</dt><dd><p>A logical variable (TRUE/FALSE).  If <code>TRUE</code>, information on 
the progress of solving the system is produced.  
Default is <code>trace = !quiet</code>.</p>
</dd>
<dt>triter</dt><dd><p>An integer that controls the frequency of tracing when 
<code>trace=TRUE</code>. Default is <code>triter=10</code>, which means that
the L2-norm of <code>fn</code> is printed at every 10-th iteration.</p>
</dd> 
<dt>noimp</dt><dd><p>An integer. Algorithm is terminated when no progress has been 
made in reducing the merit function for <code>noimp</code> consecutive iterations.
Default is <code>noimp=100</code>.</p>
</dd>
<dt>NM</dt><dd><p>A logical variable that dictates whether the Nelder-Mead algorithm 
in <code>optim</code> will be called upon to improve user-specified starting value. 
Default is <code>NM=FALSE</code>.</p>
</dd> 
<dt>BFGS</dt><dd><p>A logical variable that dictates whether the low-memory 
L-BFGS-B algorithm in <code>optim</code> will be called after certain types of 
unsuccessful termination of <code>dfsane</code>. Default is <code>BFGS=FALSE</code>.</p>
</dd>  
</dl>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>The best set of parameters that solves the nonlinear system.</p>
</td></tr>
<tr><td><code>residual</code></td>
<td>
<p>L2-norm of the function at convergence, 
divided by <code>sqrt(npar)</code>, where &quot;npar&quot; is the number of parameters.</p>
</td></tr>
<tr><td><code>fn.reduction</code></td>
<td>
<p>Reduction in the L2-norm of the function from the 
initial L2-norm.</p>
</td></tr>
<tr><td><code>feval</code></td>
<td>
<p>Number of times <code>fn</code> was evaluated.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations taken by the algorithm.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  <code>0</code> 
indicates successful convergence, in which case the <code>resid</code> is smaller 
than <code>tol</code>.  Error codes are 
<code>1</code> indicates that the iteration limit <code>maxit</code> has been reached.  
<code>2</code> is failure due to stagnation;   
<code>3</code> indicates error in function evaluation; 
<code>4</code> is failure due to exceeding 100 steplength reductions in 
line-search; and 
<code>5</code> indicates lack of improvement in objective function 
over <code>noimp</code> consecutive iterations.
</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>A text message explaining which termination criterion was used.</p>
</td></tr>
</table>


<h3>References</h3>

 
<p>J Barzilai, and JM Borwein  (1988),  Two-point step size gradient methods, <em>IMA J Numerical Analysis</em>, 8, 141-148. 
</p>
<p>L Grippo, F Lampariello, and S Lucidi (1986),  A nonmonotone line search technique for Newton's method,  <em>SIAM J on Numerical Analysis</em>, 23, 707-716. 
</p>
<p>W LaCruz, JM Martinez, and M Raydan (2006),  Spectral residual mathod without gradient information for solving large-scale nonlinear systems of equations, <em>Mathematics of Computation</em>, 75, 1429-1448. 
</p>
<p>R Varadhan and C Roland (2008),  Simple and globally-convergent methods for accelerating the convergence of any EM algorithm,  <em>Scandinavian J Statistics</em>. 
</p>
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, <a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BBsolve">BBsolve</a></code>,
<code><a href="#topic+sane">sane</a></code>,
<code><a href="#topic+spg">spg</a></code>,
<code><a href="numDeriv.html#topic+grad">grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  trigexp &lt;- function(x) {
# Test function No. 12 in the Appendix of LaCruz and Raydan (2003)
    n &lt;- length(x)
    F &lt;- rep(NA, n)
    F[1] &lt;- 3*x[1]^2 + 2*x[2] - 5 + sin(x[1] - x[2]) * sin(x[1] + x[2])
    tn1 &lt;- 2:(n-1)
    F[tn1] &lt;- -x[tn1-1] * exp(x[tn1-1] - x[tn1]) + x[tn1] * ( 4 + 3*x[tn1]^2) +
        2 * x[tn1 + 1] + sin(x[tn1] - x[tn1 + 1]) * sin(x[tn1] + x[tn1 + 1]) - 8 
    F[n] &lt;- -x[n-1] * exp(x[n-1] - x[n]) + 4*x[n] - 3
    F
    }

    p0 &lt;- rnorm(50)
    dfsane(par=p0, fn=trigexp)  # default is method=2
    dfsane(par=p0, fn=trigexp, method=1)
    dfsane(par=p0, fn=trigexp, method=3)
    dfsane(par=p0, fn=trigexp, control=list(triter=5, M=5))
######################################
 brent &lt;- function(x) {
  n &lt;- length(x)
  tnm1 &lt;- 2:(n-1)
  F &lt;- rep(NA, n)
  F[1] &lt;- 3 * x[1] * (x[2] - 2*x[1]) + (x[2]^2)/4 
  F[tnm1] &lt;-  3 * x[tnm1] * (x[tnm1+1] - 2 * x[tnm1] + x[tnm1-1]) + 
              ((x[tnm1+1] - x[tnm1-1])^2) / 4   
  F[n] &lt;- 3 * x[n] * (20 - 2 * x[n] + x[n-1]) +  ((20 - x[n-1])^2) / 4
  F
  }
  
  p0 &lt;- sort(runif(50, 0, 20))
  dfsane(par=p0, fn=brent, control=list(trace=FALSE))
  dfsane(par=p0, fn=brent, control=list(M=200, trace=FALSE))
</code></pre>

<hr>
<h2 id='multiStart'>Nonlinear Optimization or Root-Finding with Multiple Starting Values</h2><span id='topic+multiStart'></span>

<h3>Description</h3>

<p>Start <code>BBsolve</code> or <code>BBoptim</code> from multiple starting 
points to obtain multiple solutions and to test sensitivity to starting values.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  multiStart(par, fn, gr=NULL, action = c("solve", "optimize"), 
	method=c(2,3,1),  lower=-Inf, upper=Inf,
	project=NULL, projectArgs=NULL, 
	control=list(),  quiet=FALSE, details=FALSE, ...) 
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiStart_+3A_par">par</code></td>
<td>
<p>A real matrix, each row of which is an argument to <code>fn</code>,
indicating initial guesses for solving a nonlinear system <code>fn = 0</code> 
or for optimizing the objective function <code>fn</code>.</p>
</td></tr>
<tr><td><code id="multiStart_+3A_fn">fn</code></td>
<td>
<p>see <code>BBsolve</code> or <code>BBoptim</code>.</p>
</td></tr> 
<tr><td><code id="multiStart_+3A_gr">gr</code></td>
<td>
<p>Only required for optimization.  See <code>BBoptim</code>.</p>
</td></tr> 
<tr><td><code id="multiStart_+3A_action">action</code></td>
<td>
<p>A character string indicating whether to solve a nonlinear 
system or to optimize.  Default is &ldquo;solve&rdquo;.</p>
</td></tr> 
<tr><td><code id="multiStart_+3A_method">method</code></td>
<td>
<p>see <code>BBsolve</code> or <code>BBoptim</code>.</p>
</td></tr> 
<tr><td><code id="multiStart_+3A_upper">upper</code></td>
<td>
<p>An upper bound for box constraints. See <code>spg</code></p>
</td></tr>
<tr><td><code id="multiStart_+3A_lower">lower</code></td>
<td>
<p>An lower bound for box constraints. See <code>spg</code></p>
</td></tr>
<tr><td><code id="multiStart_+3A_project">project</code></td>
<td>
<p>A projection
function or character string indicating its name. The projection
function that takes a point in <code class="reqn">R^n</code> and 
projects it onto a region that defines the constraints of the problem.  
This is a vector-function that takes a real vector as argument and 
returns a real vector of the same length. 
See <code>spg</code> for more details.</p>
</td></tr> 
<tr><td><code id="multiStart_+3A_projectargs">projectArgs</code></td>
<td>
<p>A list with arguments to the <code>project</code>  
function.</p>
</td></tr>
<tr><td><code id="multiStart_+3A_control">control</code></td>
<td>
<p>See <code>BBsolve</code> and <code>BBoptim</code>.</p>
</td></tr>
<tr><td><code id="multiStart_+3A_quiet">quiet</code></td>
<td>
<p>A logical variable (TRUE/FALSE). If <code>TRUE</code> warnings 
and some additional information printing are suppressed.  
Default is <code>quiet = FALSE</code>
Note that the <code>control</code> variable <code>trace</code> and <code>quiet</code> 
affect different printing, so if <code>trace</code> is not set to <code>FALSE</code> 
there will be considerable printed output.</p>
</td></tr>
<tr><td><code id="multiStart_+3A_details">details</code></td>
<td>
<p>Logical indicating if the result should include the full
result from <code>BBsolve</code> or <code>BBoptim</code> for each starting value.</p>
</td></tr>
<tr><td><code id="multiStart_+3A_...">...</code></td>
<td>
<p>arguments passed fn (via the optimization algorithm).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimization or root-finder is run with each row of <code>par</code> indicating 
initial guesses.
</p>


<h3>Value</h3>

<p>list with elements <code>par</code>, <code>values</code>, and <code>converged</code>. 
It optionally returns an attribute called &ldquo;details&rdquo;, which is a list as long as 
the number of starting values, which contains the complete object returned 
by <code>dfsane</code> or <code>spg</code> for each starting value.</p>


<h3>References</h3>

 
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, <a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BBsolve">BBsolve</a></code>,
<code><a href="#topic+BBoptim">BBoptim</a></code>,
<code><a href="#topic+dfsane">dfsane</a></code>,
<code><a href="#topic+spg">spg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use a preset seed so the example is reproducable. 
require("setRNG")
old.seed &lt;- setRNG(list(kind="Mersenne-Twister", normal.kind="Inversion",
    seed=1234))

# Finding multiple roots of a nonlinear system
brownlin &lt;- function(x) {
# Brown's almost linear system(A.P. Morgan, ACM 1983)
# two distinct solutions if n is even
# three distinct solutions if n is odd  
  	n &lt;- length(x)
  	f &lt;- rep(NA, n)
	nm1 &lt;- 1:(n-1)
	f[nm1] &lt;- x[nm1] + sum(x) - (n+1)
	f[n] &lt;- prod(x) - 1 
	f
}

p &lt;- 9
n &lt;- 50
p0 &lt;- matrix(rnorm(n*p), n, p)  # n starting values, each of length p
ans &lt;- multiStart(par=p0, fn=brownlin)
pmat &lt;- ans$par[ans$conv, 1:p] # selecting only converged solutions
ord1 &lt;- order(abs(pmat[,1]))
round(pmat[ord1, ], 3)  # all 3 roots can be seen

# An optimization example
rosbkext &lt;- function(x){
n &lt;- length(x)
j &lt;- 2 * (1:(n/2))
jm1 &lt;- j - 1
sum(100 * (x[j] - x[jm1]^2)^2 + (1 - x[jm1])^2)
}

p0 &lt;- rnorm(50)
spg(par=p0, fn=rosbkext)
BBoptim(par=p0, fn=rosbkext)

pmat &lt;- matrix(rnorm(100), 20, 5)  # 20 starting values each of length 5 
ans &lt;- multiStart(par=pmat, fn=rosbkext, action="optimize")
ans
attr(ans, "details")[[1]]  # 

pmat &lt;- ans$par[ans$conv, 1:5] # selecting only converged solutions
round(pmat, 3)
</code></pre>

<hr>
<h2 id='project'>spg Projection Functions</h2><span id='topic+projectLinear'></span>

<h3>Description</h3>

<p>Projection function implementing contraints for spg parameters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>     projectLinear(par, A, b, meq)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="project_+3A_par">par</code></td>
<td>
<p>A real vector argument (as for <code>fn</code>), indicating the
parameter values to which the constraint should be applied.</p>
</td></tr>
<tr><td><code id="project_+3A_a">A</code></td>
<td>
<p>A matrix. See details.</p>
</td></tr> 
<tr><td><code id="project_+3A_b">b</code></td>
<td>
<p>A vector. See details.</p>
</td></tr> 
<tr><td><code id="project_+3A_meq">meq</code></td>
<td>
<p>See details.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function <code>projectLinear</code> can be used by <code>spg</code> to 
define the constraints of the problem. It projects a point 
in <code class="reqn">R^n</code> onto a region that defines the constraints. 
It takes a real vector <code>par</code> as argument and returns a real vector 
of the same length.
</p>
<p>The function <code>projectLinear</code> incorporates linear equalities and 
inequalities in nonlinear optimization using a projection method, 
where an infeasible point is projected onto the feasible region using 
a quadratic programming solver.  
The inequalities are defined such that:  <code>A %*% x - b &gt; 0 </code>.
The first &lsquo;meq&rsquo; rows of A and the first &lsquo;meq&rsquo; elements of b correspond 
to equality constraints.
</p>


<h3>Value</h3>

<p>A vector of the constrained parameter values.</p>


<h3>See Also</h3>

<p><code><a href="#topic+spg">spg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example
fn &lt;- function(x) (x[1] - 3/2)^2 + (x[2] - 1/8)^4

gr &lt;- function(x) c(2 * (x[1] - 3/2) , 4 * (x[2] - 1/8)^3)

# This is the set of inequalities
# x[1] - x[2] &gt;= -1
# x[1] + x[2] &gt;= -1
# x[1] - x[2] &lt;= 1
# x[1] + x[2] &lt;= 1

# The inequalities are written in R such that:  Amat %*% x  &gt;= b 
Amat &lt;- matrix(c(1, -1, 1, 1, -1, 1, -1, -1), 4, 2, byrow=TRUE)
b &lt;- c(-1, -1, -1, -1)
meq &lt;- 0  # all 4 conditions are inequalities

p0 &lt;- rnorm(2)
spg(par=p0, fn=fn, gr=gr, project="projectLinear", 
      projectArgs=list(A=Amat, b=b, meq=meq))

meq &lt;- 1  # first condition is now an equality
spg(par=p0, fn=fn, gr=gr, project="projectLinear", 
      projectArgs=list(A=Amat, b=b, meq=meq))


# box-constraints can be incorporated as follows:
# x[1] &gt;= 0
# x[2] &gt;= 0
# x[1] &lt;= 0.5
# x[2] &lt;= 0.5

Amat &lt;- matrix(c(1, 0, 0, 1, -1, 0, 0, -1), 4, 2, byrow=TRUE)
b &lt;- c(0, 0, -0.5, -0.5)

meq &lt;- 0
spg(par=p0, fn=fn, gr=gr, project="projectLinear", 
   projectArgs=list(A=Amat, b=b, meq=meq))

# Note that the above is the same as the following:
spg(par=p0, fn=fn, gr=gr, lower=0, upper=0.5)


# An example showing how to impose other constraints in spg()

fr &lt;- function(x) { ## Rosenbrock Banana function
  x1 &lt;- x[1] 
  x2 &lt;- x[2] 
  100 * (x2 - x1 * x1)^2 + (1 - x1)^2 
  } 

# Impose a constraint that sum(x) = 1

proj &lt;- function(x){ x / sum(x) }

spg(par=runif(2), fn=fr, project="proj") 

# Illustration of the importance of `projecting' the constraints, rather 
#   than simply finding a feasible point:

fr &lt;- function(x) { ## Rosenbrock Banana function 
x1 &lt;- x[1] 
x2 &lt;- x[2] 
100 * (x2 - x1 * x1)^2 + (1 - x1)^2 
} 
# Impose a constraint that sum(x) = 1 

proj &lt;- function(x){ 
# Although this function does give a feasible point it is 
#  not a "projection" in the sense of the nearest feasible point to `x'
x / sum(x) 
} 

p0 &lt;- c(0.93, 0.94)  

# Note, the starting value is infeasible so the next 
#   result is "Maximum function evals exceeded"

spg(par=p0, fn=fr, project="proj") 

# Correct approach to doing the projection using the `projectLinear' function

spg(par=p0, fn=fr, project="projectLinear", projectArgs=list(A=matrix(1, 1, 2), b=1, meq=1)) 

# Impose additional box constraint on first parameter

p0 &lt;- c(0.4, 0.94)    # need feasible starting point

spg(par=p0, fn=fr,  lower=c(-0.5, -Inf), upper=c(0.5, Inf),
  project="projectLinear", projectArgs=list(A=matrix(1, 1, 2), b=1, meq=1)) 


</code></pre>

<hr>
<h2 id='sane'> Solving Large-Scale Nonlinear System of Equations</h2><span id='topic+sane'></span>

<h3>Description</h3>

<p>Non-Monotone spectral approach for Solving Large-Scale 
Nonlinear Systems of Equations</p>


<h3>Usage</h3>

<pre><code class='language-R'>  sane(par, fn, method=2, control=list(),
       quiet=FALSE, alertConvergence=TRUE, ...) 
 </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sane_+3A_fn">fn</code></td>
<td>
<p>a function that takes a real vector as argument and returns 
a real vector of same length (see details).</p>
</td></tr>
<tr><td><code id="sane_+3A_par">par</code></td>
<td>
<p>A real vector argument to <code>fn</code>, indicating the 
initial guess for the root of the nonlinear system.</p>
</td></tr>
<tr><td><code id="sane_+3A_method">method</code></td>
<td>
<p>An integer (1, 2, or 3) specifying which Barzilai-Borwein 
steplength to use.  The default is 2.  See *Details*.</p>
</td></tr> 
<tr><td><code id="sane_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See *Details*.</p>
</td></tr>
<tr><td><code id="sane_+3A_quiet">quiet</code></td>
<td>
<p>A logical variable (TRUE/FALSE). If <code>TRUE</code> warnings 
and some additional information printing are suppressed.  
Default is <code>quiet = FALSE</code>
Note that <code>quiet</code> and the <code>control</code> variable <code>trace</code> 
affect different printing, so if <code>trace</code> is not set to <code>FALSE</code> 
there will be considerable printed output.</p>
</td></tr>
<tr><td><code id="sane_+3A_alertconvergence">alertConvergence</code></td>
<td>
<p>A logical variable. With the default <code>TRUE</code>
a warning is issued if convergence is not obtained. When set to <code>FALSE</code>
the warning is suppressed.</p>
</td></tr>
<tr><td><code id="sane_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>fn</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>sane</code> implements a non-monotone spectral residual method 
for finding a root of nonlinear systems.  It stands for &quot;spectral approach 
for nonlinear equations&quot;.  
It differs from the function <code>dfsane</code> in that it requires an 
approximation of a directional derivative at every iteration of the merit 
function <code class="reqn">F(x)^t F(x)</code>.
</p>
<p>R adaptation, with significant modifications, by Ravi Varadhan, 
Johns Hopkins University (March 25, 2008), from the original FORTRAN code 
of La Cruz and Raydan (2003).  
</p>
<p>A major modification in our R adaptation of the original FORTRAN code is the 
availability of 3 different options for Barzilai-Borwein (BB) steplengths: 
<code>method = 1</code> is the BB 
steplength used in LaCruz and Raydan (2003);  <code>method = 2</code> is equivalent to
the other steplength proposed in Barzilai and Borwein's (1988) original paper. 
Finally, <code>method = 3</code>, is a new steplength, which is equivalent to that 
first proposed in Varadhan and Roland (2008) for accelerating the EM algorithm.
In fact, Varadhan and Roland (2008) considered 3 equivalent steplength schemes 
in their EM acceleration work.  Here, we have chosen <code>method = 2</code> 
as the &quot;default&quot; method, as it generally performed better than the other 
schemes in our numerical experiments.  
</p>
<p>Argument <code>control</code> is a list specifing any changes to default values of 
algorithm control parameters.  Note that the names of these must be 
specified completely.  Partial matching will not work.
Argument <code>control</code> has the following components:
</p>

<dl>
<dt>M</dt><dd><p>A positive integer, typically between 5-20, that controls the 
monotonicity of the algorithm.  <code>M=1</code> would enforce strict monotonicity 
in the reduction of L2-norm of <code>fn</code>, whereas larger values allow for 
more non-monotonicity.  Global convergence under non-monotonicity is ensured 
by enforcing the Grippo-Lampariello-Lucidi condition (Grippo et al. 1986) in a 
non-monotone line-search algorithm.  Values of <code>M</code> between 5 to 20 are 
generally good, although some problems may require a much larger M.  
The default is <code>M = 10</code>.</p>
</dd> 
<dt>maxit</dt><dd><p>The maximum number of iterations.  The default is 
<code>maxit = 1500</code>.</p>
</dd>
<dt>tol</dt><dd><p>The absolute convergence tolerance on the residual L2-norm 
of <code>fn</code>.  Convergence is declared 
when <code class="reqn">\|F(x)\| / \sqrt(npar) &lt; \mbox{tol}</code>.  
Default is <code>tol = 1.e-07</code>.</p>
</dd>
<dt>trace</dt><dd><p>A logical variable (TRUE/FALSE).  If <code>TRUE</code>, information on 
the progress of solving the system is produced.  
Default is <code>trace = !quiet</code>.</p>
</dd>
<dt>triter</dt><dd><p>An integer that controls the frequency of tracing 
when <code>trace=TRUE</code>. Default is <code>triter=10</code>, which means that
the L2-norm of <code>fn</code> is printed at every 10-th iteration.</p>
</dd>
<dt>noimp</dt><dd><p>An integer. Algorithm is terminated when no progress has been 
made in reducing the merit function for <code>noimp</code> consecutive iterations.  
Default is <code>noimp=100</code>.</p>
</dd>
<dt>NM</dt><dd><p>A logical variable that dictates whether the Nelder-Mead algorithm 
in <code>optim</code> will be called upon to improve user-specified starting value. 
Default is <code>NM=FALSE</code>.</p>
</dd>
<dt>BFGS</dt><dd><p>A logical variable that dictates whether the low-memory L-BFGS-B 
algorithm in <code>optim</code> will be called after certain types of unsuccessful 
termination of <code>sane</code>. Default is <code>BFGS=FALSE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>The best set of parameters that solves the nonlinear system.</p>
</td></tr>
<tr><td><code>residual</code></td>
<td>
<p>L2-norm of the function evaluated at <code>par</code>, divided 
by <code>sqrt(npar)</code>, where &quot;npar&quot; is the number of parameters.</p>
</td></tr>
<tr><td><code>fn.reduction</code></td>
<td>
<p>Reduction in the L2-norm of the function from the 
initial L2-norm.</p>
</td></tr>
<tr><td><code>feval</code></td>
<td>
<p>Number of times <code>fn</code> was evaluated.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations taken by the algorithm.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence. 
<code>0</code> indicates successful convergence, in which case the <code>resid</code> 
is smaller than 
<code>tol</code>. Error codes are <code>1</code> indicates that the iteration 
limit <code>maxit</code> has been reached.  
<code>2</code> indicates error in function evaluation;  
<code>3</code> is failure due to exceeding 100 steplength reductions in line-search; 
<code>4</code> denotes failure due to an anomalous iteration; and 
<code>5</code> indicates lack of improvement in objective function over <code>noimp</code> 
consecutive iterations.
</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>A text message explaining which termination criterion was used.</p>
</td></tr>
</table>


<h3>References</h3>

 
<p>J Barzilai, and JM Borwein  (1988),  Two-point step size gradient 
methods, <em>IMA J Numerical Analysis</em>, 8, 141-148. 
</p>
<p>L Grippo, F Lampariello, and S Lucidi (1986),  A nonmonotone line search technique 
for Newton's method,  <em>SIAM J on Numerical Analysis</em>, 23, 707-716. 
</p>
<p>W LaCruz, and M Raydan (2003),  Nonmonotone spectral methods for large-scale
nonlinear systems, <em>Optimization Methods and Software</em>, 18, 583-599. 
</p>
<p>R Varadhan and C Roland (2008),  Simple and globally-convergent methods for 
accelerating the convergence of any EM algorithm,  
<em>Scandinavian J Statistics</em>. 
</p>
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, <a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BBsolve">BBsolve</a></code>,
<code><a href="#topic+dfsane">dfsane</a></code>,
<code><a href="#topic+spg">spg</a></code>,
<code><a href="numDeriv.html#topic+grad">grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  trigexp &lt;- function(x) {
# Test function No. 12 in the Appendix of LaCruz and Raydan (2003)
    n &lt;- length(x)
    F &lt;- rep(NA, n)
    F[1] &lt;- 3*x[1]^2 + 2*x[2] - 5 + sin(x[1] - x[2]) * sin(x[1] + x[2])
    tn1 &lt;- 2:(n-1)
    F[tn1] &lt;- -x[tn1-1] * exp(x[tn1-1] - x[tn1]) + x[tn1] * ( 4 + 3*x[tn1]^2) +
        2 * x[tn1 + 1] + sin(x[tn1] - x[tn1 + 1]) * sin(x[tn1] + x[tn1 + 1]) - 8 
    F[n] &lt;- -x[n-1] * exp(x[n-1] - x[n]) + 4*x[n] - 3
    F
    }

    p0 &lt;- rnorm(50)
    sane(par=p0, fn=trigexp)
    sane(par=p0, fn=trigexp, method=1)    
######################################
brent &lt;- function(x) {
  n &lt;- length(x)
  tnm1 &lt;- 2:(n-1)
  F &lt;- rep(NA, n)
  F[1] &lt;- 3 * x[1] * (x[2] - 2*x[1]) + (x[2]^2)/4 
  F[tnm1] &lt;- 3 * x[tnm1] * (x[tnm1+1] - 2 * x[tnm1] + x[tnm1-1]) + 
               ((x[tnm1+1] - x[tnm1-1])^2) / 4   
  F[n] &lt;- 3 * x[n] * (20 - 2 * x[n] + x[n-1]) +  ((20 - x[n-1])^2) / 4
  F
  }
  
  p0 &lt;- sort(runif(50, 0, 10))
  sane(par=p0, fn=brent, control=list(trace=FALSE))
  sane(par=p0, fn=brent, control=list(M=200, trace=FALSE))
</code></pre>

<hr>
<h2 id='spg'>Large-Scale Optimization</h2><span id='topic+spg'></span>

<h3>Description</h3>

<p>Spectral projected gradient method for large-scale optimization with simple constraints.</p>


<h3>Usage</h3>

<pre><code class='language-R'>     spg(par, fn, gr=NULL, method=3, lower=-Inf, upper=Inf, 
           project=NULL, projectArgs=NULL, 
	   control=list(), quiet=FALSE, alertConvergence=TRUE, ...)
 </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spg_+3A_par">par</code></td>
<td>
<p>A real vector argument to <code>fn</code>, indicating the initial guess for the optimization of nonlinear 
objective function <code>fn</code>.</p>
</td></tr>
<tr><td><code id="spg_+3A_fn">fn</code></td>
<td>
<p>Nonlinear objective function that is to be optimized. 
A scalar function that takes a real vector as argument and 
returns a scalar that is the value of the function at that point 
(see details).</p>
</td></tr>
<tr><td><code id="spg_+3A_gr">gr</code></td>
<td>
<p>The gradient of the objective function <code>fn</code> evaluated at the 
argument.  This is a vector-function that takes a real 
vector as argument and returns a real vector of the same length.  
It defaults to &quot;NULL&quot;, which means that gradient is evaluated numerically.  
Computations are dramatically faster in high-dimensional problems when 
the exact gradient is provided.  See *Example*.</p>
</td></tr> 
<tr><td><code id="spg_+3A_method">method</code></td>
<td>
<p>An integer (1, 2, or 3) specifying which Barzilai-Borwein 
steplength to use.  The default is 3.  See *Details*.</p>
</td></tr> 
<tr><td><code id="spg_+3A_upper">upper</code></td>
<td>
<p>An upper bound for box constraints.</p>
</td></tr>
<tr><td><code id="spg_+3A_lower">lower</code></td>
<td>
<p>An lower bound for box constraints.</p>
</td></tr>
<tr><td><code id="spg_+3A_project">project</code></td>
<td>
<p>A projection
function or character string indicating its name. The projection
function takes a point in <code class="reqn">R^n</code> and 
projects it onto a region that defines the constraints of the problem.  
This is a vector-function that takes a real vector as argument and 
returns a real vector of the same length. See *Details*. 
If a projection function is not supplied, arguments <code>lower</code> and
<code>upper</code> will cause the use of an internally defined function that
enforces the implied box constraints.</p>
</td></tr> 
<tr><td><code id="spg_+3A_projectargs">projectArgs</code></td>
<td>
<p>A list with arguments to the <code>project</code>  
function. See *Details*. </p>
</td></tr>
<tr><td><code id="spg_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See *Details*.</p>
</td></tr>
<tr><td><code id="spg_+3A_quiet">quiet</code></td>
<td>
<p>A logical variable (TRUE/FALSE). If <code>TRUE</code> warnings 
and some additional information printing are suppressed.  
Default is <code>quiet = FALSE</code>
Note that <code>quiet</code> and the <code>control</code> variable <code>trace</code>  
affect different printing, so if <code>trace</code> is not set to <code>FALSE</code> 
there will be considerable printed output.</p>
</td></tr>
<tr><td><code id="spg_+3A_alertconvergence">alertConvergence</code></td>
<td>
<p>A logical variable. With the default <code>TRUE</code>
a warning is issued if convergence is not obtained. When set to <code>FALSE</code>
the warning is suppressed.</p>
</td></tr>
<tr><td><code id="spg_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>fn</code> and <code>gr</code>.
(Both must accept any specified arguments, either 
explicitly or by having a ... argument, but
they do not need to use them all.)</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>R adaptation, with significant modifications, by Ravi Varadhan, Johns
Hopkins University (March 25, 2008), from the original FORTRAN code of
Birgin, Martinez, and Raydan (2001). The original is available at the 
TANGO project <a href="http://www.ime.usp.br/~egbirgin/tango/downloads.php">http://www.ime.usp.br/~egbirgin/tango/downloads.php</a>
</p>
<p>A major modification in our R adaptation of the original FORTRAN code is the 
availability of 3 different options for Barzilai-Borwein (BB) 
steplengths: <code>method = 1</code> is the BB 
steplength used in Birgin, Martinez and Raydan (2000);  <code>method = 2</code> is 
the other steplength proposed in Barzilai and Borwein's (1988) original paper.  
Finally, <code>method = 3</code>, is a new steplength, which was first proposed in 
Varadhan and Roland (2008) for accelerating the EM algorithm.  
In fact, Varadhan and Roland (2008) considered 3 similar steplength schemes in 
their EM acceleration work.  Here, we have chosen <code>method = 3</code> 
as the &quot;default&quot; method.  This method may be slightly slower than the 
other 2 BB steplength schemes, but it generally exhibited more reliable 
convergence to a better optimum in our experiments.  
We recommend that the user try the other steplength schemes if the default 
method does not perform well in their problem.  
</p>
<p>Box constraints can be imposed by vectors <code>lower</code> and <code>upper</code>. 
Scalar values for <code>lower</code> and <code>upper</code> are expanded to apply to 
all parameters. The default <code>lower</code> is <code>-Inf</code> and <code>upper</code> 
is <code>+Inf</code>, which imply no constraints.
</p>
<p>The <code>project</code> argument provides a way to implement more general constraints
to be imposed on the parameters in <code>spg</code>. <code>projectArgs</code> is passed
to the <code>project</code> function if one is specified.  The first argument of any <code>project</code> function should be <code>par</code> and any other arguments should be passed using its argument <code>projectArgs</code>.    
To avoid confusion it is suggested that user defined <code>project</code>
functions should not use arguments  <code>lower</code> and <code>upper</code>.
</p>
<p>The function <code><a href="#topic+projectLinear">projectLinear</a></code> incorporates linear equalities and 
inequalities. This function also provides an example of how other projections
might be implemented.
</p>
<p>Argument <code>control</code> is a list specifing any changes to default values of 
algorithm control parameters.  Note that the names of these must be 
specified completely.  Partial matching will not work. 
The list items are as follows:
</p>

<dl>
<dt>M</dt><dd><p>A positive integer, typically between 5-20, that controls the monotonicity of the algorithm.  <code>M=1</code> would enforce strict monotonicity 
in the reduction of L2-norm of <code>fn</code>, whereas larger values allow for more non-monotonicity.  Global convergence under non-monotonicity is ensured by 
enforcing the Grippo-Lampariello-Lucidi condition (Grippo et al. 1986) in a non-monotone line-search algorithm.  Values of <code>M</code> 
between 5 to 20 are generally good.  The default is <code>M = 10</code>.</p>
</dd> 
<dt>maxit</dt><dd><p>The maximum number of iterations.  The default is <code>maxit = 1500</code>.</p>
</dd>
<dt>ftol</dt><dd><p>Convergence tolerance on the absolute change in objective function between successive iterations.  
Convergence is declared when the change is less than <code>ftol</code>.  Default is <code>ftol = 1.e-10</code>.</p>
</dd>
<dt>gtol</dt><dd><p>Convergence tolerance on the infinity-norm of projected gradient <code>gr</code> evaluated at the current parameter.  
Convergence is declared when the infinity-norm of projected gradient is less
than <code>gtol</code>.  Default is <code>gtol = 1.e-05</code>.</p>
</dd>
<dt>maxfeval</dt><dd><p>Maximum limit on the number of function evaluations.  Default is <code>maxfeval = 10000</code>.</p>
</dd>
<dt>maximize</dt><dd><p>A logical variable indicating whether the objective function is to be maximized.  Default is <code>maximize = FALSE</code> indicating
minimization.  For maximization (e.g. log-likelihood maximization in statistical modeling), this may be set to <code>TRUE</code>.</p>
</dd>
<dt>trace</dt><dd><p>A logical variable (TRUE/FALSE). If <code>TRUE</code>, information on 
the progress of optimization is printed.  Default is <code>trace = !quiet</code>.</p>
</dd>
<dt>triter</dt><dd><p>An integer that controls the frequency of tracing 
when <code>trace=TRUE</code>. Default is <code>triter=10</code>, which means that
the objective <code>fn</code> and the infinity-norm of its projected gradient are
printed at every 10-th iteration.</p>
</dd>   
<dt>eps</dt><dd><p>A small positive increment used in the finite-difference 
approximation of gradient.  Default is 1.e-07.</p>
</dd>
<dt>checkGrad</dt><dd><p><code>NULL</code> or a  logical variable <code>TRUE/FALSE</code> 
indicating whether to 
check the provided analytical gradient against a numerical approximation. 
With the default <code>NULL</code> the gradient is checked if it is estimated to take
less than about ten seconds. A warning will be issued in the case it takes 
longer. The default can be overridden by specifying <code>TRUE</code> or <code>FALSE</code>.
It is recommended that this be set to FALSE for high-dimensional problems, 
after making sure that the gradient is correctly specified, possibly by running
once with <code>TRUE</code> specified.</p>
</dd>
<dt>checkGrad.tol</dt><dd><p>A small positive value use to compare the maximum relative
difference between a user supplied gradient gr and the numerical approximation
calculated by grad from package <span class="pkg">numDeriv</span>. The default is 1.e-06.
If this value is exceeded then an error message is issued, as it is a 
reasonable indication of a problem with the user supplied gr. The user can
either fix the gr function, remove it so the finite-difference 
approximation is used, or increase the tolerance so the check passes.</p>
</dd>
</dl>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>Parameters that optimize the nonlinear objective function, 
if convergence is successful.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the objective function at termination.</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>L-infinity norm of the projected gradient of the objective function at termination. If convergence is successful, this should be less than <code>gtol</code>.</p>
</td></tr> 
<tr><td><code>fn.reduction</code></td>
<td>
<p>Reduction in the value of the function from its initial value. This is negative in maximization.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations taken by the algorithm. The gradient is evaluated once each iteration, so the number of gradient evaluations will also be equal to <code>iter</code>, plus any evaluations necessary for <code>checkGrad</code>.</p>
</td></tr>
<tr><td><code>feval</code></td>
<td>
<p>Number of times the objective <code>fn</code> was evaluated.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  <code>0</code> 
indicates successful convergence, in which case the projcted gradient is smaller 
than <code>pgtol</code> or the change in objective function is smaller than <code>ftol</code>.  Error codes are: <code>1</code> indicates that the maximum limit 
for iterations <code>maxit</code> has been reached.  <code>2</code> indicates that 
maximum limit on function evals has been exceeded.  <code>3</code> indicates 
failure due to error in function evaluation. <code>4</code> indicates failure due 
to error in gradient evaluation. <code>5</code> indicates failure due to error in 
projection.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>A text message explaining which termination criterion was used.</p>
</td></tr>
</table>


<h3>References</h3>

   
<p>Birgin EG, Martinez JM, and Raydan M (2000): Nonmonotone spectral projected gradient methods on convex sets, <em>SIAM J Optimization</em>, 10, 1196-1211.
</p>
<p>Birgin EG, Martinez JM, and Raydan M (2001): SPG: software for convex-constrained optimization, <em>ACM Transactions on Mathematical Software</em>.
</p>
<p>L Grippo, F Lampariello, and S Lucidi (1986),  A nonmonotone line search technique for Newton's method,  <em>SIAM J on Numerical Analysis</em>, 23, 707-716. 
</p>
<p>M Raydan (1997),  Barzilai-Borwein gradient method for large-scale unconstrained minimization problem, <em>SIAM J of Optimization</em>, 7, 26-33.
</p>
<p>R Varadhan and C Roland (2008), Simple and globally-convergent methods for accelerating the convergence of any EM algorithm,  <em>Scandinavian J Statistics</em>, doi: 10.1111/j.1467-9469.2007.00585.x.  
</p>
<p>R Varadhan and PD Gilbert (2009),  BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function, <em>J. Statistical Software</em>, 32:4, <a href="http://www.jstatsoft.org/v32/i04/">http://www.jstatsoft.org/v32/i04/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+projectLinear">projectLinear</a></code>,
<code><a href="#topic+BBoptim">BBoptim</a></code>,
<code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="stats.html#topic+nlm">nlm</a></code>,
<code><a href="#topic+sane">sane</a></code>,
<code><a href="#topic+dfsane">dfsane</a></code>,
<code><a href="numDeriv.html#topic+grad">grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sc2.f &lt;- function(x){ sum((1:length(x)) * (exp(x) - x)) / 10}

sc2.g &lt;- function(x){ (1:length(x)) * (exp(x) - 1) / 10}

p0 &lt;- rnorm(50)
ans.spg1 &lt;- spg(par=p0, fn=sc2.f)  # Default is method=3
ans.spg2 &lt;- spg(par=p0, fn=sc2.f, method=1)
ans.spg3 &lt;- spg(par=p0, fn=sc2.f, method=2)
ans.cg &lt;- optim(par=p0, fn=sc2.f, method="CG")  #Uses conjugate-gradient method in "optim"
ans.lbfgs &lt;- optim(par=p0, fn=sc2.f, method="L-BFGS-B")  #Uses low-memory BFGS method in "optim"

# Now we use exact gradient.  
# Computation is much faster compared to when using numerical gradient.
ans.spg1 &lt;- spg(par=p0, fn=sc2.f, gr=sc2.g)

############
# Another example illustrating use of additional parameters to objective function 
valley.f &lt;- function(x, cons) {
  n &lt;- length(x)
  f &lt;- rep(NA, n)
  j &lt;- 3 * (1:(n/3))
  jm2 &lt;- j - 2
  jm1 &lt;- j - 1
  f[jm2] &lt;- (cons[2] * x[jm2]^3 + cons[1] * x[jm2]) * exp(-(x[jm2]^2)/100) - 1
  f[jm1] &lt;- 10 * (sin(x[jm2]) - x[jm1])
  f[j] &lt;- 10 * (cos(x[jm2]) - x[j])
  sum(f*f)
  }

k &lt;- c(1.003344481605351, -3.344481605351171e-03)
p0 &lt;- rnorm(30)  # number of parameters should be a multiple of 3 for this example
ans.spg2 &lt;- spg(par=p0, fn=valley.f, cons=k, method=2)  
ans.cg &lt;- optim(par=p0, fn=valley.f, cons=k, method="CG")  
ans.lbfgs &lt;- optim(par=p0, fn=valley.f, cons=k, method="L-BFGS-B")  

####################################################################
# Here is a statistical example illustrating log-likelihood maximization.

poissmix.loglik &lt;- function(p,y) {
  # Log-likelihood for a binary Poisson mixture
  i &lt;- 0:(length(y)-1)
  loglik &lt;- y*log(p[1]*exp(-p[2])*p[2]^i/exp(lgamma(i+1)) + 
        (1 - p[1])*exp(-p[3])*p[3]^i/exp(lgamma(i+1)))
  return (sum(loglik) )
  }

# Data from Hasselblad (JASA 1969)
poissmix.dat &lt;- data.frame(death=0:9, freq=c(162,267,271,185,111,61,27,8,3,1))
y &lt;- poissmix.dat$freq

# Lower and upper bounds on parameters
lo &lt;- c(0.001,0,0)  
hi &lt;- c(0.999, Inf, Inf)

p0 &lt;- runif(3,c(0.2,1,1),c(0.8,5,8))  # randomly generated starting values

ans.spg &lt;- spg(par=p0, fn=poissmix.loglik, y=y, lower=lo, upper=hi, 
     control=list(maximize=TRUE))

# how to compute hessian at the MLE
  require(numDeriv)
  hess &lt;- hessian(x=ans.spg$par, poissmix.loglik, y=y)
  se &lt;- sqrt(-diag(solve(hess)))  # approximate standard errors


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
