<!DOCTYPE html><html lang="en"><head><title>Help for package tall</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tall}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mobydick'><p>Lemmatized Text of Moby-Dick (Chapters 1-10)</p></a></li>
<li><a href='#reinert'><p>Segment clustering based on the Reinert method - Simple clustering</p></a></li>
<li><a href='#reinPlot'><p>Plot Terms by Cluster</p></a></li>
<li><a href='#reinSummary'><p>Summarize Reinert Clustering Results</p></a></li>
<li><a href='#tall'><p>TALL UI</p></a></li>
<li><a href='#term_per_cluster'><p>Extract Terms and Segments for Document Clusters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Text Analysis for All</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>An R 'shiny' app designed for diverse text analysis tasks, offering a wide range of methodologies tailored to Natural Language Processing (NLP) needs. 
             It is a versatile, general-purpose tool for analyzing textual data. 
             'tall' features a comprehensive workflow, including data cleaning, preprocessing, statistical analysis, and visualization, all integrated for effective text analysis.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/massimoaria/tall">https://github.com/massimoaria/tall</a>, <a href="https://www.k-synth.com/tall/">https://www.k-synth.com/tall/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/massimoaria/tall/issues">https://github.com/massimoaria/tall/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), shiny</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, dplyr (&ge; 1.1.0), shinyWidgets, shinydashboardPlus,
chromote, later, promises, tidyr, purrr, plotly, stringr, Rcpp
(&ge; 1.0.3), RSpectra, rlang, DT, openxlsx, visNetwork, igraph,
udpipe, topicmodels, pdftools, textrank, strucchange,
sparkline, tidygraph, readxl, readtext, jsonlite, fontawesome,
ggraph, ca, ldatuning, shinycssloaders, shinyjs, shinyFiles,
readr, curl, pagedown, parallel, doParallel</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-13 11:44:18 UTC; massimoaria</td>
</tr>
<tr>
<td>Author:</td>
<td>Massimo Aria [aut, cre, cph] (0000-0002-8517-9411),
  Maria Spano <a href="https://orcid.org/0000-0002-3103-2342"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Luca D'Aniello <a href="https://orcid.org/0000-0003-1019-9212"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Corrado Cuccurullo
    <a href="https://orcid.org/0000-0002-7401-8575"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Michelangelo Misuraca
    <a href="https://orcid.org/0000-0002-8794-966X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Massimo Aria &lt;aria@unina.it&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-13 12:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mobydick'>Lemmatized Text of Moby-Dick (Chapters 1-10)</h2><span id='topic+mobydick'></span>

<h3>Description</h3>

<p>This dataset contains the lemmatized version of the first 10 chapters of the novel Moby-Dick by Herman Melville.
The data is structured as a dataframe with multiple linguistic annotations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mobydick)
</code></pre>


<h3>Format</h3>

<p>A dataframe with multiple rows and 26 columns:
</p>

<dl>
<dt>doc_id</dt><dd><p>Character: Unique document identifier</p>
</dd>
<dt>paragraph_id</dt><dd><p>Integer: Paragraph index within the document</p>
</dd>
<dt>sentence_id</dt><dd><p>Integer: Sentence index within the paragraph</p>
</dd>
<dt>sentence</dt><dd><p>Character: Original sentence text</p>
</dd>
<dt>start</dt><dd><p>Integer: Start position of the token in the sentence</p>
</dd>
<dt>end</dt><dd><p>Integer: End position of the token in the sentence</p>
</dd>
<dt>term_id</dt><dd><p>Integer: Unique term identifier</p>
</dd>
<dt>token_id</dt><dd><p>Integer: Token index in the sentence</p>
</dd>
<dt>token</dt><dd><p>Character: Original token (word)</p>
</dd>
<dt>lemma</dt><dd><p>Character: Lemmatized form of the token</p>
</dd>
<dt>upos</dt><dd><p>Character: Universal POS tag</p>
</dd>
<dt>xpos</dt><dd><p>Character: Language-specific POS tag</p>
</dd>
<dt>feats</dt><dd><p>Character: Morphological features</p>
</dd>
<dt>head_token_id</dt><dd><p>Integer: Head token in dependency tree</p>
</dd>
<dt>dep_rel</dt><dd><p>Character: Dependency relation label</p>
</dd>
<dt>deps</dt><dd><p>Character: Enhanced dependency relations</p>
</dd>
<dt>misc</dt><dd><p>Character: Additional information</p>
</dd>
<dt>folder</dt><dd><p>Character: Folder containing the document</p>
</dd>
<dt>split_word</dt><dd><p>Character: The word used to separate the chapters in the original book</p>
</dd>
<dt>filename</dt><dd><p>Character: Source file name</p>
</dd>
<dt>doc_selected</dt><dd><p>Logical: Whether the document is selected</p>
</dd>
<dt>POSSelected</dt><dd><p>Logical: Whether POS was selected</p>
</dd>
<dt>sentence_hl</dt><dd><p>Character: Highlighted sentence</p>
</dd>
<dt>docSelected</dt><dd><p>Logical: Whether the document was manually selected</p>
</dd>
<dt>noHapax</dt><dd><p>Logical: Whether hapax legomena were removed</p>
</dd>
<dt>noSingleChar</dt><dd><p>Logical: Whether single-character words were removed</p>
</dd>
<dt>lemma_original_nomultiwords</dt><dd><p>Character: Lemmatized form without multi-word units</p>
</dd>
</dl>



<h3>Source</h3>

<p>Extracted and processed from the text of Moby-Dick by Herman Melville.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mobydick)
head(mobydick)
</code></pre>

<hr>
<h2 id='reinert'>Segment clustering based on the Reinert method - Simple clustering</h2><span id='topic+reinert'></span>

<h3>Description</h3>

<p>Segment clustering based on the Reinert method - Simple clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reinert(
  x,
  k = 10,
  term = "token",
  segment_size = 40,
  min_segment_size = 3,
  min_split_members = 5,
  cc_test = 0.3,
  tsj = 3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reinert_+3A_x">x</code></td>
<td>
<p>tall data frame of documents</p>
</td></tr>
<tr><td><code id="reinert_+3A_k">k</code></td>
<td>
<p>maximum number of clusters to compute</p>
</td></tr>
<tr><td><code id="reinert_+3A_term">term</code></td>
<td>
<p>indicates the type of form &quot;lemma&quot; or &quot;token&quot;. Default value is term = &quot;lemma&quot;.</p>
</td></tr>
<tr><td><code id="reinert_+3A_segment_size">segment_size</code></td>
<td>
<p>number of forms by document. Default value is segment_size = 40</p>
</td></tr>
<tr><td><code id="reinert_+3A_min_segment_size">min_segment_size</code></td>
<td>
<p>minimum number of forms by document. Default value is min_segment_size = 5</p>
</td></tr>
<tr><td><code id="reinert_+3A_min_split_members">min_split_members</code></td>
<td>
<p>minimum number of segment in a cluster</p>
</td></tr>
<tr><td><code id="reinert_+3A_cc_test">cc_test</code></td>
<td>
<p>contingency coefficient value for feature selection</p>
</td></tr>
<tr><td><code id="reinert_+3A_tsj">tsj</code></td>
<td>
<p>minimum frequency value for feature selection</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the references for original articles on the method.
Special thanks to the authors of the rainette package (https://github.com/juba/rainette)
for inspiring the coding approach used in this function.
</p>


<h3>Value</h3>

<p>The result is a list of both class <code>hclust</code> and <code>reinert_tall</code>.
</p>


<h3>References</h3>


<ul>
<li><p> Reinert M, Une méthode de classification descendante hiérarchique: application à l'analyse lexicale par contexte, Cahiers de l'analyse des données, Volume 8, Numéro 2, 1983. <a href="http://www.numdam.org/item/?id=CAD_1983__8_2_187_0">http://www.numdam.org/item/?id=CAD_1983__8_2_187_0</a>
</p>
</li>
<li><p> Reinert M., Alceste une méthodologie d'analyse des données textuelles et une application: Aurelia De Gerard De Nerval, Bulletin de Méthodologie Sociologique, Volume 26, Numéro 1, 1990. <a href="https://doi.org/10.1177/075910639002600103">doi:10.1177/075910639002600103</a>
</p>
</li>
<li><p> Barnier J., Privé F., rainette: The Reinert Method for Textual Data Clustering, 2023, <a href="https://doi.org/10.32614/CRAN.package.rainette">doi:10.32614/CRAN.package.rainette</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

data(mobydick)
res &lt;- reinert(
  x=mobydick,
  k = 10,
  term = "token",
  segment_size = 40,
  min_segment_size = 5,
  min_split_members = 10,
  cc_test = 0.3,
  tsj = 3
)


</code></pre>

<hr>
<h2 id='reinPlot'>Plot Terms by Cluster</h2><span id='topic+reinPlot'></span>

<h3>Description</h3>

<p>This function creates a horizontal bar plot to visualize the most significant terms
for each cluster, based on their Chi-squared statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reinPlot(terms, nPlot = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reinPlot_+3A_terms">terms</code></td>
<td>
<p>A data frame containing terms and their associated statistics, such as Chi-squared values,
generated by the <code>term_per_cluster</code> function. The data frame must include the following columns:
</p>

<ul>
<li> <p><code>term</code>: The term to plot.
</p>
</li>
<li> <p><code>chi_square</code>: The Chi-squared statistic associated with the term.
</p>
</li>
<li> <p><code>sign</code>: The sign of the term (<code>"positive"</code> or <code>"negative"</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="reinPlot_+3A_nplot">nPlot</code></td>
<td>
<p>Integer. The number of top terms to plot for each sign (<code>"positive"</code> and <code>"negative"</code>). Default is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function organizes the input data by Chi-squared values and selects the top terms for each sign.
The plot uses different colors for positive and negative terms, with hover tooltips providing detailed information.
</p>


<h3>Value</h3>

<p>An interactive horizontal bar plot (using <code>plotly</code>) displaying the top terms for each cluster. The plot includes:
</p>

<ul>
<li><p> Bars representing the Chi-squared values of terms.
</p>
</li>
<li><p> Hover information displaying the term and its Chi-squared value.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+term_per_cluster">term_per_cluster</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(mobydick)
res &lt;- reinert(
  x=mobydick,
  k = 10,
  term = "token",
  segment_size = 40,
  min_segment_size = 5,
  min_split_members = 10,
  cc_test = 0.3,
  tsj = 3
)

tc &lt;- term_per_cluster(res, cutree = NULL, k=1, negative=FALSE)

fig &lt;- reinPlot(tc$terms, nPlot = 10)

## End(Not run)

</code></pre>

<hr>
<h2 id='reinSummary'>Summarize Reinert Clustering Results</h2><span id='topic+reinSummary'></span>

<h3>Description</h3>

<p>This function summarizes the results of the Reinert clustering algorithm, including the most frequent documents and significant terms for each cluster.
The input is the result returned by the <code>term_per_cluster</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reinSummary(tc, n = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reinSummary_+3A_tc">tc</code></td>
<td>
<p>A list returned by the <code>term_per_cluster</code> function. The list includes:
</p>

<ul>
<li> <p><code>segments</code>: A data frame with segments information, including <code>cluster</code> and <code>doc_id</code>.
</p>
</li>
<li> <p><code>terms</code>: A data frame with terms information, including <code>cluster</code>, <code>sign</code>, <code>chi_square</code>, and <code>term</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="reinSummary_+3A_n">n</code></td>
<td>
<p>Integer. The number of top terms (based on Chi-squared value) to include in the summary for each cluster and sign. Default is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the following steps:
</p>

<ol>
<li><p> Extracts the most frequent document for each cluster.
</p>
</li>
<li><p> Summarizes the number of documents per cluster.
</p>
</li>
<li><p> Selects the top <code>n</code> terms for each cluster, separated by positive and negative signs.
</p>
</li>
<li><p> Combines the terms and segment information into a final summary table.
</p>
</li></ol>



<h3>Value</h3>

<p>A data frame summarizing the clustering results. The table includes:
</p>

<ul>
<li> <p><code>cluster</code>: The cluster ID.
</p>
</li>
<li> <p><code>Positive terms</code>: The top <code>n</code> positive terms for each cluster, concatenated into a single string.
</p>
</li>
<li> <p><code>Negative terms</code>: The top <code>n</code> negative terms for each cluster, concatenated into a single string.
</p>
</li>
<li> <p><code>Most frequent document</code>: The document ID that appears most frequently in each cluster.
</p>
</li>
<li> <p><code>N. of Documents per Cluster</code>: The number of documents in each cluster.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+term_per_cluster">term_per_cluster</a></code>, <code><a href="#topic+reinPlot">reinPlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(mobydick)
res &lt;- reinert(
  x=mobydick,
  k = 10,
  term = "token",
  segment_size = 40,
  min_segment_size = 5,
  min_split_members = 10,
  cc_test = 0.3,
  tsj = 3
)

tc &lt;- term_per_cluster(res, cutree = NULL, k=1:10, negative=FALSE)

S &lt;- reinSummary(tc, n=10)

head(S, 10)


</code></pre>

<hr>
<h2 id='tall'>TALL UI</h2><span id='topic+tall'></span>

<h3>Description</h3>

<p><code>tall</code> performs text analysis for all.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tall(
  host = "127.0.0.1",
  port = NULL,
  launch.browser = TRUE,
  maxUploadSize = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tall_+3A_host">host</code></td>
<td>
<p>The IPv4 address that the application should listen on.
Defaults to the shiny.host option, if set, or &quot;127.0.0.1&quot; if not.</p>
</td></tr>
<tr><td><code id="tall_+3A_port">port</code></td>
<td>
<p>is the TCP port that the application should listen on. If the port is not specified,
and the shiny.port option is set (with options(shiny.port = XX)), then that port will be used.
Otherwise, use a random port.</p>
</td></tr>
<tr><td><code id="tall_+3A_launch.browser">launch.browser</code></td>
<td>
<p>If true, the system's default web browser will be launched automatically
after the app is started. Defaults to true in interactive sessions only. This value of
this parameter can also be a function to call with the application's URL.</p>
</td></tr>
<tr><td><code id="tall_+3A_maxuploadsize">maxUploadSize</code></td>
<td>
<p>is a integer. The max upload file size argument. Default value is 1000 (megabyte)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='term_per_cluster'>Extract Terms and Segments for Document Clusters</h2><span id='topic+term_per_cluster'></span>

<h3>Description</h3>

<p>This function processes the results of a document clustering algorithm based on the Reinert method.
It computes the terms and their significance for each cluster, as well as the associated document segments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>term_per_cluster(res, cutree = NULL, k = 1, negative = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="term_per_cluster_+3A_res">res</code></td>
<td>
<p>A list containing the results of the Reinert clustering algorithm. Must include at least <code>dtm</code> (a document-term matrix) and <code>corresp_uce_uc_full</code> (a correspondence between segments and clusters).</p>
</td></tr>
<tr><td><code id="term_per_cluster_+3A_cutree">cutree</code></td>
<td>
<p>A custom cutree structure. If <code>NULL</code>, the default <code>cutree_reinart</code> is used to determine cluster membership.</p>
</td></tr>
<tr><td><code id="term_per_cluster_+3A_k">k</code></td>
<td>
<p>A vector of integers specifying the clusters to analyze. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="term_per_cluster_+3A_negative">negative</code></td>
<td>
<p>Logical. If <code>TRUE</code>, include negative terms in the results. If <code>FALSE</code>, exclude them. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function integrates document-term matrix rows for missing segments, calculates term statistics for each cluster,
and filters terms based on their significance. Terms can be excluded based on their significance (<code>signExcluded</code>).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>terms</code></td>
<td>
<p>A data frame of significant terms for each cluster. Columns include:
</p>

<ul>
<li> <p><code>chi_square</code>: Chi-squared statistic for the term.
</p>
</li>
<li> <p><code>p_value</code>: P-value of the chi-squared test.
</p>
</li>
<li> <p><code>sign</code>: Significance of the term (<code>positive</code>, <code>negative</code>, or <code>none</code>).
</p>
</li>
<li> <p><code>term</code>: The term itself.
</p>
</li>
<li> <p><code>freq</code>: Observed frequency of the term in the cluster.
</p>
</li>
<li> <p><code>indep</code>: Expected frequency of the term under independence.
</p>
</li>
<li> <p><code>cluster</code>: The cluster ID.
</p>
</li></ul>

</td></tr>
<tr><td><code>segments</code></td>
<td>
<p>A data frame of document segments associated with each cluster. Columns include:
</p>

<ul>
<li> <p><code>uc</code>: Unique segment identifier.
</p>
</li>
<li> <p><code>doc_id</code>: Document ID for the segment.
</p>
</li>
<li> <p><code>cluster</code>: Cluster ID.
</p>
</li>
<li> <p><code>segment</code>: The text content of each segment.
</p>
</li></ul>

</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>

data(mobydick)
res &lt;- reinert(
  x=mobydick,
  k = 10,
  term = "token",
  segment_size = 40,
  min_segment_size = 5,
  min_split_members = 10,
  cc_test = 0.3,
  tsj = 3
)

tc &lt;- term_per_cluster(res, cutree = NULL, k=1:10, negative=FALSE)

head(tc$segments,10)

head(tc$terms,10)



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
