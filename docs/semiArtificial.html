<!DOCTYPE html><html lang="en"><head><title>Help for package semiArtificial</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {semiArtificial}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#semiArtificial-package'><p>Generation and evaluation of semi-artificial data</p></a></li>
<li><a href='#cleanData'><p> Rejection of new instances based on their distance to existing instances</p></a></li>
<li><a href='#dataSimilarity'><p> Evaluate statistical similarity of two data sets</p></a></li>
<li><a href='#dsClustCompare'><p> Evaluate clustering similarity of two data sets</p></a></li>
<li><a href='#newdata'><p> Generate semi-artificial data using a generator</p></a></li>
<li><a href='#performanceCompare'><p> Evaluate similarity of two data sets based on predictive performance</p></a></li>
<li><a href='#rbfDataGen'><p>A data generator based on RBF network</p></a></li>
<li><a href='#treeEnsemble'><p>A data generator based on forest</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Generator of Semi-Artificial Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-09-23</td>
</tr>
<tr>
<td>Author:</td>
<td>Marko Robnik-Sikonja</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marko Robnik-Sikonja &lt;marko.robnik@fri.uni-lj.si&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains methods to generate and evaluate semi-artificial data sets. 
 Based on a given data set different methods learn data properties using machine learning algorithms and
 generate new data with the same properties.
 The package currently includes the following data generators:
  i) a RBF network based generator using rbfDDA() from package 'RSNNS',
  ii) a Random Forest based generator for both classification and regression problems
  iii) a density forest based generator for unsupervised data
 Data evaluation support tools include:
  a) single attribute based statistical evaluation: mean, median, standard deviation, skewness, kurtosis, medcouple, L/RMC, KS test, Hellinger distance
  b) evaluation based on clustering using Adjusted Rand Index (ARI) and FM
  c) evaluation based on classification performance with various learning models, e.g., random forests.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://lkm.fri.uni-lj.si/rmarko/software/">http://lkm.fri.uni-lj.si/rmarko/software/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>CORElearn (&ge;
1.50.3),RSNNS,MASS,nnet,cluster,fpc,stats,timeDate,robustbase,ks,logspline,methods,mcclust,flexclust,StatMatch</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-23 19:34:31 UTC; marko</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-23 20:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='semiArtificial-package'>Generation and evaluation of semi-artificial data</h2><span id='topic+semiArtificial-package'></span><span id='topic+semiArtificial'></span>

<h3>Description</h3>

<p>The package semiArtificial contains methods to generate and evaluate semi-artificial data sets.
Different data generators take a data set as an input, learn its properties using machine learning 
algorithms and generates new data with the same properties.
</p>


<h3>Details</h3>

<p>The package currently includes the following data generators:
</p>

<ul>
<li><p> a RBF network based generator using rbfDDA model from RSNNS package.
</p>
</li>
<li><p> generator using density tree forest for unsupervised data,
</p>
</li>
<li><p> generator using random forest for classification and regression.
</p>
</li></ul>

<p>Data evaluation support tools include:
</p>

<ul>
<li><p> statistical evaluation: mean, median,standard deviation, skewness, kurtosis, medcouple, L/RMC,
</p>
</li>
<li><p> evaluation based on clustering using Adjusted Rand Index (ARI) and Fowlkes-Mallows index (FM),
</p>
</li>
<li><p> evaluation based on prediction with a model, e.g., random forests.
</p>
</li></ul>

<p>Further software and development versions are available at <a href="http://lkm.fri.uni-lj.si/rmarko/software/">http://lkm.fri.uni-lj.si/rmarko/software/</a>. 
</p>


<h3>Author(s)</h3>

<p>Marko Robnik-Sikonja 
</p>


<h3>References</h3>

<p>Marko Robnik-Sikonja: Not enough data? Generate it!. <em>Technical Report, University of Ljubljana, Faculty of Computer and Information Science</em>, 2014
</p>
<p>Other references are available from <a href="http://lkm.fri.uni-lj.si/rmarko/papers/">http://lkm.fri.uni-lj.si/rmarko/papers/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbfDataGen">rbfDataGen</a></code>,
<code><a href="#topic+treeEnsemble">treeEnsemble</a></code>,
<code><a href="#topic+newdata">newdata</a></code>,
<code><a href="#topic+dataSimilarity">dataSimilarity</a></code>,
<code><a href="#topic+dsClustCompare">dsClustCompare</a></code>,
<code><a href="#topic+performanceCompare">performanceCompare</a></code>.
</p>

<hr>
<h2 id='cleanData'> Rejection of new instances based on their distance to existing instances</h2><span id='topic+cleanData'></span>

<h3>Description</h3>

<p>The function contains three data cleaning methods, 
the first two reject instances whose distance to their nearest neighbors in the existing data are too small 
or too large. The first checks distance between instances disregarding class,
the second checks distances between instances taking only instances from the same class into account.
The third method reassigns response variable using the prediction model stored in the generator <code>teObject</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cleanData(teObject, newdat, similarDropP=NA, dissimilarDropP=NA, 
          similarDropPclass=NA, dissimilarDropPclass=NA, 
		  nearestInstK=1, reassignResponse=FALSE, cleaningObject=NULL) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cleanData_+3A_teobject">teObject</code></td>
<td>
<p> An object of class <code>TreeEnsemble</code> containing a generator structure as returned by
<code><a href="#topic+treeEnsemble">treeEnsemble</a></code>. The <code>teObject</code> contains generator's training instances from which we compute 
a distance distribution of instances to their <code>nearestInsK</code> nearest instances.
This distance distribution, computed on the training data of the generator, serves as a criterion to reject new instances from <code>newdata</code>, 
i.e. based on parameters below we reject the instances too close or to far away from their nearest neighbors in generator's training data.
The computed distance distributions are stored and returned as <code>cleaningObject</code> component of returned list. If it is provided on subsequent 
calls, this reduces computational load.  </p>
</td></tr>
<tr><td><code id="cleanData_+3A_newdat">newdat</code></td>
<td>
<p> A <code>data.frame</code> object with the (newly generated) data to be cleaned.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_similardropp">similarDropP</code></td>
<td>
<p>With numeric parameters <code>similarDropP</code> and <code>dissimilarDropP</code> 
(with the default value NA and the valid value range in [0, 1]) one removes instances in <code>newdat</code>
too close to generator's training instances or too far away from these instances. The distance distribution is computed based on instances stored in 
<code>teObject</code>. For each instance in $teObject$ we store the distance to its <code>nearestInsK</code> nearest  instances
(disregarding the identical instances). These distances are sorted and represent a distribution of nearest distances for all training instances.
The values <code>similarDropP</code> and <code>dissimilarDropP</code> represent a proportion of allowed smaller/larger distances 
computed on the generator's training data contained in the <code>teObject</code>.   </p>
</td></tr>
<tr><td><code id="cleanData_+3A_dissimilardropp">dissimilarDropP</code></td>
<td>
<p>See <code>similarDropP</code>.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_similardroppclass">similarDropPclass</code></td>
<td>
<p>For classification problems only and similarly to the <code>similarDropP</code> and <br />
<code>dissimilarDropP</code> above, 
with  the <code>similarDropPclass</code> and <code>dissimilarDropPclass</code> (also in a [0, 1] range) we also removes instances in <code>newdat</code>
too close to generator's training instances or too far away from these instances, but only taking near instances from the same class into account.
The <code>similarDropPclass</code> contains either a single integer giving thresholds for all class values or a vector of thresholds, one for each class.
If the vector is of insufficient length it is replicated using function <code><a href="base.html#topic+rep">rep</a></code>.
The generated distance distributions are stored in the <code>cleaningObject</code> component of the returned list. </p>
</td></tr>
<tr><td><code id="cleanData_+3A_dissimilardroppclass">dissimilarDropPclass</code></td>
<td>
<p>See <code>similarDropPclass</code>.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_nearestinstk">nearestInstK</code></td>
<td>
<p>An integer with default value of 1, controls how many generator's training instances we take into account when computing 
the distance distribution of nearest instances.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_reassignresponse">reassignResponse</code></td>
<td>
<p>is a <code>logical</code> value controlling whether the response variable of the <code>newdat</code> shall be set anew 
using a random forest prediction model or taken as it is. The default value <code>reassign=FALSE</code> means that values of response are not changed.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_cleaningobject">cleaningObject</code></td>
<td>
<p> is a list object with a precomputed distance distributions and predictor from previous runs of the same function.
If provided, this saves computation time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the training instances stored in the generator <code>teObject</code> to compute distribution of distances from instances to their 
<code>nearestInstK</code> nearest instances. For classification problems the distributions can also be computed only for instances from the same class.
Using these near distance distributions the function rejects all instances too close or too far away from existing instances. 
</p>
<p>The default value of <code>similarDropP</code>, <code>dissimilarDropP</code>, <code>similarDropPclass</code>, and <code>dissimilarDropPclass</code> is NA and means that
the near/far values are not rejected. The same effect has value 0 for <code>similarDropP</code> and <code>similarDropPclass</code>, and value 1 for
<code>dissimilarDropP</code> and <code>dissimilarDropPclass</code>.
</p>


<h3>Value</h3>

<p>The method returns a <code>list</code> object  with two components:
</p>
<table role = "presentation">
<tr><td><code>cleanData</code></td>
<td>
<p>is a <code>data.frame</code> containing the instances left after rejection of too close or too distant instances from <code>newdata</code>.</p>
</td></tr>
<tr><td><code>cleaningObject</code></td>
<td>
<p>is a <code>list</code> containing computed distributions of nearest distances (also class-based fro classification problems, 
and possibly a predictor used for reassigning the response variable.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>See Also</h3>

<p><code><a href="#topic+treeEnsemble">treeEnsemble</a></code>, <code><a href="#topic+newdata.TreeEnsemble">newdata.TreeEnsemble</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># inspect properties of the iris data set
plot(iris, col=iris$Species)
summary(iris)

irisEnsemble&lt;- treeEnsemble(Species~.,iris,noTrees=10)

# use the generator to create new data with the generator
irisNewEns &lt;- newdata(irisEnsemble, size=150)

#inspect properties of the new data
plot(irisNewEns, col = irisNewEns$Species) #plot generated data
summary(irisNewEns)

clObj &lt;- cleanData(irisEnsemble, irisNewEns, similarDropP=0.05, dissimilarDropP=0.95, 
                   similarDropPclass=0.05, dissimilarDropPclass=0.95, 
		           nearestInstK=1, reassignResponse=FALSE, cleaningObject=NULL) 
head(clObj$cleanData)
</code></pre>

<hr>
<h2 id='dataSimilarity'> Evaluate statistical similarity of two data sets</h2><span id='topic+dataSimilarity'></span>

<h3>Description</h3>

<p>Use mean, standard deviation, skewness, kurtosis, Hellinger distance and KS test to compare 
similarity of two data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataSimilarity(data1, data2, dropDiscrete=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dataSimilarity_+3A_data1">data1</code></td>
<td>
<p> A <code>data.frame</code> containing the reference data.</p>
</td></tr>
<tr><td><code id="dataSimilarity_+3A_data2">data2</code></td>
<td>
<p> A <code>data.frame</code> with the same number and names of columns as <code>data1</code>.</p>
</td></tr>
<tr><td><code id="dataSimilarity_+3A_dropdiscrete">dropDiscrete</code></td>
<td>
<p> A vector discrete attribute indices to skip in comparison. Typically we might skip class, 
because its distribution was forced by the user.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function compares data stored in <code>data1</code> with <code>data2</code> on per attribute basis by
computing several statistics:
mean, standard deviation, skewness, kurtosis, Hellinger distance and KS test. 
</p>


<h3>Value</h3>

<p>The method returns a list of statistics computed on both data sets:
</p>
<table role = "presentation">
<tr><td><code>equalInstances</code></td>
<td>
<p>The number of instances in <code>data2</code> equal to the instances in <code>data1</code>.</p>
</td></tr>
<tr><td><code>stats1num</code></td>
<td>
<p>A matrix with rows containing statistics (mean, standard deviation, skewness, and kurtosis) computed on numeric attributes of <code>data1</code>.</p>
</td></tr>
<tr><td><code>stats2num</code></td>
<td>
<p>A matrix with rows containing statistics (mean, standard deviation, skewness, and kurtosis) computed on numeric attributes of <code>data2</code>.</p>
</td></tr>
<tr><td><code>ksP</code></td>
<td>
<p>A vector with p-values of Kolmogorov-Smirnov two sample tests, performed on matching attributes from <code>data1</code> and <code>data2</code>.</p>
</td></tr>
<tr><td><code>freq1</code></td>
<td>
<p>A list with value frequencies for discrete attributes in <code>data1</code>.</p>
</td></tr>
<tr><td><code>freq2</code></td>
<td>
<p>A list with value frequencies for discrete attributes in <code>data2</code>.</p>
</td></tr>
<tr><td><code>dfreq</code></td>
<td>
<p>A list with differences in frequencies of discrete attributes' values between  <code>data1</code> and <code>data2</code>.</p>
</td></tr>
<tr><td><code>dstatsNorm</code></td>
<td>
<p>A matrix with rows containing difference between statistics (mean, standard deviation, skewness, and kurtosis) 
computed on [0,1] normalized numeric attributes for <code>data1</code> and <code>data2.</code></p>
</td></tr>
<tr><td><code>hellingerDist</code></td>
<td>
<p>A vector with Hellinger distances between matching attributes from <code>data1</code> and <code>data2</code>.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>See Also</h3>

<p><code><a href="#topic+newdata.RBFgenerator">newdata.RBFgenerator</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use iris data set, split into training and testing data
set.seed(12345)
train &lt;- sample(1:nrow(iris),size=nrow(iris)*0.5)
irisTrain &lt;- iris[train,]
irisTest &lt;- iris[-train,]

# create RBF generator
irisGenerator&lt;- rbfDataGen(Species~.,irisTrain)

# use the generator to create new data
irisNew &lt;- newdata(irisGenerator, size=100)

# compare statistics of original and new data
dataSimilarity(irisTest, irisNew)

</code></pre>

<hr>
<h2 id='dsClustCompare'> Evaluate clustering similarity of two data sets</h2><span id='topic+dsClustCompare'></span>

<h3>Description</h3>

<p>Similarity of two data sets is compared with a method using any of
clustering comparison metrics: Adjusted Rand Index (ARI), Fowlkes-Mallows index(FM),
Jaccard Index (J), or Variation of Information index (VI).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsClustCompare(data1, data2) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsClustCompare_+3A_data1">data1</code></td>
<td>
<p> A <code>data.frame</code> containing the reference data.</p>
</td></tr>
<tr><td><code id="dsClustCompare_+3A_data2">data2</code></td>
<td>
<p> A <code>data.frame</code> with the same number and names of columns as <code>data1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function compares data stored in <code>data1</code> with <code>data2</code> by first performing partitioning around medoids (PAM) 
clustering on <code>data1</code>. 
Instances from <code>data2</code> are than assigned to the cluster with the closest medoid. 
In second step PAM clustering is performed on <code>data2</code> and instances from <code>data1</code> are assigned to the clusters with closest medoids. 
The procedure gives us two clusterings on the same instances which we can compare using any of ARI, FM, J, or VI. 
The higher the value of ARI/FM/J the more similar are the two data sets, and reverse is true for VI, where two perfectly matching partitions
produce 0 score.    
For random clustering ARI returns a value around zero (negative values are possible) and for perfectly matching clustering ARI is 1. 
FM and J values are strictly in [0, 1].
</p>


<h3>Value</h3>

<p>The method returns a value of a list containing ARI and/or FM, depending on the parameters.
</p>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>See Also</h3>

<p><code><a href="#topic+newdata.RBFgenerator">newdata.RBFgenerator</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use iris data set

# create RBF generator
irisGenerator&lt;- rbfDataGen(Species~.,iris)

# use the generator to create new data
irisNew &lt;- newdata(irisGenerator, size=200)

# compare ARI computed on clustering with original and new data
dsClustCompare(iris, irisNew)

</code></pre>

<hr>
<h2 id='newdata'> Generate semi-artificial data using a generator</h2><span id='topic+newdata.RBFgenerator'></span><span id='topic+newdata'></span><span id='topic+newdata.TreeEnsemble'></span>

<h3>Description</h3>

<p>Using a generator build with <code><a href="#topic+rbfDataGen">rbfDataGen</a></code> or <code><a href="#topic+treeEnsemble">treeEnsemble</a></code> the method generates <code>size</code> new instances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RBFgenerator'
newdata(object, size, var=c("estimated","Silverman"), 
                               classProb=NULL, defaultSpread=0.05, ... )
## S3 method for class 'TreeEnsemble'
newdata(object, fillData=NULL, 
                               size=ifelse(is.null(fillData),1,nrow(fillData)), 
                               onlyPath=FALSE, classProb=NULL, 
                               predictClass=FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newdata_+3A_object">object</code></td>
<td>
<p> An object of class <code>RBFgenerator</code> or <code>TreeEnsemble</code> containing a generator structure as returned by <code><a href="#topic+rbfDataGen">rbfDataGen</a></code> or <code><a href="#topic+treeEnsemble">treeEnsemble</a></code>, respectively.  </p>
</td></tr>
<tr><td><code id="newdata_+3A_filldata">fillData</code></td>
<td>
<p> A dataframe with part of the values already specified. All missing values (i.e. NA values) are filled in by the generator.</p>
</td></tr>
<tr><td><code id="newdata_+3A_size">size</code></td>
<td>
<p> A number of instances to generate. By default this is one instance, or in the case of existing fillData this is the number of rows in that dataframe.</p>
</td></tr>
<tr><td><code id="newdata_+3A_var">var</code></td>
<td>
<p>For the generator of type <code>RBFgenerator</code> the parameter <code>var</code> determines the method of kernel width (variance) estimation. Supported options are <code>"estimated"</code> and <code>"Silverman"</code>.</p>
</td></tr>
<tr><td><code id="newdata_+3A_classprob">classProb</code></td>
<td>
<p>For classification problems, a vector of desired class value probability distribution. Default value <code>classProb=NULL</code> uses probability distribution of the generator's training instances. </p>
</td></tr>
<tr><td><code id="newdata_+3A_defaultspread">defaultSpread</code></td>
<td>
<p>For the generator of type <code>RBFgenerator</code> the parameter is a numeric value replacing zero spread in case <code>var="estimated"</code> is used. The value <code>defaultSpread=NULL</code> keeps zero spread values.  </p>
</td></tr>
<tr><td><code id="newdata_+3A_onlypath">onlyPath</code></td>
<td>
<p>For the generator of type <code>TreeEnsemble</code> and attribute density data in the leaves (<code>densityData="leaf"</code>), 
the parameter is a boolean variable indicating if only attributes on the path from the root to the leaf are generated in the leaf.
If <code>onlyPath=FALSE</code> all value are generated in the first randomly chosen leaf of a tree, else only attributes on 
the path are generated and then the next random tree is selected. </p>
</td></tr>
<tr><td><code id="newdata_+3A_predictclass">predictClass</code></td>
<td>
<p>For classification problems and the generator of type <code>TreeEnsemble</code> the parameter
determines if the class value is set through prediction with the forest (the constructed generator serves as a predictor) or set according to the 
class value distribution of the selected leaf. </p>
</td></tr>
<tr><td><code id="newdata_+3A_...">...</code></td>
<td>
<p> Additional parameters passed to density estimation functions kde, logspline, and quantile.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function uses the <code>object</code> structure as returned by <code><a href="#topic+rbfDataGen">rbfDataGen</a></code> or <code><a href="#topic+treeEnsemble">treeEnsemble</a></code>. 
In case of <code>RBFgenerator</code> the object contains descriptions of the Gaussian kernels, which model the original data. 
The kernels are used to generate  a required number of new instances.
The kernel width of provided kernels can be set in two ways. By setting <code>var="estimated"</code> the estimated spread of the
training instances that have the maximal activation value for the particular kernel is used. 
Using <code>var="Silverman"</code> width is set by the generalization of Silverman's rule of thumb to multivariate
case (unreliable for larger dimensions). 
</p>
<p>In case of TreeEnsemble generator no additional parameters are needed, except for the number of generated instances.
</p>


<h3>Value</h3>

<p>The method returns a <code>data.frame</code> object  with required number of instances.
</p>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbfDataGen">rbfDataGen</a></code>, <code><a href="#topic+treeEnsemble">treeEnsemble</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># inspect properties of the iris data set
plot(iris, col=iris$Species)
summary(iris)

# create RBF generator
irisRBF&lt;- rbfDataGen(Species~.,iris)
# create treesemble  generator
irisEnsemble&lt;- treeEnsemble(Species~.,iris,noTrees=10)


# use the generator to create new data with both generators
irisNewRBF &lt;- newdata(irisRBF, size=150)
irisNewEns &lt;- newdata(irisEnsemble, size=150)

#inspect properties of the new data
plot(irisNewRBF, col = irisNewRBF$Species) #plot generated data
summary(irisNewRBF)
plot(irisNewEns, col = irisNewEns$Species) #plot generated data
summary(irisNewEns)
</code></pre>

<hr>
<h2 id='performanceCompare'> Evaluate similarity of two data sets based on predictive performance</h2><span id='topic+performanceCompare'></span>

<h3>Description</h3>

<p>Depending on the type of problem (classification or regression), a classification performance (accuracy, AUC, brierScore, etc) 
or regression performance (RMSE, MSE, MAE, RMAE, etc) on two data sets is used to compare the similarity of two data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performanceCompare(data1, data2, formula, model="rf", stat=NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="performanceCompare_+3A_data1">data1</code></td>
<td>
<p> A <code>data.frame</code> containing the reference data.</p>
</td></tr>
<tr><td><code id="performanceCompare_+3A_data2">data2</code></td>
<td>
<p> A <code>data.frame</code> with the same number and names of columns as <code>data1</code>.</p>
</td></tr>
<tr><td><code id="performanceCompare_+3A_formula">formula</code></td>
<td>
<p> A <code>formula</code> specifying the response and predictive variables.</p>
</td></tr>
<tr><td><code id="performanceCompare_+3A_model">model</code></td>
<td>
<p> A predictive model used for performance comparison. The default value &quot;rf&quot; stands for random forest, 
but any classification or regression model supported by function <code>CoreModel</code> in 
<a href="https://CRAN.R-project.org/package=CORElearn">CORElearn</a> package can be used. </p>
</td></tr>
<tr><td><code id="performanceCompare_+3A_stat">stat</code></td>
<td>
<p> A statistics used as performance indicator. The default value is NULL and means that for classification &quot;accuracy&quot; is used,
and for regression &quot;RMSE&quot;&quot; (relative mean squared error) is used. Other values supported and output by  <code>modelEval</code> 
from <a href="https://CRAN.R-project.org/package=CORElearn">CORElearn</a> package can be used e.g., &quot;AUC&quot; or &quot;brierScore&quot;.</p>
</td></tr>
<tr><td><code id="performanceCompare_+3A_...">...</code></td>
<td>
<p> Additional parameters passed to <code>CoreModel</code> function. </p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function compares data stored in <code>data1</code> with <code>data2</code> by comparing models constructed on <code>data1</code>
and evaluated on both <code>data1</code> and <code>data2</code> with models built on <code>data2</code> and evaluated on 
both <code>data1</code> and <code>data2</code>. The difference between these performances are indicative on similarity of 
the data sets if used in machine learning and data mining. The performance indicator used is determined 
by parameter <code>stat</code>.
</p>


<h3>Value</h3>

<p>The method returns a list of performance indicators computed on both data sets:
</p>
<table role = "presentation">
<tr><td><code>diff.m1</code></td>
<td>
<p>The difference between performance of model built on <code>data1</code> (and evaluated on both <code>data1</code> and <code>data2</code>.)</p>
</td></tr>
<tr><td><code>diff.m2</code></td>
<td>
<p>The difference between performance of model built on <code>data2</code> (and evaluated on both <code>data1</code> and <code>data2</code>.)</p>
</td></tr>
<tr><td><code>perf.m1d1</code></td>
<td>
<p>The performance of model built on <code>data1</code> on <code>data1</code>. </p>
</td></tr>
<tr><td><code>perf.m1d2</code></td>
<td>
<p>The performance of model built on <code>data1</code> on <code>data2</code>. </p>
</td></tr>
<tr><td><code>perf.m2d1</code></td>
<td>
<p>The performance of model built on <code>data2</code> on <code>data1</code>. </p>
</td></tr>
<tr><td><code>perf.m2d2</code></td>
<td>
<p>The performance of model built on <code>data2</code> on <code>data2</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>See Also</h3>

<p><code><a href="#topic+newdata.RBFgenerator">newdata.RBFgenerator</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use iris data set

# create RBF generator
irisGenerator&lt;- rbfDataGen(Species~.,iris)

# use the generator to create new data
irisNew &lt;- newdata(irisGenerator, size=200)

# compare statistics of original and new data
performanceCompare(iris, irisNew, Species~.)

</code></pre>

<hr>
<h2 id='rbfDataGen'>A data generator based on RBF network</h2><span id='topic+rbfDataGen'></span>

<h3>Description</h3>

<p>Using given <code>formula</code> and <code>data</code> the method builds a RBF network and extracts its properties thereby preparing a data generator which can be used 
with <code><a href="#topic+newdata.RBFgenerator">newdata.RBFgenerator</a></code> method to generate semi-artificial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> rbfDataGen(formula, data, eps=1e-4, minSupport=1, 
            nominal=c("encodeBinary","asInteger")) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbfDataGen_+3A_formula">formula</code></td>
<td>
<p> A formula specifying the response and variables to be modeled. </p>
</td></tr>
<tr><td><code id="rbfDataGen_+3A_data">data</code></td>
<td>
<p> A data frame with training data. </p>
</td></tr>
<tr><td><code id="rbfDataGen_+3A_eps">eps</code></td>
<td>
<p> The minimal probability considered in data generator to be larger than 0.</p>
</td></tr>
<tr><td><code id="rbfDataGen_+3A_minsupport">minSupport</code></td>
<td>
<p>The minimal number of instances defining a Gaussian kernel to copy the kernel to the data generator.</p>
</td></tr>
<tr><td><code id="rbfDataGen_+3A_nominal">nominal</code></td>
<td>
<p>The way how to treat nominal features. The option <code>"asInteger"</code> converts factors 
into integers and treats them as numeric features. The option <code>"encodeBinary"</code> converts each nominal 
attribute into a set of binary features, which encode the nominal value, e.g., for three valued attribute 
three binary attributes are constructed, each encoding a presence of one nominal value with 0 or 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter <code>formula</code> is used as a mechanism to select features (attributes)
and the prediction variable (response, class). Only simple terms can be used and
interaction terms are not supported. The simplest way is
to specify just the response variable using e.g. <code>class ~ .</code>. See examples below.
</p>
<p>A RBF network is build using <code>rbfDDA</code> from <a href="https://CRAN.R-project.org/package=RSNNS">RSNNS</a> package. 
The learned Gaussian kernels are extracted and used in data generation with 
<code><a href="#topic+newdata.RBFgenerator">newdata.RBFgenerator</a></code> method.
</p>


<h3>Value</h3>

<p>The created model is returned as a structure of class <code>RBFgenerator</code>, containing the following items:
</p>
<table role = "presentation">
<tr><td><code>noGaussians</code></td>
<td>
<p>The number of extracted Gaussian kernels.</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>A matrix of Gaussian kernels' centers, with one row for each Gaussian kernel.</p>
</td></tr>
<tr><td><code>probs</code></td>
<td>
<p>A vector of kernel probabilities. Probabilities are defined as relative frequencies of training set instances with  maximal activation in the given kernel.</p>
</td></tr>
<tr><td><code>unitClass</code></td>
<td>
<p>A vector of class values, one for each kernel.</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>A vector of kernels' biases, one for each kernel. The bias is multiplied by the kernel activation to produce output value of given RBF network unit.</p>
</td></tr>
<tr><td><code>spread</code></td>
<td>
<p>A matrix of estimated variances for the kernels, one row for each kernel. 
The j-th value in i-th row represents the variance of training instances for j-th attribute with maximal activation 
in i-th Gaussian.</p>
</td></tr>
<tr><td><code>gNoActivated</code></td>
<td>
<p>A vector containing numbers of training instances with maximal activation in each kernel.</p>
</td></tr>
<tr><td><code>noAttr</code></td>
<td>
<p>The number of attributes in training data.</p>
</td></tr>
<tr><td><code>datNames</code></td>
<td>
<p>A vector of attributes' names.</p>
</td></tr>
<tr><td><code>originalNames</code></td>
<td>
<p>A vector of original attribute names.</p>
</td></tr>
<tr><td><code>attrClasses</code></td>
<td>
<p>A vector of attributes' classes (i.e., data types like <code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code>attrLevels</code></td>
<td>
<p>A list of levels for discrete attributes (with class <code>factor</code>).</p>
</td></tr>
<tr><td><code>attrOrdered</code></td>
<td>
<p>A vector of type logical indicating whether the attribute is <code>ordered</code> (only possible for attributes of type <code>factor</code>.</p>
</td></tr>
<tr><td><code>normParameters</code></td>
<td>
<p>A list of parameters for normalization of attributes to [0,1].</p>
</td></tr>
<tr><td><code>noCol</code></td>
<td>
<p>The number of columns in the internally generated data set.</p>
</td></tr>
<tr><td><code>isDiscrete</code></td>
<td>
<p>A vector of type logical, each value indicating whether a respective attribute is discrete.</p>
</td></tr>
<tr><td><code>noAttrGen</code></td>
<td>
<p>The number of attributes to generate.</p>
</td></tr>
<tr><td><code>nominal</code></td>
<td>
<p>The value of parameter <code>nominal</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>References</h3>

<p>Marko Robnik-Sikonja: Not enough data? Generate it!. <em>Technical Report, University of Ljubljana, Faculty of Computer and Information Science</em>, 2014
</p>
<p>Other references are available from <a href="http://lkm.fri.uni-lj.si/rmarko/papers/">http://lkm.fri.uni-lj.si/rmarko/papers/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newdata.RBFgenerator">newdata.RBFgenerator</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use iris data set, split into training and testing, inspect the data
set.seed(12345)
train &lt;- sample(1:nrow(iris),size=nrow(iris)*0.5)
irisTrain &lt;- iris[train,]
irisTest &lt;- iris[-train,]

# inspect properties of the original data
plot(irisTrain, col=irisTrain$Species)
summary(irisTrain)

# create rbf generator
irisGenerator&lt;- rbfDataGen(Species~.,irisTrain)

# use the generator to create new data
irisNew &lt;- newdata(irisGenerator, size=200)

#inspect properties of the new data
plot(irisNew, col = irisNew$Species) #plot generated data
summary(irisNew)
</code></pre>

<hr>
<h2 id='treeEnsemble'>A data generator based on forest</h2><span id='topic+treeEnsemble'></span><span id='topic+indAttrGen'></span>

<h3>Description</h3>

<p>Using given <code>formula</code> and <code>data</code> the method <code>treeEnsemble</code> builds a tree ensemble and turns it into a data generator, which can be used with <code><a href="#topic+newdata">newdata</a></code> method to generate 
semi-artificial data. The methods supports classification, regression, and unsupervised data, depending on the input and parameters.
The method <code>indAttrGen</code> generates data from the same distribution as the input data, but 
assuming conditionally independent attributes. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'> treeEnsemble(formula, dataset, noTrees = 100, minNodeWeight=2, noSelectedAttr=0, 
  	problemType=c("byResponse","classification", "regression","density"),
    densityData=c("leaf", "topDown", "bottomUp","no"),
    cdfEstimation = c("ecdf","logspline","kde"), 
	densitySplitMethod=c("balancedSplit","randomSplit","maxVariance"),
    estimator=NULL,...) 

indAttrGen(formula, dataset, cdfEstimation = c("ecdf","logspline","kde"), 
           problemType="byResponse") 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="treeEnsemble_+3A_formula">formula</code></td>
<td>
<p> A formula specifying the response and variables to be modeled. </p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_dataset">dataset</code></td>
<td>
<p> A data frame with training data. </p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_notrees">noTrees</code></td>
<td>
<p> The number of trees in the ensemble.</p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_minnodeweight">minNodeWeight</code></td>
<td>
<p>The minimal number of instances in a tree leaf.</p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_noselectedattr">noSelectedAttr</code></td>
<td>
<p>Number of randomly selected attributes in each node which are considered as possible splits. In general this should be a positive integer, 
but values 0, -1, and -2 are also possible. 
The default value is <code>noSelectedAttr=0</code>, which causes random selection of integer rounded <code class="reqn">\sqrt{a}</code> attributes, where $a$ is the number of all attributes. 
Value -1 means that <code class="reqn">1+\log_2{a}</code> attributes are selected and value -2 means that all attributes are selected.</p>
</td></tr>   
<tr><td><code id="treeEnsemble_+3A_problemtype">problemType</code></td>
<td>
<p>The type of the problem modeled: classification, regression, or unsupervised (density estimation). The default value  <code>"byResponse"</code> indicates that 
the problem type is deducted based on <code>formula</code> and <code>data</code>. </p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_densitydata">densityData</code></td>
<td>
<p>The type of generator data and place where new instances are generated: in the leafs, top down from the root of the tree to the leaves, bottom up from
the leaves to root. In case of value <code>"no"</code> the ensemble contains no generator data and can be used as an ordinary ensemble predictor (although 
probably slow, as it is written entirely in R).</p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_cdfestimation">cdfEstimation</code></td>
<td>
<p>The manner values are generated and the type of data stored in the generator: <code>"ecdf"</code> indicates values are generated from empirical cumulative 
distributions stored for each variable separately; <code>"logspline"</code> means that value distribution is modeled with logsplines, and <code>"kde"</code> 
indicates that Gaussian kernel density estimation is used.</p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_densitysplitmethod">densitySplitMethod</code></td>
<td>
<p>In case <code>problemType="density"</code> the parameters determines the criteria for selection of split in the density tree. Possible choices are 
balanced (a split value is chosen in such a way that the split is balanced), random (split value is chosen randomly) and maxVariance (split with 
maximal variance is chosen).</p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_estimator">estimator</code></td>
<td>
<p>The attribute estimator used to select the node split in classification and regression trees. Function <code>attrEval</code> from <code>CORElearn</code> package is 
used, so the values have to be compatible with that function. The default value <code>NULL</code> chooses Gini index in case of classification problems and MSE 
(mean squared error in resulting splits) in case of regression.</p>
</td></tr>
<tr><td><code id="treeEnsemble_+3A_...">...</code></td>
<td>
<p>Further parameters to be passed onto probability density estimators.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter <code>formula</code> is used as a mechanism to select features (attributes)
and the prediction variable (response) from the data. Only simple terms can be used and
interaction terms are not supported. The simplest way is
to specify just the response variable using e.g. <code>class ~ .</code>. For unsupervised problems all variables can be selected using formula <code> ~ .</code>.
See examples below.
</p>
<p>A forest of trees is build using R code. The base models of the ensemble are classification, regression or density trees with additional information stored at the 
appropriate nodes. New data can be generated using <code><a href="#topic+newdata">newdata</a></code> method.
</p>
<p>The method <code>indAttrGen</code> generates data from the same distribution as the input data (provided in 
<code>dataset</code>), but assumes conditional independence of attributes. This assumption makes the generated data
a simple baseline generator. Internally, the method calls <code>treeEnsemble</code> with parameters 
<code>noTrees=1</code>, <code>minNodeWeight=nrow(dataset)</code>, <code>densityData="leaf"</code>.  
</p>


<h3>Value</h3>

<p>The created model is returned with additional data stored as a list and also in the trees. The model can be used with function <code><a href="#topic+newdata">newdata</a></code> to generate new values.
</p>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>References</h3>

<p>Marko Robnik-Sikonja: Not enough data? Generate it!. <em>Technical Report, University of Ljubljana, Faculty of Computer and Information Science</em>, 2014
</p>
<p>Other references are available from <a href="http://lkm.fri.uni-lj.si/rmarko/papers/">http://lkm.fri.uni-lj.si/rmarko/papers/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newdata">newdata</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use iris data set, split into training and testing, inspect the data
set.seed(12345)
train &lt;- sample(1:nrow(iris),size=nrow(iris)*0.5)
irisTrain &lt;- iris[train,]
irisTest &lt;- iris[-train,]

# inspect properties of the original data
plot(iris[,-5], col=iris$Species)
summary(iris)

# create tree ensemble generator for classification problem
irisGenerator&lt;- treeEnsemble(Species~., irisTrain, noTrees=10)

# use the generator to create new data
irisNew &lt;- newdata(irisGenerator, size=200)

#inspect properties of the new data
plot(irisNew[,-5], col = irisNew$Species) # plot generated data
summary(irisNew)

## Not run: 
# create tree ensemble generator for unsupervised problem
irisUnsupervised&lt;- treeEnsemble(~.,irisTrain[,-5], noTrees=10)
irisNewUn &lt;- newdata(irisUnsupervised, size=200)
plot(irisNewUn) # plot generated data
summary(irisNewUn)

# create tree ensemble generator for regression problem
CO2gen&lt;- treeEnsemble(uptake~.,CO2, noTrees=10)
CO2New &lt;- newdata(CO2gen, size=200)
plot(CO2) # plot original data
plot(CO2New) # plot generated data
summary(CO2)
summary(CO2New)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
