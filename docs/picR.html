<!DOCTYPE html><html><head><title>Help for package picR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {picR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#PIC'><p>Predictive Information Criteria</p></a></li>
<li><a href='#PIC.lm'><p>PIC method for Linear Models</p></a></li>
<li><a href='#PIC.mlm'><p>PIC method for Multivariable Linear Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Predictive Information Criteria for Model Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Computation of predictive information criteria (PIC) from select model object classes 
    for model selection in predictive contexts. In contrast to the more widely used Akaike 
    Information Criterion (AIC), which are derived under the assumption that target(s) of prediction 
    (i.e. validation data) are independently and identically distributed to the fitting data, the PIC
    are derived under less restrictive assumptions and thus generalize AIC to the more practically 
    relevant case of training/validation data heterogeneity. The methodology featured in this package is based on Flores (2021) <a href="https://iro.uiowa.edu/esploro/outputs/doctoral/A-new-class-of-information-criteria/9984097169902771?institution=01IOWA_INST">https://iro.uiowa.edu/esploro/outputs/doctoral/A-new-class-of-information-criteria/9984097169902771?institution=01IOWA_INST</a> "A new class of information criteria for improved prediction in the presence of training/validation data heterogeneity".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, testthat (&ge; 3.0.0), dplyr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/javenrflo/picR">https://github.com/javenrflo/picR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/javenrflo/picR/issues">https://github.com/javenrflo/picR/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-21 20:05:32 UTC; javenrflo</td>
</tr>
<tr>
<td>Author:</td>
<td>Javier Flores <a href="https://orcid.org/0000-0002-1550-1655"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Javier Flores &lt;javenrflo.pro@pm.me&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-24 17:52:36 UTC</td>
</tr>
</table>
<hr>
<h2 id='PIC'>Predictive Information Criteria</h2><span id='topic+PIC'></span>

<h3>Description</h3>

<p><code>PIC</code> is the S3 generic function for computing predictive information criteria (PIC).
Depending on the <code><a href="base.html#topic+class">class</a></code> of the fitted model supplied to <strong><code>object</code></strong>, the function
invokes the appropriate method for computing PIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PIC(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PIC_+3A_object">object</code></td>
<td>
<p>A fitted model object.</p>
</td></tr>
<tr><td><code id="PIC_+3A_newdata">newdata</code></td>
<td>
<p>An optional dataframe to be used as validation data in computing PIC. If omitted, the training data contained within <strong><code>object</code></strong> are used.</p>
</td></tr>
<tr><td><code id="PIC_+3A_...">...</code></td>
<td>
<p>Further arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PIC are model selection criteria that may be used to select from among predictive models in a candidate set.
The model with the minimum criterion value is preferred.
</p>
<p>The PIC asymptotically select the candidate model that minimizes the mean squared error of prediction (MSEP),
thus behaving similarly to the the Akaike Information Criterion (AIC). However in contrast to the AIC, the PIC
do not assume a panel of validation data that are independent and identically distributed to the set of training
data. This effectively enables the PIC to accommodate training/validation data <em>heterogeneity</em>, where training
and validation data may differ from one another in distribution.
</p>
<p>Data heterogeneity is arguably the more typical circumstance in practice, especially when one considers applications
where a set of covariates are used to model and predict some response. In these regression contexts, one often predicts
values of the response at combinations of covariate values not necessarily used in training the predictive model.
</p>


<h3>Value</h3>

<p>The form of the value returned by <code>PIC</code> depends on the fitted model class and its method-specific arguments.
Details may be found in the documentation of each method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PIC.lm">PIC.lm</a></code>, <code><a href="#topic+PIC.mlm">PIC.mlm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

# Fit a regression model
mod &lt;- lm(Sepal.Length ~ Sepal.Width + Species, data = iris)
PIC(object  = mod,
    newdata = data.frame(Sepal.Width = c(0.25, 1.74, 2.99),
                         Species = factor(c("setosa", "virginica", "virginica"),
                                          levels = c("setosa", "versicolor", "virginica"))))

# Fit a bivariable regression model
mod &lt;- lm(cbind(Sepal.Length, Sepal.Width) ~ Species + Petal.Length, data = iris)
# Note: For multivariable models, response variable columns must be included if
#       newdata is specified. If the values of the validation response(s) are
#       unknown, specify NA. If partially observed, specify NA only where unknown.
PIC(object  = mod,
    newdata = data.frame(Sepal.Length = c(4.1, NA, NA),
                         Sepal.Width  = c(NA,NA,3.2),
                         Petal.Length = c(1.2, 3.5, 7),
                         Species = factor(c("setosa", "virginica", "virginica"),
                                          levels = c("setosa", "versicolor", "virginica"))))

</code></pre>

<hr>
<h2 id='PIC.lm'>PIC method for Linear Models</h2><span id='topic+PIC.lm'></span>

<h3>Description</h3>

<p>Computation of predictive information criteria for linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm'
PIC(object, newdata, group_sizes = NULL, bootstraps = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PIC.lm_+3A_object">object</code></td>
<td>
<p>A fitted model object of <code><a href="base.html#topic+class">class</a></code> &quot;lm&quot;.</p>
</td></tr>
<tr><td><code id="PIC.lm_+3A_newdata">newdata</code></td>
<td>
<p>An optional dataframe to be used as validation data in computing PIC. If omitted, the training data contained within <code>object</code> are used.</p>
</td></tr>
<tr><td><code id="PIC.lm_+3A_group_sizes">group_sizes</code></td>
<td>
<p>An optional scalar or numeric vector indicating the sizes of <code>newdata</code> partitions. If omitted, <code>newdata</code> is not partitioned. See 'Details'.</p>
</td></tr>
<tr><td><code id="PIC.lm_+3A_bootstraps">bootstraps</code></td>
<td>
<p>An optional numeric value indicating the number of bootstrap samples to use for a bootstrapped PIC. See 'Details'.</p>
</td></tr>
<tr><td><code id="PIC.lm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PIC.lm</code> computes PIC values based on the supplied regression model. Candidate models with relatively smaller criterion values are preferred.
Depending on the value(s) supplied to <strong><code>group_sizes</code></strong>, one of three implementations of PIC are computed:
</p>

<ul>
<li> <p><strong>iPIC</strong>: The individualized predictive information criterion (iPIC) is computed when <strong><code>group_sizes = 1</code></strong>. A value
of iPIC is determined for each <em>individual</em> observation in <strong><code>newdata</code></strong>. Using iPIC, one may thus select optimal predictive
models specific to each particular validation datapoint.
</p>
</li>
<li> <p><strong>gPIC</strong>: The group predictive information criterion (gPIC) is computed when <strong><code>group_sizes &gt; 1</code></strong> or
<strong><code>is.vector(group_sizes) == TRUE</code></strong>. A value of gPIC is determined for each cohort or <em>group</em> of observations
defined by the partitions of <strong><code>newdata</code></strong>. Using gPIC, one may thus select optimal predictive models specific to each
group of validation datapoints. For the class of regression models, the gPIC value of a group of validation observations
is equivalent to the sum of their individual iPIC values.
</p>
</li>
<li> <p><strong>tPIC</strong>: The total predictive information criterion (tPIC) is computed when <strong><code>group_sizes = NULL</code></strong>. Computation of
the tPIC is the default, and one may use the tPIC to select the optimal predictive model for the entire set of validation
datapoints. The tPIC and gPIC are equivalent when <strong><code>group_sizes = m</code></strong>, where <code>m</code> is the number of observations in
<strong><code>newdata</code></strong>. When <strong><code>newdata</code></strong> is not supplied, tPIC is exactly equivalent to the Akaike Information Criterion (<a href="stats.html#topic+AIC">AIC</a>).
</p>
</li></ul>

<p>If a numeric value is supplied to <strong><code>bootstraps</code></strong> the total Predictive information criterion (tPIC) is computed <strong><code>bootstraps</code></strong> times, where
generated bootstrap samples are each used as sets of validation data in computing the tPIC. The resulting tPIC values are then averaged to generate a single,
bootstrapped tPIC value. Model selection based on this bootstrapped tPIC value may lead to the selection of a more generally applicable predictive model whose
predictive accuracy is not strictly optimized to a particular set of validation data.
</p>
<p>For further details, see <a href="https://iro.uiowa.edu/esploro/outputs/doctoral/A-new-class-of-information-criteria/9984097169902771?institution=01IOWA_INST"><em>A new class of information criteria for improved prediction in the presence of training/validation data heterogeneity</em></a>.
</p>


<h3>Value</h3>

<p>If <code>group_sizes = NULL</code> or <code>bootstraps &gt; 0</code>, a scalar is returned. Otherwise, <code>newdata</code> is
returned with an appended column labeled 'PIC' containing either iPIC or gPIC values,
depending on the value provided to <code>group_sizes</code>.
</p>


<h3>References</h3>

<p>Flores, J.E. (2021), <em>A new class of information criteria for improved prediction in the presence of training/validation data heterogeneity</em> [Unpublished PhD dissertation]. University of Iowa.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PIC">PIC</a></code>, <code><a href="#topic+PIC.mlm">PIC.mlm</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

# Fit a regression model
mod &lt;- lm(Sepal.Length ~ ., data = iris)
class(mod)

# Hypothetical validation data
set.seed(1)
vdat &lt;- iris[sample(1:nrow(iris), 10),]

# tPIC, newdata not supplied
PIC(object = mod)
AIC(mod) # equivalent to PIC since training and validation data are the same above

# tPIC, newdata supplied
PIC(object = mod, newdata = vdat)
AIC(mod) # not equivalent to PIC since training and validation data differ above

# gPIC
PIC(object = mod, newdata = vdat, group_sizes = c(5,3,2))
PIC(object = mod, newdata = vdat, group_sizes = 5)

# iPIC
PIC(object = mod, newdata = vdat, group_sizes = rep(1, 10))
PIC(object = mod, newdata = vdat, group_sizes = 1)

# bootstrapped tPIC (based on 10 bootstrap samples)
set.seed(1)
PIC(object = mod, bootstraps = 10)

</code></pre>

<hr>
<h2 id='PIC.mlm'>PIC method for Multivariable Linear Models</h2><span id='topic+PIC.mlm'></span>

<h3>Description</h3>

<p>Computation of predictive information criteria for multivariable linear models. Currently, computations are
supported for only bivariable linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlm'
PIC(object, newdata, group_sizes = NULL, bootstraps = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PIC.mlm_+3A_object">object</code></td>
<td>
<p>A fitted model object of <code><a href="base.html#topic+class">class</a></code> &quot;mlm&quot;.</p>
</td></tr>
<tr><td><code id="PIC.mlm_+3A_newdata">newdata</code></td>
<td>
<p>An optional dataframe to be used as validation data in computing PIC. If omitted, the training data contained within <code>object</code> are used. If specified, <strong><code>newdata</code></strong> must contain columns for each model response. See 'Details'.</p>
</td></tr>
<tr><td><code id="PIC.mlm_+3A_group_sizes">group_sizes</code></td>
<td>
<p>An optional scalar or numeric vector indicating the sizes of <code>newdata</code> partitions. If omitted, <code>newdata</code> is not partitioned. See 'Details'.</p>
</td></tr>
<tr><td><code id="PIC.mlm_+3A_bootstraps">bootstraps</code></td>
<td>
<p>An optional numeric value indicating the number of bootstrap samples to use for a bootstrapped PIC. See 'Details'.</p>
</td></tr>
<tr><td><code id="PIC.mlm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PIC.mlm</code> computes PIC values based on the supplied multivariable regression model. Candidate models with relatively smaller criterion values are preferred.
Depending on the value(s) supplied to <strong><code>group_sizes</code></strong>, one of three implementations of PIC are computed:
</p>

<ul>
<li> <p><strong>iPIC</strong>: The individualized predictive information criterion (iPIC) is computed when <strong><code>group_sizes = 1</code></strong>. A value
of iPIC is determined for each <em>individual</em> observation in <strong><code>newdata</code></strong>. Using iPIC, one may thus select optimal predictive
models specific to each particular validation datapoint.
</p>
</li>
<li> <p><strong>gPIC</strong>: The group predictive information criterion (gPIC) is computed when <strong><code>group_sizes &gt; 1</code></strong> or
<strong><code>is.vector(group_sizes) == TRUE</code></strong>. A value of gPIC is determined for each cohort or <em>group</em> of observations
defined by the partitions of <strong><code>newdata</code></strong>. Using gPIC, one may thus select optimal predictive models specific to each
group of validation datapoints. For the class of regression models, the gPIC value of a group of validation observations
is equivalent to the sum of their individual iPIC values.
</p>
</li>
<li> <p><strong>tPIC</strong>: The total predictive information criterion (tPIC) is computed when <strong><code>group_sizes = NULL</code></strong>. Computation of
the tPIC is the default, and one may use the tPIC to select the optimal predictive model for the entire set of validation
datapoints. The tPIC and gPIC are equivalent when <strong><code>group_sizes = m</code></strong>, where <code>m</code> is the number of observations in
<strong><code>newdata</code></strong>. When <strong><code>newdata</code></strong> is not supplied, tPIC is exactly equivalent to the Akaike Information Criterion (<a href="stats.html#topic+AIC">AIC</a>).
</p>
</li></ul>

<p>Distinct from the computation for the class of &quot;lm&quot; models (<a href="#topic+PIC.lm">PIC.lm</a>), the PIC computation for multivariable regression models differs
depending on the whether validation data are partially or completely unobserved. If partially unobserved, where only some values of the multivariable response vector
are unknown/unobserved, any remaining observed values are used in the PIC computation.
</p>
<p>If a numeric value is supplied to <strong><code>bootstraps</code></strong> the total Predictive information criterion (tPIC) is computed <strong><code>bootstraps</code></strong> times, where
generated bootstrap samples are each used as sets of validation data in computing the tPIC. It is assumed that the multivariable response vectors are each
completely unobserved. The resulting tPIC values are then averaged to generate a single,
bootstrapped tPIC value. Model selection based on this bootstrapped tPIC value may lead to the selection of a more generally applicable predictive model whose
predictive accuracy is not strictly optimized to a particular set of validation data.
</p>
<p>For further details, see <a href="https://iro.uiowa.edu/esploro/outputs/doctoral/A-new-class-of-information-criteria/9984097169902771?institution=01IOWA_INST"><em>A new class of information criteria for improved prediction in the presence of training/validation data heterogeneity</em></a>.
</p>


<h3>Value</h3>

<p>If <code>group_sizes = NULL</code> or <code>bootstraps &gt; 0</code>, a scalar is returned. Otherwise, <code>newdata</code> is
returned with an appended column labeled 'PIC' containing either iPIC or gPIC values,
depending on the value provided to <code>group_sizes</code>.
</p>


<h3>References</h3>

<p>Flores, J.E. (2021), <em>A new class of information criteria for improved prediction in the presence of training/validation data heterogeneity</em> [Unpublished PhD dissertation]. University of Iowa.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PIC">PIC</a></code>, <code><a href="#topic+PIC.lm">PIC.lm</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(dplyr, quietly = TRUE)
data(iris)

# Fit a bivariable regression model
mod &lt;- lm(cbind(Sepal.Length, Sepal.Width) ~ ., data = iris)
class(mod)

# Hypothetical validation data
set.seed(1)
vdat &lt;- iris[sample(1:nrow(iris), 10),]

# tPIC, completely unobserved response data
PIC(object = mod, newdata = vdat %&gt;% dplyr::mutate(Sepal.Length = NA, Sepal.Width = NA))

# tPIC, partially unobserved response data
PIC(object = mod, newdata = vdat %&gt;% dplyr::mutate(Sepal.Length = NA))

# tPIC, mix of completely and partially unobserved cases.
PIC(object = mod, newdata = vdat %&gt;%
dplyr::mutate(Sepal.Length = ifelse(Sepal.Length &lt; 6, NA, Sepal.Length),
Sepal.Width = ifelse(Sepal.Width &lt; 3.3, NA, Sepal.Width)))

# tPIC, newdata not supplied
PIC(object = mod)

# gPIC
PIC(object = mod, newdata = vdat, group_sizes = c(5,3,2))
PIC(object = mod, newdata = vdat, group_sizes = 5)

# iPIC
PIC(object = mod, newdata = vdat, group_sizes = rep(1, 10))
PIC(object = mod, newdata = vdat, group_sizes = 1)

# bootstrapped tPIC (based on 10 bootstrap samples)
set.seed(1)
PIC(object = mod, bootstraps = 10)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
