<!DOCTYPE html><html><head><title>Help for package repfdr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {repfdr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#binned_zmat'>
<p>Three GWAS studies - input objects to main function</p></a></li>
<li><a href='#binned_zmat_sim'>
<p>Simulated data set - input objects to main function</p></a></li>
<li><a href='#em.control'>
<p>Control Parameters for the EM algorithm</p></a></li>
<li><a href='#hconfigs'>
<p>Enumeration of all possible vectors of association status.</p></a></li>
<li><a href='#hmat_sim'>
<p>Simulated data set - indicators of association status matrix</p></a></li>
<li><a href='#ldr'>
<p>Estimation of posterior probabilities for the vectors of association status</p></a></li>
<li><a href='#piem'>
<p>Estimation of the prior probabilities for each association status vector.</p></a></li>
<li><a href='#repfdr'>
<p>Bayes and local Bayes false discovery rate  estimation for replicability analysis</p></a></li>
<li><a href='#SNPlocations'>
<p>Three GWAS studies SNPs locations and data</p></a></li>
<li><a href='#twosided.PValues.tobins'>
<p>Binning of two sided P-Values and estimation of the probabilities in each bin for the null and non-null states.</p></a></li>
<li><a href='#zmat_sim'>
<p>Simulated data set</p></a></li>
<li><a href='#ztobins'>
<p>Binning of z-scores and estimation of the probabilities in each bin for the null and non-null states.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Replicability Analysis for Multiple Studies of High Dimension</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimation of Bayes and local Bayes false discovery rates for
      replicability analysis (Heller &amp; Yekutieli, 2014 &lt;<a href="https://doi.org/10.1214%2F13-AOAS697">doi:10.1214/13-AOAS697</a>&gt; ;
      Heller at al., 2015 &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtu434">doi:10.1093/bioinformatics/btu434</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>splines,Rcpp (&ge; 0.12.6)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/barakbri/repfdr">https://github.com/barakbri/repfdr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/barakbri/repfdr/issues">https://github.com/barakbri/repfdr/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-09-27 16:17:06 UTC; barak</td>
</tr>
<tr>
<td>Author:</td>
<td>Ruth Heller [cre, aut],
  Shachar Kaufman [aut],
  Shay Yaacoby [aut],
  David Israeli [aut],
  Barak Brill [aut],
  Daniel Yekutieli [aut],
  Stephen Turner [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ruth Heller &lt;ruheller@gmail.com&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-09-28 10:52:07 UTC</td>
</tr>
<tr>
<td>Suggests:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
</table>
<hr>
<h2 id='binned_zmat'>
Three GWAS studies - input objects to main function 
</h2><span id='topic+binned_zmat'></span><span id='topic+bz'></span><span id='topic+pbz'></span>

<h3>Description</h3>

<p>This data was created from the <code>zmat</code> matrix (see <code><a href="#topic+SNPlocations">SNPlocations</a></code>)  using <code><a href="#topic+ztobins">ztobins</a></code> function. It contain two objects to be input to the main function <code>repfdr</code>.
</p>


<h3>Format</h3>

<p>The file includes two objects - a matrix and 3d array:
</p>
<p><code>bz</code> is a matrix of binned 249024 z-scores (in rows) in each of the 3 studies (columns).
</p>
<p><code>pbz</code> is a 3-dimensional array which contains for each study (first dimension), the probabilities of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/binned_zmat.RData',
  destfile = "binned_zmat.RData")
load(file = "binned_zmat.RData")

bz[1:5,]
pbz[,1:5,]

## End(Not run)
</code></pre>

<hr>
<h2 id='binned_zmat_sim'>
Simulated data set - input objects to main function
</h2><span id='topic+binned_zmat_sim'></span><span id='topic+bz_sim'></span><span id='topic+pbz_sim'></span>

<h3>Description</h3>

<p>This data was created from the <code><a href="#topic+zmat_sim">zmat_sim</a></code> matrix  using <code><a href="#topic+ztobins">ztobins</a></code> function. It contain two objects to be input to the main function <code>repfdr</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(binned_zmat_sim)</code></pre>


<h3>Format</h3>

<p>The file includes two objects - a matrix and 3d array:
</p>
<p><code>bz_sim</code> is a matrix of binned 10000 z-scores (in rows) in each of the 3 studies (columns).
</p>
<p><code>pbz_sim</code> is a 3-dimensional array which contains for each study (first dimension), the probabilities of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binned_zmat_sim)
bz_sim[1:5,]
pbz_sim[,1:5,]
</code></pre>

<hr>
<h2 id='em.control'>
Control Parameters for the EM algorithm
</h2><span id='topic+em.control'></span>

<h3>Description</h3>

<p>Input parameters for the EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>em.control(pi.initial = NULL, max.iter = 10000, tol = 1e-12,
           nr.threads = 0, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="em.control_+3A_pi.initial">pi.initial</code></td>
<td>

<p>Initial guess for the probabilities of the vectors of associations status. If <code>NULL</code> then 0.9 is assigned for the <code>c(0,...,0)</code> configuration and 0.1 is distributed uniformly for all other configurations.
</p>
</td></tr>
<tr><td><code id="em.control_+3A_max.iter">max.iter</code></td>
<td>

<p>Maximum number of EM iterations.
</p>
</td></tr>
<tr><td><code id="em.control_+3A_tol">tol</code></td>
<td>

<p>Tolerance (in maximum absolute difference between two EM iterations in estimated probabilities) before declaring convergence and stopping.
</p>
</td></tr>
<tr><td><code id="em.control_+3A_nr.threads">nr.threads</code></td>
<td>

<p>Number of processing threads to use. If zero (the default), will automatically detect the number of compute cores available and spawn one thread per core.
</p>
</td></tr>
<tr><td><code id="em.control_+3A_verbose">verbose</code></td>
<td>

<p>An indicator of whether to report progress (running iteration number) during computation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is used inside the <code>control</code> argument in <code><a href="#topic+repfdr">repfdr</a></code> and <code><a href="#topic+piem">piem</a></code>.
</p>


<h3>Value</h3>

<p>A list with the input values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+repfdr">repfdr</a></code> <code><a href="#topic+piem">piem</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/binned_zmat.RData',
  destfile = "binned_zmat.RData")
load(file = "binned_zmat.RData")
out &lt;- repfdr(pbz,bz,"replication",
              control = em.control(pi.initial = c(0.48,rep(0.02,26)),
              verbose = TRUE, nr.threads = 1))
# iterations are printed; run bit slower (1 thread)

## End(Not run)
</code></pre>

<hr>
<h2 id='hconfigs'>
Enumeration of all possible vectors of association status.
</h2><span id='topic+hconfigs'></span>

<h3>Description</h3>

<p>The function generates a matrix with all possible vectors of association status (in rows), given the number of studies and number of possible association status states in each study (2 or 3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hconfigs(n.studies, n.association.status = 3, studies.names = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hconfigs_+3A_n.studies">n.studies</code></td>
<td>
<p>Number of studies in the analysis.
</p>
</td></tr>
<tr><td><code id="hconfigs_+3A_n.association.status">n.association.status</code></td>
<td>
<p>either 2 for no-association\association or 3 for no-association\negative-association\positive-association.
</p>
</td></tr>
<tr><td><code id="hconfigs_+3A_studies.names">studies.names</code></td>
<td>

<p>Optional study names to display.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This  matrix should be used when selecting the rows indices for the association status vectors that are in the non-null set, specified by the used in <code>non.null.rows</code> in the function <code><a href="#topic+repfdr">repfdr</a></code>.
</p>


<h3>Value</h3>

<p>Matrix with rows indicating all the possible vectors of association status.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+repfdr">repfdr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
(H &lt;- hconfigs(n.studies = 3))
# in replication analysis the non-null vectors are:
H[apply(H,1,function(y){ sum(y==1)&gt;1 | sum(y==-1)&gt;1 }),]
# in meta-analysis there is only one null vector (c(0,0,0)):
H[rowSums(abs(H))!=0,]

hconfigs(n.studies = 3, n.association.status= 2)
</code></pre>

<hr>
<h2 id='hmat_sim'>
Simulated data set - indicators of association status matrix 
</h2><span id='topic+hmat_sim'></span>

<h3>Description</h3>

<p>A matrix of size 10000x3 of indicators of whether each z-score from <code><a href="#topic+zmat_sim">zmat_sim</a></code> belongs to a non-null hypothesis for the feature in the study (1) or to a null hypothesis for the feature in the study (0).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hmat_sim)</code></pre>


<h3>Format</h3>

<p><code>hmat_sim</code> is a matrix of 10000 rows, each row a vector of the true association status from which the z-scores in the same row in <code>zmat_sim</code> was generated. Specifically, for a zero entry in hmat_sim the corresponding z-score in <code>zmat_sim</code> was generated from the standard normal distribution, and for a unit entry in hmat_sim the corresponding z-score in <code>zmat_sim</code> was generated from the normal distribution with mean 3 and variance one.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### use hmat_sim to generate the simulated z-scores:

data(hmat_sim)
m &lt;- nrow(hmat_sim)
set.seed(12)
zmat_sim1  &lt;- matrix(rnorm(n=3*m,mean=hmat_sim*3),nrow=m,ncol=3)
rm(m,H)

data(zmat_sim)
stopifnot(all.equal(zmat_sim1,zmat_sim))

#### hmat_sim was generated by the following code:

H &lt;- hconfigs(n.studies= 3, n.association.status=2)
f &lt;- c(0.895,0.005,0.005,0.02,0.005,0.02,0.02,0.03) # frequencies for the association status vectors
m = 10000 # number of tests in each study
hmat_sim1 &lt;- matrix(rep(x = H, times = m*cbind(f,f,f)),ncol=3) 

data(hmat_sim)
stopifnot(all.equal(hmat_sim1,hmat_sim))

# the simulation design
cbind(H,f)  
sum(f)      # all sum to 1?
</code></pre>

<hr>
<h2 id='ldr'>
Estimation of posterior probabilities for the vectors of association status
</h2><span id='topic+ldr'></span>

<h3>Description</h3>

<p>The function finds the posterior probabilities ofeach vector of association status for each feature, given the feature's vector of binned z-scores.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldr(pdf.binned.z, binned.z.mat, Pi, h.vecs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldr_+3A_pdf.binned.z">pdf.binned.z</code></td>
<td>
<p>Same input as in <code><a href="#topic+repfdr">repfdr</a></code>.
A 3-dimensional array which contains for each study (first dimension), the probability of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension). The third dimension can be of size 2 or 3, depending on the number of association states: if the association can be either null or only in one direction, the dimension is 2; if the association can be either null, or positive, or negative, the dimension is 3.  
Element <code>[[1]]</code> in the output of <code><a href="#topic+ztobins">ztobins</a></code>.
</p>
</td></tr>
<tr><td><code id="ldr_+3A_binned.z.mat">binned.z.mat</code></td>
<td>

<p>Same input as in <code><a href="#topic+repfdr">repfdr</a></code>.
A matrix of the bin numbers for each of the z-scores (rows) in each study (columns).
Element <code>[[2]]</code> in the output of <code><a href="#topic+ztobins">ztobins</a></code>.
</p>
</td></tr>
<tr><td><code id="ldr_+3A_pi">Pi</code></td>
<td>

<p>The estimated prior probabilities for each association status vector. Can be extracted from the output of   <code><a href="#topic+repfdr">repfdr</a></code> or <code><a href="#topic+piem">piem</a></code>, see Example section. 
</p>
</td></tr>
<tr><td><code id="ldr_+3A_h.vecs">h.vecs</code></td>
<td>

<p>The row indices in <code>H</code> (see <code><a href="#topic+hconfigs">hconfigs</a></code>), corresponding to the association status vectors. By default the posterior probabilities of all possible vectors of association status are computed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A subset of features (e.g most significant) can be specified as the rows in <code>binned.z.mat</code>, so the posterior probabilities of the vectors of association status are computed for this subset of features. See Example section.  
</p>


<h3>Value</h3>

<p>Matrix with rows that contain for each of the vectors of association status  the posterior probabilities. The columns are the different feature.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+repfdr">repfdr</a></code>, <code><a href="#topic+piem">piem</a></code>, <code><a href="#topic+hconfigs">hconfigs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/binned_zmat.RData',
  destfile = "binned_zmat.RData")
load(file = "binned_zmat.RData")
  
data(Pi)

# Fdr calculation:
output3 &lt;- repfdr(pbz, bz, "replication",Pi.previous.result = Pi)

BayesFdr &lt;- output3$mat[,"Fdr"]
sum(BayesFdr &lt;= 0.05)

# The posterior probabilities for the the first five features with Bayes FDR at most 0.05:
post &lt;- ldr(pbz,bz[which(BayesFdr &lt;= 0.05)[1:5],],Pi)
round(post,4)

# posteriors for a subset of the association status vectors can also be reported,
# here the subset is the four first association status vectors:
post &lt;- ldr(pbz,bz[which(BayesFdr &lt;= 0.05)[1:5],],Pi,h.vecs= 1:4)
round(post,4)

## End(Not run)
</code></pre>

<hr>
<h2 id='piem'>
Estimation of the prior probabilities for each association status vector.
</h2><span id='topic+piem'></span><span id='topic+Pi'></span>

<h3>Description</h3>

<p>The function calls an expectation-maximization (EM) algorithm to estimate the prior probabilities of each association status vector. It is also used internally in <code><a href="#topic+repfdr">repfdr</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>piem(pdf.binned.z, binned.z.mat, control = em.control())</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="piem_+3A_pdf.binned.z">pdf.binned.z</code></td>
<td>
<p>Same input as in <code><a href="#topic+repfdr">repfdr</a></code>.
A 3-dimensional array which contains for each study (first dimension), the probabilities of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension). The third dimension can be of size 2 or 3, depending on the number of association states: if the association can be either null or only in one direction, the dimension is 2; if the association can be either null, or positive, or negative, the dimension is 3.  
Element <code>[[1]]</code> in the output of <code><a href="#topic+ztobins">ztobins</a></code>. 
</p>
</td></tr>
<tr><td><code id="piem_+3A_binned.z.mat">binned.z.mat</code></td>
<td>

<p>Same input as in <code><a href="#topic+repfdr">repfdr</a></code>.
A matrix of the bin numbers for each the z-scores (rows) in each study (columns).
Element <code>[[2]]</code> in the output of <code><a href="#topic+ztobins">ztobins</a></code>.
</p>
</td></tr>
<tr><td><code id="piem_+3A_control">control</code></td>
<td>

<p>List of control parameters to pass to the EM algorithm. See <code><a href="#topic+em.control">em.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation of the EM algorithm is in C, and allows paralel processing. By default, the software automatically detects the number of available processing threads. See <code><a href="#topic+em.control">em.control</a></code> for the option of providing the number of threads to use, as well as for the additional control parameters. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>all.iterations</code></td>
<td>
<p>Matrix with number of columns equal to  the number of EM iterations, and each column is the estimated probability distribution of the vector of association status.</p>
</td></tr>
<tr><td><code>last.iteration</code></td>
<td>
<p>Matrix of the vectors of association status along with the column vector of the last EM iteration, which contains the estimated probabilities of the vectors of association status.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p><code>C</code> implementation by Shachar Kaufman.
</p>


<h3>References</h3>

<p>Heller, Ruth, and Daniel Yekutieli. &quot;Replicability analysis for Genome-wide Association studies.&quot; <em>arXiv preprint arXiv:1209.2829</em> (2012).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+repfdr">repfdr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/binned_zmat.RData',
  destfile = "binned_zmat.RData")
load(file = "binned_zmat.RData")
#binned_zmat can also be generated via 
output_piem &lt;- piem(pbz, bz)

# extract the last iteration to use it in repfdr (see help(repfdr)):
Pi1 &lt;- output_piem$last.iteration
data(Pi)
stopifnot(all.equal(Pi,Pi1))

# simulation data:
data(binned_zmat_sim)
output_piem_sim &lt;- piem(pbz_sim, bz_sim)
Pi_sim &lt;- output_piem_sim$last.iteration

# following are the true proportions in the data: (see help(hmat_sim) for data generation details.)
f &lt;- c(0.895,0.005,0.005,0.02,0.005,0.02,0.02,0.03) 

# the estimation vs the true proportions:
cbind(round(Pi_sim,6),f)

## End(Not run)
</code></pre>

<hr>
<h2 id='repfdr'>
Bayes and local Bayes false discovery rate  estimation for replicability analysis
</h2><span id='topic+repfdr'></span><span id='topic+manhattan'></span>

<h3>Description</h3>

<p>Estimate Bayes and local Bayes false discovery rates (FDRs) from multiple studies, for replicability analysis and for meta-analysis, as presented in Heller and Yekutieli (see reference below). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repfdr(pdf.binned.z, binned.z.mat,
       non.null = c("replication", "meta-analysis",
       "user.defined"),
       non.null.rows = NULL,Pi.previous.result = NULL,
       control = em.control(), clusters = NULL, 
       clusters.ldr.report=NULL, clusters.verbose=T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repfdr_+3A_pdf.binned.z">pdf.binned.z</code></td>
<td>

<p>A 3-dimensional array which contains for each study (first dimension), the probabilities of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension). The third dimension can be of size 2 or 3, depending on the number of association states: if the association can be either null or non-null (e.g. only in one direction), the dimension is 2; if the association can be either null, or positive, or negative, the dimension is 3.  
Element <code>[[1]]</code> in the output of <code><a href="#topic+ztobins">ztobins</a></code>. 
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_binned.z.mat">binned.z.mat</code></td>
<td>

<p>A matrix of the bin numbers for each of the z-scores (rows) in each study (columns).
Element <code>[[2]]</code> in the output of <code><a href="#topic+ztobins">ztobins</a></code>.
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_non.null">non.null</code></td>
<td>

<p>Indicates the desired analysis: <code>replication</code>, <code>meta-analysis</code> or <code>user.defined</code>. When <code>user.defined</code> is selected <code>non.null.rows</code> must be specified. 
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_non.null.rows">non.null.rows</code></td>
<td>

<p>Vector of row indices in <code>H</code> (see <code><a href="#topic+hconfigs">hconfigs</a></code>), indicating which vectors of association status should be considered as non-null in the analysis. <code>H</code> is the output of hconfigs(dim(pdf.binned.z)[1], dim(pdf.binned.z)[3]), i.e. the matrix with rows indicating the possible vectors of association status, where <code>dim(pdf.binned.z)[1]</code> is the number of studies and <code>dim(pdf.binned.z)[3]</code> is the number of association states in each study (2 or 3). 
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_pi.previous.result">Pi.previous.result</code></td>
<td>

<p>An optional Vector of probabilities for each association status. If <code>NULL</code>, then the probabilities are estimated with the EM algorithm. An estimation result from a previous run of <code><a href="#topic+repfdr">repfdr</a></code> or <code><a href="#topic+piem">piem</a></code> can be supplied to shorten the run-time of the function, see Example section. 
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_control">control</code></td>
<td>

<p>List of control parameters to pass to the EM algorithm. See <code><a href="#topic+em.control">em.control</a></code>.
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_clusters">clusters</code></td>
<td>
<p> Used for performing analysis in each cluster, and than aggregating results together.Default value is <code>NULL</code> (no clusters in data). To use clusters, argument must be vector of integer, filled with number from 1 to wanted number of clusters. Vector is of length of number of studies, where <code>clusters[i]</code> is the cluster membership of the ith study.
NULL
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_clusters.ldr.report">clusters.ldr.report</code></td>
<td>

<p>Sets whether local fdr values (available through the function <code>ldr</code> for non clustered data) should be displayed with the output. Default value is <code>NULL</code> (no ldr values reported). Other options are <code>'ALL'</code> (all ldr valeus are reported) or a vector of integers for the indices of the SNPs to be reported)
</p>
</td></tr>
<tr><td><code id="repfdr_+3A_clusters.verbose">clusters.verbose</code></td>
<td>

<p>if set to <code>TRUE</code>, messages will be printed to screen regarding the state of the calculation (which cluster is currently being processes, and aggregation procecdure by SNP). Default is <code>FALSE</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>N</code> studies, each examining the same <code>M</code> features, the binned z-scores and the (estimated) probabilities under the null and non-null states in each study are given as input. 
These inputs can be produced from the z-scores using the function <code><a href="#topic+ztobins">ztobins</a></code>.
</p>
<p>The function calls <code><a href="#topic+piem">piem</a></code>  for the computation of the probabilities for each vector of association status. The number of probabilies estimated is  <code>x^N</code>, where <code>x=2,3</code> is the number of possible association states in each study.    
</p>
<p>The function calls <code><a href="#topic+ldr">ldr</a></code> for the computation of the conditional probability of each of the vectors of association status in the null set given the binned z-scores. The null set contains the rows in <code><a href="#topic+hconfigs">hconfigs</a>(N,x)</code> that:  are excluded from <code>non.null.rows</code> if <code>non.null</code> is <code>user.defined</code>;  that are non-zero if <code>non.null</code> is <code>meta-analysis</code>; that contain at most one 1 if <code>non.null</code> is <code>replication</code> and <code>x=2</code>; that contain at most one 1 or one -1 if <code>non.null</code> is <code>replication</code> and <code>x=3</code>. 
</p>
<p>The local Bayes FDR is estimated to be the sum of conditional probabilities in the null set for each feature. The empirical Bayes FDR is the average of all local Bayes FDRs that are at most the value of the local Bayes FDR for each feature. The list of discoveries at level q are all features with empirical Bayes FDR at most q.
</p>
<p>If many studies are available, one may not be able to compute RepFDR directly at the original data. If however, different groups of studies are known to be independent (e.g., if  a SNP is non null for studies 1,2 is independent of the SNP being non null in studies 3,4) one may Run RepFDR in each cluster seperatly and then aggregate the results. This is done by providing a vector for the <code>clusters</code> argument, with an integer value stating the cluster membership for each study.
See the values section below for the results returned from this function, when partitioning the data to clusters.
See vignette('RepFDR') for a complete example, on how to run RepFDR in clusters.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mat</code></td>
<td>
<p>An <code>Mx2</code> Matrix with a row for each feature (<code>M</code> rows) and two columns, the estimated local Bayes FDR (fdr) and the estimated Bayes FDR (Fdr).</p>
</td></tr>
<tr><td><code>Pi</code></td>
<td>
<p>Vector of the estimated probabilities for each of the <code>x^N</code> possible vectors of association status. If <code>clusters</code> is not <code>NULL</code>, A matrix with number of rows being <code>choose(2+nr_studies,2)</code> (for <code>n.association</code> being 3) or <code>choose(1+nr_studies,1)</code> (for <code>n.association</code> being 3). The last column represents an aggregated probability over all combintaions for row.</p>
</td></tr>
<tr><td><code>repfdr.mat.percluster</code></td>
<td>

<p>Returned if <code>clusters</code> is not <code>NULL</code>. A list of the <code>mat</code> values returned from the RepFDR analysis, per cluster.
</p>
</td></tr>
<tr><td><code>repfdr.Pi.percluster</code></td>
<td>

<p>Returned if <code>clusters</code> is not <code>NULL</code>. A list of the <code>Pi</code> values returned from the RepFDR analysis, per cluster.
</p>
</td></tr>
<tr><td><code>ldr</code></td>
<td>

<p>Returned if <code>clusters.ldr.report</code> is not <code>NULL</code>. A matrix with number of rows being <code>choose(2+nr_studies,2)</code> (for <code>n.association</code> being 3) or <code>choose(1+nr_studies,1)</code> (for <code>n.association</code> being 3). Each row holds the local fdr values for a combination of non null values, for the reported SNPs. The first three columns count the number of studies for each reported state (number of null studies, number of non null studies). Other values in the row give the local fdr value, per reported SNP, for the specificed system of hypotheses.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ruth Heller, Shachar Kaufman, Shay Yaacoby, Barak Brill, Daniel Yekutieli.
</p>


<h3>References</h3>

<p>Heller, R., &amp; Yekutieli, D. (2014). Replicability analysis for genome-wide association studies. <em>The Annals of Applied Statistics</em>, 8(1), 481-498.
</p>
<p>Heller, R., Yaacoby, S., &amp; Yekutieli, D. (2014). repfdr: a tool for replicability analysis for genome-wide association studies. <em>Bioinformatics</em>, btu434.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Example 1: a simulation; each feature in each study has two association states,
####            null and positive, prior is known
#This example generates the Z scores for two studies, with 0.05 probability to have
# non - null signal in each study.
# The prior matrix is being pregenerated to show the optimal values.
# if this matrix was not supplied, the repfdr method would estimate it
# using an EM algorithm. See the next examples for estimating the prior as well using repfdr.

set.seed(1)
n = 2 #two studies
m=10000 # ten thounsand, SNPs
H_Study_1 = rbinom(m,1,prob = 0.05) #signal of 1, for SNPS with association in the first study
H_Study_2 = rbinom(m,1,prob = 0.05) #signal of 1, for SNPS with association in the second study
Zmat = matrix(rnorm(n*m),nrow = m) #generate matrix

#insert signal (mean shift of 3) for the first study
Zmat[which(H_Study_1==1),1] = Zmat[which(H_Study_1==1),1]  + 4 

#insert signal to the second study
Zmat[which(H_Study_2==1),2] = Zmat[which(H_Study_2==1),2]  + 4 

#estimate densities via ztobins:
ztobins_res = ztobins(Zmat,n.association.status = 2,plot.diagnostics = FALSE,n.bin= 100) 

#writing out the prior explicitly. If this was not supplied, 
#the repfdr would try to estimate this prior from the data.
Precomputed_Pi = matrix(NA,ncol = 3,nrow = 4)
Precomputed_Pi[,1] = c(0,1,0,1)
Precomputed_Pi[,2] = c(0,0,1,1)
Precomputed_Pi[,3] = c(0.95^2,0.95*0.05,0.95*0.05,0.05^2)
colnames(Precomputed_Pi) = c('Study 1','Study 2','Pi')

#run repfdr
repfdr_res = repfdr(ztobins_res$pdf.binned.z,
                    ztobins_res$binned.z.mat,
                    non.null = 'replication',
                    Pi.previous.result = Precomputed_Pi)

#The precomputed prior matrix. if this would not 
repfdr_res$Pi

#local fdr0 and Fdr for each SNP
head(repfdr_res$mat)

Non_Null = which(H_Study_1 ==1 &amp; H_Study_2 == 1)
Reported = which(repfdr_res$mat[,2] &lt;= 0.05)
TP = length(intersect(Reported,  Non_Null))
TP
FP = length(Reported) - TP
FP
FN = length(Non_Null - TP)
FN


#### Example 2: a simulation; each feature in each study has two association states,
####            null and positive, prior is estimated
## Not run: 
# a) Replicablity analysis:
data(binned_zmat_sim) # this loads the binned z-scores as well as the (estimated) probabilities
# in each bin for each state 
output.rep &lt;- repfdr(pbz_sim, bz_sim, "replication")
BayesFdr.rep &lt;- output.rep$mat[,"Fdr"]
Rej &lt;- (BayesFdr.rep &lt;= 0.05)
sum(Rej)

# which of the tests are true replicability findings? (we know this since the data was simulated)
data(hmat_sim)
true.rep   &lt;- apply(hmat_sim,1,function(y){ sum(y==1)&gt;1 })


# Compute the false discovery proportion (FDP) for replicability:
sum(Rej * !true.rep) / sum(true.rep)

# we can use the previously calculated Pi for further computations (e.g meta-analysis):
Pi_sim &lt;- output.rep$Pi

# b) meta-analysis:
output.meta &lt;- repfdr(pbz_sim, bz_sim, "meta-analysis", Pi.previous.result = Pi_sim)

BayesFdr.meta &lt;- output.meta$mat[,"Fdr"]
Rej &lt;- (BayesFdr.meta &lt;= 0.05)
sum(Rej)

# which of the tests are true association findings? (we know this since the data was simulated)
true.assoc &lt;- rowSums(hmat_sim) &gt;= 1

# Compute the false discovery proportion (FDP) for association:
sum(Rej * !true.assoc) / sum(true.assoc) 


## End(Not run)

## Not run: 
#### Example 3: SNPs data; each SNP in each study has three association states,
####            negative, null, or positive: 

# load the bins of the z-scores and their probabilities.
download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/binned_zmat.RData',
  destfile = "binned_zmat.RData")
load(file = "binned_zmat.RData")
# can also be generated from SNPlocation - see ztobins documentation.

# load the prior probabilities for each association status vector.
data(Pi)
Pi # the proportions vector was computed using piem()
   # with the following command: Pi &lt;- piem(pbz, bz)$last.iteration

# a) replicablity analysis:
output.rep &lt;- repfdr(pbz, bz, "replication",Pi.previous.result=Pi)
BayesFdr.rep &lt;- output.rep$mat[,"Fdr"]
Rej &lt;- sum(BayesFdr.rep &lt;= 0.05)
sum(Rej)

# The posterior probabilities for the first five features with Bayes FDR at most 0.05:
post &lt;- ldr(pbz,bz[order(BayesFdr.rep)[1:5],],Pi)
round(post,4)

# posteriors for a subset of the association status vectors can also be reported:
H &lt;- hconfigs( dim(bz)[2], 3)
h.replicability = apply(H, 1, function(y) {sum(y == 1)&gt; 1 | sum(y == -1) &gt;1})
post &lt;- ldr(pbz,bz[order(BayesFdr.rep)[1:5],],Pi,h.vecs= which(h.replicability==1))
round(post,4)

# b) meta-analysis:
output.meta &lt;- repfdr(pbz, bz, "meta-analysis", Pi.previous.result = Pi) 
BayesFdr.meta &lt;- output.meta$mat[,"Fdr"]
Rej &lt;- sum(BayesFdr.meta &lt;= 0.05)
sum(Rej)

## End(Not run)

## manhattan plot (ploting can take a while):
# code for manhattan plot by Stephen Turner (see copyrights at the source code manhattan.r)

## Not run:  
  data(SNPlocations)
  par(mfrow=c(2,1))
  # Replication 
  manhattan(dataframe=cbind(SNPlocations,P=BayesFdr.rep),ymax=10.5,pch=20,
            limitchromosomes=1:4,suggestiveline=-log(0.05,10),genomewideline=F,cex=0.25,
            annotate=SNPlocations$SNP[BayesFdr.rep&lt;=0.05],main="Replication")
  # Association
  manhattan(dataframe=cbind(SNPlocations,P=BayesFdr.meta),ymax=10.5,cex=0.25,
            limitchromosomes=1:4,suggestiveline=-log(0.05,10),genomewideline=F,pch=20,
            annotate=SNPlocations$SNP[BayesFdr.rep&lt;=0.05],main="Meta-analysis")
  par(mfrow=c(1,1))

## End(Not run)
</code></pre>

<hr>
<h2 id='SNPlocations'>
Three GWAS studies SNPs locations and data
</h2><span id='topic+SNPlocations'></span>

<h3>Description</h3>

<p><code>SNPlocations</code> includes the locations of SNPs in chromosomes 1 to 4.
Data was simulated to the SNPs with HAPGEN2 for three studies and a sample of it was taken (Chromosomes 1 to 4) for the examples. The data is summarized as z-scores(transformed p-values, with inverse standard normal cumulative distribution).
The z-scores matrix can be download from the web (see example).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SNPlocations)</code></pre>


<h3>Format</h3>

<p><code>SNPlocations</code> data.frame of 249024 SNPs' names, chromosome number and location on the chromosomes.
<code>zmat</code> Matrix of 249024 SNPs' z-scores (in rows) in each of the 3 studies (columns).
</p>


<h3>Source</h3>

<p>See:
Su, Zhan, Jonathan Marchini, and Peter Donnelly. &quot;HAPGEN2: simulation of multiple disease SNPs.&quot; Bioinformatics 27.16 (2011): 2304-2305.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SNPlocations)
head(SNPlocations)

## Not run: 
download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/zmat.RData',destfile = "zmat.RData")
load(file = "zmat.RData")

input.to.repfdr &lt;- ztobins(zmat, 3, df= 15)
pbz &lt;- input.to.repfdr$pdf.binned.z
bz  &lt;- input.to.repfdr$binned.z.mat

## End(Not run)
</code></pre>

<hr>
<h2 id='twosided.PValues.tobins'>
Binning of two sided P-Values and estimation of the probabilities in each bin for the null and non-null states.
</h2><span id='topic+twosided.PValues.tobins'></span>

<h3>Description</h3>

<p>For each study, the function discretizes two sided P-values into bins and estimates the probabilities in each bin for the null and non-null states.
</p>
<p>The function can plot diagnostic plots (disabled by default) for model fit. These should be monitored for misfit of model to data, before using function output in <code>repfdr</code>. See description of diagnostic plots below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twosided.PValues.tobins(pval.mat, n.bins = 120, type = 0, df = 7,
                                   central.prop = 0.5,
                                   pi0=NULL,plot.diagnostics = FALSE,
                                   trim.z=FALSE,trim.z.upper = 8,
                                   trim.z.lower = -8, force.bin.number = FALSE,
                                   pi.plugin.lambda = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twosided.PValues.tobins_+3A_pval.mat">pval.mat</code></td>
<td>

<p>Matrix of two sided P-Values of the features (in rows) in each study (columns).
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_n.bins">n.bins</code></td>
<td>

<p>Number of bins in the discretization of the z-score axis (the number of bins is <code>n.bins - 1</code>). If the number of z-scores per study is small, we set <code>n.bins</code> to a number lower than the default of 120 (about equals to the square root of the number of z-scores). To override the bin number cap (and create a discretization of the data that is sparse), use the <code>force.bin.number = TRUE</code> argument.
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_type">type</code></td>
<td>

<p>Type of fitting used for f; 0 is a natural spline, 1 is a polynomial, in either case with degrees of freedom <code>df</code> (so total degrees of freedom including the intercept is <code>df+1</code>).
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_df">df</code></td>
<td>

<p>Degrees of freedom for fitting the estimated density f(z).
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_central.prop">central.prop</code></td>
<td>

<p>Central proportion of the z-scores used like the area of zero-assumption to estimate pi0.
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_pi0">pi0</code></td>
<td>

<p>Sets argument for estimation of proportion of null hypotheses. Default value is NULL (automatic estimation of pi0) for every study. Second option is to supply vector of values between 0 and 1 (with length of the number of studies/ columns of <code>zmat</code>. These values will be used for pi0.
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_plot.diagnostics">plot.diagnostics</code></td>
<td>

<p>If set to <code>TRUE</code>, will show disgnostics plots for density estimation for each study. First plot is a histogram of counts for each bin (Displayed as white bars), along with fitted density in green. Pink bars represent the observed number of counts in each bins, minus the expected number of null hypotheses by the model (truncated at zero). Red and Orange dashed lines represent the estimated densities for non null distributions fitted by the spline. A blue dashed line represents the density component of Z scores for null SNPS, N(0,1).
</p>
<p>A second plot is the Normal Q-Q plot of Zscores, converted using <code>qnorm</code> to the normal scale. A valid graph should coincide with a the linear fit displayed. A misfit with the linear plot could indicate either a null distribution which is not standard normal (a problem), or an extreme number of non null P-Values (Signal is not sparse, output is still valid). A black dashed line markes the expected fit for the standard normal distribution (with a single black dot for the (0,0) point). If the linear fit for the Q-Q plot (red line) does not match the dashed black line, the null distribution of the data is not standard normal.
</p>
<p>Misfit in these two plots should be investigated by the user, before using output in <code>repfdr</code>
</p>
<p>Default value is <code>False</code>.
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_trim.z">trim.z</code></td>
<td>
<p> If set to <code>TRUE</code>, Z scores above <code>trim.z.upper</code> or below <code>trim.z.lower</code> will be trimmed at their respective limits. Default value if <code>FALSE</code>
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_trim.z.upper">trim.z.upper</code></td>
<td>

<p>Upper bound for trimming Z scores. Default value is 8
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_trim.z.lower">trim.z.lower</code></td>
<td>

<p>Lower bound for trimming Z scores. Default value is -8
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_force.bin.number">force.bin.number</code></td>
<td>
<p>Set to <code>T</code> to be able to create a discretization with <code>n.bins&gt;sqrt(nrow(zmat))</code>.
</p>
</td></tr>
<tr><td><code id="twosided.PValues.tobins_+3A_pi.plugin.lambda">pi.plugin.lambda</code></td>
<td>

<p>The function makes use of the plugin estimator for the estimation of the proportion of null hypotheses. The plugin  estimator is  <code>(sum(Pvalues &gt; pi.plugin.lambda) + 1)/(m * (1-pi.plugin.lambda))</code> where <code>m</code> is the number of P-values. Default value is 0.05. This should be set to the type 1 error used for hypothesis testing.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This utility function outputs the first two arguments to be input in the main function <code><a href="#topic+repfdr">repfdr</a></code>.
</p>


<h3>Value</h3>

<p>A list with:
</p>
<table>
<tr><td><code>pdf.binned.z</code></td>
<td>

<p>A 3-dimensional array which contains for each study (first dimension), the probabilities of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension). The third dimension can be of size 2 or 3, depending on the number of association states: if the association can be either null or only in one direction, the dimension is 2; if the association can be either null, or positive, or negative, the dimension is 3.  
</p>
</td></tr>
<tr><td><code>binned.z.mat</code></td>
<td>

<p>A matrix of the bin numbers for each the z-scores (rows) in each study (columns).
</p>
</td></tr>
<tr><td><code>breaks.matrix</code></td>
<td>

<p>A matrix with <code>n.bins + 1</code> rows and ncol(zmat) columns, representing for each study the discretization chosed. Values are the between bin breaks. First and last values are the edges of the outmost bins.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>Number of degrees of freedom, used for spline fitting of density.
</p>
</td></tr>
<tr><td><code>proportions</code></td>
<td>

<p>Matrix with <code>n.association.status</code> rows, and <code>ncol(zmat)</code> columns, giving the estimated proportion of each component, for each study.
</p>
</td></tr>
<tr><td><code>PlotWarnings</code></td>
<td>

<p>Vector of size <code>ncol{zmat}</code>, keeping the warnings given for each study (available here, in the plots for each study and printed to console). With no warnings given for study, value is <code>NA</code>
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+repfdr">repfdr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# we generate a dataset with p=10000 pvalues for two studies,
# p1=300 of which are non null:
set.seed(1)
p = 10000
p1 = 300
z1 = (rnorm(p))
z2 = (rnorm(p))
temp = rnorm(p1, 3.5,0.5)
z1[1:p1] = temp + rnorm(p1,0,0.2)
z2[1:p1] = temp + rnorm(p1,0,0.2)

zmat.example = cbind(z1,z2)
pmat.example = 1-(pnorm(abs(zmat.example)) - pnorm(-1*abs(zmat.example)))

twosided.pval.res = twosided.PValues.tobins(pmat.example,
                                            plot.diagnostics = TRUE)

twosided.pval.res$proportions

</code></pre>

<hr>
<h2 id='zmat_sim'>
Simulated data set 
</h2><span id='topic+zmat_sim'></span>

<h3>Description</h3>

<p>A simulated data set from three studies, with 10000 &quot;features&quot; in each study, each of which yielded a z-score. The data comprises 10000x3 z-scores.
See <code><a href="#topic+hmat_sim">hmat_sim</a></code> for the indicators of association status matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(zmat_sim)</code></pre>


<h3>Format</h3>

<p><code>zmat_sim</code> is a matrix of 10000 z-scores (in rows) in each of the 3 studies (columns).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(zmat_sim)
head(zmat_sim)

## Not run: 
  input.to.repfdr &lt;- ztobins(zmat_sim, 2 )
  pbz_sim1 &lt;- input.to.repfdr$pdf.binned.z
  bz_sim1  &lt;- input.to.repfdr$binned.z.mat
  
  data(binned_zmat_sim)
  stopifnot(all.equal(pbz_sim1,pbz_sim))
  stopifnot(all.equal(bz_sim1,bz_sim))

## End(Not run)

#### zmat_sim was generated by the following code:
data(hmat_sim)
set.seed(12)
m &lt;- nrow(hmat_sim)
zmat_sim1  &lt;- matrix(rnorm(n=3*m,mean=hmat_sim*3),nrow=m,ncol=3)
data(zmat_sim)
stopifnot(all.equal(zmat_sim1,zmat_sim))
</code></pre>

<hr>
<h2 id='ztobins'>
Binning of z-scores and estimation of the probabilities in each bin for the null and non-null states.
</h2><span id='topic+ztobins'></span>

<h3>Description</h3>

<p>For each study, the function discretizes the z-scores into bins and estimates the probabilities in each bin for the null and non-null states.
</p>
<p>The function can plot diagnostic plots (disabled by default) for model fit. These should be monitored for misfit of model to data, before using function output in <code>repfdr</code>. See description of diagnostic plots below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ztobins(zmat, n.association.status = 3, n.bins = 120, type = 0, df = 7,
                    central.prop = 0.5,
                    pi0=NULL,plot.diagnostics = FALSE,
                    trim.z=FALSE,trim.z.upper = 8,trim.z.lower = -8,
                    force.bin.number = FALSE,
                    pi.using.plugin = FALSE, pi.plugin.lambda = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ztobins_+3A_zmat">zmat</code></td>
<td>

<p>Matrix of z-scores of the features (in rows) in each study (columns).
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_n.association.status">n.association.status</code></td>
<td>

<p>either 2 for no-association\association or 3 for no-associtation\negative-association\positive-association.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_n.bins">n.bins</code></td>
<td>

<p>Number of bins in the discretization of the z-score axis (the number of bins is <code>n.bins - 1</code>). If the number of z-scores per study is small, we set <code>n.bins</code> to a number lower than the default of 120 (about equals to the square root of the number of z-scores). To override the bin number cap (and create a discretization of the data that is sparse), use the <code>force.bin.number = TRUE</code> argument.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_type">type</code></td>
<td>

<p>Type of fitting used for f; 0 is a natural spline, 1 is a polynomial, in either case with degrees of freedom <code>df</code> (so total degrees of freedom including the intercept is <code>df+1</code>).
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_df">df</code></td>
<td>

<p>Degrees of freedom for fitting the estimated density f(z).
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_central.prop">central.prop</code></td>
<td>

<p>Central proportion of the z-scores used like the area of zero-assumption to estimate pi0.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_pi0">pi0</code></td>
<td>

<p>Sets argument for estimation of proportion of null hypotheses. Default value is NULL (automatic estimation of pi0) for every study. Second option is to supply vector of values between 0 and 1 (with length of the number of studies/ columns of <code>zmat</code>. These values will be used for pi0.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_plot.diagnostics">plot.diagnostics</code></td>
<td>

<p>If set to <code>TRUE</code>, will show disgnostics plots for density estimation for each study. First plot is a histogram of counts for each bin (Displayed as white bars), along with fitted density in green. Pink bars represent the observed number of counts in each bins, minus the expected number of null hypotheses by the model (truncated at zero). Red and Orange dashed lines represent the estimated densities for non null distributions fitted by the spline. A blue dashed line represents the density component of Z scores for null SNPS, N(0,1).
</p>
<p>A second plot is the Normal Q-Q plot of Zscores, converted using <code>qnorm</code> to the normal scale. A valid graph should coincide with a the linear fit displayed. A misfit with the linear plot could indicate either a null distribution which is not standard normal (a problem), or an extreme number of non null P-Values (Signal is not sparse, output is still valid). A black dashed line markes the expected fit for the standard normal distribution (with a single black dot for the (0,0) point). If the linear fit for the Q-Q plot (red line) does not match the dashed black line, the null distribution of the data is not standard normal.
</p>
<p>Misfit in these two plots should be investigated by the user, before using output in <code>repfdr</code>
</p>
<p>Default value is <code>False</code>.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_trim.z">trim.z</code></td>
<td>
<p> If set to <code>TRUE</code>, Z scores above <code>trim.z.upper</code> or below <code>trim.z.lower</code> will be trimmed at their respective limits. Default value if <code>FALSE</code>
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_trim.z.upper">trim.z.upper</code></td>
<td>

<p>Upper bound for trimming Z scores. Default value is 8
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_trim.z.lower">trim.z.lower</code></td>
<td>

<p>Lower bound for trimming Z scores. Default value is -8
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_force.bin.number">force.bin.number</code></td>
<td>
<p>Set to <code>T</code> to be able to create a discretization with <code>n.bins&gt;sqrt(nrow(zmat))</code>.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_pi.using.plugin">pi.using.plugin</code></td>
<td>

<p>Logical flag indicating whether estimation of the number of null hypotheses should be done using the plugin estimator.(Default is <code>F</code>). The plugin  estimator is  <code>(sum(Pvalues &gt; pi.plugin.lambda) + 1)/(m * (1-pi.plugin.lambda))</code> where <code>m</code> is the number of P-values.
</p>
</td></tr>
<tr><td><code id="ztobins_+3A_pi.plugin.lambda">pi.plugin.lambda</code></td>
<td>

<p>Parameter used for estimation of proportion of null hypotheses, for one sided tests. Default value is 0.05. This should be set to the type 1 error used for hypothesis testing.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This utility function outputs the first two arguments to be input in the main function <code><a href="#topic+repfdr">repfdr</a></code>.
</p>


<h3>Value</h3>

<p>A list with:
</p>
<table>
<tr><td><code>pdf.binned.z</code></td>
<td>

<p>A 3-dimensional array which contains for each study (first dimension), the probabilities of a z-score to fall in the bin (second dimension), under each hypothesis status (third dimension). The third dimension can be of size 2 or 3, depending on the number of association states: if the association can be either null or only in one direction, the dimension is 2; if the association can be either null, or positive, or negative, the dimension is 3.  
</p>
</td></tr>
<tr><td><code>binned.z.mat</code></td>
<td>

<p>A matrix of the bin numbers for each the z-scores (rows) in each study (columns).
</p>
</td></tr>
<tr><td><code>breaks.matrix</code></td>
<td>

<p>A matrix with <code>n.bins + 1</code> rows and ncol(zmat) columns, representing for each study the discretization chosed. Values are the between bin breaks. First and last values are the edges of the outmost bins.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>Number of degrees of freedom, used for spline fitting of density.
</p>
</td></tr>
<tr><td><code>proportions</code></td>
<td>

<p>Matrix with <code>n.association.status</code> rows, and <code>ncol(zmat)</code> columns, giving the estimated proportion of each component, for each study.
</p>
</td></tr>
<tr><td><code>PlotWarnings</code></td>
<td>

<p>Vector of size <code>ncol{zmat}</code>, keeping the warnings given for each study (available here, in the plots for each study and printed to console). With no warnings given for study, value is <code>NA</code>
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+repfdr">repfdr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulated example using both the central proportion estimator 
# and the plug in estimator for the proportion of null hypotheses:

set.seed(1)
p = 10000
p1 = 300
z1 = (rnorm(p))
z2 = (rnorm(p))
temp = rnorm(p1, 3.5,0.5)
z1[1:p1] = temp + rnorm(p1,0,0.2)
z2[1:p1] = temp + rnorm(p1,0,0.2)

z1.abs = abs(z1)
z2.abs = abs(z2)
plot(z1,z2)
hist(z1)
hist(z2)

zmat.example = cbind(z1,z2)

ztobins.res = ztobins(zmat.example,
                      plot.diagnostics = TRUE)
ztobins.res$proportions

ztobins.res.plugin.estimator = ztobins(zmat.example,
                           pi.using.plugin = TRUE,
                           plot.diagnostics = TRUE)

ztobins.res.plugin.estimator$proportions

## Not run: 

# three association states case (H in {-1,0,1}):
download.file('http://www.math.tau.ac.il/~ruheller/repfdr_RData/zmat.RData',destfile = "zmat.RData")
load(file = "zmat.RData")

input.to.repfdr3 &lt;- ztobins(zmat, 3, df = 15)
pbz    &lt;- input.to.repfdr3$pdf.binned.z
bz     &lt;- input.to.repfdr3$binned.z.mat

# two association states case (H in {0,1}):
data(zmat_sim)

input.to.repfdr &lt;- ztobins(zmat_sim, 2, n.bins = 100 ,plot.diagnostics = T)
pbz_sim    &lt;- input.to.repfdr$pdf.binned.z
bz_sim     &lt;- input.to.repfdr$binned.z.mat

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
