<!DOCTYPE html><html><head><title>Help for package psychonetrics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {psychonetrics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#psychonetrics-package'>
<p>Structural Equation Modeling and Confirmatory Network Analysis</p></a></li>
<li><a href='#aggregate_bootstraps'>
<p>Aggregate Bootstrapped Models</p></a></li>
<li><a href='#bifactor'>
<p>Bi-factor models</p></a></li>
<li><a href='#bootstrap'>
<p>Bootstrap a psychonetrics model</p></a></li>
<li><a href='#changedata'>
<p>Change the data of a psychonetrics object</p></a></li>
<li><a href='#CIplot'>
<p>Plot Analytic Confidence Intervals</p></a></li>
<li><a href='#compare'>
<p>Model comparison</p></a></li>
<li><a href='#covML'>
<p>Maximum likelihood covariance estimate</p></a></li>
<li><a href='#diagnostics'>
<p>Diagnostic functions</p></a></li>
<li><a href='#dlvm1'>
<p>Lag-1 dynamic latent variable model family of psychonetrics models for panel data</p></a></li>
<li><a href='#duplicationMatrix'>
<p>Model matrices used in derivatives</p></a></li>
<li><a href='#emergencystart'>
<p>Reset starting values to simple defaults</p></a></li>
<li><a href='#esa'>
<p>Ergodic Subspace Analysis</p></a></li>
<li><a href='#factorscores'>
<p>Compute factor scores</p></a></li>
<li><a href='#fit'>
<p>Print fit indices</p></a></li>
<li><a href='#fixpar'>
<p>Parameters modification</p></a></li>
<li><a href='#fixstart'>
<p>Attempt to Fix Starting Values</p></a></li>
<li><a href='#generate'>
<p>Generate data from a fitted psychonetrics object</p></a></li>
<li><a href='#getmatrix'>
<p>Extract an estimated matrix</p></a></li>
<li><a href='#getVCOV'>
<p>Obtain the asymptotic covariance matrix</p></a></li>
<li><a href='#groupequal'>
<p>Group equality constrains</p></a></li>
<li><a href='#Ising'>
<p>Ising model</p></a></li>
<li><a href='#Jonas'>
<p>Jonas dataset</p></a></li>
<li><a href='#latentgrowth'>
<p>Latnet growth curve model</p></a></li>
<li><a href='#logbook'>
<p>Retrieve the psychonetrics logbook</p></a></li>
<li><a href='#lvm'>
<p>Continuous latent variable family of psychonetrics models</p></a></li>
<li><a href='#meta_varcov'>
<p>Variance-covariance and GGM meta analysis</p></a></li>
<li><a href='#MIs'>
<p>Print modification indices</p></a></li>
<li><a href='#ml_lvm'>
<p>Multi-level latent variable model family</p></a></li>
<li><a href='#ml_tsdlvm1'>
<p>Multi-level Lag-1 dynamic latent variable model family of psychonetrics models for time-series data</p></a></li>
<li><a href='#modelsearch'>
<p>Stepwise model search</p></a></li>
<li><a href='#parameters'>
<p>Print parameter estimates</p></a></li>
<li><a href='#parequal'>
<p>Set equality constrains across parameters</p></a></li>
<li><a href='#partialprune'>
<p>Partial pruning of multi-group models</p></a></li>
<li><a href='#prune'>
<p>Stepdown model search by pruning non-significant parameters.</p></a></li>
<li><a href='#psychonetrics_bootstrap-class'><p>Class <code>"psychonetrics_bootstrap"</code></p></a></li>
<li><a href='#psychonetrics_log-class'><p>Class <code>"psychonetrics"</code></p></a></li>
<li><a href='#psychonetrics_update'>
<p>Model updating functions</p></a></li>
<li><a href='#psychonetrics-class'><p>Class <code>"psychonetrics"</code></p></a></li>
<li><a href='#runmodel'>
<p>Run a psychonetrics model</p></a></li>
<li><a href='#setestimator'>
<p>Convenience functions</p></a></li>
<li><a href='#setverbose'>
<p>Should messages of computation progress be printed?</p></a></li>
<li><a href='#simplestructure'>
<p>Generate factor loadings matrix with simple structure</p></a></li>
<li><a href='#StarWars'>
<p>Star Wars dataset</p></a></li>
<li><a href='#stepup'>
<p>Stepup model search along modification indices</p></a></li>
<li><a href='#transmod'>
<p>Transform between model types</p></a></li>
<li><a href='#tsdlvm1'>
<p>Lag-1 dynamic latent variable model family of psychonetrics models for time-series data</p></a></li>
<li><a href='#unionmodel'>
<p>Unify models across groups</p></a></li>
<li><a href='#var1'>
<p>Lag-1 vector autoregression family of psychonetrics models</p></a></li>
<li><a href='#varcov'>
<p>Variance-covariance family of psychonetrics models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Structural Equation Modeling and Confirmatory Network Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.13</td>
</tr>
<tr>
<td>Author:</td>
<td>Sacha Epskamp</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data &lt;<a href="https://doi.org/10.31234%2Fosf.io%2F8ha93">doi:10.31234/osf.io/8ha93</a>&gt;. Allows for confirmatory testing and fit as well as exploratory model search.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp (&ge; 0.11.3), RcppArmadillo, pbv, roptim</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, qgraph, numDeriv, dplyr, abind, Matrix (&ge; 1.6-5),
lavaan, corpcor, glasso, mgcv, optimx, VCA, pbapply, parallel,
magrittr, IsingSampler, tidyr, psych, GA, combinat, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>psychTools, semPlot, graphicalVAR, metaSEM, mvtnorm, ggplot2</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://psychonetrics.org/">http://psychonetrics.org/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/SachaEpskamp/psychonetrics/issues">https://github.com/SachaEpskamp/psychonetrics/issues</a></td>
</tr>
<tr>
<td>StagedInstall:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-20 17:09:07 UTC; Sacha</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-20 18:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='psychonetrics-package'>
Structural Equation Modeling and Confirmatory Network Analysis
</h2><span id='topic+psychonetrics-package'></span><span id='topic+psychonetrics'></span>

<h3>Description</h3>

<p>Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data &lt;doi:10.31234/osf.io/8ha93&gt;. Allows for confirmatory testing and fit as well as exploratory model search.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> psychonetrics</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Structural Equation Modeling and Confirmatory Network Analysis</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.13</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Sacha Epskamp</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Sacha Epskamp &lt;mail@sachaepskamp.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data &lt;doi:10.31234/osf.io/8ha93&gt;. Allows for confirmatory testing and fit as well as exploratory model search.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
LinkingTo: </td><td style="text-align: left;"> Rcpp (&gt;= 0.11.3), RcppArmadillo, pbv, roptim</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 4.3.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> methods, qgraph, numDeriv, dplyr, abind, Matrix (&gt;= 1.6-5),
lavaan, corpcor, glasso, mgcv, optimx, VCA, pbapply, parallel,
magrittr, IsingSampler, tidyr, psych, GA, combinat, rlang</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> psychTools, semPlot, graphicalVAR, metaSEM, mvtnorm, ggplot2</td>
</tr>
<tr>
 <td style="text-align: left;">
ByteCompile: </td><td style="text-align: left;"> true</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> http://psychonetrics.org/</td>
</tr>
<tr>
 <td style="text-align: left;">
BugReports: </td><td style="text-align: left;"> https://github.com/SachaEpskamp/psychonetrics/issues</td>
</tr>
<tr>
 <td style="text-align: left;">
StagedInstall: </td><td style="text-align: left;"> true</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Archs: </td><td style="text-align: left;"> x64</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
CIplot                  Plot Analytic Confidence Intervals
Ising                   Ising model
Jonas                   Jonas dataset
MIs                     Print modification indices
StarWars                Star Wars dataset
addMIs                  Model updating functions
aggregate_bootstraps    Aggregate Bootstrapped Models
bifactor                Bi-factor models
bootstrap               Bootstrap a psychonetrics model
changedata              Change the data of a psychonetrics object
checkJacobian           Diagnostic functions
compare                 Model comparison
covML                   Maximum likelihood covariance estimate
dlvm1                   Lag-1 dynamic latent variable model family of
                        psychonetrics models for panel data
duplicationMatrix       Model matrices used in derivatives
emergencystart          Reset starting values to simple defaults
esa                     Ergodic Subspace Analysis
factorscores            Compute factor scores
fit                     Print fit indices
fixpar                  Parameters modification
fixstart                Attempt to Fix Starting Values
generate                Generate data from a fitted psychonetrics
                        object
getVCOV                 Obtain the asymptotic covariance matrix
getmatrix               Extract an estimated matrix
groupequal              Group equality constrains
latentgrowth            Latnet growth curve model
logbook                 Retrieve the psychonetrics logbook
lvm                     Continuous latent variable family of
                        psychonetrics models
meta_varcov             Variance-covariance and GGM meta analysis
ml_lvm                  Multi-level latent variable model family
ml_tsdlvm1              Multi-level Lag-1 dynamic latent variable model
                        family of psychonetrics models for time-series
                        data
modelsearch             Stepwise model search
parameters              Print parameter estimates
parequal                Set equality constrains across parameters
partialprune            Partial pruning of multi-group models
prune                   Stepdown model search by pruning
                        non-significant parameters.
psychonetrics-class     Class '"psychonetrics"'
psychonetrics-package   Structural Equation Modeling and Confirmatory
                        Network Analysis
psychonetrics_bootstrap-class
                        Class '"psychonetrics_bootstrap"'
psychonetrics_log-class
                        Class '"psychonetrics"'
runmodel                Run a psychonetrics model
setestimator            Convenience functions
setverbose              Should messages of computation progress be
                        printed?
simplestructure         Generate factor loadings matrix with simple
                        structure
stepup                  Stepup model search along modification indices
transmod                Transform between model types
tsdlvm1                 Lag-1 dynamic latent variable model family of
                        psychonetrics models for time-series data
unionmodel              Unify models across groups
var1                    Lag-1 vector autoregression family of
                        psychonetrics models
varcov                  Variance-covariance family of psychonetrics
                        models
</pre>
<p>This package can be used to perform Structural Equation Modeling and confirmatory network modeling. Current implemented families of models are (1) the variance&ndash;covariance matrix (<code><a href="#topic+varcov">varcov</a></code>), (2) the latent variable model (<code><a href="#topic+lvm">lvm</a></code>), (3) the lag-1 vector autoregression model (<code><a href="#topic+var1">var1</a></code>), and (4) the dynamical lag-1 latent variable model for panel data (<code><a href="#topic+dlvm1">dlvm1</a></code>) and for time-series data (<code><a href="#topic+tsdlvm1">tsdlvm1</a></code>).
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>
<p>Maintainer: Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>


<h3>References</h3>

<p>More information: psychonetrics.org
</p>

<hr>
<h2 id='aggregate_bootstraps'>
Aggregate Bootstrapped Models
</h2><span id='topic+aggregate_bootstraps'></span>

<h3>Description</h3>

<p>Aggregates bootstrap results into a <code>psychonetrics_bootstrap</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_bootstraps(sample, bootstraps, remove_problematic = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_bootstraps_+3A_sample">sample</code></td>
<td>

<p>The original <code>psychonetrics</code> object (not bootstrapped)
</p>
</td></tr>
<tr><td><code id="aggregate_bootstraps_+3A_bootstraps">bootstraps</code></td>
<td>

<p>A list of bootstrapped <code>psychonetrics</code> objects (i.e., using <code>bootstrap = TRUE</code>)
</p>
</td></tr>
<tr><td><code id="aggregate_bootstraps_+3A_remove_problematic">remove_problematic</code></td>
<td>
<p>Remove bootstraps that did not converge (sum of absolute gradient &gt; 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After running this function, the helper functions <code>parameters</code>, <code>fit</code>, and <code>CIplot</code> can be used to investigate bootstrap results.  
</p>


<h3>Value</h3>

<p>An object of the class <code>psychonetrics_bootstrap</code>
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='bifactor'>
Bi-factor models
</h2><span id='topic+bifactor'></span>

<h3>Description</h3>

<p>Wrapper to <code>lvm</code> to specify a bi-factor model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bifactor(data, lambda, latents, bifactor = "g", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bifactor_+3A_data">data</code></td>
<td>

<p>The data as used by <code><a href="#topic+lvm">lvm</a></code>
</p>
</td></tr>
<tr><td><code id="bifactor_+3A_lambda">lambda</code></td>
<td>

<p>The factor loadings matrix *without* the bifactor, as used by by <code><a href="#topic+lvm">lvm</a></code>
</p>
</td></tr>
<tr><td><code id="bifactor_+3A_latents">latents</code></td>
<td>

<p>A vector of names of the latent variables, as used by <code><a href="#topic+lvm">lvm</a></code>
</p>
</td></tr>
<tr><td><code id="bifactor_+3A_bifactor">bifactor</code></td>
<td>

<p>Name of the bifactor
</p>
</td></tr>
<tr><td><code id="bifactor_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+lvm">lvm</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='bootstrap'>
Bootstrap a psychonetrics model
</h2><span id='topic+bootstrap'></span>

<h3>Description</h3>

<p>This function will bootstrap the data (once) and return a new unevaluated psychonetrics object. It requres <code>storedata = TRUE</code> to be used when forming a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap(x, replacement = TRUE, proportion = 1, verbose = TRUE, storedata = FALSE, 
          baseline_saturated = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_replacement">replacement</code></td>
<td>

<p>Logical, should new samples be drawn with replacement?
</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_proportion">proportion</code></td>
<td>

<p>Proportion of sample to be drawn. Set to lower than $1$ for subsampling.
</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the bootstrapped data also be stored?
</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>Logical, should the baseline and saturated models be included?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='changedata'>
Change the data of a psychonetrics object
</h2><span id='topic+changedata'></span>

<h3>Description</h3>

<p>This function can be used to change the data in a psychonetrics object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>changedata(x, data, covs, nobs, means, groups, missing = "listwise")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="changedata_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="changedata_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="changedata_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. IMPORTANT NOTE: psychonetrics expects the maximum likelihood (ML) covariance matrix, which is NOT obtained from <code><a href="stats.html#topic+cov">cov</a></code> directly. Manually rescale the result of <code><a href="stats.html#topic+cov">cov</a></code> with <code>(nobs - 1)/nobs</code> to obtain the ML covariance matrix.
</p>
</td></tr>
<tr><td><code id="changedata_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="changedata_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="changedata_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="changedata_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='CIplot'>
Plot Analytic Confidence Intervals
</h2><span id='topic+CIplot'></span>

<h3>Description</h3>

<p>Function to plot analytic confidence intervals (CI) of matrix elements estimated in psychonetrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CIplot(x, matrices, alpha_ci = 0.05, alpha_color = c(0.05,
                   0.01, 0.001, 1e-04), labels, labels2, labelstart,
                   print = TRUE, major_break = 0.2, minor_break = 0.1,
                   split0, prop0, prop0_cex = 1, prop0_alpha = 0.95,
                   prop0_minAlpha = 0.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CIplot_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_matrices">matrices</code></td>
<td>

<p>Vector of strings indicating the matrices to plot CIs for
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_alpha_ci">alpha_ci</code></td>
<td>

<p>The alpha level used for the CIs
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_alpha_color">alpha_color</code></td>
<td>

<p>A vector of alphas used for coloring the CIs
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_labels">labels</code></td>
<td>

<p>The labels for the variables associated with the rows of a matrix.
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_labels2">labels2</code></td>
<td>

<p>The labels for the variables associated with the columns of a matrix. Defaults to the value of <code>labels</code> for square matrices.
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_labelstart">labelstart</code></td>
<td>

<p>The value to determine if labels are printed to the right or to the left of the CI
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_print">print</code></td>
<td>

<p>Logical, should the plots also be printed? Only works when one matrix is used in 'matrices'
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_major_break">major_break</code></td>
<td>

<p>Numeric indicating the step size between major breaks
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_minor_break">minor_break</code></td>
<td>

<p>Numeric indicating the step size between minor breaks
</p>
</td></tr>
<tr><td><code id="CIplot_+3A_split0">split0</code></td>
<td>
<p>Logical only used for results of <code>aggregate_bootstraps</code>. When set to TRUE, the displayed intervals are based on occasions when the parameter was not estimated to be zero, and an extra box is added indicating the number of times a parameter is estimated to be zero. Defaults to <code>TRUE</code> when model selection is used and <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="CIplot_+3A_prop0">prop0</code></td>
<td>
<p>Logical only used for results of <code>aggregate_bootstraps</code>, should boxes indicating the proportion of times parameters were estimated to be zero be added to the plot? Defaults to the value of <code>split0</code>.</p>
</td></tr>
<tr><td><code id="CIplot_+3A_prop0_cex">prop0_cex</code></td>
<td>
<p>Only used for results of <code>aggregate_bootstraps</code>. Size of the boxes indicating number of times a parameter was set to zero.</p>
</td></tr>
<tr><td><code id="CIplot_+3A_prop0_alpha">prop0_alpha</code></td>
<td>
<p>Only used for results of <code>aggregate_bootstraps</code>. Transparency of the boxes indicating number of times a parameter was set to zero.</p>
</td></tr>
<tr><td><code id="CIplot_+3A_prop0_minalpha">prop0_minAlpha</code></td>
<td>
<p>Only used for results of <code>aggregate_bootstraps</code>. Minimal transparency of the *lines* of plotted intervals as the proportion of times an edge was not included goes to 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single ggplot2 object, or a list of ggplot2 objects for each matrix requested.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example from ?ggm ###
# Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit an empty GGM:
mod0 &lt;- ggm(ConsData, vars = vars)

# Run the model:
mod0 &lt;- mod0 %&gt;% runmodel

# Labels:
labels &lt;- c(
  "indifferent to the feelings of others",
  "inquire about others' well-being",
  "comfort others",
  "love children",
  "make people feel at ease")

# Plot the CIs:
CIplot(mod0,  "omega", labels = labels, labelstart = 0.2)

### Example from ?gvar ###
library("dplyr")
library("graphicalVAR")

beta &lt;- matrix(c(
  0,0.5,
  0.5,0
),2,2,byrow=TRUE)
kappa &lt;- diag(2)
simData &lt;- graphicalVARsim(50, beta, kappa)

# Form model:
model &lt;- gvar(simData)

# Evaluate model:
model &lt;- model %&gt;% runmodel

# Plot the CIs:
CIplot(model,  "beta")

</code></pre>

<hr>
<h2 id='compare'>
Model comparison
</h2><span id='topic+compare'></span><span id='topic+print.psychonetrics_compare'></span>

<h3>Description</h3>

<p>This function will print a table comparing multiple models on chi-square, AIC and BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare(...)

## S3 method for class 'psychonetrics_compare'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_+3A_...">...</code></td>
<td>

<p>Any number of <code>psychonetrics</code> models. Can be named to change the rownames of the output.
</p>
</td></tr>
<tr><td><code id="compare_+3A_x">x</code></td>
<td>
<p>Output of the <code>compare</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with chi-square values, degrees of freedoms, RMSEAs, AICs, and BICs.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='covML'>
Maximum likelihood covariance estimate
</h2><span id='topic+covML'></span><span id='topic+covMLtoUB'></span><span id='topic+covUBtoML'></span>

<h3>Description</h3>

<p>These functions complement the base R <code>cov</code> function by simplifying obtaining maximum likelihood (ML) covariance estimates (denominator n) instead of unbiased (UB) covariance estimates (denominator n-1). The function <code>covML</code> can be used to obtain ML estimates, the function <code>covUBtoML</code> transforms from UB to ML estimates, and the function <code>covMLtoUB</code> transforms from UB to ML estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covML(x, ...)
covUBtoML(x, n, ...)
covMLtoUB(x, n, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covML_+3A_x">x</code></td>
<td>

<p>A dataset
</p>
</td></tr>
<tr><td><code id="covML_+3A_n">n</code></td>
<td>

<p>The sample size
</p>
</td></tr>
<tr><td><code id="covML_+3A_...">...</code></td>
<td>

<p>Arguments sent to the <code>cov</code> function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("StarWars")
Y &lt;- StarWars[,1:10]

# Unbiased estimate:
UB &lt;- cov(Y)

# ML Estimate:
ML &lt;- covML(Y)

# Check:
all(abs(UB - covMLtoUB(ML, nrow(Y))) &lt; sqrt(.Machine$double.eps))
all(abs(ML - covUBtoML(UB, nrow(Y))) &lt; sqrt(.Machine$double.eps))
</code></pre>

<hr>
<h2 id='diagnostics'>
Diagnostic functions
</h2><span id='topic+checkJacobian'></span><span id='topic+checkFisher'></span>

<h3>Description</h3>

<p>The 'checkJacobian' function can be used to check if the analytic gradient / 
Jacobian is aligned with the numerically approximated gradient / Jacobian, and 
the 'checkFisher' function can be used to check if the analytic Hessian is 
aligned with the numerically approximated Hessian.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkJacobian(x, f = "default", jac = "default", transpose = FALSE, 
          plot = TRUE, perturbStart = FALSE, method = "Richardson")

checkFisher(x, f = "default", fis = "default", transpose = FALSE, 
          plot = TRUE,  perturbStart = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagnostics_+3A_x">x</code></td>
<td>

<p>A 'psychonetrics' object
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_f">f</code></td>
<td>

<p>A custom fit function or the psychonetrics default fit function (default).
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_jac">jac</code></td>
<td>

<p>A custom Jacobian function or the psychonetrics default Jacobian function 
(default).
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_fis">fis</code></td>
<td>

<p>A custom Fischer information function or the psychonetrics default Fischer 
information function (default).
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_transpose">transpose</code></td>
<td>

<p>Should the numeric Jacobian be transposed?
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_plot">plot</code></td>
<td>

<p>Should a diagnostic plot be produced?
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_perturbstart">perturbStart</code></td>
<td>

<p>Should start values be perturbed (only used in development)
</p>
</td></tr>
<tr><td><code id="diagnostics_+3A_method">method</code></td>
<td>

<p>Numeric derivative method (default: Richardson)
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='dlvm1'>
Lag-1 dynamic latent variable model family of psychonetrics models for panel data
</h2><span id='topic+dlvm1'></span><span id='topic+panelgvar'></span><span id='topic+panelvar'></span><span id='topic+panel_lvgvar'></span>

<h3>Description</h3>

<p>This is the family of models that models a dynamic factor model on panel data. There are four covariance structures that can be modeled in different ways: <code>within_latent</code>, <code>between_latent</code> for the within-person and between-person latent (contemporaneous) models respectively, and <code>within_residual</code>, <code>between_residual</code> for the within-person and between-person residual models respectively. The <code>panelgvar</code> wrapper function sets the <code>lambda</code> to an identity matrix, all residual variances to zero, and models within-person and between-person latent (contemporaneous) models as GGMs. The <code>panelvar</code> wrapper does the same but models contemporaneous relations as a variance-covariance matrix. Finally, the <code>panel_lvgvar</code> wrapper automatically models all latent networks as GGMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlvm1(data, vars, lambda, within_latent = c("cov", "chol",
                   "prec", "ggm"), within_residual = c("cov", "chol",
                   "prec", "ggm"), between_latent = c("cov", "chol",
                   "prec", "ggm"), between_residual = c("cov", "chol",
                   "prec", "ggm"), beta = "full", omega_zeta_within =
                   "full", delta_zeta_within = "diag", kappa_zeta_within
                   = "full", sigma_zeta_within = "full",
                   lowertri_zeta_within = "full", omega_epsilon_within =
                   "zero", delta_epsilon_within = "diag",
                   kappa_epsilon_within = "diag", sigma_epsilon_within =
                   "diag", lowertri_epsilon_within = "diag",
                   omega_zeta_between = "full", delta_zeta_between =
                   "diag", kappa_zeta_between = "full",
                   sigma_zeta_between = "full", lowertri_zeta_between =
                   "full", omega_epsilon_between = "zero",
                   delta_epsilon_between = "diag", kappa_epsilon_between
                   = "diag", sigma_epsilon_between = "diag",
                   lowertri_epsilon_between = "diag", nu, mu_eta,
                   identify = TRUE, identification = c("loadings",
                   "variance"), latents, groups, covs, means, nobs, start
                   = "version2", covtype = c("choose", "ML", "UB"),
                   missing = "listwise", equal = "none",
                   baseline_saturated = TRUE, estimator = "ML",
                   optimizer, storedata = FALSE, verbose = FALSE,
                   sampleStats, baseline =
                   c("stationary_random_intercept", "stationary",
                   "independence", "none"), bootstrap = FALSE, boot_sub,
                   boot_resample)

panelgvar(data, vars, within_latent = c("ggm","chol","cov","prec"), 
          between_latent = c("ggm","chol","cov","prec"), ...)

panelvar(data, vars, within_latent = c("cov","chol","prec","ggm"), 
          between_latent = c("cov","chol","prec","ggm"), ...)

panel_lvgvar(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dlvm1_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_vars">vars</code></td>
<td>
<p> Required argument.
Different from in other psychonetrics models, this must be a *matrix* with each row indicating a variable and each column indicating a measurement. The matrix must be filled with names of the variables in the dataset corresponding to variable i at wave j. NAs can be used to indicate missing waves. The rownames of this matrix will be used as variable names.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_lambda">lambda</code></td>
<td>
<p> Required argument.
A model matrix encoding the factor loading structure. Each row indicates an indicator and each column a latent. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_within_latent">within_latent</code></td>
<td>

<p>The type of within-person latent contemporaneous model to be used.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_within_residual">within_residual</code></td>
<td>

<p>The type of within-person residual model to be used.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_between_latent">between_latent</code></td>
<td>

<p>The type of between-person latent model to be used.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_between_residual">between_residual</code></td>
<td>

<p>The type of between-person residual model to be used.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_beta">beta</code></td>
<td>

<p>A model matrix encoding the temporal relationships (transpose of temporal network). A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix. Can also be <code>"full"</code> for a full temporal network or <code>"zero"</code> for an empty temporal network.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_omega_zeta_within">omega_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_delta_zeta_within">delta_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_kappa_zeta_within">kappa_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_sigma_zeta_within">sigma_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_lowertri_zeta_within">lowertri_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_omega_epsilon_within">omega_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_delta_epsilon_within">delta_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_kappa_epsilon_within">kappa_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_sigma_epsilon_within">sigma_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_lowertri_epsilon_within">lowertri_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_omega_zeta_between">omega_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_delta_zeta_between">delta_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_kappa_zeta_between">kappa_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_sigma_zeta_between">sigma_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_lowertri_zeta_between">lowertri_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_omega_epsilon_between">omega_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_delta_epsilon_between">delta_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_kappa_epsilon_between">kappa_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_sigma_epsilon_between">sigma_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_lowertri_epsilon_between">lowertri_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_nu">nu</code></td>
<td>

<p>Optional vector encoding the intercepts of the observed variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_mu_eta">mu_eta</code></td>
<td>

<p>Optional vector encoding the means of the latent variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be automatically identified?
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_identification">identification</code></td>
<td>

<p>Type of identification used. <code>"loadings"</code> to fix the first factor loadings to 1, and <code>"variance"</code> to fix the diagonal of the latent variable model matrix (sigma_zeta, lowertri_zeta, delta_zeta or kappa_zeta) to 1.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_latents">latents</code></td>
<td>

<p>An optional character vector with names of the latent variables.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. IMPORTANT NOTE: psychonetrics expects the maximum likelihood (ML) covariance matrix, which is NOT obtained from <code><a href="stats.html#topic+cov">cov</a></code> directly. Manually rescale the result of <code><a href="stats.html#topic+cov">cov</a></code> with <code>(nobs - 1)/nobs</code> to obtain the ML covariance matrix.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_start">start</code></td>
<td>
<p>Start value specification. Can be either a string or a psychonetrics model. If it is a string, <code>"version2"</code> indicates the latest version of start value computation, <code>"version1"</code> indicates start values as they were computed up to version 0.11, and <code>"simple"</code> indicate simple starting values. If this is a psychonetrics model the starting values will be based on the ouptut. This can be useful, for example, if you first estimate a model with matrices set to a Cholesky decomposition, then use those values as start values for estimating Gaussian graphical models.</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation, <code>"FIML"</code> for full-information maximum likelihood estimation, <code>"ULS"</code> for unweighted least squares estimation, <code>"WLS"</code> for weighted least squares estimation, and <code>"DWLS"</code> for diagonally weighted least squares estimation.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code><a href="#topic+bootstrap">bootstrap</a></code>).
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should progress be printed to the console?
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_covtype">covtype</code></td>
<td>

<p>If 'covs' is used, this is the type of covariance (maximum likelihood or unbiased) the input covariance matrix represents. Set to <code>"ML"</code> for maximum likelihood estimates (denominator n) and <code>"UB"</code> to unbiased estimates (denominator n-1). The default will try to find the type used, by investigating which is most likely to result from integer valued datasets.
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_baseline">baseline</code></td>
<td>
<p>What baseline model should be used? <code>"stationary_random_intercept"</code> includes both within- and between person variances constrained equal across time (default), <code>"stationary"</code> only includes within-person variances constrained equal across time, <code>"independence"</code> (default up to version 0.11) includes a variance for every variable at every time point (not constrained equal across time), and <code>"none"</code> includes no baseline model.</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="dlvm1_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>dlvm1</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("dplyr")

# Smoke data cov matrix, based on LISS data panel https://www.dataarchive.lissdata.nl
smoke &lt;- structure(c(47.2361758611759, 43.5366809116809, 41.0057465682466, 
                     43.5366809116809, 57.9789886039886, 47.6992521367521, 
                     41.0057465682466, 
                     47.6992521367521, 53.0669434731935), .Dim = c(3L, 3L), 
                   .Dimnames = list(
                       c("smoke2008", "smoke2009", "smoke2010"), c("smoke2008", 
                   "smoke2009", "smoke2010")))

# Design matrix:
design &lt;- matrix(rownames(smoke),1,3)

# Form model:
mod &lt;- panelvar(vars = design, 
                covs = smoke, nobs = 352
)


# Run model:
mod &lt;- mod %&gt;% runmodel

# Evaluate fit:
mod %&gt;% fit

</code></pre>

<hr>
<h2 id='duplicationMatrix'>
Model matrices used in derivatives
</h2><span id='topic+duplicationMatrix'></span><span id='topic+eliminationMatrix'></span><span id='topic+diagonalizationMatrix'></span>

<h3>Description</h3>

<p>These matrices are used in the analytic gradients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicationMatrix(n, diag = TRUE)

eliminationMatrix(n, diag = TRUE)

diagonalizationMatrix(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicationMatrix_+3A_n">n</code></td>
<td>

<p>Number of rows and columns in the original matrix
</p>
</td></tr>
<tr><td><code id="duplicationMatrix_+3A_diag">diag</code></td>
<td>

<p>Logical indicating if the diagonal should be included (set to FALSE for derivative of vech(x))
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sparse matrix
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Duplication matrix for 10 variables:
duplicationMatrix(10)

# Elimination matrix for 10 variables:
eliminationMatrix(10)

# Diagonailzation matrix for 10 variables:
diagonalizationMatrix(10)
</code></pre>

<hr>
<h2 id='emergencystart'>
Reset starting values to simple defaults
</h2><span id='topic+emergencystart'></span>

<h3>Description</h3>

<p>This function overwrites the starting values to simple defaults. This can help in cases where optimization fails.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emergencystart(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emergencystart_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>psychonetrics</code> model.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='esa'>
Ergodic Subspace Analysis
</h2><span id='topic+esa'></span><span id='topic+esa_manual'></span><span id='topic+plot.esa'></span><span id='topic+plot.esa_manual'></span><span id='topic+print.esa'></span><span id='topic+print.esa_manual'></span>

<h3>Description</h3>

<p>These functions implement Ergodic Subspace Analysis by von Oertzen, Schmiedek and Voelkle (2020). The functions can be used on the output of a <code><a href="#topic+dlvm1">dlvm1</a></code> model, or manually by supplying a within persons and between persons variance-covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>esa(x, cutoff = 0.1,
    between = c("crosssection", "between"))
esa_manual(sigma_wp, sigma_bp, cutoff = 0.1)
## S3 method for class 'esa'
print(x, printref = TRUE, ...)
## S3 method for class 'esa_manual'
print(x, printref = TRUE, ...)
## S3 method for class 'esa'
plot(x, plot = c("observed", "latent"), ...)
## S3 method for class 'esa_manual'
plot(x,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="esa_+3A_x">x</code></td>
<td>

<p>Output of a <code><a href="#topic+dlvm1">dlvm1</a></code> model
</p>
</td></tr>
<tr><td><code id="esa_+3A_sigma_wp">sigma_wp</code></td>
<td>

<p>Manual within-person variance-covariance matrix
</p>
</td></tr>
<tr><td><code id="esa_+3A_sigma_bp">sigma_bp</code></td>
<td>

<p>Manual between-person variance-covariance matrix
</p>
</td></tr>
<tr><td><code id="esa_+3A_cutoff">cutoff</code></td>
<td>

<p>Cutoff used to determine ergodicity
</p>
</td></tr>
<tr><td><code id="esa_+3A_printref">printref</code></td>
<td>

<p>Logical, should the reference be printed?
</p>
</td></tr>
<tr><td><code id="esa_+3A_plot">plot</code></td>
<td>

<p>Should ergodicity of observed or latent variables be plotted?
</p>
</td></tr>
<tr><td><code id="esa_+3A_between">between</code></td>
<td>

<p>Should the between-persons variance-covariance matrix be based on exected cross-sectional or between-person relations
</p>
</td></tr>
<tr><td><code id="esa_+3A_...">...</code></td>
<td>

<p>Not used
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For each group a <code>esa_manual</code> object with the following elements:
</p>
<table>
<tr><td><code>ergodicity</code></td>
<td>
<p>Ergodicity values of each component</p>
</td></tr>
<tr><td><code>Q_esa</code></td>
<td>
<p>Component loadings</p>
</td></tr>
<tr><td><code>V_bp</code></td>
<td>
<p>Between persons subspace</p>
</td></tr>
<tr><td><code>V_ergodic</code></td>
<td>
<p>Ergodic subspace</p>
</td></tr>
<tr><td><code>V_wp</code></td>
<td>
<p>Within person subspace</p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>Cutoff value used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>


<h3>References</h3>

<p>von Oertzen, T., Schmiedek, F., and Voelkle, M. C. (2020). Ergodic Subspace Analysis. Journal of Intelligence, 8(1), 3.
</p>

<hr>
<h2 id='factorscores'>
Compute factor scores
</h2><span id='topic+factorscores'></span>

<h3>Description</h3>

<p>Currently, only the <code>lvm</code> framework with single group and no missing data is supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factorscores(data, model, method = c("bartlett", "regression"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factorscores_+3A_data">data</code></td>
<td>

<p>Dataset to compute factor scores for
</p>
</td></tr>
<tr><td><code id="factorscores_+3A_model">model</code></td>
<td>

<p>A psychonetrics model
</p>
</td></tr>
<tr><td><code id="factorscores_+3A_method">method</code></td>
<td>

<p>The method to use: <code>"regression"</code> or <code>"bartlett"</code>
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>

<hr>
<h2 id='fit'>
Print fit indices
</h2><span id='topic+fit'></span>

<h3>Description</h3>

<p>This function will print all fit indices of the model/
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a data frame with fit measure estimates.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit an empty GGM:
mod0 &lt;- ggm(ConsData, vars = vars, omega = "zero")

# Run model:
mod0 &lt;- mod0 %&gt;% runmodel

# Inspect fit:
mod0 %&gt;% fit # Pretty bad fit...
</code></pre>

<hr>
<h2 id='fixpar'>
Parameters modification
</h2><span id='topic+fixpar'></span><span id='topic+freepar'></span>

<h3>Description</h3>

<p>The <code>fixpar</code> function can be used to fix a parameter to some value (Typically zero), and the <code>freepar</code> function can be used to free a parameter from being fixed to a value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixpar(x, matrix, row, col, value = 0, group, verbose, 
        log = TRUE, runmodel = FALSE, ...)

freepar(x, matrix, row, col, start, group, verbose, log =
        TRUE, runmodel = FALSE, startEPC = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixpar_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_matrix">matrix</code></td>
<td>

<p>String indicating the matrix of the parameter
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_row">row</code></td>
<td>

<p>Integer or string indicating the row of the matrix of the parameter
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_col">col</code></td>
<td>

<p>Integer or string indicating the column of the matrix of the parameter
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_value">value</code></td>
<td>

<p>Used in <code>fixpar</code> to indicate the value to which a parameters is constrained
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_start">start</code></td>
<td>

<p>Used in <code>freepar</code> to indicate the starting value of the parameter
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_group">group</code></td>
<td>

<p>Integer indicating the group of the parameter to be constrained
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_log">log</code></td>
<td>

<p>Logical, should the log be updated?
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_runmodel">runmodel</code></td>
<td>

<p>Logical, should the model be updated?
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_startepc">startEPC</code></td>
<td>

<p>Logical, should the starting value be set at the expected parameter change?
</p>
</td></tr>
<tr><td><code id="fixpar_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>runmodel</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='fixstart'>
Attempt to Fix Starting Values
</h2><span id='topic+fixstart'></span>

<h3>Description</h3>

<p>This function attempts to fix starting values by comparing the analytic gradient to a numerically approximated gradient. Parameters with a difference between the analytic and numeric gradient that exceeds 'maxdiff' will be reduced by a factor of 'reduce' in each iteration until the average absolute difference between analytic and numeric gradients is lower than 'tol'. Only off-diagonal elements in omega, sigma, kappa, lowertri or rho matrices or any element in beta matrices are adjusted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixstart(x, reduce = 0.5, maxdiff = 0.1, tol = 0.01, maxtry = 25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixstart_+3A_x">x</code></td>
<td>

<p>A 'psychonetrics' model
</p>
</td></tr>
<tr><td><code id="fixstart_+3A_reduce">reduce</code></td>
<td>

<p>The factor with which problematic parameters are reduced in each iteration.
</p>
</td></tr>
<tr><td><code id="fixstart_+3A_maxdiff">maxdiff</code></td>
<td>

<p>Maximum difference between analytic and numeric gradient to be considered problematic.
</p>
</td></tr>
<tr><td><code id="fixstart_+3A_tol">tol</code></td>
<td>

<p>Average absolute difference between analytic and numeric gradient that is considered acceptable.
</p>
</td></tr>
<tr><td><code id="fixstart_+3A_maxtry">maxtry</code></td>
<td>

<p>Maximum number of iterations to attempt to fix starting values.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='generate'>
Generate data from a fitted psychonetrics object
</h2><span id='topic+generate'></span>

<h3>Description</h3>

<p>This function will generate new data from the estimated mean and variance-covariance structure of a psychonetrics model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate(x, n = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="generate_+3A_n">n</code></td>
<td>

<p>Number of cases to sample per group.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with simulated data
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='getmatrix'>
Extract an estimated matrix
</h2><span id='topic+getmatrix'></span>

<h3>Description</h3>

<p>This function will extract an estimated matrix, and will either return a single matrix for single group models or a list of such matrices for multiple group models. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getmatrix(x, matrix, group, threshold = FALSE, alpha = 0.01,
           adjust = c("none", "holm", "hochberg", "hommel",
           "bonferroni", "BH", "BY", "fdr"), mode = c("tested",
           "all"), diag = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getmatrix_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_matrix">matrix</code></td>
<td>

<p>String indicating the matrix to be extracted.
</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_group">group</code></td>
<td>

<p>Integer indicating the group for the matrix to be extracted.
</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_threshold">threshold</code></td>
<td>
<p>Logical. Should the matrix be thresholded (non-significant values set to zero? Can also be a value with an absolute threshold below wich parameters are set to zero.)</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_alpha">alpha</code></td>
<td>

<p>Significance level to use.
</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_adjust">adjust</code></td>
<td>

<p>p-value adjustment method to use. See <code>p.adjust</code>.
</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_mode">mode</code></td>
<td>

<p>Mode for adjusting for multiple comparisons. Should all parameters be considered as the total number of tests or only the tested parameters (parameters of interest)?
</p>
</td></tr>
<tr><td><code id="getmatrix_+3A_diag">diag</code></td>
<td>
<p>Set to FALSE to set diagonal elements to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of parameter estimates, of a list of such matrices for multiple group models.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars, omega = "full")

# Run model:
mod &lt;- mod %&gt;% runmodel

# Obtain network:
mod %&gt;% getmatrix("omega")
</code></pre>

<hr>
<h2 id='getVCOV'>
Obtain the asymptotic covariance matrix
</h2><span id='topic+getVCOV'></span>

<h3>Description</h3>

<p>This function can be used to obtain the estimated asymptotic covariance matrix from a <code>psychonetrics</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getVCOV(model, approximate_SEs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getVCOV_+3A_model">model</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="getVCOV_+3A_approximate_ses">approximate_SEs</code></td>
<td>

<p>Logical, should standard errors be approximated? If true, an approximate matrix inverse of the Fischer information is used to obtain the standard errors.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a matrix.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='groupequal'>
Group equality constrains
</h2><span id='topic+groupequal'></span><span id='topic+groupfree'></span>

<h3>Description</h3>

<p>The <code>groupequal</code> function constrains parameters equal across groups, and the <code>groupfree</code> function frees equality constrains across groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>groupequal(x, matrix, row, col, verbose, log = TRUE, runmodel =
                    FALSE, identify = TRUE, ...)

groupfree(x, matrix, row, col, verbose, log = TRUE, runmodel =
                    FALSE, identify = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="groupequal_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_matrix">matrix</code></td>
<td>

<p>String indicating the matrix of the parameter
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_row">row</code></td>
<td>

<p>Integer or string indicating the row of the matrix of the parameter
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_col">col</code></td>
<td>

<p>Integer or string indicating the column of the matrix of the parameter
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_log">log</code></td>
<td>

<p>Logical, should the log be updated?
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_runmodel">runmodel</code></td>
<td>

<p>Logical, should the model be updated?
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be identified?
</p>
</td></tr>
<tr><td><code id="groupequal_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>runmodel</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='Ising'>
Ising model
</h2><span id='topic+Ising'></span>

<h3>Description</h3>

<p>This is the family of Ising models fit to dichotomous datasets. Note that the input matters (see also https://arxiv.org/abs/1811.02916) in this model! Models based on a dataset that is encoded with -1 and 1 are not entirely equivalent to models based on datasets encoded with 0 and 1 (non-equivalences occur in multi-group settings with equality constrains). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ising(data, omega = "full", tau, beta, vars, groups, covs,
                   means, nobs, covtype = c("choose", "ML", "UB"),
                   responses, missing = "listwise", equal = "none",
                   baseline_saturated = TRUE, estimator = "default",
                   optimizer, storedata = FALSE, WLS.W, sampleStats,
                   identify = TRUE, verbose = FALSE, maxNodes = 20,
                   min_sum = -Inf, bootstrap = FALSE, boot_sub,
                   boot_resample)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ising_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_omega">omega</code></td>
<td>

<p>The network structure. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions nNode x nNode with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_tau">tau</code></td>
<td>

<p>Optional vector encoding the threshold/intercept structure. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_beta">beta</code></td>
<td>

<p>Optional scalar encoding the inverse temperature. 1 indicate free beta parameters, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such scalers.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_vars">vars</code></td>
<td>

<p>An optional character vector encoding the variables used in the analyis. Must equal names of the dataset in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_groups">groups</code></td>
<td>

<p>An optional character vector encoding the variables used in the analyis. Must equal names of the dataset in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. Make sure <code>covtype</code> argument is set correctly to the type of covariances used. 
</p>
</td></tr>
<tr><td><code id="Ising_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_covtype">covtype</code></td>
<td>

<p>If 'covs' is used, this is the type of covariance (maximum likelihood or unbiased) the input covariance matrix represents. Set to <code>"ML"</code> for maximum likelihood estimates (denominator n) and <code>"UB"</code> to unbiased estimates (denominator n-1). The default will try to find the type used, by investigating which is most likely to result from integer valued datasets.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_responses">responses</code></td>
<td>

<p>A vector of dichotemous responses used (e.g., <code>c(-1,1)</code> or <code>c(0,1)</code>. Only needed when 'covs' is used.)
</p>
</td></tr>
<tr><td><code id="Ising_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion. NOT RECOMMENDED TO BE USED YET IN ISING MODEL.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="Ising_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation, <code>"FIML"</code> for full-information maximum likelihood estimation, <code>"ULS"</code> for unweighted least squares estimation, <code>"WLS"</code> for weighted least squares estimation, and <code>"DWLS"</code> for diagonally weighted least squares estimation. Only ML estimation is currently supported for the Ising model. 
</p>
</td></tr>
<tr><td><code id="Ising_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code>bootstrap</code>).
</p>
</td></tr>
<tr><td><code id="Ising_+3A_wls.w">WLS.W</code></td>
<td>

<p>Optional WLS weights matrix. CURRENTLY NOT USED.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="Ising_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be identified?
</p>
</td></tr>
<tr><td><code id="Ising_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="Ising_+3A_maxnodes">maxNodes</code></td>
<td>

<p>The maximum number of nodes allowed in the analysis. This function will stop with an error if more nodes are used (it is not recommended to set this higher).
</p>
</td></tr>
<tr><td><code id="Ising_+3A_min_sum">min_sum</code></td>
<td>

<p>The minimum sum score that is artifically possible in the dataset. Defaults to -Inf. Set this only if you know a lower sum score is not possible in the data, for example due to selection bias.
</p>
</td></tr>
<tr><td><code id="Ising_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="Ising_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="Ising_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Ising Model takes the following form:
</p>
<p><code class="reqn">\Pr(\boldsymbol{Y} = \boldsymbol{y})  =  \frac{\exp\left( -\beta H\left(\boldsymbol{y}; \boldsymbol{\tau}, \boldsymbol{\Omega}\right)\right)}{Z(\boldsymbol{\tau}, \boldsymbol{\Omega})}</code>
</p>
<p>With Hamiltonian:
</p>
<p><code class="reqn">H\left(\boldsymbol{y}; \boldsymbol{\tau}, \boldsymbol{\Omega}\right) = -\sum_{i=1}^{m} \tau_i y_{i} - \sum_{i=2}^{m} \sum_{j=1}^{i-1} \omega_{ij} y_i y_j.</code>
</p>
<p>And Z representing the partition function or normalizing constant.
</p>


<h3>Value</h3>

<p>An object of the class psychonetrics 
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>


<h3>References</h3>

<p>Epskamp, S., Maris, G., Waldorp, L. J., &amp; Borsboom, D. (2018). Network Psychometrics. In: Irwing, P., Hughes, D., &amp; Booth, T. (Eds.), The Wiley Handbook of Psychometric Testing, 2 Volume Set: A Multidisciplinary Reference on Survey, Scale and Test Development. New York: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("dplyr")
data("Jonas")

# Variables to use:
vars &lt;- names(Jonas)[1:10]

# Arranged groups to put unfamiliar group first (beta constrained to 1):
Jonas &lt;- Jonas[order(Jonas$group),]

# Form saturated model:
model1 &lt;- Ising(Jonas, vars = vars, groups = "group")

# Run model:
model1 &lt;- model1 %&gt;% runmodel(approximate_SEs = TRUE)
# We approximate the SEs because there are zeroes in the crosstables
# of people that know Jonas. This leads to uninterpretable edge
# estimates, but as can be seen below only in the model with
# non-equal estimates across groups.

# Prune-stepup to find a sparse model:
model1b &lt;- model1 %&gt;% prune(alpha = 0.05) %&gt;%  stepup(alpha = 0.05)

# Equal networks:
suppressWarnings(
  model2 &lt;- model1 %&gt;% groupequal("omega") %&gt;% runmodel
)

# Prune-stepup to find a sparse model:
model2b &lt;- model2 %&gt;% prune(alpha = 0.05) %&gt;% stepup(mi = "mi_equal", alpha = 0.05)

# Equal thresholds:
model3 &lt;- model2 %&gt;% groupequal("tau") %&gt;% runmodel

# Prune-stepup to find a sparse model:
model3b &lt;- model3 %&gt;% prune(alpha = 0.05) %&gt;% stepup(mi = "mi_equal", alpha = 0.05)

# Equal beta:
model4 &lt;- model3 %&gt;% groupequal("beta") %&gt;% runmodel

# Prune-stepup to find a sparse model:
model4b &lt;- model4 %&gt;% prune(alpha = 0.05) %&gt;% stepup(mi = "mi_equal", alpha = 0.05)

# Compare all models:
compare(
  `1. all parameters free (dense)` = model1,
  `2. all parameters free (sparse)` = model1b,
  `3. equal networks (dense)` = model2,
  `4. equal networks (sparse)` = model2b,
  `5. equal networks and thresholds (dense)` = model3,
  `6. equal networks and thresholds (sparse)` = model3b,
  `7. all parameters equal (dense)` = model4,
  `8. all parameters equal (sparse)` = model4b
) %&gt;% arrange(BIC)

</code></pre>

<hr>
<h2 id='Jonas'>
Jonas dataset
</h2><span id='topic+Jonas'></span>

<h3>Description</h3>

<p>Responses of 10 attitude items towards a researcher named Jonas. Participants were shown three photos of Jonas with the text: &quot;This is Jonas, a researcher from Germany who is now becoming a PhD in Psychology&quot;. Subsequently, the participants had to answer 10 yes / no questions starting with &quot;I believe that Jonas...&quot;, as well as rate their familliarity with Jonas. The sample consists of people familiar with Jonas and not familiar with Jonas, and allows for testing Attitudinal Entropy Framework &lt;doi:10.1080/1047840X.2018.1537246&gt;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Jonas")</code></pre>


<h3>Format</h3>

<p>A data frame with 215 observations on the following 12 variables. 
</p>

<dl>
<dt><code>scientist</code></dt><dd><p>... is a good scientist</p>
</dd>
<dt><code>jeans</code></dt><dd><p>... Is a person that wears beautiful jeans</p>
</dd>
<dt><code>cares</code></dt><dd><p>... really cares about people like you</p>
</dd>
<dt><code>economics</code></dt><dd><p>... would solve our economic problems</p>
</dd>
<dt><code>hardworking</code></dt><dd><p>... is hardworking</p>
</dd>
<dt><code>honest</code></dt><dd><p>... is honest</p>
</dd>
<dt><code>intouch</code></dt><dd><p>... is in touch with ordinary people</p>
</dd>
<dt><code>knowledgeable</code></dt><dd><p>... is knowledgeable</p>
</dd>
<dt><code>makeupmind</code></dt><dd><p>... can't make up his mind</p>
</dd>
<dt><code>getsthingsdone</code></dt><dd><p>... gets things done</p>
</dd>
<dt><code>familiar</code></dt><dd><p>Answers to the question &quot;How familiar are you with Jonas?&quot; (three responses possible)</p>
</dd>
<dt><code>group</code></dt><dd><p>The question 'familiar' categorized in two groups (&quot;Knows Jonas&quot; and &quot;Doesn't Know Jonas&quot;)</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(Jonas)
</code></pre>

<hr>
<h2 id='latentgrowth'>
Latnet growth curve model
</h2><span id='topic+latentgrowth'></span>

<h3>Description</h3>

<p>Wrapper to <code>lvm</code> to specify a latent growth curve model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>latentgrowth(vars, time = seq_len(ncol(vars)) - 1, covariates =
                   character(0), covariates_as = c("regression",
                   "covariance"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="latentgrowth_+3A_vars">vars</code></td>
<td>

<p>Different from in other psychonetrics models, this must be a *matrix* with each row indicating a variable and each column indicating a measurement. The matrix must be filled with names of the variables in the dataset corresponding to variable i at wave j. NAs can be used to indicate missing waves. The rownames of this matrix will be used as variable names.
</p>
</td></tr>
<tr><td><code id="latentgrowth_+3A_time">time</code></td>
<td>

<p>A vector with the encoding of each measurement (e.g., 0, 1, 2, 3).
</p>
</td></tr>
<tr><td><code id="latentgrowth_+3A_covariates">covariates</code></td>
<td>

<p>A vector with strings indicating names of between-person covariate variables in the data
</p>
</td></tr>
<tr><td><code id="latentgrowth_+3A_covariates_as">covariates_as</code></td>
<td>

<p>Should covariates be included as regressions or actual covariates?
</p>
</td></tr>
<tr><td><code id="latentgrowth_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+lvm">lvm</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://github.com/SachaEpskamp/SEM-code-examples/tree/master/Latent_growth_examples/psychonetrics">https://github.com/SachaEpskamp/SEM-code-examples/tree/master/Latent_growth_examples/psychonetrics</a> for examples
</p>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>). See for an example <a href="https://github.com/SachaEpskamp/SEM-code-examples/tree/master/Latent_growth_examples/psychonetrics">https://github.com/SachaEpskamp/SEM-code-examples/tree/master/Latent_growth_examples/psychonetrics</a>.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("dplyr")

# Smoke data cov matrix, based on LISS data panel https://www.dataarchive.lissdata.nl
smoke &lt;- structure(c(47.2361758611759, 43.5366809116809, 41.0057465682466, 
                     43.5366809116809, 57.9789886039886, 47.6992521367521, 
                     41.0057465682466, 
                     47.6992521367521, 53.0669434731935), .Dim = c(3L, 3L), 
                   .Dimnames = list(
                       c("smoke2008", "smoke2009", "smoke2010"), c("smoke2008", 
                   "smoke2009", "smoke2010")))

# Design matrix:
design &lt;- matrix(rownames(smoke),1,3)

# Form model:
mod &lt;- latentgrowth(vars = design, 
                covs = smoke, nobs = 352
)

## Not run: 
# Run model:
mod &lt;- mod %&gt;% runmodel

# Evaluate fit:
mod %&gt;% fit

# Look at parameters:
mod %&gt;% parameters

## End(Not run)
</code></pre>

<hr>
<h2 id='logbook'>
Retrieve the psychonetrics logbook
</h2><span id='topic+logbook'></span>

<h3>Description</h3>

<p>This function can be used to retrieve the logbook of a 'psychonetrics' object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logbook(x, log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logbook_+3A_x">x</code></td>
<td>

<p>A 'psychonetrics' object.
</p>
</td></tr>
<tr><td><code id="logbook_+3A_log">log</code></td>
<td>

<p>Logical, should the entry that the logbook is accessed be added?
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='lvm'>
Continuous latent variable family of psychonetrics models
</h2><span id='topic+lvm'></span><span id='topic+lnm'></span><span id='topic+rnm'></span><span id='topic+lrnm'></span>

<h3>Description</h3>

<p>This is the family of models that models the data as a structural equation model (SEM), allowing the latent and residual variance-covariance matrices to be further modeled as networks. The <code>latent</code> and <code>residual</code> arguments can be used to define what latent and residual models are used respectively: <code>"cov"</code> (default) models a variance-covariance matrix directly, <code>"chol"</code> models a Cholesky decomposition, <code>"prec"</code> models a precision matrix, and <code>"ggm"</code> models a Gaussian graphical model (Epskamp, Rhemtulla and Borsboom, 2017). The wrapper <code>lnm()</code> sets <code>latent = "ggm"</code> for the latent network model (LNM), the wrapper  <code>rnm()</code> sets <code>residual = "ggm"</code> for the residual network model (RNM), and the wrapper  <code>lrnm()</code> combines the LNM and RNM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lvm(data, lambda, latent = c("cov", "chol", "prec",
                   "ggm"), residual = c("cov", "chol", "prec", "ggm"),
                   sigma_zeta = "full", kappa_zeta = "full", omega_zeta =
                   "full", lowertri_zeta = "full", delta_zeta = "full",
                   sigma_epsilon = "diag", kappa_epsilon = "diag",
                   omega_epsilon = "zero", lowertri_epsilon = "diag",
                   delta_epsilon = "diag", beta = "zero", nu, nu_eta,
                   identify = TRUE, identification = c("loadings",
                   "variance"), vars, latents, groups, covs, means, nobs,
                   missing = "listwise", equal = "none",
                   baseline_saturated = TRUE, estimator = "ML",
                   optimizer, storedata = FALSE, WLS.W, covtype =
                   c("choose", "ML", "UB"), standardize = c("none", "z",
                   "quantile"), sampleStats, verbose = FALSE,
                   simplelambdastart = FALSE, bootstrap = FALSE,
                   boot_sub, boot_resample)

lnm(...)
rnm(...)
lrnm(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lvm_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_lambda">lambda</code></td>
<td>

<p>A model matrix encoding the factor loading structure. Each row indicates an indicator and each column a latent. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_latent">latent</code></td>
<td>

<p>The type of latent model used. See description.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_residual">residual</code></td>
<td>

<p>The type of residual model used. See description.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_sigma_zeta">sigma_zeta</code></td>
<td>

<p>Only used when <code>latent = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_kappa_zeta">kappa_zeta</code></td>
<td>

<p>Only used when <code>latent = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_omega_zeta">omega_zeta</code></td>
<td>

<p>Only used when <code>latent = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_lowertri_zeta">lowertri_zeta</code></td>
<td>

<p>Only used when <code>latent = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_delta_zeta">delta_zeta</code></td>
<td>

<p>Only used when <code>latent = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code>, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_sigma_epsilon">sigma_epsilon</code></td>
<td>

<p>Only used when <code>residual = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_kappa_epsilon">kappa_epsilon</code></td>
<td>

<p>Only used when <code>residual = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_omega_epsilon">omega_epsilon</code></td>
<td>

<p>Only used when <code>residual = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_lowertri_epsilon">lowertri_epsilon</code></td>
<td>

<p>Only used when <code>residual = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_delta_epsilon">delta_epsilon</code></td>
<td>

<p>Only used when <code>residual = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code>, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_beta">beta</code></td>
<td>

<p>A model matrix encoding the structural relations between latent variables. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_nu">nu</code></td>
<td>

<p>Optional vector encoding the intercepts of the observed variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_nu_eta">nu_eta</code></td>
<td>

<p>Optional vector encoding the intercepts of the latent variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be automatically identified?
</p>
</td></tr>
<tr><td><code id="lvm_+3A_identification">identification</code></td>
<td>

<p>Type of identification used. <code>"loadings"</code> to fix the first factor loadings to 1, and <code>"variance"</code> to fix the diagonal of the latent variable model matrix (sigma_zeta, lowertri_zeta, delta_zeta or kappa_zeta) to 1.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_vars">vars</code></td>
<td>

<p>An optional character vector encoding the variables used in the analysis. Must equal names of the dataset in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_latents">latents</code></td>
<td>

<p>An optional character vector with names of the latent variables.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. Make sure <code>covtype</code> argument is set correctly to the type of covariances used. 
</p>
</td></tr>
<tr><td><code id="lvm_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="lvm_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation, <code>"FIML"</code> for full-information maximum likelihood estimation, <code>"ULS"</code> for unweighted least squares estimation, <code>"WLS"</code> for weighted least squares estimation, and <code>"DWLS"</code> for diagonally weighted least squares estimation.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code><a href="#topic+bootstrap">bootstrap</a></code>).
</p>
</td></tr>
<tr><td><code id="lvm_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should progress be printed to the console?
</p>
</td></tr>
<tr><td><code id="lvm_+3A_wls.w">WLS.W</code></td>
<td>

<p>The weights matrix used in WLS estimation (experimental)
</p>
</td></tr>
<tr><td><code id="lvm_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="lvm_+3A_covtype">covtype</code></td>
<td>

<p>If 'covs' is used, this is the type of covariance (maximum likelihood or unbiased) the input covariance matrix represents. Set to <code>"ML"</code> for maximum likelihood estimates (denominator n) and <code>"UB"</code> to unbiased estimates (denominator n-1). The default will try to find the type used, by investigating which is most likely to result from integer valued datasets.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_standardize">standardize</code></td>
<td>

<p>Which standardization method should be used? <code>"none"</code> (default) for no standardization, <code>"z"</code> for z-scores, and <code>"quantile"</code> for a non-parametric transformation to the quantiles of the marginal standard normal distribution.
</p>
</td></tr>
<tr><td><code id="lvm_+3A_simplelambdastart">simplelambdastart</code></td>
<td>
<p>Logical, should simple start values be used for lambda? Setting this to TRUE can avoid some estimation problems.</p>
</td></tr>
<tr><td><code id="lvm_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="lvm_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="lvm_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="lvm_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>varcov</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model used in this family is:
</p>
<p><code class="reqn">\mathrm{var}( \boldsymbol{y} ) = \boldsymbol{\Lambda} (\boldsymbol{I} - \boldsymbol{B})^{-1} \boldsymbol{\Sigma}_{\zeta}  (\boldsymbol{I} - \boldsymbol{B})^{-1\top}  \boldsymbol{\Lambda}^{\top} +  \boldsymbol{\Sigma}_{\varepsilon} </code>
</p>
<p><code class="reqn">\mathcal{E}( \boldsymbol{y} ) = \boldsymbol{\nu} +  \boldsymbol{\Lambda}  (\boldsymbol{I} - \boldsymbol{B})^{-1} \boldsymbol{\nu}_eta</code>
</p>
<p>in which the latent covariance matrix can further be modeled in three ways. With <code>latent = "chol"</code> as Cholesky decomposition:
</p>
<p><code class="reqn">\boldsymbol{\Sigma}_{\zeta} = \boldsymbol{L}_{\zeta}\boldsymbol{L}_{\zeta}</code>,
</p>
<p>with <code>latent = "prec"</code> as Precision matrix:
</p>
<p><code class="reqn">\boldsymbol{\Sigma}_{\zeta} = \boldsymbol{K}_{\zeta}^{-1}</code>,
</p>
<p>and finally with <code>latent = "ggm"</code> as Gaussian graphical model:
</p>
<p><code class="reqn">\boldsymbol{\Sigma}_{\zeta} = \boldsymbol{\Delta}_{\zeta}(\boldsymbol{I} - \boldsymbol{\Omega}_{\zeta})^(-1) \boldsymbol{\Delta}_{\zeta}</code>.
</p>
<p>Likewise, the residual covariance matrix can also further be modeled in three ways. With <code>residual = "chol"</code> as Cholesky decomposition:
</p>
<p><code class="reqn">\boldsymbol{\Sigma}_{\varepsilon} = \boldsymbol{L}_{\varepsilon}\boldsymbol{L}_{\varepsilon}</code>,
</p>
<p>with <code>latent = "prec"</code> as Precision matrix:
</p>
<p><code class="reqn">\boldsymbol{\Sigma}_{\varepsilon} = \boldsymbol{K}_{\varepsilon}^{-1}</code>,
</p>
<p>and finally with <code>latent = "ggm"</code> as Gaussian graphical model:
</p>
<p><code class="reqn">\boldsymbol{\Sigma}_{\varepsilon} = \boldsymbol{\Delta}_{\varepsilon}(\boldsymbol{I} - \boldsymbol{\Omega}_{\varepsilon})^(-1) \boldsymbol{\Delta}_{\varepsilon}</code>.
</p>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>References</h3>

<p>Epskamp, S., Rhemtulla, M., &amp; Borsboom, D. (2017). Generalized network psychometrics: Combining network and latent variable models. Psychometrika, 82(4), 904-927.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("dplyr")

### Confirmatory Factor Analysis ###

# Example also shown in https://youtu.be/Hdu5z-fwuk8

# Load data:
data(StarWars)

# Originals only:
Lambda &lt;- matrix(1,4)

# Model:
mod0 &lt;- lvm(StarWars, lambda = Lambda, vars = c("Q1","Q5","Q6","Q7"), 
            identification = "variance", latents = "Originals")
            
# Run model:
mod0 &lt;- mod0 %&gt;% runmodel

# Evaluate fit:
mod0 %&gt;% fit


# Full analysis
# Factor loadings matrix:
Lambda &lt;- matrix(0, 10, 3)
Lambda[1:4,1] &lt;- 1
Lambda[c(1,5:7),2] &lt;- 1
Lambda[c(1,8:10),3] &lt;- 1

# Observed variables:
obsvars &lt;- paste0("Q",1:10)

# Latents:
latents &lt;- c("Prequels","Original","Sequels")

# Make model:
mod1 &lt;- lvm(StarWars, lambda = Lambda, vars = obsvars, 
            identification = "variance", latents = latents)

# Run model:
mod1 &lt;- mod1 %&gt;% runmodel

# Look at fit:
mod1

# Look at parameter estimates:
mod1 %&gt;% parameters

# Look at modification indices:
mod1 %&gt;% MIs

# Add and refit:
mod2 &lt;- mod1 %&gt;% freepar("sigma_epsilon","Q10","Q4") %&gt;% runmodel

# Compare:
compare(original = mod1, adjusted = mod2)

# Fit measures:
mod2 %&gt;% fit

### Path diagrams ###
# semPlot is not (yet) supported by default, but can be used as follows:
# Load packages:
library("semPlot")

# Estimates:
lambdaEst &lt;- getmatrix(mod2, "lambda")
psiEst &lt;- getmatrix(mod2, "sigma_zeta")
thetaEst &lt;- getmatrix(mod2, "sigma_epsilon")

# LISREL Model: LY = Lambda (lambda-y), TE = Theta (theta-epsilon), PS = Psi
mod &lt;- lisrelModel(LY =  lambdaEst, PS = psiEst, TE = thetaEst)

# Plot with semPlot:
semPaths(mod, "std", "est", as.expression = "nodes")


# We can make this nicer (set whatLabels = "none" to hide labels):
semPaths(mod,

# this argument controls what the color of edges represent. In this case, 
# standardized parameters:
    what = "std", 
    
# This argument controls what the edge labels represent. In this case, parameter 
# estimates:
    whatLabels = "est", 
    
# This argument draws the node and edge labels as mathematical exprssions:    
    as.expression = "nodes", 
  
# This will plot residuals as arrows, closer to what we use in class:
    style = "lisrel",
    
# This makes the residuals larger:
    residScale = 10, 
    
# qgraph colorblind friendly theme:
    theme = "colorblind",
    
# tree layout options are "tree", "tree2", and "tree3":
    layout = "tree2", 

# This makes the latent covariances connect at a cardinal center point:
    cardinal = "lat cov",

# Changes curve into rounded straight lines:
    curvePivot = TRUE, 
    
# Size of manifest variables:
    sizeMan = 4, 
    
# Size of latent varibales:
    sizeLat = 10, 
    
# Size of edge labels:
    edge.label.cex = 1,
    
# Sets the margins:
    mar = c(9,1,8,1), 
    
# Prevents re-ordering of ovbserved variables:
    reorder = FALSE, 
    
# Width of the plot:
    width = 8, 
    
# Height of plot:
    height = 5, 

# Colors according to latents:
    groups = "latents",
    
# Pastel colors:
    pastel = TRUE, 
    
# Disable borders:
    borders = FALSE 
    )
    
# Use arguments filetype = "pdf" and filename = "semPlotExample1" to store PDF

### Latent Network Modeling ###

# Latent network model:
lnm &lt;- lvm(StarWars, lambda = Lambda, vars = obsvars,
           latents = latents, identification = "variance",
           latent = "ggm")

# Run model:
lnm &lt;- lnm %&gt;% runmodel

# Look at parameters:
lnm %&gt;% parameters

# Remove non-sig latent edge:
lnm &lt;- lnm %&gt;% prune(alpha = 0.05)

# Compare to the original CFA model:
compare(cfa = mod1, lnm = lnm)

# Plot network:
library("qgraph")
qgraph(lnm@modelmatrices[[1]]$omega_zeta, labels = latents,
       theme = "colorblind", vsize = 10)

# A wrapper for the latent network model is the lnm function:
lnm2 &lt;- lnm(StarWars, lambda = Lambda, vars = obsvars,
            latents = latents, identification = "variance")
lnm2 &lt;- lnm2 %&gt;% runmodel %&gt;% prune(alpha = 0.05)
compare(lnm, lnm2) # Is the same as the model before.

# I could also estimate a "residual network model", which adds partial correlations to 
# the residual level:
# This can be done using lvm(..., residal = "ggm") or with rnm(...)
rnm &lt;- rnm(StarWars, lambda = Lambda, vars = obsvars,
           latents = latents, identification = "variance")
# Stepup search:
rnm &lt;- rnm %&gt;% stepup

# It will estimate the same model (with link Q10 - Q4) as above. In the case of only one 
# partial correlation, There is no difference between residual covariances (SEM) or 
# residual partial correlations (RNM).


# For more information on latent and residual network models, see:
# Epskamp, S., Rhemtulla, M.T., &amp; Borsboom, D. Generalized Network Psychometrics: 
# Combining Network and Latent Variable Models 
# (2017). Psychometrika. doi:10.1007/s11336-017-9557-x

### Gaussian graphical models ###

# All psychonetrics functions (e.g., lvm, lnm, rnm...) allow input via a covariance 
# matrix, with the "covs" and "nobs" arguments.
# The following fits a baseline GGM network with no edges:
S &lt;- (nrow(StarWars) - 1)/ (nrow(StarWars)) * cov(StarWars[,1:10])
ggmmod &lt;- ggm(covs = S, nobs = nrow(StarWars))

# Run model with stepup search and pruning:
ggmmod &lt;- ggmmod%&gt;% prune  %&gt;% modelsearch

# Fit measures:
ggmmod %&gt;% fit

# Plot network:
nodeNames &lt;- c(
"I am a huge Star Wars\nfan! (star what?)",
"I would trust this person\nwith my democracy.",
"I enjoyed the story of\nAnakin's early life.",
"The special effects in\nthis scene are awful (Battle of\nGeonosis).",
"I would trust this person\nwith my life.",
"I found Darth Vader's big\nreveal in 'Empire' one of the greatest
moments in movie history.",
"The special effects in\nthis scene are amazing (Death Star\nExplosion).",
"If possible, I would\ndefinitely buy this\ndroid.",
"The story in the Star\nWars sequels is an improvement to\nthe previous movies.",
"The special effects in\nthis scene are marvellous (Starkiller\nBase Firing)."
)
library("qgraph")
qgraph(as.matrix(ggmmod@modelmatrices[[1]]$omega), nodeNames = nodeNames, 
    legend.cex = 0.25,  theme = "colorblind", layout = "spring")

# We can actually compare this model statistically (note they are not nested) to the 
# latent variable model:
compare(original_cfa = mod1, adjusted_cfa = mod2, exploratory_ggm = ggmmod)


### Meausrement invariance ###
# Let's say we are interested in seeing if people &gt;= 30 like the original trilogy better 
# than people &lt; 30.
# First we can make a grouping variable:
StarWars$agegroup &lt;- ifelse(StarWars$Q12 &lt; 30, "young", "less young")

# Let's look at the distribution:
table(StarWars$agegroup) # Pretty even...

# Observed variables:
obsvars &lt;- paste0("Q",1:10)

# Let's look at the mean scores:
StarWars %&gt;% group_by(agegroup) %&gt;% summarize_each_(funs(mean),vars = obsvars)
# Less young people seem to score higher on prequel questions and lower on other 
# questions

# Factor loadings matrix:
Lambda &lt;- matrix(0, 10, 3)
Lambda[1:4,1] &lt;- 1
Lambda[c(1,5:7),2] &lt;- 1
Lambda[c(1,8:10),3] &lt;- 1

# Residual covariances:
Theta &lt;- diag(1, 10)
Theta[4,10] &lt;- Theta[10,4] &lt;- 1

# Latents:
latents &lt;- c("Prequels","Original","Sequels")

# Make model:
mod_configural &lt;- lvm(StarWars, lambda = Lambda, vars = obsvars,
            latents = latents, sigma_epsilon = Theta,
            identification = "variance",
            groups =  "agegroup")

# Run model:
mod_configural &lt;- mod_configural %&gt;% runmodel

# Look at fit:
mod_configural
mod_configural %&gt;% fit

# Looks good, let's try weak invariance:
mod_weak &lt;- mod_configural %&gt;% groupequal("lambda") %&gt;% runmodel

# Compare models:
compare(configural = mod_configural, weak = mod_weak)

# weak invariance can be accepted, let's try strong:
mod_strong &lt;- mod_weak %&gt;% groupequal("nu") %&gt;% runmodel
# Means are automatically identified

# Compare models:
compare(configural = mod_configural, weak = mod_weak, strong = mod_strong)

# Questionable p-value and AIC difference, but ok BIC difference. This is quite good, but 
# let's take a look. I have not yet implemented LM tests for equality constrains, but we 
# can look at something called "equality-free" MIs:
mod_strong %&gt;% MIs(matrices = "nu", type = "free")

# Indicates that Q10 would improve fit. We can also look at residuals:
residuals(mod_strong)

# Let's try freeing intercept 10:
mod_strong_partial &lt;- mod_strong %&gt;% groupfree("nu",10) %&gt;% runmodel

# Compare all models:
compare(configural = mod_configural,
        weak = mod_weak,
        strong = mod_strong,
        strong_partial = mod_strong_partial)

# This seems worth it and lead to an acceptable model! It seems that older people find 
# the latest special effects more marvellous!
mod_strong_partial %&gt;% getmatrix("nu")

# Now let's investigate strict invariance:
mod_strict &lt;- mod_strong_partial %&gt;% groupequal("sigma_epsilon") %&gt;% runmodel

# Compare all models:
compare(configural = mod_configural,
        weak = mod_weak,
        strong_partial = mod_strong_partial,
        strict = mod_strict)
# Strict invariance can be accepted!

#  Now we can test for homogeneity!
# Are the latent variances equal?
mod_eqvar &lt;- mod_strict %&gt;% groupequal("sigma_zeta") %&gt;% runmodel

# Compare:
compare(strict = mod_strict, eqvar = mod_eqvar) 

# This is acceptable. What about the means? (alpha = nu_eta)
mod_eqmeans &lt;- mod_eqvar %&gt;% groupequal("nu_eta") %&gt;% runmodel

# Compare:
compare(eqvar = mod_eqvar, eqmeans = mod_eqmeans)

# Rejected! We could look at MIs again:
mod_eqmeans %&gt;% MIs(matrices = "nu_eta", type = "free")

# Indicates the strongest effect for prequels. Let's see what happens:
eqmeans2 &lt;- mod_eqvar %&gt;% 
  groupequal("nu_eta",row = c("Original","Sequels")) %&gt;% runmodel

# Compare:
compare(eqvar = mod_eqvar, eqmeans = eqmeans2)
# Questionable, what about the sequels as well?

eqmeans3 &lt;- mod_eqvar %&gt;% groupequal("nu_eta", row = "Original") %&gt;% runmodel

# Compare:
compare(eqvar = mod_eqvar, eqmeans = eqmeans3)

# Still questionable.. Let's look at the mean differences:
mod_eqvar %&gt;% getmatrix("nu_eta")

# Looks like people over 30 like the prequels better and the other two trilogies less!

</code></pre>

<hr>
<h2 id='meta_varcov'>
Variance-covariance and GGM meta analysis
</h2><span id='topic+meta_varcov'></span><span id='topic+meta_ggm'></span>

<h3>Description</h3>

<p>Meta analysis of correlation matrices to fit a homogenous correlation matrix or Gaussian graphical model. Based on meta-analytic SEM (Jak and Cheung, 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_varcov(cors, nobs, Vmats, Vmethod = c("individual", "pooled",
                   "metaSEM_individual", "metaSEM_weighted"), Vestimation
                   = c("averaged", "per_study"), type = c("cor", "ggm"),
                   sigma_y = "full", kappa_y = "full", omega_y = "full",
                   lowertri_y = "full", delta_y = "full", rho_y = "full",
                   SD_y = "full", randomEffects = c("chol", "cov",
                   "prec", "ggm", "cor"), sigma_randomEffects = "full",
                   kappa_randomEffects = "full", omega_randomEffects =
                   "full", lowertri_randomEffects = "full",
                   delta_randomEffects = "full", rho_randomEffects =
                   "full", SD_randomEffects = "full", vars,
                   baseline_saturated = TRUE, optimizer, estimator =
                   c("FIML", "ML"), sampleStats, verbose = FALSE,
                   bootstrap = FALSE, boot_sub, boot_resample)
  
meta_ggm(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meta_varcov_+3A_cors">cors</code></td>
<td>

<p>A list of correlation matrices. Must contain rows and columns with <code>NA</code>s for variables not included in a study. 
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_nobs">nobs</code></td>
<td>

<p>A vector with the number of observations per study.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_vmats">Vmats</code></td>
<td>

<p>Optional list with 'V' matrices (sampling error variance approximations).
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_vmethod">Vmethod</code></td>
<td>

<p>Which method should be used to apprixomate the sampling error variance?
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_vestimation">Vestimation</code></td>
<td>

<p>How should the sampling error estimates be evaluated?
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_type">type</code></td>
<td>

<p>What to model? Currently only <code>"cor"</code> and <code>"ggm"</code> are supported.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_sigma_y">sigma_y</code></td>
<td>

<p>Only used when <code>type = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_kappa_y">kappa_y</code></td>
<td>

<p>Only used when <code>type = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_omega_y">omega_y</code></td>
<td>

<p>Only used when <code>type = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_lowertri_y">lowertri_y</code></td>
<td>

<p>Only used when <code>type = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_delta_y">delta_y</code></td>
<td>

<p>Only used when <code>type = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code> (not recommended), or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_rho_y">rho_y</code></td>
<td>

<p>Only used when <code>type = "cor"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_sd_y">SD_y</code></td>
<td>

<p>Only used when <code>type = "cor"</code>. Either <code>"diag"</code> or <code>"zero"</code>, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_randomeffects">randomEffects</code></td>
<td>

<p>What to model for the random effects? 
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_sigma_randomeffects">sigma_randomEffects</code></td>
<td>

<p>Only used when <code>type = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_kappa_randomeffects">kappa_randomEffects</code></td>
<td>

<p>Only used when <code>randomEffects = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_omega_randomeffects">omega_randomEffects</code></td>
<td>

<p>Only used when <code>randomEffects = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_lowertri_randomeffects">lowertri_randomEffects</code></td>
<td>

<p>Only used when <code>randomEffects = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_delta_randomeffects">delta_randomEffects</code></td>
<td>

<p>Only used when <code>randomEffects = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code>, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_rho_randomeffects">rho_randomEffects</code></td>
<td>

<p>Only used when <code>randomEffects = "cor"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_sd_randomeffects">SD_randomEffects</code></td>
<td>

<p>Only used when <code>randomEffects = "cor"</code>. Either <code>"diag"</code> or <code>"zero"</code>, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_vars">vars</code></td>
<td>

<p>Variables to be included.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation or <code>"FIML"</code> for full-information maximum likelihood estimation.
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should progress be printed to the console?
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="meta_varcov_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>meta_varcov</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>


<h3>References</h3>

<p>Jak, S., and Cheung, M. W. L. (2019). Meta-analytic structural equation modeling with moderating effects on SEM parameters. Psychological methods.
</p>

<hr>
<h2 id='MIs'>
Print modification indices
</h2><span id='topic+MIs'></span>

<h3>Description</h3>

<p>This function prints a list of modification indices (MIs)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MIs(x, all = FALSE, matrices, type = c("normal", "equal", "free"), top = 10, 
    verbose = TRUE, nonZero = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MIs_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="MIs_+3A_all">all</code></td>
<td>

<p>Logical, should all MIs be printed or only the highest?
</p>
</td></tr>
<tr><td><code id="MIs_+3A_matrices">matrices</code></td>
<td>

<p>Optional vector of matrices to include in the output.
</p>
</td></tr>
<tr><td><code id="MIs_+3A_type">type</code></td>
<td>

<p>String indicating which kind of modification index should be printed. (<code>"mi"</code> is the typical MI, <code>"mi_free"</code> is the modification index free from equality constrains across groups, and <code>"mi_equal"</code> is the modification index if the parameter is added constrained equal across all groups).
</p>
</td></tr>
<tr><td><code id="MIs_+3A_top">top</code></td>
<td>

<p>Number of MIs to include in output if <code>all = FALSE</code>
</p>
</td></tr>
<tr><td><code id="MIs_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="MIs_+3A_nonzero">nonZero</code></td>
<td>

<p>Logical, should only MIs be printed of non-zero parameters? Useful to explore violations of group equality.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a relevant subset of the data frame containing all information on the parameters, or a list of such data frames if multiple types of MIs are requested.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars, omega = "zero")

# Run model:
mod &lt;- mod %&gt;% runmodel

# Modification indices:
mod %&gt;% MIs
</code></pre>

<hr>
<h2 id='ml_lvm'>
Multi-level latent variable model family
</h2><span id='topic+ml_lvm'></span><span id='topic+ml_lnm'></span><span id='topic+ml_rnm'></span><span id='topic+ml_lrnm'></span>

<h3>Description</h3>

<p>This family is the two-level random intercept variant of the <code><a href="#topic+lvm">lvm</a></code> model family. It is mostly a special case of the <code><a href="#topic+dlvm1">dlvm1</a></code> family, with the addition of structural effects rather than temporal effects in the <code>beta</code> matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml_lnm(...)
ml_rnm(...)
ml_lrnm(...)
ml_lvm(data, lambda, clusters, within_latent = c("cov",
                   "chol", "prec", "ggm"), within_residual = c("cov",
                   "chol", "prec", "ggm"), between_latent = c("cov",
                   "chol", "prec", "ggm"), between_residual = c("cov",
                   "chol", "prec", "ggm"), beta_within = "zero",
                   beta_between = "zero", omega_zeta_within = "full",
                   delta_zeta_within = "full", kappa_zeta_within =
                   "full", sigma_zeta_within = "full",
                   lowertri_zeta_within = "full", omega_epsilon_within =
                   "zero", delta_epsilon_within = "diag",
                   kappa_epsilon_within = "diag", sigma_epsilon_within =
                   "diag", lowertri_epsilon_within = "diag",
                   omega_zeta_between = "full", delta_zeta_between =
                   "full", kappa_zeta_between = "full",
                   sigma_zeta_between = "full", lowertri_zeta_between =
                   "full", omega_epsilon_between = "zero",
                   delta_epsilon_between = "diag", kappa_epsilon_between
                   = "diag", sigma_epsilon_between = "diag",
                   lowertri_epsilon_between = "diag", nu, nu_eta,
                   identify = TRUE, identification = c("loadings",
                   "variance"), vars, latents, groups, equal = "none",
                   baseline_saturated = TRUE, estimator = c("FIML",
                   "MUML"), optimizer, storedata = FALSE, verbose =
                   FALSE, standardize = c("none", "z", "quantile"),
                   sampleStats, bootstrap = FALSE, boot_sub,
                   boot_resample)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml_lvm_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Must be a raw dataset.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_lambda">lambda</code></td>
<td>

<p>A model matrix encoding the factor loading structure. Each row indicates an indicator and each column a latent. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix. Could also be the result of <code><a href="#topic+simplestructure">simplestructure</a></code>.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_clusters">clusters</code></td>
<td>

<p>A string indicating the variable in the dataset that describes group membership.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_within_latent">within_latent</code></td>
<td>

<p>The type of within-person latent contemporaneous model to be used.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_within_residual">within_residual</code></td>
<td>

<p>The type of within-person residual model to be used.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_between_latent">between_latent</code></td>
<td>

<p>The type of between-person latent model to be used.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_between_residual">between_residual</code></td>
<td>

<p>The type of between-person residual model to be used.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_beta_within">beta_within</code></td>
<td>

<p>A model matrix encoding the within-cluster structural. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix. Defaults to <code>"zero"</code>.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_beta_between">beta_between</code></td>
<td>

<p>A model matrix encoding the between-cluster structural. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix. Defaults to <code>"zero"</code>.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_omega_zeta_within">omega_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_delta_zeta_within">delta_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_kappa_zeta_within">kappa_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_sigma_zeta_within">sigma_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_lowertri_zeta_within">lowertri_zeta_within</code></td>
<td>

<p>Only used when <code>within_latent = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_omega_epsilon_within">omega_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_delta_epsilon_within">delta_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_kappa_epsilon_within">kappa_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_sigma_epsilon_within">sigma_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_lowertri_epsilon_within">lowertri_epsilon_within</code></td>
<td>

<p>Only used when <code>within_residual = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_omega_zeta_between">omega_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_delta_zeta_between">delta_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_kappa_zeta_between">kappa_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_sigma_zeta_between">sigma_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_lowertri_zeta_between">lowertri_zeta_between</code></td>
<td>

<p>Only used when <code>between_latent = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_omega_epsilon_between">omega_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "ggm"</code>. Can be <code>"full"</code>, <code>"zero"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_delta_epsilon_between">delta_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "ggm"</code>. Can be <code>"diag"</code>, <code>"zero"</code> (not recommended), or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_kappa_epsilon_between">kappa_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "prec"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_sigma_epsilon_between">sigma_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "cov"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_lowertri_epsilon_between">lowertri_epsilon_between</code></td>
<td>

<p>Only used when <code>between_residual = "chol"</code>. Can be <code>"full"</code>, <code>"diag"</code>, or a typical model matrix with 0s indicating parameters constrained to zero, 1s indicating free parameters, and higher integers indicating equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_nu">nu</code></td>
<td>

<p>Optional vector encoding the intercepts of the observed variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_nu_eta">nu_eta</code></td>
<td>

<p>Optional vector encoding the intercepts of the latent variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be automatically identified?
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_identification">identification</code></td>
<td>

<p>Type of identification used. <code>"loadings"</code> to fix the first factor loadings to 1, and <code>"variance"</code> to fix the diagonal of the latent variable model matrix (sigma_zeta, lowertri_zeta, delta_zeta or kappa_zeta) to 1.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_vars">vars</code></td>
<td>

<p>An optional character vector with names of the variables used.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_latents">latents</code></td>
<td>

<p>An optional character vector with names of the latent variables.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_estimator">estimator</code></td>
<td>

<p>Estimator used. Currently only <code>"FIML"</code> is supported.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Usually either <code>"nlminb"</code> (with box constrains) or <code>"ucminf"</code> (ignoring box constrains), but any optimizer supported by <code>optimr</code> can be used.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code><a href="#topic+bootstrap">bootstrap</a></code>).
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should progress be printed to the console?
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_standardize">standardize</code></td>
<td>

<p>Which standardization method should be used? <code>"none"</code> (default) for no standardization, <code>"z"</code> for z-scores, and <code>"quantile"</code> for a non-parametric transformation to the quantiles of the marginal standard normal distribution.
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="ml_lvm_+3A_...">...</code></td>
<td>

<p>Arguments sent to 'ml_lvm'
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>

<hr>
<h2 id='ml_tsdlvm1'>
Multi-level Lag-1 dynamic latent variable model family of psychonetrics models for time-series data
</h2><span id='topic+ml_tsdlvm1'></span><span id='topic+ml_ts_lvgvar'></span><span id='topic+ml_gvar'></span><span id='topic+ml_var'></span>

<h3>Description</h3>

<p>This function is a wrapper around <code><a href="#topic+dlvm1">dlvm1</a></code> that allows for specifying the model using a long format data and similar input as the <code>mlVAR</code> package. The <code>ml_ts_lvgvar</code> simply sets <code>within_latent = "ggm"</code> and <code>between_latent = "ggm"</code> by default. The <code>ml_gvar</code> and <code>ml_var</code> are simple wrappers with different named defaults for contemporaneous and between-person effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml_tsdlvm1(data, beepvar, idvar, vars, groups, estimator = "FIML", 
  standardize = c("none", "z", "quantile"), ...)

ml_ts_lvgvar(...)

ml_gvar(..., contemporaneous = c("ggm", "cov", "chol", "prec"), 
        between = c("ggm", "cov", "chol", "prec"))
             
ml_var(..., contemporaneous = c("cov", "chol", "prec", "ggm"), 
        between = c("cov", "chol", "prec", "ggm"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml_tsdlvm1_+3A_data">data</code></td>
<td>

<p>The data to be used. Must be raw data in long format (each row indicates one person at one time point).
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_beepvar">beepvar</code></td>
<td>

<p>Optional string indicating assessment beep per day. Adding this argument will cause non-consecutive beeps to be treated as missing!
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_idvar">idvar</code></td>
<td>

<p>String indicating the subject ID
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_vars">vars</code></td>
<td>

<p>Vectors of variables to include in the analysis
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_estimator">estimator</code></td>
<td>

<p>Estimator to be used. Must be <code>"FIML"</code>.
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_standardize">standardize</code></td>
<td>

<p>Which standardization method should be used? <code>"none"</code> (default) for no standardization, <code>"z"</code> for z-scores, and <code>"quantile"</code> for a non-parametric transformation to the quantiles of the marginal standard normal distribution.
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_contemporaneous">contemporaneous</code></td>
<td>

<p>The type of within-person latent contemporaneous model to be used.
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_between">between</code></td>
<td>

<p>The type of between-person latent model to be used.
</p>
</td></tr>
<tr><td><code id="ml_tsdlvm1_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+dlvm1">dlvm1</a></code>
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>

<hr>
<h2 id='modelsearch'>
Stepwise model search
</h2><span id='topic+modelsearch'></span>

<h3>Description</h3>

<p>This function peforms stepwise model search to find an optimal model that (locally) minimzes some criterion (by default, the BIC). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelsearch(x, criterion = "bic", matrices, prunealpha = 0.01,
                    addalpha = 0.01, verbose, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelsearch_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="modelsearch_+3A_criterion">criterion</code></td>
<td>

<p>String indicating the criterion to minimize. Any criterion from <code><a href="#topic+fit">fit</a></code> can be used.
</p>
</td></tr>
<tr><td><code id="modelsearch_+3A_matrices">matrices</code></td>
<td>

<p>Vector of strings indicating which matrices should be searched. Will default to network structures and factor loadings.
</p>
</td></tr>
<tr><td><code id="modelsearch_+3A_prunealpha">prunealpha</code></td>
<td>

<p>Minimal alpha used to consider edges to be removed
</p>
</td></tr>
<tr><td><code id="modelsearch_+3A_addalpha">addalpha</code></td>
<td>

<p>Maximum alpha used to consider edges to be added
</p>
</td></tr>
<tr><td><code id="modelsearch_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="modelsearch_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+runmodel">runmodel</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The full algorithm is as follows:
</p>
<p>1. Evaluate all models in which an edge is removed that has p &gt; prunealpha, or an edge is added that has a modification index with p &lt; addalpha
</p>
<p>2. If none of these models improve the criterion, return the previous model and stop the algorithm
</p>
<p>3. Update the model to the model that improved the criterion the most
</p>
<p>4. Evaluate all other considered models that improved the criterion 
</p>
<p>5. If none of these models improve the criterion, go to 1, else go to 3
</p>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prune">prune</a></code>, <code><a href="#topic+stepup">stepup</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars)

# Run model:
mod &lt;- mod %&gt;% runmodel

# Model search
mod &lt;- mod %&gt;% prune(alpha= 0.01) %&gt;% modelsearch

</code></pre>

<hr>
<h2 id='parameters'>
Print parameter estimates
</h2><span id='topic+parameters'></span>

<h3>Description</h3>

<p>This function will print a list of parameters of the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parameters(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parameters_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a data frame containing information on all parameters.
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars, omega = "zero")

# Run model:
mod &lt;- mod %&gt;% runmodel

# Parameter estimates:
mod %&gt;% parameters
</code></pre>

<hr>
<h2 id='parequal'>
Set equality constrains across parameters
</h2><span id='topic+parequal'></span>

<h3>Description</h3>

<p>This function can be used to set parameters equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parequal(x, ..., inds = integer(0), verbose, log = TRUE,
                    runmodel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parequal_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="parequal_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>runmodel</code>
</p>
</td></tr>
<tr><td><code id="parequal_+3A_inds">inds</code></td>
<td>

<p>Parameter indices of parameters to be constrained equal
</p>
</td></tr>
<tr><td><code id="parequal_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="parequal_+3A_log">log</code></td>
<td>

<p>Logical, should the log be updated?
</p>
</td></tr>
<tr><td><code id="parequal_+3A_runmodel">runmodel</code></td>
<td>

<p>Logical, should the model be updated?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='partialprune'>
Partial pruning of multi-group models
</h2><span id='topic+partialprune'></span>

<h3>Description</h3>

<p>This function will search for a multi-group model with equality constrains on some but not all parameters. This is called partial pruning (Epskamp, Isvoranu, &amp; Cheung, 2020; Haslbeck, 2020).  The algorithm is as follows: 1. remove all parameters not significant at alpha in all groups (without equality constrains), 2. create a union model with all parameters included in any group included in all groups and constrained equal. 3. Stepwise free equality constrains of the parameter that features the largest sum of modification indices until BIC can no longer be improved. 4. Select and return (by default) the best model according to BIC (original model, pruned model, union model and partially pruned model). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partialprune(x, alpha = 0.01, matrices, verbose, combinefun = unionmodel, 
             return = c("best","partialprune","union_equal","prune"),
               criterion = "bic",  best = c("lowest","highest"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partialprune_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_alpha">alpha</code></td>
<td>

<p>Significance level to use.
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_matrices">matrices</code></td>
<td>

<p>Vector of strings indicating which matrices should be pruned. Will default to network structures.
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_combinefun">combinefun</code></td>
<td>

<p>Function used to combine models of different groups.
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_return">return</code></td>
<td>

<p>What model to retur? <code>"best"</code> for best fitting model (according to BIC, <code>"partialprune"</code> for the partialpruned model, <code>"union_equal"</code> for the union model with equality constraints, and <code>"prune"</code> for the originally pruned model without equality constraints.)
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_best">best</code></td>
<td>

<p>Should the lowest or the highest index of <code>criterion</code> be used to select the final model?
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_criterion">criterion</code></td>
<td>

<p>What criterion to use for the model selection in the last step? Defaults to <code>"bic"</code> for BIC selection.
</p>
</td></tr>
<tr><td><code id="partialprune_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+prune">prune</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>


<h3>References</h3>

<p>Epskamp, S., Isvoranu, A. M., &amp; Cheung, M. (2020). Meta-analytic gaussian network aggregation. PsyArXiv preprint. DOI:10.31234/osf.io/236w8.
</p>
<p>Haslbeck, J. (2020). Estimating Group Differences in Network Models using Moderation Analysis. PsyArXiv preprint. DOI:10.31234/osf.io/926pv.
</p>

<hr>
<h2 id='prune'>
Stepdown model search by pruning non-significant parameters.
</h2><span id='topic+prune'></span>

<h3>Description</h3>

<p>This function will (recursively) remove parameters that are not significant and refit the model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prune(x, alpha = 0.01, adjust = c("none", "holm",
                    "hochberg", "hommel", "bonferroni", "BH", "BY",
                    "fdr"), matrices, runmodel = TRUE, recursive = FALSE,
                    verbose, log = TRUE, identify = TRUE, startreduce = 1,
                    limit = Inf, mode = c("tested","all"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prune_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="prune_+3A_alpha">alpha</code></td>
<td>

<p>Significance level to use.
</p>
</td></tr>
<tr><td><code id="prune_+3A_adjust">adjust</code></td>
<td>

<p>p-value adjustment method to use. See <code>p.adjust</code>.
</p>
</td></tr>
<tr><td><code id="prune_+3A_matrices">matrices</code></td>
<td>

<p>Vector of strings indicating which matrices should be pruned. Will default to network structures.
</p>
</td></tr>
<tr><td><code id="prune_+3A_runmodel">runmodel</code></td>
<td>

<p>Logical, should the model be evaluated after pruning?
</p>
</td></tr>
<tr><td><code id="prune_+3A_recursive">recursive</code></td>
<td>

<p>Logical, should the pruning process be repeated?
</p>
</td></tr>
<tr><td><code id="prune_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="prune_+3A_log">log</code></td>
<td>

<p>Logical, should the log be updated?
</p>
</td></tr>
<tr><td><code id="prune_+3A_identify">identify</code></td>
<td>

<p>Logical, should models be identified automatically?
</p>
</td></tr>
<tr><td><code id="prune_+3A_startreduce">startreduce</code></td>
<td>

<p>A numeric value indicating a factor with which the starting values should be reduced. Can be useful when encountering numeric problems.
</p>
</td></tr>
<tr><td><code id="prune_+3A_limit">limit</code></td>
<td>

<p>The maximum number of parameters to be pruned.
</p>
</td></tr>
<tr><td><code id="prune_+3A_mode">mode</code></td>
<td>

<p>Mode for adjusting for multiple comparisons. Should all parameters be considered as the total number of tests or only the tested parameters (parameters of interest)?
</p>
</td></tr>
<tr><td><code id="prune_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+runmodel">runmodel</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stepup">stepup</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars, omega = "full")

# Run model:
mod &lt;- mod %&gt;% runmodel

# Prune model:
mod &lt;- mod %&gt;% prune(adjust = "fdr", recursive = FALSE)
</code></pre>

<hr>
<h2 id='psychonetrics_bootstrap-class'>Class <code>"psychonetrics_bootstrap"</code></h2><span id='topic+psychonetrics_bootstrap-class'></span><span id='topic+show+2Cpsychonetrics_bootstrap-method'></span>

<h3>Description</h3>

<p>Class for aggregated bootstrap results.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("psychonetrics_bootstrap", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>model</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>submodel</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>parameters</code>:</dt><dd><p>Object of class <code>"data.frame"</code> ~~ </p>
</dd>
<dt><code>models</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>matrices</code>:</dt><dd><p>Object of class <code>"data.frame"</code> ~~ </p>
</dd>
<dt><code>fitmeasures</code>:</dt><dd><p>Object of class <code>"data.frame"</code> ~~ </p>
</dd>
<dt><code>distribution</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>verbose</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
<dt><code>boot_sub</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ </p>
</dd>
<dt><code>boot_resample</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
<dt><code>n_fail</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ </p>
</dd>
<dt><code>n_success</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ </p>
</dd>
<dt><code>types</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>show</dt><dd><p><code>signature(object = "psychonetrics_bootstrap")</code>: ... </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("psychonetrics_bootstrap")
</code></pre>

<hr>
<h2 id='psychonetrics_log-class'>Class <code>"psychonetrics"</code></h2><span id='topic+psychonetrics_log-class'></span><span id='topic+show+2Cpsychonetrics_log-method'></span>

<h3>Description</h3>

<p>A logbook entry in the psychonetrics logbook
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("psychonetrics_log", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>event</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>time</code>:</dt><dd><p>Object of class <code>"POSIXct"</code> ~~ </p>
</dd>
<dt><code>sessionInfo</code>:</dt><dd><p>Object of class <code>"sessionInfo"</code> ~~ </p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>show</dt><dd><p><code>signature(object = "psychonetrics_log")</code>: ... </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("psychonetrics_log")
</code></pre>

<hr>
<h2 id='psychonetrics_update'>
Model updating functions
</h2><span id='topic+addMIs'></span><span id='topic+addSEs'></span><span id='topic+addfit'></span><span id='topic+identify'></span>

<h3>Description</h3>

<p>These functions update a psychonetrics model. Typically they are not required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addMIs(x, matrices = "all", type = c("normal", "free",
                    "equal"), verbose, analyticFisher = TRUE)

addSEs(x, verbose, approximate_SEs = FALSE)

addfit(x, verbose)

identify(x)


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psychonetrics_update_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="psychonetrics_update_+3A_matrices">matrices</code></td>
<td>

<p>Optional vector of matrices to include in MIs.
</p>
</td></tr>
<tr><td><code id="psychonetrics_update_+3A_type">type</code></td>
<td>

<p>String indicating which modification indices should be updated.
</p>
</td></tr>
<tr><td><code id="psychonetrics_update_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="psychonetrics_update_+3A_analyticfisher">analyticFisher</code></td>
<td>

<p>Logical indicating if an analytic Fisher information matrix should be used.
</p>
</td></tr>
<tr><td><code id="psychonetrics_update_+3A_approximate_ses">approximate_SEs</code></td>
<td>

<p>Logical, should standard errors be approximated? If true, an approximate matrix inverse of the Fischer information is used to obtain the standard errors.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='psychonetrics-class'>Class <code>"psychonetrics"</code></h2><span id='topic+psychonetrics-class'></span><span id='topic+resid+2Cpsychonetrics-method'></span><span id='topic+residuals+2Cpsychonetrics-method'></span><span id='topic+show+2Cpsychonetrics-method'></span>

<h3>Description</h3>

<p>Main class for psychonetrics results.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("psychonetrics", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>model</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>submodel</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>parameters</code>:</dt><dd><p>Object of class <code>"data.frame"</code> ~~ </p>
</dd>
<dt><code>matrices</code>:</dt><dd><p>Object of class <code>"data.frame"</code> ~~ </p>
</dd>
<dt><code>meanstructure</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
<dt><code>computed</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
<dt><code>sample</code>:</dt><dd><p>Object of class <code>"psychonetrics_samplestats"</code> ~~ </p>
</dd>
<dt><code>modelmatrices</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>log</code>:</dt><dd><p>Object of class <code>"psychonetrics_log"</code> ~~ </p>
</dd>
<dt><code>optim</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>fitmeasures</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>baseline_saturated</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>equal</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>objective</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ </p>
</dd>
<dt><code>information</code>:</dt><dd><p>Object of class <code>"matrix"</code> ~~ </p>
</dd>
<dt><code>identification</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>optimizer</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>optim.args</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>estimator</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>distribution</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ </p>
</dd>
<dt><code>extramatrices</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>rawts</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
<dt><code>Drawts</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>types</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ </p>
</dd>
<dt><code>cpp</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
<dt><code>verbose</code>:</dt><dd><p>Object of class <code>"logical"</code> ~~ </p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>resid</dt><dd><p><code>signature(object = "psychonetrics")</code>: ... </p>
</dd>
<dt>residuals</dt><dd><p><code>signature(object = "psychonetrics")</code>: ... </p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "psychonetrics")</code>: ... </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("psychonetrics")
</code></pre>

<hr>
<h2 id='runmodel'>
Run a psychonetrics model
</h2><span id='topic+runmodel'></span>

<h3>Description</h3>

<p>This is the main function  used to run a psychonetrics model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runmodel(x, level = c("gradient", "fitfunction"), addfit =
                   TRUE, addMIs = TRUE, addSEs = TRUE, addInformation =
                   TRUE, log = TRUE, verbose, optim.control,
                   analyticFisher = TRUE, warn_improper = FALSE,
                   warn_gradient = TRUE, warn_bounds = TRUE,
                   return_improper = TRUE, bounded = TRUE,
                   approximate_SEs = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runmodel_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_level">level</code></td>
<td>

<p>Level at which the model should be estimated. Defaults to <code>"gradient"</code> to indicate the analytic gradient should be used.
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_addfit">addfit</code></td>
<td>

<p>Logical, should fit measures be added?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_addmis">addMIs</code></td>
<td>

<p>Logical, should modification indices be added?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_addses">addSEs</code></td>
<td>

<p>Logical, should standard errors be added?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_addinformation">addInformation</code></td>
<td>

<p>Logical, should the Fisher information be added?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_log">log</code></td>
<td>

<p>Logical, should the log be updated?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_optim.control">optim.control</code></td>
<td>

<p>A list with options for <code>optimr</code>
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_analyticfisher">analyticFisher</code></td>
<td>

<p>Logical, should the analytic Fisher information be used? If <code>FALSE</code>, numeric information is used instead.
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_return_improper">return_improper</code></td>
<td>

<p>Should a result in which improper computation was used be return? Improper computation can mean that a pseudoinverse of small spectral shift was used in computing the inverse of a matrix.
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_warn_improper">warn_improper</code></td>
<td>
<p>Logical. Should a warning be given when at some point in the estimation a pseudoinverse was used?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_warn_gradient">warn_gradient</code></td>
<td>
<p>Logical. Should a warning be given when the average absolute gradient is &gt; 1?</p>
</td></tr>
<tr><td><code id="runmodel_+3A_bounded">bounded</code></td>
<td>
<p>Logical. Should bounded estimation be used (e.g., variances should be positive)?
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_approximate_ses">approximate_SEs</code></td>
<td>

<p>Logical, should standard errors be approximated? If true, an approximate matrix inverse of the Fischer information is used to obtain the standard errors.
</p>
</td></tr>
<tr><td><code id="runmodel_+3A_warn_bounds">warn_bounds</code></td>
<td>

<p>Should a warning be given when a parameter is estimated near its bounds?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars, omega = "full")

# Run model:
mod &lt;- mod %&gt;% runmodel
</code></pre>

<hr>
<h2 id='setestimator'>
Convenience functions
</h2><span id='topic+setestimator'></span><span id='topic+setoptimizer'></span><span id='topic+usecpp'></span>

<h3>Description</h3>

<p>These functions can be used to change some estimator options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setestimator(x, estimator)

setoptimizer(x, optimizer = c("default", "nlminb", "ucminf",
                 "cpp_L-BFGS-B", "cpp_BFGS", "cpp_CG", "cpp_SANN",
                 "cpp_Nelder-Mead"), optim.args)


usecpp(x, use = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setestimator_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="setestimator_+3A_estimator">estimator</code></td>
<td>

<p>A string indicating the estimator to be used
</p>
</td></tr>
<tr><td><code id="setestimator_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="setestimator_+3A_use">use</code></td>
<td>

<p>Logical indicating if C++ should be used (currently only used in FIML)
</p>
</td></tr>
<tr><td><code id="setestimator_+3A_optim.args">optim.args</code></td>
<td>
<p>List of arguments to sent to the optimizer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default optimizer is nlminb with the following arguments:
</p>

<ul>
<li><p> eval.max=20000L
</p>
</li>
<li><p> iter.max=10000L
</p>
</li>
<li><p> trace=0L
</p>
</li>
<li><p> abs.tol=sqrt(.Machine$double.eps)
</p>
</li>
<li><p> rel.tol=sqrt(.Machine$double.eps)
</p>
</li>
<li><p> step.min=1.0
</p>
</li>
<li><p> step.max=1.0
</p>
</li>
<li><p> x.tol=1.5e-8
</p>
</li>
<li><p> xf.tol=2.2e-14
</p>
</li></ul>



<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='setverbose'>
Should messages of computation progress be printed?
</h2><span id='topic+setverbose'></span>

<h3>Description</h3>

<p>This function controls if messages should be printed for a psychonetrics model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setverbose(x, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setverbose_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="setverbose_+3A_verbose">verbose</code></td>
<td>

<p>Logical indicating if verbose should be enabled
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='simplestructure'>
Generate factor loadings matrix with simple structure
</h2><span id='topic+simplestructure'></span>

<h3>Description</h3>

<p>This function generates the input for <code>lambda</code> arguments in latent variable models using a simple structure. The input is a vector with an element for each variable indicating the factor the variable loads on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplestructure(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplestructure_+3A_x">x</code></td>
<td>

<p>A vector indicating which factor each indicator loads on.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sacha Epskamp &lt;mail@sachaepskamp.com&gt;
</p>

<hr>
<h2 id='StarWars'>
Star Wars dataset
</h2><span id='topic+StarWars'></span>

<h3>Description</h3>

<p>This questionaire was constructed by Carolin Katzera, Charlotte Tanis, Esther Niehoff, Myrthe Veenman, and Jason Nak as part of an assignment for a course on confirmatory factor analysis (http://sachaepskamp.com/SEM2018). They also collected the data among fellow psychology students as well as through social media. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("StarWars")</code></pre>


<h3>Format</h3>

<p>A data frame with 271 observations on the following 13 variables.
</p>

<dl>
<dt><code>Q1</code></dt><dd><p>I am a huge Star Wars fan! (star what?)</p>
</dd>
<dt><code>Q2</code></dt><dd><p>I would trust this person with my democracy &lt;picture of Jar Jar Binks&gt;</p>
</dd>
<dt><code>Q3</code></dt><dd><p>I enjoyed the story of Anakin's early life</p>
</dd>
<dt><code>Q4</code></dt><dd><p>The special effects in this scene are awful &lt;video of the Battle of Geonosis&gt;</p>
</dd>
<dt><code>Q5</code></dt><dd><p>I would trust this person with my life &lt;picture of Han Solo&gt;</p>
</dd>
<dt><code>Q6</code></dt><dd><p>I found Darth Vader'ss big reveal in &quot;Empire&quot; one of the greatest moments in movie history</p>
</dd>
<dt><code>Q7</code></dt><dd><p>The special effects in this scene are amazing &lt;video of the Death Star explosion&gt;</p>
</dd>
<dt><code>Q8</code></dt><dd><p>If possible, I would definitely buy this droid &lt;picture of BB-8&gt;</p>
</dd>
<dt><code>Q9</code></dt><dd><p>The story in the Star Wars sequels is an improvement to the previous movies</p>
</dd>
<dt><code>Q10</code></dt><dd><p>The special effects in this scene are marvellous &lt;video of the Starkiller Base firing&gt;</p>
</dd>
<dt><code>Q11</code></dt><dd><p>What is your gender?</p>
</dd>
<dt><code>Q12</code></dt><dd><p>How old are you?</p>
</dd>
<dt><code>Q13</code></dt><dd><p>Have you seen any of the Star Wars movies?</p>
</dd>
</dl>



<h3>Details</h3>

<p>The questionaire is online at https://github.com/SachaEpskamp/SEM-code-examples/blob/master/CFA_fit_examples/StarWars_questionaire.pdf. The authors of the questionaire defined a measurement model before collecting data: Q2 - Q4 are expected to load on a &quot;prequel&quot; factor, Q5 - Q7 are expected to load in a &quot;originals&quot; factor, and Q8 - Q10 are expected to load on a &quot;sequal&quot; factor. Finally, Q1 is expected to load on all three.
</p>


<h3>Source</h3>

<p>https://github.com/SachaEpskamp/SEM-code-examples/blob/master/CFA_fit_examples
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(StarWars)
</code></pre>

<hr>
<h2 id='stepup'>
Stepup model search along modification indices
</h2><span id='topic+stepup'></span>

<h3>Description</h3>

<p>This function automatically peforms step-up search by adding the parameter with the largest modification index until some criterion is reached or no modification indices are significant at alpha.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepup(x, alpha = 0.01, criterion = "bic", matrices, mi =
                    c("mi", "mi_free", "mi_equal"), greedyadjust =
                    c("bonferroni", "none", "holm", "hochberg", "hommel",
                    "fdr", "BH", "BY"), stopif, greedy = FALSE, verbose,
                    checkinformation = TRUE, singularinformation =
                    c("tryfix", "skip", "continue", "stop"), startEPC =
                    TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepup_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="stepup_+3A_alpha">alpha</code></td>
<td>

<p>Significance level to use.
</p>
</td></tr>
<tr><td><code id="stepup_+3A_criterion">criterion</code></td>
<td>

<p>String indicating the criterion to minimize. Any criterion from <code><a href="#topic+fit">fit</a></code> can be used.
</p>
</td></tr>
<tr><td><code id="stepup_+3A_matrices">matrices</code></td>
<td>

<p>Vector of strings indicating which matrices should be searched. Will default to network structures and factor loadings.
</p>
</td></tr>
<tr><td><code id="stepup_+3A_mi">mi</code></td>
<td>

<p>String indicating which kind of modification index should be used (<code>"mi"</code> is the typical MI, <code>"mi_free"</code> is the modification index free from equality constrains across groups, and <code>"mi_equal"</code> is the modification index if the parameter is added constrained equal across all groups).
</p>
</td></tr>
<tr><td><code id="stepup_+3A_greedyadjust">greedyadjust</code></td>
<td>

<p>String indicating which p-value adjustment should be used in greedy start. Any method from <code>p.adjust</code> can be used.
</p>
</td></tr>
<tr><td><code id="stepup_+3A_stopif">stopif</code></td>
<td>

<p>An R expression, using objects from <code>fit</code>, which will break stepup search if it evaluates to <code>TRUE</code>. For example, <code>stopif = rmsea &lt; 0.05</code> will lead to search to stop if rmsea is below 0.05. 
</p>
</td></tr>
<tr><td><code id="stepup_+3A_greedy">greedy</code></td>
<td>

<p>Logical, should a greedy start be used? If <code>TRUE</code>, the first step adds any parameter that is significant (after adjustement)
</p>
</td></tr>
<tr><td><code id="stepup_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="stepup_+3A_checkinformation">checkinformation</code></td>
<td>

<p>Logical, should the Fisher information be checked for potentially non-identified models?
</p>
</td></tr>
<tr><td><code id="stepup_+3A_singularinformation">singularinformation</code></td>
<td>

<p>String indicating how to proceed if the information matrix is singular. <code>"tryfix"</code> 
will adjust starting values to try to fix the proble, <code>"skip"</code> will lead to the algorithm
to skip the current parameter, <code>"continue"</code> will ignore the situation, and <code>"stop"</code>
will break the algorithm and return a list with the last two models.
</p>
</td></tr>
<tr><td><code id="stepup_+3A_startepc">startEPC</code></td>
<td>

<p>Logical, should the starting value be set at the expected parameter change?
</p>
</td></tr>
<tr><td><code id="stepup_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code><a href="#topic+runmodel">runmodel</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prune">prune</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;%
  select(A1:A5, gender) %&gt;%
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Let's fit a full GGM:
mod &lt;- ggm(ConsData, vars = vars, omega = "full")

# Run model:
mod &lt;- mod %&gt;%runmodel %&gt;%prune(alpha = 0.05)

# Remove an edge (example):
mod &lt;- mod %&gt;%fixpar("omega",1,2) %&gt;%runmodel

# Stepup search
mod &lt;- mod %&gt;%stepup(alpha = 0.05)

</code></pre>

<hr>
<h2 id='transmod'>
Transform between model types
</h2><span id='topic+transmod'></span>

<h3>Description</h3>

<p>This function allows to transform a model variance&ndash;covariance structure from one type to another. Its main uses are to (1) use a Cholesky decomposition to estimate a saturated covariance matrix or GGM, and (2) to transform between conditional (ggm) and marginal associations (cov).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transmod(x, ..., verbose, keep_computed = FALSE, log = TRUE,
         identify = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transmod_+3A_x">x</code></td>
<td>

<p>A psychonetrics model
</p>
</td></tr>
<tr><td><code id="transmod_+3A_...">...</code></td>
<td>

<p>Named arguments with the new types to use (e.g., <code>between = "ggm"</code> or <code>y = "cov"</code>)
</p>
</td></tr>
<tr><td><code id="transmod_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="transmod_+3A_keep_computed">keep_computed</code></td>
<td>

<p>Logical, should the model be stated to be uncomputed adter the transformation? In general, a model does not need to be re-computed as transformed parameters should be at the maximum likelihood estimate.
</p>
</td></tr>
<tr><td><code id="transmod_+3A_log">log</code></td>
<td>

<p>Logical, should a logbook entry be made?
</p>
</td></tr>
<tr><td><code id="transmod_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be identified after transforming?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Transformations are only possible if the model is diagonal (e.g., no partial correlations) or saturated (e.g., all covariances included).
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Model with Cholesky decompositon:
mod &lt;- varcov(ConsData, vars = vars, type = "chol")

# Run model:
mod &lt;- mod %&gt;% runmodel

# Transform to GGM:
mod_trans &lt;- transmod(mod, type = "ggm") %&gt;% runmodel
# Note: runmodel often not needed

# Obtain thresholded GGM:
getmatrix(mod_trans, "omega", threshold = TRUE)
</code></pre>

<hr>
<h2 id='tsdlvm1'>
Lag-1 dynamic latent variable model family of psychonetrics models for time-series data
</h2><span id='topic+tsdlvm1'></span><span id='topic+ts_lvgvar'></span>

<h3>Description</h3>

<p>This is the family of models that models a dynamic factor model on time-series. There are two covariance structures that can be modeled in different ways: <code>contemporaneous</code> for the contemporaneous model and <code>residual</code> for the residual model. These can be set to <code>"cov"</code> for covariances, <code>"prec"</code> for a precision matrix, <code>"ggm"</code> for a Gaussian graphical model and <code>"chol"</code> for a Cholesky decomposition. The <code>ts_lvgvar</code> wrapper function sets <code>contemporaneous = "ggm"</code> for the graphical VAR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tsdlvm1(data, lambda, contemporaneous = c("cov", "chol",
                   "prec", "ggm"), residual = c("cov", "chol", "prec",
                   "ggm"), beta = "full", omega_zeta = "full", delta_zeta
                   = "diag", kappa_zeta = "full", sigma_zeta = "full",
                   lowertri_zeta = "full", omega_epsilon = "zero",
                   delta_epsilon = "diag", kappa_epsilon = "diag",
                   sigma_epsilon = "diag", lowertri_epsilon = "diag", nu,
                   mu_eta, identify = TRUE, identification =
                   c("loadings", "variance"), latents, beepvar, dayvar,
                   idvar, vars, groups, covs, means, nobs, missing =
                   "listwise", equal = "none", baseline_saturated = TRUE,
                   estimator = "ML", optimizer, storedata = FALSE,
                   sampleStats, covtype = c("choose", "ML", "UB"),
                   centerWithin = FALSE, standardize = c("none", "z",
                   "quantile"), verbose = FALSE, bootstrap = FALSE,
                   boot_sub, boot_resample)

ts_lvgvar(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tsdlvm1_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_lambda">lambda</code></td>
<td>

<p>A model matrix encoding the factor loading structure. Each row indicates an indicator and each column a latent. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_contemporaneous">contemporaneous</code></td>
<td>

<p>The type of contemporaneous model used. See description.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_residual">residual</code></td>
<td>

<p>The type of residual model used. See description.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_beta">beta</code></td>
<td>

<p>A model matrix encoding the temporal relationships (transpose of temporal network) between latent variables. A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.  Can also be <code>"full"</code> for a full temporal network or <code>"zero"</code> for an empty temporal network.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_omega_zeta">omega_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_delta_zeta">delta_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code> (not recommended), or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_kappa_zeta">kappa_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_sigma_zeta">sigma_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_lowertri_zeta">lowertri_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_omega_epsilon">omega_epsilon</code></td>
<td>

<p>Only used when <code>residual = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_delta_epsilon">delta_epsilon</code></td>
<td>

<p>Only used when <code>residual = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code> (not recommended), or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_kappa_epsilon">kappa_epsilon</code></td>
<td>

<p>Only used when <code>residual = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_sigma_epsilon">sigma_epsilon</code></td>
<td>

<p>Only used when <code>residual = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_lowertri_epsilon">lowertri_epsilon</code></td>
<td>

<p>Only used when <code>residual = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_nu">nu</code></td>
<td>

<p>Optional vector encoding the intercepts of the observed variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_mu_eta">mu_eta</code></td>
<td>

<p>Optional vector encoding the means of the latent variables. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free intercepts, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be automatically identified?
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_identification">identification</code></td>
<td>

<p>Type of identification used. <code>"loadings"</code> to fix the first factor loadings to 1, and <code>"variance"</code> to fix the diagonal of the latent variable model matrix (sigma_zeta, lowertri_zeta, delta_zeta or kappa_zeta) to 1.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_latents">latents</code></td>
<td>

<p>An optional character vector with names of the latent variables.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_beepvar">beepvar</code></td>
<td>

<p>Optional string indicating assessment beep per day. Adding this argument will cause non-consecutive beeps to be treated as missing!
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_dayvar">dayvar</code></td>
<td>

<p>Optional string indicating assessment day. Adding this argument makes sure that the first measurement of a day is not regressed on the last measurement of the previous day. IMPORTANT: only add this if the data has multiple observations per day.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_idvar">idvar</code></td>
<td>

<p>Optional string indicating the subject ID
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_vars">vars</code></td>
<td>

<p>An optional character vector encoding the variables used in the analyis. Must equal names of the dataset in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. Make sure <code>covtype</code> argument is set correctly to the type of covariances used. 
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation, <code>"FIML"</code> for full-information maximum likelihood estimation, <code>"ULS"</code> for unweighted least squares estimation, <code>"WLS"</code> for weighted least squares estimation, and <code>"DWLS"</code> for diagonally weighted least squares estimation.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code>bootstrap</code>).
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_standardize">standardize</code></td>
<td>

<p>Which standardization method should be used? <code>"none"</code> (default) for no standardization, <code>"z"</code> for z-scores, and <code>"quantile"</code> for a non-parametric transformation to the quantiles of the marginal standard normal distribution.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_centerwithin">centerWithin</code></td>
<td>

<p>Logical, should data be within-person centered?
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_covtype">covtype</code></td>
<td>

<p>If 'covs' is used, this is the type of covariance (maximum likelihood or unbiased) the input covariance matrix represents. Set to <code>"ML"</code> for maximum likelihood estimates (denominator n) and <code>"UB"</code> to unbiased estimates (denominator n-1). The default will try to find the type used, by investigating which is most likely to result from integer valued datasets.
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="tsdlvm1_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>tsdlvm1</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: this example is wrapped in a dontrun environment because the data is not 
# available locally.
## Not run: 
# Obtain the data from:
#
# Epskamp, S., van Borkulo, C. D., van der Veen, D. C., Servaas, M. N., Isvoranu, A. M., 
# Riese, H., &amp; Cramer, A. O. (2018). Personalized network modeling in psychopathology: 
# The importance of contemporaneous and temporal connections. Clinical Psychological 
# Science, 6(3), 416-427.
# 
# Available here: https://osf.io/c8wjz/
tsdata &lt;- read.csv("Supplementary2_data.csv")

# Encode time variable in a way R understands:
tsdata$time &lt;- as.POSIXct(tsdata$time, tz = "Europe/Amsterdam")

# Extract days:
tsdata$Day &lt;- as.Date(tsdata$time, tz = "Europe/Amsterdam")

# Variables to use:
vars &lt;- c("relaxed", "sad", "nervous", "concentration", "tired", "rumination", 
          "bodily.discomfort")

# Create lambda matrix (in this case: one factor):
Lambda &lt;- matrix(1,7,1)

# Estimate dynamical factor model:
model &lt;- tsdlvm1(
  tsdata, 
  lambda = Lambda,
  vars = vars, 
  dayvar = "Day",
  estimator = "FIML"
)

# Run model:
model &lt;- model %&gt;% runmodel

# Look at fit:
model %&gt;% print
model %&gt;% fit # Pretty bad fit

## End(Not run)
</code></pre>

<hr>
<h2 id='unionmodel'>
Unify models across groups
</h2><span id='topic+unionmodel'></span><span id='topic+intersectionmodel'></span>

<h3>Description</h3>

<p>The <code>unionmodel</code> will add all parameters to all groups that are free in at least one group, and the <code>intersectionmodel</code> will constrain all parameters across groups to zero unless they are free to estimate in all groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unionmodel(x, runmodel = FALSE, verbose, log = TRUE, identify =
                    TRUE, matrices, ...)

intersectionmodel(x, runmodel = FALSE, verbose, log = TRUE, identify =
                    TRUE, matrices, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unionmodel_+3A_x">x</code></td>
<td>

<p>A <code>psychonetrics</code> model.
</p>
</td></tr>
<tr><td><code id="unionmodel_+3A_runmodel">runmodel</code></td>
<td>

<p>Logical, should the model be updated?
</p>
</td></tr>
<tr><td><code id="unionmodel_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="unionmodel_+3A_log">log</code></td>
<td>

<p>Logical, should the log be updated?
</p>
</td></tr>
<tr><td><code id="unionmodel_+3A_identify">identify</code></td>
<td>

<p>Logical, should the model be identified?
</p>
</td></tr>
<tr><td><code id="unionmodel_+3A_matrices">matrices</code></td>
<td>

<p>Which matrices should be used to form the union/intersection model?
</p>
</td></tr>
<tr><td><code id="unionmodel_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>runmodel</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class psychonetrics (<a href="#topic+psychonetrics-class">psychonetrics-class</a>)
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>

<hr>
<h2 id='var1'>
Lag-1 vector autoregression family of psychonetrics models
</h2><span id='topic+var1'></span><span id='topic+gvar'></span>

<h3>Description</h3>

<p>This is the family of models that models time-series data using a lag-1 vector autoregressive model (VAR; Epskamp,Waldorp, Mottus, Borsboom, 2018). The model is fitted to the Toeplitz matrix, but unlike typical SEM software the block of covariances of the lagged variables is not used in estimating the temporal and contemporaneous relationships (the block is modeled completely separately using a cholesky decomposition, and does not enter the model elsewise). The <code>contemporaneous</code> argument can be used to define what contemporaneous model is used: <code>contemporaneous = "cov"</code> (default) models a variance-covariance matrix, <code>contemporaneous = "chol"</code> models a Cholesky decomposition, <code>contemporaneous = "prec"</code> models a precision matrix, and <code>contemporaneous = "ggm"</code> (alias: <code>gvar()</code>) models a Gaussian graphical model, also then known as a graphical VAR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var1(data, contemporaneous = c("cov", "chol", "prec",
                   "ggm"), beta = "full", omega_zeta = "full", delta_zeta
                   = "full", kappa_zeta = "full", sigma_zeta = "full",
                   lowertri_zeta = "full", mu, beepvar, dayvar, idvar,
                   vars, groups, covs, means, nobs, missing = "listwise",
                   equal = "none", baseline_saturated = TRUE, estimator =
                   "ML", optimizer, storedata = FALSE, covtype =
                   c("choose", "ML", "UB"), standardize = c("none", "z",
                   "quantile"), sampleStats, verbose = FALSE, bootstrap =
                   FALSE, boot_sub, boot_resample)

gvar(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var1_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="var1_+3A_contemporaneous">contemporaneous</code></td>
<td>

<p>The type of contemporaneous model used. See description.
</p>
</td></tr>
<tr><td><code id="var1_+3A_beta">beta</code></td>
<td>

<p>A model matrix encoding the temporal relationships (transpose of temporal network). A 0 encodes a fixed to zero element, a 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.  Can also be <code>"full"</code> for a full temporal network or <code>"zero"</code> for an empty temporal network.
</p>
</td></tr>
<tr><td><code id="var1_+3A_omega_zeta">omega_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="var1_+3A_delta_zeta">delta_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "ggm"</code>. Either <code>"diag"</code> to estimate all scalings or <code>"zero"</code> (not recommended) to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="var1_+3A_kappa_zeta">kappa_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="var1_+3A_sigma_zeta">sigma_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="var1_+3A_lowertri_zeta">lowertri_zeta</code></td>
<td>

<p>Only used when <code>contemporaneous = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="var1_+3A_mu">mu</code></td>
<td>

<p>Optional vector encoding the mean structure. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free means, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="var1_+3A_beepvar">beepvar</code></td>
<td>

<p>Optional string indicating assessment beep per day. Adding this argument will cause non-consecutive beeps to be treated as missing!
</p>
</td></tr>
<tr><td><code id="var1_+3A_dayvar">dayvar</code></td>
<td>

<p>Optional string indicating assessment day. Adding this argument makes sure that the first measurement of a day is not regressed on the last measurement of the previous day. IMPORTANT: only add this if the data has multiple observations per day.
</p>
</td></tr>
<tr><td><code id="var1_+3A_idvar">idvar</code></td>
<td>

<p>Optional string indicating the subject ID
</p>
</td></tr>
<tr><td><code id="var1_+3A_vars">vars</code></td>
<td>

<p>An optional character vector encoding the variables used in the analyis. Must equal names of the dataset in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="var1_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="var1_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. Make sure <code>covtype</code> argument is set correctly to the type of covariances used. 
</p>
</td></tr>
<tr><td><code id="var1_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="var1_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="var1_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion.
</p>
</td></tr>
<tr><td><code id="var1_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="var1_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="var1_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation, <code>"FIML"</code> for full-information maximum likelihood estimation, <code>"ULS"</code> for unweighted least squares estimation, <code>"WLS"</code> for weighted least squares estimation, and <code>"DWLS"</code> for diagonally weighted least squares estimation.
</p>
</td></tr>
<tr><td><code id="var1_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="var1_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code>bootstrap</code>).
</p>
</td></tr>
<tr><td><code id="var1_+3A_standardize">standardize</code></td>
<td>

<p>Which standardization method should be used? <code>"none"</code> (default) for no standardization, <code>"z"</code> for z-scores, and <code>"quantile"</code> for a non-parametric transformation to the quantiles of the marginal standard normal distribution.
</p>
</td></tr>
<tr><td><code id="var1_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="var1_+3A_covtype">covtype</code></td>
<td>

<p>If 'covs' is used, this is the type of covariance (maximum likelihood or unbiased) the input covariance matrix represents. Set to <code>"ML"</code> for maximum likelihood estimates (denominator n) and <code>"UB"</code> to unbiased estimates (denominator n-1). The default will try to find the type used, by investigating which is most likely to result from integer valued datasets.
</p>
</td></tr>
<tr><td><code id="var1_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should messages be printed?
</p>
</td></tr>
<tr><td><code id="var1_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="var1_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="var1_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="var1_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>var1</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This will be updated in a later version.
</p>


<h3>Value</h3>

<p>An object of the class psychonetrics
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>References</h3>

<p>Epskamp, S., Waldorp, L. J., Mottus, R., &amp; Borsboom, D. (2018). The Gaussian graphical model in cross-sectional and time-series data. Multivariate Behavioral Research, 53(4), 453-480.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lvm">lvm</a></code>, <code><a href="#topic+varcov">varcov</a></code>, <code><a href="#topic+dlvm1">dlvm1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("dplyr")
library("graphicalVAR")

beta &lt;- matrix(c(
  0,0.5,
  0.5,0
),2,2,byrow=TRUE)
kappa &lt;- diag(2)
simData &lt;- graphicalVARsim(50, beta, kappa)

# Form model:
model &lt;- gvar(simData)

# Evaluate model:
model &lt;- model %&gt;% runmodel

# Parameter estimates:
model %&gt;% parameters

# Plot the CIs:
CIplot(model,  "beta")

# Note: this example is wrapped in a dontrun environment because the data is not 
# available locally.
## Not run: 
# Longer example:
#
# Obtain the data from:
#
# Epskamp, S., van Borkulo, C. D., van der Veen, D. C., Servaas, M. N., Isvoranu, A. M., 
# Riese, H., &amp; Cramer, A. O. (2018). Personalized network modeling in psychopathology: 
# The importance of contemporaneous and temporal connections. Clinical Psychological 
# Science, 6(3), 416-427.
# 
# Available here: https://osf.io/c8wjz/

tsdata &lt;- read.csv("Supplementary2_data.csv")

# Encode time variable in a way R understands:
tsdata$time &lt;- as.POSIXct(tsdata$time, tz = "Europe/Amsterdam")

# Extract days:
tsdata$Day &lt;- as.Date(tsdata$time, tz = "Europe/Amsterdam")

# Variables to use:
vars &lt;- c("relaxed", "sad", "nervous", "concentration", "tired", "rumination", 
          "bodily.discomfort")

# Estimate, prune with FDR, and perform stepup search:
model_FDRprune &lt;- gvar(
  tsdata, 
  vars = vars, 
  dayvar = "Day",
  estimator = "FIML"
  ) %&gt;% 
  runmodel %&gt;% 
  prune(adjust = "fdr", recursive = FALSE) %&gt;% 
  stepup(criterion = "bic")

# Estimate with greedy stepup search:
model_stepup &lt;- gvar(
  tsdata, 
  vars = vars, 
  dayvar = "Day",
  estimator = "FIML",
  omega_zeta = "zero",
  beta = "zero"
) %&gt;% 
  runmodel %&gt;% 
  stepup(greedy = TRUE, greedyadjust = "bonferroni", criterion = "bic")

# Compare models:
compare(
  FDRprune = model_FDRprune,
  stepup = model_stepup
)
# Very similar but not identical. Stepup is prefered here according to AIC and BIC

# Stepup results:
temporal &lt;- getmatrix(model_stepup, "PDC") # PDC = Partial Directed Correlations
contemporaneous &lt;- getmatrix(model_stepup, "omega_zeta")

# Average layout:
library("qgraph")
L &lt;- averageLayout(temporal, contemporaneous)

# Labels:
labs &lt;- gsub("\\.","\n",vars)

# Plot:
layout(t(1:2))
qgraph(temporal, layout = L, theme = "colorblind", directed=TRUE, diag=TRUE,
       title = "Temporal", vsize = 12, mar = rep(6,4), asize = 5,
       labels = labs)
qgraph(contemporaneous, layout = L, theme = "colorblind", 
       title = "Contemporaneous", vsize = 12, mar = rep(6,4), asize = 5,
       labels = labs)

## End(Not run)
</code></pre>

<hr>
<h2 id='varcov'>
Variance-covariance family of psychonetrics models
</h2><span id='topic+varcov'></span><span id='topic+cholesky'></span><span id='topic+precision'></span><span id='topic+prec'></span><span id='topic+ggm'></span><span id='topic+corr'></span>

<h3>Description</h3>

<p>This is the family of models that models only a variance-covariance matrix with mean structure. The <code>type</code> argument can be used to define what model is used: <code>type = "cov"</code> (default) models a variance-covariance matrix directly, <code>type = "chol"</code> (alias: <code>cholesky()</code>) models a Cholesky decomposition, <code>type = "prec"</code> (alias: <code>precision()</code>) models a precision matrix, <code>type = "ggm"</code> (alias: <code>ggm()</code>) models a Gaussian graphical model (Epskamp, Rhemtulla and Borsboom, 2017), and <code>type = "cor"</code> (alias: <code>corr()</code>) models a correlation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varcov(data, type = c("cov", "chol", "prec", "ggm", "cor"),
                   sigma = "full", kappa = "full", omega = "full",
                   lowertri = "full", delta = "diag", rho = "full", SD =
                   "full", mu, tau, vars, ordered = character(0), groups,
                   covs, means, nobs, missing = "listwise", equal =
                   "none", baseline_saturated = TRUE, estimator =
                   "default", optimizer, storedata = FALSE, WLS.W,
                   sampleStats, meanstructure, corinput, verbose = FALSE,
                   covtype = c("choose", "ML", "UB"), standardize =
                   c("none", "z", "quantile"), fullFIML = FALSE,
                   bootstrap = FALSE, boot_sub, boot_resample)
cholesky(...)
precision(...)
prec(...)
ggm(...)
corr(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varcov_+3A_data">data</code></td>
<td>

<p>A data frame encoding the data used in the analysis. Can be missing if <code>covs</code> and <code>nobs</code> are supplied.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_type">type</code></td>
<td>

<p>The type of model used. See description.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_sigma">sigma</code></td>
<td>

<p>Only used when <code>type = "cov"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_kappa">kappa</code></td>
<td>

<p>Only used when <code>type = "prec"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_omega">omega</code></td>
<td>

<p>Only used when <code>type = "ggm"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_lowertri">lowertri</code></td>
<td>

<p>Only used when <code>type = "chol"</code>. Either <code>"full"</code> to estimate every element freely, <code>"diag"</code> to only include diagonal elements, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_delta">delta</code></td>
<td>

<p>Only used when <code>type = "ggm"</code>. Either <code>"diag"</code> or <code>"zero"</code> (not recommended), or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_rho">rho</code></td>
<td>

<p>Only used when <code>type = "cor"</code>. Either <code>"full"</code> to estimate every element freely, <code>"zero"</code> to set all elements to zero, or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_sd">SD</code></td>
<td>

<p>Only used when <code>type = "cor"</code>. Either <code>"diag"</code> or <code>"zero"</code> (not recommended), or a matrix of the dimensions node x node with 0 encoding a fixed to zero element, 1 encoding a free to estimate element, and higher integers encoding equality constrains. For multiple groups, this argument can be a list or array with each element/slice encoding such a matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_mu">mu</code></td>
<td>

<p>Optional vector encoding the mean structure. Set elements to 0 to indicate fixed to zero constrains, 1 to indicate free means, and higher integers to indicate equality constrains. For multiple groups, this argument can be a list or array with each element/column encoding such a vector.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_tau">tau</code></td>
<td>

<p>Optional list encoding the thresholds per variable.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_vars">vars</code></td>
<td>

<p>An optional character vector encoding the variables used in the analyis. Must equal names of the dataset in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_groups">groups</code></td>
<td>

<p>An optional string indicating the name of the group variable in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_covs">covs</code></td>
<td>

<p>A sample variance&ndash;covariance matrix, or a list/array of such matrices for multiple groups. Make sure <code>covtype</code> argument is set correctly to the type of covariances used. 
</p>
</td></tr>
<tr><td><code id="varcov_+3A_means">means</code></td>
<td>

<p>A vector of sample means, or a list/matrix containing such vectors for multiple groups.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_nobs">nobs</code></td>
<td>

<p>The number of observations used in <code>covs</code> and <code>means</code>, or a vector of such numbers of observations for multiple groups.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_covtype">covtype</code></td>
<td>

<p>If 'covs' is used, this is the type of covariance (maximum likelihood or unbiased) the input covariance matrix represents. Set to <code>"ML"</code> for maximum likelihood estimates (denominator n) and <code>"UB"</code> to unbiased estimates (denominator n-1). The default will try to find the type used, by investigating which is most likely to result from integer valued datasets.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_missing">missing</code></td>
<td>

<p>How should missingness be handled in computing the sample covariances and number of observations when <code>data</code> is used. Can be <code>"listwise"</code> for listwise deletion, or <code>"pairwise"</code> for pairwise deletion.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_equal">equal</code></td>
<td>

<p>A character vector indicating which matrices should be constrained equal across groups. 
</p>
</td></tr>
<tr><td><code id="varcov_+3A_baseline_saturated">baseline_saturated</code></td>
<td>

<p>A logical indicating if the baseline and saturated model should be included. Mostly used internally and NOT Recommended to be used manually.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_estimator">estimator</code></td>
<td>

<p>The estimator to be used. Currently implemented are <code>"ML"</code> for maximum likelihood estimation, <code>"FIML"</code> for full-information maximum likelihood estimation, <code>"ULS"</code> for unweighted least squares estimation, <code>"WLS"</code> for weighted least squares estimation, and <code>"DWLS"</code> for diagonally weighted least squares estimation.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_optimizer">optimizer</code></td>
<td>

<p>The optimizer to be used. Can be one of <code>"nlminb"</code> (the default R <code>nlminb</code> function), <code>"ucminf"</code> (from the <code>optimr</code> package), and C++ based optimizers <code>"cpp_L-BFGS-B"</code>, <code>"cpp_BFGS"</code>, <code>"cpp_CG"</code>, <code>"cpp_SANN"</code>, and <code>"cpp_Nelder-Mead"</code>. The C++ optimizers are faster but slightly less stable. Defaults to <code>"nlminb"</code>.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_storedata">storedata</code></td>
<td>

<p>Logical, should the raw data be stored? Needed for bootstrapping (see <code>bootstrap</code>).
</p>
</td></tr>
<tr><td><code id="varcov_+3A_standardize">standardize</code></td>
<td>

<p>Which standardization method should be used? <code>"none"</code> (default) for no standardization, <code>"z"</code> for z-scores, and <code>"quantile"</code> for a non-parametric transformation to the quantiles of the marginal standard normal distribution.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_wls.w">WLS.W</code></td>
<td>

<p>Optional WLS weights matrix.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_samplestats">sampleStats</code></td>
<td>

<p>An optional sample statistics object. Mostly used internally. 
</p>
</td></tr>
<tr><td><code id="varcov_+3A_verbose">verbose</code></td>
<td>

<p>Logical, should progress be printed to the console?
</p>
</td></tr>
<tr><td><code id="varcov_+3A_ordered">ordered</code></td>
<td>

<p>A vector with strings indicating the variables that are ordered catagorical, or set to <code>TRUE</code> to model all variables as ordered catagorical.
</p>
</td></tr>
<tr><td><code id="varcov_+3A_meanstructure">meanstructure</code></td>
<td>

<p>Logical, should the meanstructure be modeled explicitly?
</p>
</td></tr>
<tr><td><code id="varcov_+3A_corinput">corinput</code></td>
<td>

<p>Logical, is the input a correlation matrix?
</p>
</td></tr>
<tr><td><code id="varcov_+3A_fullfiml">fullFIML</code></td>
<td>

<p>Logical, should row-wise FIML be used? Not recommended!
</p>
</td></tr>
<tr><td><code id="varcov_+3A_bootstrap">bootstrap</code></td>
<td>

<p>Should the data be bootstrapped? If <code>TRUE</code> the data are resampled and a bootstrap sample is created. These must be aggregated using <code><a href="#topic+aggregate_bootstraps">aggregate_bootstraps</a></code>! Can be <code>TRUE</code> or <code>FALSE</code>. Can also be <code>"nonparametric"</code> (which sets <code>boot_sub = 1</code> and <code>boot_resample = TRUE</code>) or <code>"case"</code> (which sets <code>boot_sub = 0.75</code> and <code>boot_resample = FALSE</code>).
</p>
</td></tr>
<tr><td><code id="varcov_+3A_boot_sub">boot_sub</code></td>
<td>

<p>Proportion of cases to be subsampled (<code>round(boot_sub * N)</code>).
</p>
</td></tr>
<tr><td><code id="varcov_+3A_boot_resample">boot_resample</code></td>
<td>

<p>Logical, should the bootstrap be with replacement (<code>TRUE</code>) or without replacement (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="varcov_+3A_...">...</code></td>
<td>

<p>Arguments sent to <code>varcov</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model used in this family is:
</p>
<p><code class="reqn">\mathrm{var}(\boldsymbol{y} ) = \boldsymbol{\Sigma}</code>
</p>
<p><code class="reqn">\mathcal{E}( \boldsymbol{y} ) = \boldsymbol{\mu}</code>
</p>
<p>in which the covariance matrix can further be modeled in three ways. With <code>type = "chol"</code> as Cholesky decomposition:
</p>
<p><code class="reqn">\boldsymbol{\Sigma} = \boldsymbol{L}\boldsymbol{L}</code>,
</p>
<p>with <code>type = "prec"</code> as Precision matrix:
</p>
<p><code class="reqn">\boldsymbol{\Sigma} = \boldsymbol{K}^{-1}</code>,
</p>
<p>and finally with <code>type = "ggm"</code> as Gaussian graphical model:
</p>
<p><code class="reqn">\boldsymbol{\Sigma} = \boldsymbol{\Delta}(\boldsymbol{I} - \boldsymbol{\Omega})^(-1) \boldsymbol{\Delta}</code>.
</p>


<h3>Value</h3>

<p>An object of the class psychonetrics 
</p>


<h3>Author(s)</h3>

<p>Sacha Epskamp
</p>


<h3>References</h3>

<p>Epskamp, S., Rhemtulla, M., &amp; Borsboom, D. (2017). Generalized network psychometrics: Combining network and latent variable models. Psychometrika, 82(4), 904-927.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lvm">lvm</a></code>, <code><a href="#topic+var1">var1</a></code>, <code><a href="#topic+dlvm1">dlvm1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData &lt;- bfi %&gt;% 
  select(A1:A5, gender) %&gt;% 
  na.omit # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars &lt;- names(ConsData)[1:5]

# Saturated estimation:
mod_saturated &lt;- ggm(ConsData, vars = vars)

# Run the model:
mod_saturated &lt;- mod_saturated %&gt;% runmodel

# We can look at the parameters:
mod_saturated %&gt;% parameters

# Labels:
labels &lt;- c(
  "indifferent to the feelings of others",
  "inquire about others' well-being",
  "comfort others",
  "love children",
  "make people feel at ease")
  
# Plot CIs:
CIplot(mod_saturated,  "omega", labels = labels, labelstart = 0.2)



# We can also fit an empty network:
mod0 &lt;- ggm(ConsData, vars = vars, omega = "zero")

# Run the model:
mod0 &lt;- mod0 %&gt;% runmodel

# We can look at the modification indices:
mod0 %&gt;% MIs

# To automatically add along modification indices, we can use stepup:
mod1 &lt;- mod0 %&gt;% stepup

# Let's also prune all non-significant edges to finish:
mod1 &lt;- mod1 %&gt;% prune

# Look at the fit:
mod1 %&gt;% fit

# Compare to original (baseline) model:
compare(baseline = mod0, adjusted = mod1)

# We can also look at the parameters:
mod1 %&gt;% parameters

# Or obtain the network as follows:
getmatrix(mod1, "omega")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
