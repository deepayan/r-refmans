<!DOCTYPE html><html lang="en"><head><title>Help for package mstDIF</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mstDIF}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mstDIF-package'><p>mstDIF: A Collection of Statistical Tests for DIF Detection in Multistage Tests</p></a></li>
<li><a href='#bootstrap_sctest'><p>A score-based DIF test using the parametric bootstrap approach.</p></a></li>
<li><a href='#log_reg'><p>A logistic regression DIF test for MSTs</p></a></li>
<li><a href='#mstDIF'><p>A general function to detect differential item functioning (DIF) in multistage tests (MSTs)</p></a></li>
<li><a href='#mstDIF-Methods'><p>Methods for the mstDIF-class</p></a></li>
<li><a href='#mstSIB'><p>The mstSIB test for MSTs</p></a></li>
<li><a href='#permutation_sctest'><p>A score-based DIF test using the permutation approach.</p></a></li>
<li><a href='#toydata'><p>A Toy Example of 1000 Respondents Working on a Multistage Test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of DIF Tests for Multistage Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>expm, Matrix, PP, mirt (&ge; 1.31), scDIFtest, eRm</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvtnorm, testthat, knitr, rmarkdown, strucchange</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of statistical tests for the detection of differential
    item functioning (DIF) in multistage tests. Methods entail logistic regression,
    an adaptation of the simultaneous item bias test (SIBTEST), and various score-based tests.
    The presented tests provide itemwise test for DIF along categorical, ordinal or metric covariates. Methods for uniform and non-uniform 
    DIF effects are available depending on which method is used.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-30 09:57:01 UTC; rdebelak-adm</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Author:</td>
<td>Rudolf Debelak [aut, cre],
  Dries Debeer [aut],
  Sebastian Appelbaum [ctb],
  Mark J. Gierl [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rudolf Debelak &lt;rudolf.debelak@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-30 11:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='mstDIF-package'>mstDIF: A Collection of Statistical Tests for DIF Detection in Multistage Tests</h2><span id='topic+mstDIF-package'></span>

<h3>Description</h3>

<p>A Collection of Statistical Tests for the Detection of Differential
Item Functioning (DIF) in Multistage Tests. Methods entail logistic regression,
mstSIB, and various score-based tests.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Rudolf Debelak <a href="mailto:rudolf.debelak@gmail.com">rudolf.debelak@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Dries Debeer <a href="mailto:debeer.dries@gmail.com">debeer.dries@gmail.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Sebastian Appelbaum [contributor]
</p>
</li>
<li><p> Mark J. Gierl [contributor]
</p>
</li></ul>


<hr>
<h2 id='bootstrap_sctest'>A score-based DIF test using the parametric bootstrap approach.</h2><span id='topic+bootstrap_sctest'></span>

<h3>Description</h3>

<p><code>bootstrap_sctest</code> computes a score test to detect DIF in multiple 
item/parameters with respect to multiple person covariates (<code>DIF_covariate</code>).
A parametric bootstrap approach is applied to obtain p-values. That is, given the 
(item and person) parameters, new data sets are sampled to create the distribution 
of the test statistic under the null hypothesis. The functionality is limited to 
the 1-, 2-, and 3-parameter logistic models.
Only DIF with respect to the <code>a</code> and <code>b</code> parameters is tested for,
which correspond to the item discrimination and the item difficulty parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_sctest(
  resp,
  theta = NULL,
  a = rep(1, length(b)),
  b,
  c = rep(0, length(b)),
  DIF_covariate = NULL,
  parameters = c("per_item", "ab", "a", "b"),
  item_selection = NULL,
  nSamples = 1000,
  theta_method = c("wle", "mle", "eap", "map"),
  slope_intercept = FALSE,
  statistic = "auto",
  meanCenter = TRUE,
  decorrelate = FALSE,
  impact_groups = rep(1, dim(resp)[1])
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrap_sctest_+3A_resp">resp</code></td>
<td>
<p>A matrix (or data frame) containing the responses, with the
items in the columns.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_theta">theta</code></td>
<td>
<p>A vector with the true/estimated ability parameters or NULL
(the default) which leads to the ability parameters being estimated.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_a">a</code></td>
<td>
<p>A vector of item slopes/item discriminations.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_b">b</code></td>
<td>
<p>A vector of item locations/item difficulties.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_c">c</code></td>
<td>
<p>A vector of pseudo guessing parameters.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_dif_covariate">DIF_covariate</code></td>
<td>
<p>A list with the person covariate(s) to test for as
element(s).</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_parameters">parameters</code></td>
<td>
<p>A character string, either &quot;per_item&quot;, &quot;ab&quot;, &quot;a&quot;, or &quot;b&quot;,
to specify which parameters should be tested for.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_item_selection">item_selection</code></td>
<td>
<p>A character vector with the column names or an integer
vector with the column numbers in the <code>resp</code>, specifying the items for
which the test should be computed. When set to NULL (i.t., the default),
all the items are tested.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_nsamples">nSamples</code></td>
<td>
<p>An integer value with the number of permutations to be
sampled.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_theta_method">theta_method</code></td>
<td>
<p>A character string, either &quot;wle&quot;, &quot;mle&quot;, &quot;eap&quot;, of
&quot;map&quot; that specifies the estimator for the ability estimation. Only
relevant when <code>theta == NULL</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_slope_intercept">slope_intercept</code></td>
<td>
<p>A logical value indicating whether the slope-intercept
formulation of the 2-/3-PL model should be used.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_statistic">statistic</code></td>
<td>
<p>A character string, either &quot;auto&quot;, &quot;DM&quot;, &quot;CvM&quot;,
&quot;maxLM&quot;, &quot;LMuo&quot;, &quot;WDMo&quot;, or &quot;maxLMo&quot;, specifying the test statistic to be used.</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_meancenter">meanCenter</code></td>
<td>
<p>A logical value: should the score contributions be mean
centered per parameter?</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_decorrelate">decorrelate</code></td>
<td>
<p>A logical value: should the score contributions be
decorrelated?</p>
</td></tr>
<tr><td><code id="bootstrap_sctest_+3A_impact_groups">impact_groups</code></td>
<td>
<p>A vector indicating impact-group membership for
each person.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Author: Dries Debeer
</p>


<h3>Value</h3>

<p>A list with four elements:
</p>

<dl>
<dt><code>statistics</code></dt><dd><p>A matrix containing all the test statistics.</p>
</dd>
<dt><code>p</code></dt><dd><p>A matrix containing the obtained <em>p</em>-values.</p>
</dd>
<dt><code>nSamples</code></dt><dd><p>The number of samples taken.</p>
</dd>
<dt><code>DIF_covariate</code></dt><dd><p>A list containing all the covariate(s) used to order
the score contributions, as well as the used test statistics.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+permutation_sctest">permutation_sctest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("toydata")
resp &lt;- toydata$resp
group_categ &lt;- toydata$group_categ
it &lt;- toydata$it
discr &lt;- it[,1]
diff &lt;- it[,2]

bootstrap_sctest(resp = resp, DIF_covariate = group_categ, a = discr, b = diff, 
decorrelate = FALSE)


</code></pre>

<hr>
<h2 id='log_reg'>A logistic regression DIF test for MSTs</h2><span id='topic+log_reg'></span>

<h3>Description</h3>

<p>This function allows the detection of itemwise DIF for Multistage Tests. It is based on the comparison
of three logistic regression models for each item. The first logistic regression model (Model 1)
predicts the positiveness of each response solely on the estimated ability parameters. The second
logistic regression model (Model 2) predicts the positiveness based on the ability parameters
and the membership to the focal and reference group as additive predictor variables.
The third model (Model 3) uses the same predictors as Model 2 to predict the positiveness of the responses, but
also includes an interaction effect. Three model comparisons are carried out (Models 1/2, Models 1/3, Models 2/3)
based on two criteria: The comparison of the Nagelkerke R squared values, and the p-values of a likelihood ratio test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_reg(resp, DIF_covariate, theta = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_reg_+3A_resp">resp</code></td>
<td>
<p>A data frame containing the response matrix. Rows correspond to respondents, columns to items.</p>
</td></tr>
<tr><td><code id="log_reg_+3A_dif_covariate">DIF_covariate</code></td>
<td>
<p>A factor indicating the membership to the reference and focal groups.</p>
</td></tr>
<tr><td><code id="log_reg_+3A_theta">theta</code></td>
<td>
<p>A vector of ability estimates for each respondent.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Author: Sebastian Appelbaum, with minor changes by Rudolf Debelak and Dries Debeer
</p>


<h3>Value</h3>

<p>A list with four elements. The first element is the response matrix, the second element is the name of
the DIF covariate, and the third element is the name of the test. The fourth element is a data frame where
each row corresponds to an item. The columns of this data frame correspond to the following entries:
</p>

<dl>
<dt><code>N</code></dt><dd><p>The number of responses observed for this item.</p>
</dd>
<dt><code>overall_chi_sq</code></dt><dd><p>The chi squared statistic of the likelihood ratio test comparing Model 1 and Model 3.</p>
</dd>
<dt><code>overall_p_value</code></dt><dd><p>The p-values of the likelihood ratio test comparing Model 1 and Model 3 as
an indicator for the overall DIF effect.</p>
</dd>
<dt><code>Delta_NagelkerkeR2</code></dt><dd><p>The difference of the Nagelkerke R squared values for Model 1 and Model 3.</p>
</dd>
<dt><code>UDIF_chi_sq</code></dt><dd><p>The chi squared statistic of the likelihood ratio test comparing Model 1 and Model 2.</p>
</dd>
<dt><code>UDIF_p_value</code></dt><dd><p>The p-values of the likelihood ratio test comparing Model 1 and Model 2.</p>
</dd>
<dt><code>UDIF_Delta_NagelkerkeR2</code></dt><dd><p>The difference of the Nagelkerke R squared values for Model 1 and Model 2.</p>
</dd>
<dt><code>CDIF_chi_sq</code></dt><dd><p>The chi squared statistic of the likelihood ratio test comparing Model 2 and Model 3.</p>
</dd>
<dt><code>CDIF_p_value</code></dt><dd><p>The p-values of the likelihood ratio test comparing Model 2 and Model 3.</p>
</dd>
<dt><code>CDIF_Delta_NagelkerkeR2</code></dt><dd><p>The difference of the Nagelkerke R squared values for Model 2 and Model 3.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("toydata")
resp &lt;- toydata$resp
group_categ &lt;- toydata$group_categ
theta_est &lt;- toydata$theta_est
log_reg(resp, DIF_covariate = factor(group_categ), theta = theta_est)


</code></pre>

<hr>
<h2 id='mstDIF'>A general function to detect differential item functioning (DIF) in multistage tests (MSTs)</h2><span id='topic+mstDIF'></span><span id='topic+mstDIF.default'></span><span id='topic+mstDIF.AllModelClass'></span><span id='topic+mstDIF.dRm'></span>

<h3>Description</h3>

<p>This function allows the application of various methods for the detection of differential item functioning
in multistage tests. Currently five methods are implemented: 1. Logistic Regression, 2. mstSIB, 3. analytical
score-base tests, 4. a score-based Bootstrap test, 5. a score-based permutation test. The required input
depends on the chosen DIF test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
mstDIF(resp, DIF_covariate, method, theta = NULL, see = NULL, ...)

## S3 method for class 'AllModelClass'
mstDIF(
  object,
  DIF_covariate,
  method,
  theta = NULL,
  see = NULL,
  theta_method = "WLE",
  ...
)

## S3 method for class 'dRm'
mstDIF(object, DIF_covariate, method, theta = NULL, see = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mstDIF_+3A_resp">resp</code>, <code id="mstDIF_+3A_object">object</code></td>
<td>
<p>A data frame or matrix containing the response matrix. Rows correspond to 
respondents, columns to items. Or an object of class SingleGroup-class or MultiGroup-class object
as returned by mirt, or a dRm object as returned by the RM function in eRm.</p>
</td></tr>
<tr><td><code id="mstDIF_+3A_dif_covariate">DIF_covariate</code></td>
<td>
<p>A vector of ability estimates for each respondent.</p>
</td></tr>
<tr><td><code id="mstDIF_+3A_method">method</code></td>
<td>
<p>A character value indicating the DIF test that should be used. Possible values are &quot;logreg&quot;
(Logistic regression), &quot;mstsib&quot; (mstSIB), &quot;bootstrap&quot; (score-based Bootstrap test), &quot;permutation&quot; (score-based)
permutation test) and &quot;analytical&quot; (analytical score-based test).</p>
</td></tr>
<tr><td><code id="mstDIF_+3A_theta">theta</code></td>
<td>
<p>Estimates of the ability parameters.</p>
</td></tr>
<tr><td><code id="mstDIF_+3A_see">see</code></td>
<td>
<p>Estimates of the standard error of estimation.</p>
</td></tr>
<tr><td><code id="mstDIF_+3A_...">...</code></td>
<td>
<p>Additional, test-specific arguments.</p>
</td></tr>
<tr><td><code id="mstDIF_+3A_theta_method">theta_method</code></td>
<td>
<p>Method for estimating the ability parameters if they
should be estimated based on the responses. The calculation is carried
out by the mirt package. Can be: &quot;WLE&quot; (default),
&quot;MAP&quot;, &quot;EAP&quot;, &quot;ML&quot;, &quot;EAPsum&quot;, &quot;plausible&quot;, &quot;classify&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Author: Rudolf Debelak and Dries Debeer
</p>


<h3>Value</h3>

<p>An object of class <code>mstDIF</code>, which is a list with the following elements:
</p>

<dl>
<dt><code>resp</code></dt><dd><p>The response matrix as a data frame.</p>
</dd>
<dt><code>method</code></dt><dd><p>The used DIF detection method.</p>
</dd>
<dt><code>test</code></dt><dd><p>The used test or statistic.</p>
</dd>
<dt><code>DIF_covariate</code></dt><dd><p>The person covariate tested for DIF.</p>
</dd>
<dt><code>DIF_test</code></dt><dd><p>A list with the DIF-test results.</p>
</dd>
<dt><code>call</code></dt><dd><p>The function call.</p>
</dd>
<dt><code>method_results</code></dt><dd><p>The complete output of the selected DIF test.
Details depend on the DIF test.</p>
</dd>
</dl>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>mstDIF(default)</code>: Default mstDIF method
</p>
</li>
<li> <p><code>mstDIF(AllModelClass)</code>: mstDIF method for mirt-objects
</p>
</li>
<li> <p><code>mstDIF(dRm)</code>: mstDIF method for dRm-objects
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="#topic+mstDIF-Methods">mstDIF-Methods</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## load data
data("toydata")
resp &lt;- toydata$resp
group_categ &lt;- factor(toydata$group_categ)
theta_est &lt;- toydata$theta_est
see_est &lt;- toydata$see_est

## test DIF along a categorical covariate (a factor) using the
## logistic regression method
res1 &lt;- mstDIF(resp, DIF_covariate = group_categ, method = "logreg",
theta = theta_est)
res1
summary(res1)

## test DIF along a categorical covariate (a factor) using the
## mstSIB method
res2 &lt;- mstDIF(resp, DIF_covariate = factor(group_categ), method = "mstsib",
theta = theta_est, see = see_est)
res2
summary(res2)

</code></pre>

<hr>
<h2 id='mstDIF-Methods'>Methods for the mstDIF-class</h2><span id='topic+mstDIF-Methods'></span><span id='topic+print.mstDIF'></span><span id='topic+summary.mstDIF'></span>

<h3>Description</h3>

<p><code>print</code> and <code>summary</code> methods for objects of the
<code>mstDIF-class</code>, as returned by <code><a href="#topic+mstDIF">mstDIF</a></code>. See details
for more information about the methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mstDIF'
print(x, ...)

## S3 method for class 'mstDIF'
summary(object, DIF_type = "overall", ordered = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mstDIF-Methods_+3A_x">x</code></td>
<td>
<p>an object of class <code>mstDIF</code></p>
</td></tr>
<tr><td><code id="mstDIF-Methods_+3A_...">...</code></td>
<td>
<p>other arguments passed to the method.</p>
</td></tr>
<tr><td><code id="mstDIF-Methods_+3A_object">object</code></td>
<td>
<p>an object of class <code>mstDIF</code></p>
</td></tr>
<tr><td><code id="mstDIF-Methods_+3A_dif_type">DIF_type</code></td>
<td>
<p>a string that should one or more of &quot;overall&quot;, &quot;uniform&quot;,
&quot;non-uniform&quot;, &quot;all&quot;.</p>
</td></tr>
<tr><td><code id="mstDIF-Methods_+3A_ordered">ordered</code></td>
<td>
<p>logical: should the summary be ordered according to the obtained p-values (in ascending order)?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method prints some basic information about the
<code>mstDIF-class</code> object.
</p>
<p>The <code>summary</code> method computes a data frame with a row for each item
that was included in the test. The columns are:
</p>

<dl>
<dt>item</dt><dd><p>The name of the item</p>
</dd>
<dt>statistic</dt><dd><p>The value for the used statistic per item</p>
</dd>
<dt>p_value</dt><dd><p>The p-value per item</p>
</dd>
<dt>eff_size</dt><dd><p>An effect-size for the DIF-test, if applicable</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
## load data
data("toydata")

## fit 2PL model using mirt
mirt_model &lt;- mirt::mirt(toydata$resp, model = 1)

## test DIF along a contiuous covariate
DIFtest &lt;- mstDIF(mirt_model, DIF_covariate = toydata$group_cont,
method = "analytical")

## print
DIFtest

## summary
summary(DIFtest)


</code></pre>

<hr>
<h2 id='mstSIB'>The mstSIB test for MSTs</h2><span id='topic+mstSIB'></span>

<h3>Description</h3>

<p>This function allows the detection of itemwise DIF using the mstSIB test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mstSIB(
  resp,
  DIF_covariate,
  theta = NULL,
  see = NULL,
  cellmin = 3,
  pctmin = 0.9,
  NCell = 80
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mstSIB_+3A_resp">resp</code></td>
<td>
<p>A data frame containing the response matrix. Rows correspond to respondents, columns to items.</p>
</td></tr>
<tr><td><code id="mstSIB_+3A_dif_covariate">DIF_covariate</code></td>
<td>
<p>A vector indicating the membership to the reference (0) and focal (1) groups.</p>
</td></tr>
<tr><td><code id="mstSIB_+3A_theta">theta</code></td>
<td>
<p>A vector of ability estimates for each respondent.</p>
</td></tr>
<tr><td><code id="mstSIB_+3A_see">see</code></td>
<td>
<p>A vector of the standard error of the ability estimates for each respondent.</p>
</td></tr>
<tr><td><code id="mstSIB_+3A_cellmin">cellmin</code></td>
<td>
<p>Minimum number of respondents per cell for the focal and reference group. Cells with fewer respondents are discarded.</p>
</td></tr>
<tr><td><code id="mstSIB_+3A_pctmin">pctmin</code></td>
<td>
<p>Minimum rate of focal and reference group that should be used for estimating the over ability difference between focal and groups after discarding cells with few respondents.</p>
</td></tr>
<tr><td><code id="mstSIB_+3A_ncell">NCell</code></td>
<td>
<p>The initial number of cells for estimating the overall ability difference between the focal and reference groups.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Author: Mark J. Gierl, with minor changes by Rudolf Debelak and Dries Debeer
</p>


<h3>Value</h3>

<p>A list with four elements. The first element is the response matrix, the second element is the name of
the DIF covariate, and the third element is the name of the test. The fourth element is a matrix where each
row corresponds to an item. The columns correspond to the following entries:
</p>

<dl>
<dt>Beta</dt><dd><p>The estimated weighted ability difference between the focal and reference groups.</p>
</dd>
<dt>Vars</dt><dd><p>The estimation error of the weighted ability difference between the focal and reference groups.</p>
</dd>
<dt>N_R</dt><dd><p>The number of respondents in the reference group.</p>
</dd>
<dt>N_F</dt><dd><p>The number of respondents in the focal group.</p>
</dd>
<dt>NCell</dt><dd><p>The initial number of cells for estimating the overall ability
difference between the focal and reference groups.</p>
</dd>
<dt>p_value</dt><dd><p>The p-value of the null hypothesis that the ability difference
between the focal and reference groups is 0.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("toydata")
resp &lt;- toydata$resp
group_categ &lt;- toydata$group_categ
theta_est &lt;- toydata$theta_est
see_est &lt;- toydata$see_est
mstSIB(resp = as.data.frame(resp), theta = theta_est,
DIF_covariate = group_categ, see = see_est)

</code></pre>

<hr>
<h2 id='permutation_sctest'>A score-based DIF test using the permutation approach.</h2><span id='topic+permutation_sctest'></span>

<h3>Description</h3>

<p><code>permutation_sctest</code> computes a score test to detect DIF in multiple 
item/parameters with respect to multiple person covariates (<code>DIF_covariate</code>).
A resampling approach is applied to obtain p-values. That is, given the (item and 
person) parameters, new data sets are sampled to create the distribution of the 
test statistic under the null hypothesis. The functionality is limited to the 
1-, 2-, and 3-parameter logistic models.
Only DIF with respect to the <code>a</code> and <code>b</code> parameters is tested for,
which correspond to the item discrimination and the item difficulty parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permutation_sctest(
  resp,
  theta = NULL,
  a = rep(1, length(b)),
  b,
  c = rep(0, length(b)),
  DIF_covariate = NULL,
  parameters = c("per_item", "ab", "a", "b"),
  item_selection = NULL,
  nSamples = 1000,
  theta_method = c("wle", "mle", "eap", "map"),
  slope_intercept = FALSE,
  statistic = "auto",
  meanCenter = TRUE,
  decorrelate = FALSE,
  impact_groups = rep(1, dim(resp)[1])
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permutation_sctest_+3A_resp">resp</code></td>
<td>
<p>A matrix (or data frame) containing the responses, with the
items in the columns.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_theta">theta</code></td>
<td>
<p>A vector with the true/estimated ability parameters or NULL
(the default) which leads to the ability parameters being estimated.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_a">a</code></td>
<td>
<p>A vector of item slopes/item discriminations.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_b">b</code></td>
<td>
<p>A vector of item locations/item difficulties.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_c">c</code></td>
<td>
<p>A vector of pseudo guessing parameters.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_dif_covariate">DIF_covariate</code></td>
<td>
<p>A list with the person covariate(s) to test for as
element(s).</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_parameters">parameters</code></td>
<td>
<p>A character string, either &quot;per_item&quot;, &quot;ab&quot;, &quot;a&quot;, or &quot;b&quot;,
to specify which parameters should be tested for.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_item_selection">item_selection</code></td>
<td>
<p>A character vector with the column names or an integer
vector with the column numbers in the <code>resp</code>, specifying the items for
which the test should be computed. When set to NULL (i.t., the default),
all the items are tested.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_nsamples">nSamples</code></td>
<td>
<p>An integer value with the number of permutations to be
sampled.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_theta_method">theta_method</code></td>
<td>
<p>A character string, either &quot;wle&quot;, &quot;mle&quot;, &quot;eap&quot;, of
&quot;map&quot; that specifies the estimator for the ability estimation. Only
relevant when <code>theta == NULL</code>.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_slope_intercept">slope_intercept</code></td>
<td>
<p>A logical value indicating whether the slope-intercept
formulation of the 2-/3-PL model should be used.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_statistic">statistic</code></td>
<td>
<p>A character string, either &quot;auto&quot;, &quot;DM&quot;, &quot;CvM&quot;,
&quot;maxLM&quot;, &quot;LMuo&quot;, &quot;WDMo&quot;, or &quot;maxLMo&quot;, specifying the test statistic to be used.</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_meancenter">meanCenter</code></td>
<td>
<p>A logical value: should the score contributions be mean
centered per parameter?</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_decorrelate">decorrelate</code></td>
<td>
<p>A logical value: should the score contributions be
decorrelated?</p>
</td></tr>
<tr><td><code id="permutation_sctest_+3A_impact_groups">impact_groups</code></td>
<td>
<p>A vector indicating impact-group membership for
each person.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Author: Dries Debeer
</p>


<h3>Value</h3>

<p>A list with four elements:
</p>

<dl>
<dt><code>statistics</code></dt><dd><p>A matrix containing all the test statistics.</p>
</dd>
<dt><code>p</code></dt><dd><p>A matrix containing the obtained <em>p</em>-values.</p>
</dd>
<dt><code>nSamples</code></dt><dd><p>The number of samples taken.</p>
</dd>
<dt><code>DIF_covariate</code></dt><dd><p>A list containing all the covariate(s) used to order
the score contributions, as well as the used test statistics.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+bootstrap_sctest">bootstrap_sctest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("toydata")
resp &lt;- toydata$resp
group_categ &lt;- toydata$group_categ
it &lt;- toydata$it
discr &lt;- it[,1]
diff &lt;- it[,2]

permutation_sctest(resp = resp, DIF_covariate = group_categ, a = discr, b = diff, 
decorrelate = FALSE)


</code></pre>

<hr>
<h2 id='toydata'>A Toy Example of 1000 Respondents Working on a Multistage Test</h2><span id='topic+toydata'></span>

<h3>Description</h3>

<p>Data of 1000 respondents working on a multistage test using a (1,2,2) design. The responses were generated
based on the 2PL model. Each module consists of 7 items. Data were generated using the mstR package, version 1.2
(https://cran.r-project.org/web/packages/mstR/index.html).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toydata
</code></pre>


<h3>Format</h3>

<p>A list with 7 elements:
</p>

<dl>
<dt>resp</dt><dd><p>The response matrix, with rows corresponding to respondents and columns corresponding to items.</p>
</dd>
<dt>it</dt><dd><p>A matrix of item parameters. The columns contain the discrimination, difficulty, pseudo-guessing and 
inattention parameters of the 4PL model. The discrimination parameters were drawn from a N(1,0.2) distribution.
The difficulty parameters were drawn from normal distributions. For module 1 (items 1-7), this distributions was N(0,1),
for modules 2 and 4 (items 8-14 and 22-28) it was N(1,1) and for modules 3 and 5 (items 15-21 and 29-35)
the distribution was N(-1,1).</p>
</dd>
<dt>theta</dt><dd><p>The true ability parameters.</p>
</dd>
<dt>theta_est</dt><dd><p>The ability parameters estimated by the WLE estimator.</p>
</dd>
<dt>group_categ</dt><dd><p>A simulated categorical person covariate. The first 500 respondents belong to group 0, the remaining 500
respondents to group 1.</p>
</dd>
<dt>group_cont</dt><dd><p>A simulated continuous person covariate. It simulates an age covariate, with a uniform distribution between
20 and 60.</p>
</dd>
<dt>see_est</dt><dd><p>The standard errors of the estimated ability parameters.</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
