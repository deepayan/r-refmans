<!DOCTYPE html><html lang="en"><head><title>Help for package edl</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {edl}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#activationsCueSet'><p>Calculate the change in activation for a specific cue or set of cues.</p></a></li>
<li><a href='#activationsEvents'><p>Calculate the activations for each learning event.</p></a></li>
<li><a href='#activationsMatrix'><p>Calculate the activations for one or a set of cues.</p></a></li>
<li><a href='#activationsOutcomes'><p>Calculate the activations for all outcomes in the data.</p></a></li>
<li><a href='#check'><p>Remove empty cues and/or outcomes.</p></a></li>
<li><a href='#checkWM'><p>Check whether cues and outcomes exist in a weight matrix and optionally add.</p></a></li>
<li><a href='#createTrainingData'><p>Create event training data from a frequency data frame.</p></a></li>
<li><a href='#createWM'><p>Create empty weight matrix based on a set of cues and outcomes.</p></a></li>
<li><a href='#cueWindow'><p>Create a 'cue window', for overlapping or continuous cues.</p></a></li>
<li><a href='#dat'><p>Simulated learning data.</p></a></li>
<li><a href='#edl'><p>Toolbox for Error-Driven Learning Simulations with Two-Layer Networks</p></a></li>
<li><a href='#getActivations'><p>Function to calculate the activations.</p></a></li>
<li><a href='#getCues'><p>Extract cues from list of weightmatrices.</p></a></li>
<li><a href='#getLambda'><p>Retrieve the lambda values for all or specific outcomes</p>
for each learning event.</a></li>
<li><a href='#getOutcomes'><p>Extract outcomes from list of weightmatrices.</p></a></li>
<li><a href='#getUpdate'><p>Retrieve the weight updates and their change for each learning event.</p></a></li>
<li><a href='#getValues'><p>Retrieve all cues from a vector of text strings.</p></a></li>
<li><a href='#getWeightsByCue'><p>Extract the change of connection weights between a specific cue and all</p>
outcomes.</a></li>
<li><a href='#getWeightsByOutcome'><p>Extract the change of connection weights between all cues and a specific</p>
outcome.</a></li>
<li><a href='#getWM'><p>Retrieve all cues from a vector of text strings.</p></a></li>
<li><a href='#luceChoice'><p>Function implementing the Luce choice rule.</p></a></li>
<li><a href='#plotActivations'><p>Visualize the change of connection weights between a specific outcome and all</p>
cues.</a></li>
<li><a href='#plotCueWeights'><p>Visualize the change of connection weights between a specific cue and all</p>
outcomes.</a></li>
<li><a href='#plotNetwork'><p>Return strong weights.</p></a></li>
<li><a href='#plotOutcomeWeights'><p>Visualize the change of connection weights between a specific outcome and all</p>
cues.</a></li>
<li><a href='#RWlearning'><p>Function implementing the Rescorla-Wagner learning.</p></a></li>
<li><a href='#RWlearningMatrix'><p>Function implementing the Rescorla-Wagner learning.</p></a></li>
<li><a href='#RWlearningNoCueCompetition'><p>Function implementing the Rescorla-Wagner learning equations without cue</p>
competition (for illustration purposes).</a></li>
<li><a href='#RWlearningNoOutcomeCompetition'><p>Function implementing the Rescorla-Wagner learning equetions without</p>
outcome competition (for illustration purposes).</a></li>
<li><a href='#setBackground'><p>Set value background cue.</p></a></li>
<li><a href='#updateWeights'><p>Function implementing the Rescorla-Wagner learning for a single learning</p>
event.</a></li>
<li><a href='#updateWeightsNoCueCompetition'><p>Function implementing the Rescorla-Wagner learning equations without cue</p>
competition for a single learning event.</a></li>
<li><a href='#updateWeightsNoOutcomeCompetition'><p>Function implementing the Rescorla-Wagner learning equations without</p>
outcome competition (for illustration purposes) for a single learning
event.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-09-15</td>
</tr>
<tr>
<td>Title:</td>
<td>Toolbox for Error-Driven Learning Simulations with Two-Layer
Networks</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jacolien van Rij &lt;j.c.van.rij@rug.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Error-driven learning (based on the Widrow &amp; Hoff (1960)<a href="https://isl.stanford.edu/~widrow/papers/c1960adaptiveswitching.pdf">https://isl.stanford.edu/~widrow/papers/c1960adaptiveswitching.pdf</a> learning rule, and essentially the same as Rescorla-Wagner's learning equations (Rescorla &amp; Wagner, 1972, ISBN: 0390718017), which are also at the core of Naive Discrimination Learning, (Baayen et al, 2011, &lt;<a href="https://doi.org/10.1037%2Fa0023851">doi:10.1037/a0023851</a>&gt;) can be used to explain bottom-up human learning (Hoppe et al, &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fpy5kd">doi:10.31234/osf.io/py5kd</a>&gt;), but is also at the core of artificial neural networks applications in the form of the Delta rule. This package provides a set of functions for building small-scale simulations to investigate the dynamics of error-driven learning and it's interaction with the structure of the input. For modeling error-driven learning using the Rescorla-Wagner equations the package 'ndl' (Baayen et al, 2011, &lt;<a href="https://doi.org/10.1037%2Fa0023851">doi:10.1037/a0023851</a>&gt;) is available on CRAN at <a href="https://cran.r-project.org/package=ndl">https://cran.r-project.org/package=ndl</a>. However, the package currently only allows tracing of a cue-outcome combination, rather than returning the learned networks. To fill this gap, we implemented a new package with a few functions that facilitate inspection of the networks for small error driven learning simulations. Note that our functions are not optimized for training large data sets (no parallel processing), as they are intended for small scale simulations and course examples. (Consider the python implementation 'pyndl' <a href="https://pyndl.readthedocs.io/en/latest/">https://pyndl.readthedocs.io/en/latest/</a> for that purpose.) </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), plotfunctions (&ge; 1.4), data.table</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-16 09:48:01 UTC; jacolien</td>
</tr>
<tr>
<td>Author:</td>
<td>Jacolien van Rij <a href="https://orcid.org/0000-0001-7445-5647"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Dorothée Hoppe [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-20 07:40:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='activationsCueSet'>Calculate the change in activation for a specific cue or set of cues.</h2><span id='topic+activationsCueSet'></span>

<h3>Description</h3>

<p>Calculate the change in activation for a specific cue 
or set of cues for all outcomes (or a subset) in the weightmatrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activationsCueSet(
  wmlist,
  cueset,
  split = "_",
  select.outcomes = NULL,
  init.value = 0,
  normalize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="activationsCueSet_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>, 
or a single weightmatrix (matrix).</p>
</td></tr>
<tr><td><code id="activationsCueSet_+3A_cueset">cueset</code></td>
<td>
<p>String, specifying the cue set for which to calculate 
change in activation.</p>
</td></tr>
<tr><td><code id="activationsCueSet_+3A_split">split</code></td>
<td>
<p>String, separator between cues and/or outcomes.</p>
</td></tr>
<tr><td><code id="activationsCueSet_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit 
(or expand) the number of activations that are returned. 
The value of NULL (default) will 
return all activations (for each outcome in <code>wmlist</code>). 
Note that specified values that are not in 
the weightmatrix will return the initial value without error or 
warning. Please use <code><a href="#topic+getValues">getValues</a></code> for returning all 
outcomes in the data.</p>
</td></tr>
<tr><td><code id="activationsCueSet_+3A_init.value">init.value</code></td>
<td>
<p>Value of activations for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="activationsCueSet_+3A_normalize">normalize</code></td>
<td>
<p>Logical: whether or not the activation is normalized by 
dividing the total activation by the number of cues. Default is FALSE. If 
set to TRUE, the activation reflects the average activation per cue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of data frames. 
For each cueset defined in <code>cueset</code>, a dataframe of 
activation values is provided. These are returned as a list, with the 
cuesets as names.
</p>


<h3>Notes</h3>

<p>The outcomes are selected based on the weightmatrices, and not 
necessarily all outcomes present in the training data.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>,
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>
<p>Other functions for calculating activations: 
<code><a href="#topic+activationsEvents">activationsEvents</a>()</code>,
<code><a href="#topic+activationsMatrix">activationsMatrix</a>()</code>,
<code><a href="#topic+activationsOutcomes">activationsOutcomes</a>()</code>,
<code><a href="#topic+getActivations">getActivations</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)
head(train)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# Now we calculate the activations for all outcomes
# per event:
activations &lt;- activationsCueSet(wm, cueset="BG_bicycle_red")
names(activations)
head(activations[[1]])

# plot:
a1 &lt;- activations[[1]]
emptyPlot(nrow(a1), range(a1),
    xlab="Learning events", ylab="Activations",
    xmark=TRUE, ymark=TRUE, las=1)
for(i in 1:ncol(a1)){
    lines(a1[,i], col=i, lty=i)
}
legend_margin('topleft', legend=colnames(a1),
    col=1:ncol(a1), lty=1:ncol(a1),
    bty='n', cex=.75)

</code></pre>

<hr>
<h2 id='activationsEvents'>Calculate the activations for each learning event.</h2><span id='topic+activationsEvents'></span>

<h3>Description</h3>

<p>Calculate the activations for each learning event. 
The values are returned as data frame or as a list of data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activationsEvents(
  wmlist,
  data,
  split = "_",
  fun = NULL,
  return.list = FALSE,
  init.value = 0,
  normalize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="activationsEvents_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>, 
or a single weightmatrix (matrix).</p>
</td></tr>
<tr><td><code id="activationsEvents_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>Cues</code> and <code>Outcomes</code>. 
Number of rows should be the same as the number of weightmatrices 
in <code>wmlist</code>.</p>
</td></tr>
<tr><td><code id="activationsEvents_+3A_split">split</code></td>
<td>
<p>String, separator between cues and/or outcomes.</p>
</td></tr>
<tr><td><code id="activationsEvents_+3A_fun">fun</code></td>
<td>
<p>Function to apply to the activations for events with 
multiple outcomes. By default (<code>fun=NULL</code>) the activation values 
for each outcome are returned. If there are learning events with 
multiple outcomes, the argument <code>return.list</code> will be 
automatically set to TRUE.</p>
</td></tr>
<tr><td><code id="activationsEvents_+3A_return.list">return.list</code></td>
<td>
<p>Logical: whether or not the activation values are 
returned as list or as vector. Defaults to the value FALSE, 
returning a vector of activation values. 
But this also depends on the argument <code>fun</code> 
(see more info above).</p>
</td></tr>
<tr><td><code id="activationsEvents_+3A_init.value">init.value</code></td>
<td>
<p>Value of activations for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="activationsEvents_+3A_normalize">normalize</code></td>
<td>
<p>Logical: whether or not the activation is normalized by 
dividing the total activation by the number of cues. Default is FALSE. If 
set to TRUE, the activation reflects the average activation per cue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or list of activation values (see <code>return.list</code> 
and <code>fun</code> for the specific conditions, and the examples below).
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>,
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>
<p>Other functions for calculating activations: 
<code><a href="#topic+activationsCueSet">activationsCueSet</a>()</code>,
<code><a href="#topic+activationsMatrix">activationsMatrix</a>()</code>,
<code><a href="#topic+activationsOutcomes">activationsOutcomes</a>()</code>,
<code><a href="#topic+getActivations">getActivations</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)
head(train)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# Now we calculate the activations for each event:
train$Activation &lt;- activationsEvents(wm, train)

# With multiple outcomes per event, it is better not 
# to directly assign to a new column, as a list will 
# return. See the example below:
dat$Outcomes &lt;- paste(dat$Shape, dat$Color, sep="_")
dat$Cues &lt;- paste("BG", dat$Category, sep="_")
dat$Frequency &lt;- dat$Frequency1
head(dat)
train &lt;- createTrainingData(dat)
wm &lt;- RWlearning(train)
# This code will elicit a warning message:
## Not run: 
    act &lt;- activationsEvents(wm, train)

## End(Not run)
# this code will not elicit a warning:
act &lt;- activationsEvents(wm, train, return.list=TRUE)
head(act)
# to assign one single activation value to each event,
# we could instead apply a function, for example, by
# taking the max activation per event:
train$maxAct &lt;- activationsEvents(wm, train, fun="max")

</code></pre>

<hr>
<h2 id='activationsMatrix'>Calculate the activations for one or a set of cues.</h2><span id='topic+activationsMatrix'></span>

<h3>Description</h3>

<p>Calculate the activations for one or a set of cues. 
The values are returned as vector or data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activationsMatrix(
  wm,
  cues,
  split = "_",
  select.outcomes = NULL,
  init.value = 0,
  normalize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="activationsMatrix_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="activationsMatrix_+3A_cues">cues</code></td>
<td>
<p>String or vector of strings. Each string represents a set of 
cues, separated by <code>split</code>, for which the activations will be 
calculated. Note: the activations will be calculated for all provided cues 
together, assuming these occurred in one learning event.</p>
</td></tr>
<tr><td><code id="activationsMatrix_+3A_split">split</code></td>
<td>
<p>String, separator between cues.</p>
</td></tr>
<tr><td><code id="activationsMatrix_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the 
number of activations that are returned. The value of NULL (default) will 
return all activations (for each outcome in <code>wm</code>). 
Note that specified values that are not in 
the weightmatrix will return the initial value without error or 
warning. Please use <code><a href="#topic+getValues">getValues</a></code> for returning all 
outcomes in the data.</p>
</td></tr>
<tr><td><code id="activationsMatrix_+3A_init.value">init.value</code></td>
<td>
<p>Value of activations for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="activationsMatrix_+3A_normalize">normalize</code></td>
<td>
<p>Logical: whether or not the activation is normalized by 
dividing the total activation by the number of cues. Default is FALSE. If 
set to TRUE, the activation reflects the average activation per cue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or data frame.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>,
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>
<p>Other functions for calculating activations: 
<code><a href="#topic+activationsCueSet">activationsCueSet</a>()</code>,
<code><a href="#topic+activationsEvents">activationsEvents</a>()</code>,
<code><a href="#topic+activationsOutcomes">activationsOutcomes</a>()</code>,
<code><a href="#topic+getActivations">getActivations</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# setup data:
newdat &lt;- data.frame(Cues =paste("BG", dat$Shape, dat$Color, sep="_"),
   Outcomes  = dat$Category,
   Frequency = dat$Frequency2)
train  &lt;- createTrainingData(newdat)
# learning:
wm     &lt;- RWlearning(train)

# calculate activations for all outcomes:
mat    &lt;- getWM(wm)
activationsMatrix(mat, cues="BG_tree_green")
# only accepts one set of cues - in this case all cues 
# are combined:
activationsMatrix(mat, cues=c("BG_tree", "BG_tree_brown"))
# ... which is the same as this:
activationsMatrix(mat, cues=c("BG", "BG", "tree", "tree", "brown"))
# now select one outcome:
activationsMatrix(mat, cues=c("BG", "tree"), select.outcomes="vehicle")
# cues/outcomes not in matrix:
activationsMatrix(mat, cues=c("na"), select.outcomes="new")

</code></pre>

<hr>
<h2 id='activationsOutcomes'>Calculate the activations for all outcomes in the data.</h2><span id='topic+activationsOutcomes'></span>

<h3>Description</h3>

<p>Calculate the activations for all outcomes in the data 
per learning event. The activation values are returned as data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activationsOutcomes(
  wmlist,
  data,
  split = "_",
  select.outcomes = NULL,
  init.value = 0,
  normalize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="activationsOutcomes_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>, 
or a single weightmatrix (matrix).</p>
</td></tr>
<tr><td><code id="activationsOutcomes_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>Cues</code> and <code>Outcomes</code>. 
Number of rows should be the same as the number of weightmatrices 
in <code>wmlist</code>.</p>
</td></tr>
<tr><td><code id="activationsOutcomes_+3A_split">split</code></td>
<td>
<p>String, separator between cues and/or outcomes.</p>
</td></tr>
<tr><td><code id="activationsOutcomes_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit (or expand) 
the number of activations that are returned. 
The value of NULL (default) will 
return all activations (for each outcome in <code>data</code>). 
Note that specified values that are not in 
the weightmatrix will return the initial value without error or 
warning. Please use <code><a href="#topic+getValues">getValues</a></code> for returning all 
outcomes in the data.</p>
</td></tr>
<tr><td><code id="activationsOutcomes_+3A_init.value">init.value</code></td>
<td>
<p>Value of activations for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="activationsOutcomes_+3A_normalize">normalize</code></td>
<td>
<p>Logical: whether or not the activation is normalized by 
dividing the total activation by the number of cues. Default is FALSE. If 
set to TRUE, the activation reflects the average activation per cue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or list of activation values (see <code>return.list</code> 
and <code>fun</code> for the specific conditions, and the examples below).
</p>


<h3>Notes</h3>

<p>The outcomes are selected based on the data with events, and not 
necessarily all outcomes present in the weightmatrices. For example, 
when the weightmatrices were first trained on another data set, some 
outcomes may be present in the weightmatrices but not in the current 
training data. To include these as well, the user can specify these 
extra outcomes with the argument <code>select.outcomes</code>.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>,
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>
<p>Other functions for calculating activations: 
<code><a href="#topic+activationsCueSet">activationsCueSet</a>()</code>,
<code><a href="#topic+activationsEvents">activationsEvents</a>()</code>,
<code><a href="#topic+activationsMatrix">activationsMatrix</a>()</code>,
<code><a href="#topic+getActivations">getActivations</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)
head(train)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# Now we calculate the activations for all outcomes
# per event:
activations &lt;- activationsOutcomes(wm, train)
head(activations)

# Now with selection of outcomes (note that 'dog' does
# not occur as outcome in the data):
activations2 &lt;- activationsOutcomes(wm, train, 
    select.outcomes = c("plant", "vehicle", "dog"))
head(activations2)
tail(activations2)

</code></pre>

<hr>
<h2 id='check'>Remove empty cues and/or outcomes.</h2><span id='topic+check'></span>

<h3>Description</h3>

<p>Remove empty cues and/or outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check(data, rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>Cues</code> and <code>Outcomes</code>.</p>
</td></tr>
<tr><td><code id="check_+3A_rm">rm</code></td>
<td>
<p>Logical: whether or not to remove empty strings. (Default TRUE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>rm=FALSE</code> the function returns a code for each row of the data 
frame indicating whether an empty cue or outcome was detected. 
The function may return the following values:
</p>

<dl>
<dt>0</dt><dd><p>No empty cues and outcomes were detected in this row.</p>
</dd>
<dt>1</dt><dd><p>Empty cue(s) but not empty outcomes were detected in this row.</p>
</dd>
<dt>2</dt><dd><p>Empty outcome(s) but not empty cues were detected in this row.</p>
</dd>
<dt>3</dt><dd><p>Empty cue(s) AND empty outcome(s) were detected in this row.</p>
</dd>
</dl>



<h3>Value</h3>

<p>data frame or numeric vector (see details)
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test1 &lt;- c("a_b", "a__b", "_a_b", "a_b_", "_a__b_", "___")
## Not run: 
    # this returns an error:
    check(test1)

## End(Not run)
# data frame with cues and outcomes:
(dat &lt;- data.frame(Cues=test1, Outcomes=sample(test1), stringsAsFactors=TRUE))
# remove empty:
check(dat)
# only indicating which rows contain empty cues/outcomes:
(test &lt;- check(dat, rm=FALSE))
# check empty cues:
dat[test %in% c(1,3),]
# check empty outcomes:
dat[test %in% c(2,3),]

</code></pre>

<hr>
<h2 id='checkWM'>Check whether cues and outcomes exist in a weight matrix and optionally add.</h2><span id='topic+checkWM'></span>

<h3>Description</h3>

<p>Check whether cues and outcomes exist in a weight matrix and optionally add.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkWM(cues, outcomes, wm)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkWM_+3A_cues">cues</code></td>
<td>
<p>A vector with cues.</p>
</td></tr>
<tr><td><code id="checkWM_+3A_outcomes">outcomes</code></td>
<td>
<p>A vector with outcomes.</p>
</td></tr>
<tr><td><code id="checkWM_+3A_wm">wm</code></td>
<td>
<p>A matrix with connection weights between cues and outcomes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A weightmatrix (matrix)
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dat)
# create training data:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- 1
train &lt;- createTrainingData(dat)
# train network:
wm &lt;- RWlearning(train)
# inspect weight matrix:
wm[[1]]
# retrieve cues and outcomes from data:
c &lt;- getCues(wm)
o &lt;- getOutcomes(wm)
# add missing cues to initial weight matrix:
checkWM(c, o, wm=wm[[1]])

</code></pre>

<hr>
<h2 id='createTrainingData'>Create event training data from a frequency data frame.</h2><span id='topic+createTrainingData'></span>

<h3>Description</h3>

<p>Create event training data from a frequency data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createTrainingData(
  data,
  nruns = 1,
  random = TRUE,
  within.runs = FALSE,
  add.id = TRUE,
  check = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createTrainingData_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>Cues</code> and <code>Outcomes</code>,
and optionally <code>Frequency</code>.</p>
</td></tr>
<tr><td><code id="createTrainingData_+3A_nruns">nruns</code></td>
<td>
<p>Numeric: number of times to run through the data.</p>
</td></tr>
<tr><td><code id="createTrainingData_+3A_random">random</code></td>
<td>
<p>Logical: randomize the data or not (defaults to TRUE).</p>
</td></tr>
<tr><td><code id="createTrainingData_+3A_within.runs">within.runs</code></td>
<td>
<p>Logical: apply setting of <code>random</code> to the data 
_within_ each run (if set to TRUE) or over all data (if set to 
FALSE). Default setting is FALSE. 
Note that to randomize the data within seprate runs, both <code>random</code> 
and <code>within.runs</code> should be set to TRUE.</p>
</td></tr>
<tr><td><code id="createTrainingData_+3A_add.id">add.id</code></td>
<td>
<p>Logical: whether or not to add columns that identify events 
(default is TRUE). The column <code>Item</code> is added to describe each type 
of event (unless this column already exists in <code>data</code>), the column 
<code>Run</code> is added when <code>within.runs=TRUE</code>, and the column 
<code>Trial</code> indicates the order of events within the data frame or 
within the run (when <code>within.runs=TRUE</code>).</p>
</td></tr>
<tr><td><code id="createTrainingData_+3A_check">check</code></td>
<td>
<p>Logical: check for empty strings (&quot;&quot;) or not (defaults 
to TRUE). If empty strings are found, they will be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)
head(train)
dim(train)
# the rows should be equal to the sum of frequencies in dat:
sum(dat$Frequency)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)
# inspect weight matrix:
wm[[1]]

# retrieve cues and outcomes from data:
c &lt;- getCues(wm)
o &lt;- getOutcomes(wm)
# add missing cues to initial weight matrix:
checkWM(c, o, wm=wm[[1]])

# -------------------
# additional possibility for  
# simulating experimental designs:
# -------------------
dat$Frequency &lt;- dat$Frequency2
train2 &lt;- createTrainingData(dat, nruns=5)
head(train2)
# items are completely randomized, 
# and not equally distributed over the experiment:
train2$Run &lt;- rep(1:5, each=(nrow(train2)/5))
table(train2$Run, train2$Item)
# in this way the items are randomized within each run: 
train3 &lt;- createTrainingData(dat, nruns=5, within.runs=TRUE)
head(train3)
table(train3$Run, train3$Item)
# difference in learning (may take some time):
## Not run: 
wm2 &lt;- RWlearning(train2)
plotCueWeights(wm2, cue="brown")	
wm3 &lt;- RWlearning(train3)
plotCueWeights(wm3, cue="brown")	
plotOutcomeWeights(wm3, outcome="animal")	

## End(Not run)
</code></pre>

<hr>
<h2 id='createWM'>Create empty weight matrix based on a set of cues and outcomes.</h2><span id='topic+createWM'></span>

<h3>Description</h3>

<p>Create empty weight matrix based on a set of cues and outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createWM(cues, outcomes, background = NULL, init.value = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createWM_+3A_cues">cues</code></td>
<td>
<p>A vector with cues.</p>
</td></tr>
<tr><td><code id="createWM_+3A_outcomes">outcomes</code></td>
<td>
<p>A vector with outcomes.</p>
</td></tr>
<tr><td><code id="createWM_+3A_background">background</code></td>
<td>
<p>A string specifying the background cue. Sets this as the 
value of the background cue for all functions in this R session. If NULL, 
the current value of the background cue will be used.</p>
</td></tr>
<tr><td><code id="createWM_+3A_init.value">init.value</code></td>
<td>
<p>Initial value for all connections, typically set to 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A weightmatrix (matrix)
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code>link{RWlearning}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)

# the function RWlearning uses createWM to construct a weight matrix: 
cues &lt;- getValues(dat$Cues, unique=TRUE)
outcomes &lt;- getValues(dat$Outcomes, unique=TRUE)
createWM(cues=cues, outcomes=outcomes)
# add background cue:
createWM(cues=cues, outcomes=outcomes, background=TRUE)

</code></pre>

<hr>
<h2 id='cueWindow'>Create a 'cue window', for overlapping or continuous cues.</h2><span id='topic+cueWindow'></span>

<h3>Description</h3>

<p>Create a 'cue window', for overlapping or continuous cues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cueWindow(
  x,
  n = 1,
  step = 1,
  weights = NULL,
  min = 1,
  max = 100,
  round.values = TRUE,
  split = "_",
  premark = "",
  postmark = "",
  as.numeric = FALSE,
  dec = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cueWindow_+3A_x">x</code></td>
<td>
<p>A vector with numeric cues.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_n">n</code></td>
<td>
<p>Numeric value specifying the window size. If <code>n</code> has two 
values, the first value indicates the left window size, and the second 
value the size of the right window.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_step">step</code></td>
<td>
<p>Numeric value, indicating the difference between adjacent 
cues values. Set to 1 by default.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_weights">weights</code></td>
<td>
<p>A vector with weights (round numbers) for multiplying the
elements within the window. Defaults to NULL (which will give all cues 
the same weight).</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_min">min</code></td>
<td>
<p>Numeric value specifying the lowest value on the scale. 
Defaults to 1.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_max">max</code></td>
<td>
<p>Numeric value specifying the maximum value on the scale. 
Defaults to 100.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_round.values">round.values</code></td>
<td>
<p>Logical, whether or not to round the values of 
<code>x</code> to multiples of <code>step</code> on the continuum between <code>min</code> 
and <code>max</code>. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_split">split</code></td>
<td>
<p>String, specifying the cue separator. Default value is &quot;_&quot;.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_premark">premark</code></td>
<td>
<p>String, specifying a character to add before each cue.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_postmark">postmark</code></td>
<td>
<p>String, specifying a character to add after each cue.</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_as.numeric">as.numeric</code></td>
<td>
<p>Logical, whether or not to return the numeric values 
of the window as a list. Default is FALSE (return cue sets as a vector of 
strings).</p>
</td></tr>
<tr><td><code id="cueWindow_+3A_dec">dec</code></td>
<td>
<p>Number of decimals for rounding. Defaults to NULL 
(automatically determined).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of strings (default), or a list with vectors of numbers.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate random sample of cues on continuum of 1-10,
# with sep=1:
set.seed(123)
cues &lt;- round(runif(20, min=0.5, max=10.5),1)

# Note that cues will be converted to rounded numbers
# as round.values=TRUE. With cue window of 3:
cueWindow(cues, n=3, max=10)
# step of 0.5 increases number of neighboring cues:
cueWindow(cues, n=3, max=10, step=.5)
# cue window of 5:
cueWindow(cues, n=5, max=10)
# asymmetrical window:
cueWindow(cues, n=c(2,1), max=10, step=.5)

# non-uniform weights:
cueWindow(cues, n=5, max=10, weights=c(1,2,3,2,1)) 
cueWindow(cues, n=2.5, max=10, step=.5, weights=c(1,2,3,2,1)) 
# left cues have stronger weights:
cueWindow(cues, n=5, max=10, weights=c(3,3,2,1,1))
# adjust weights, so that cue itself is not included:
cueWindow(cues, n=c(2,1), max=10, weights=c(1,1,0,1))
# premarking:
cueWindow(cues, n=2, max=10, weights=c(1,1,1), premark="stimulus")
# numeric output:
cueWindow(cues, n=2, max=10, weights=c(1,2,1), as.numeric=TRUE)

</code></pre>

<hr>
<h2 id='dat'>Simulated learning data.</h2><span id='topic+dat'></span>

<h3>Description</h3>

<p>Data set for illustrating discrimination learning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dat
</code></pre>


<h3>Format</h3>

<p>A data frame with 36 rows and 5 variables:
</p>

<dl>
<dt><code>Shape</code></dt><dd><p>Shape is the discriminative cue. 6 shapes: 
cat, rabbit, flower, tree, car, bicycle.</p>
</dd>
<dt><code>Color</code></dt><dd><p>Color is the nondiscriminative cue. 6 colors: 
brown, gray, white, yellow, red, blue.</p>
</dd>
<dt><code>Category</code></dt><dd><p>Three categories: animal, plant, vehicle.</p>
</dd>
<dt><code>Frequency1</code></dt><dd><p>Different frequency values assigned 
to the shapes, no difference between colors.</p>
</dd>
<dt><code>Frequency2</code></dt><dd><p>Different frequency values assigned 
to the color-shape combinations, no difference between categories.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>

<hr>
<h2 id='edl'>Toolbox for Error-Driven Learning Simulations with Two-Layer Networks</h2><span id='topic+edl'></span>

<h3>Description</h3>

<p>The package 'edl' provides a set of functions that facilitate 
the evaluation, interpretation, and visualization of small error-driven 
learning simulations.
</p>


<h3>Details</h3>

<p>Error-driven learning is based on the Widrow &amp; Hoff (1960) learning 
rule and the Rescorla-Wagner's learning 
equations (Rescorla &amp; Wagner, 1972), which are also at the core of 
Naive Discrimination Learning (Baayen et al, 2011). Error-driven can 
be used to explain bottom-up human learning 
(Hoppe et al, under revision), but is also at the 
core of artificial neural networks applications in the form of the 
Delta rule. 
This package provides a set of functions for building 
small-scale simulations to investigate the dynamics of error-driven 
learning and it's interaction with the structure of the input. For 
modeling error-driven learning using the Rescorla-Wagner equations 
the package 'ndl' (Baayen et al, 2011) is available on CRAN at 
<a href="https://cran.r-project.org/package=ndl">https://cran.r-project.org/package=ndl</a>. However, the package 
currently only allows tracing of a cue-outcome combination, rather 
than returning the learned networks.  
To fill this gap, we implemented a new package with 
a few functions that facilitate inspection of the networks for small 
error driven learning simulations. Note that our functions are not 
optimized for training large data sets (no parallel processing), as 
they are intended for small scale simulations and course examples. 
(Consider the python implementation <code>pyndl</code> 
<a href="https://pyndl.readthedocs.io/en/latest/">https://pyndl.readthedocs.io/en/latest/</a> for that purpose.)
</p>


<h3>Getting started</h3>


<ul>
<li> <p><code>vignette("edl", package="edl")</code> - 
summarizes the core functions for training and visualization of results.
</p>
</li></ul>

<p>Also available online: <a href="https://jacolienvanrij.com/Rpackages/edl/">https://jacolienvanrij.com/Rpackages/edl/</a>.
</p>


<h3>References</h3>

<p>Dorothée Hoppe, Petra Hendriks, Michael Ramscar, &amp; Jacolien van Rij 
(2021): An exploration of error-driven learning in simple 
two-layer networks from a discriminative learning perspective. 
To appear in Behavior Research Methods.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij and Dorothée Hoppe, 
originally based on the package 'ndl'.
</p>
<p>Maintainer: Jacolien van Rij (<a href="mailto:j.c.van.rij@rug.nl">j.c.van.rij@rug.nl</a>)
</p>
<p>University of Groningen, The Netherlands
</p>

<hr>
<h2 id='getActivations'>Function to calculate the activations.</h2><span id='topic+getActivations'></span>

<h3>Description</h3>

<p>Calculate the activations for all or specific outcomes 
on the basis of a set of cues. This function combines the various 
functions to calculate the activations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getActivations(
  wmlist,
  data = NULL,
  cueset = NULL,
  split = "_",
  select.outcomes = NULL,
  init.value = 0,
  normalize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getActivations_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>. 
Or, alternatively, <code>wmlist</code> can be a single weightmatrix.</p>
</td></tr>
<tr><td><code id="getActivations_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>Cues</code> and <code>Outcomes</code>, 
specifying one learning event per row (i.e., assuming 
<code>Frequency=1</code>, as data generated with 
<code><a href="#topic+createTrainingData">createTrainingData</a></code>). 
Optional argument: when <code>data</code> is provided, the activations will 
be calculated for each learning event in <code>data</code> (i.e., for 
the combination of cues and outcomes). When <code>data</code> is set to NULL 
(no data frame provided), this function will use the cue sets 
specified in <code>cueset</code>. Use the argument <code>select.outcomes</code> 
to specify a set of outcomes for which to calculate the activations 
instead of for the observed outcome(s) only. See examples.</p>
</td></tr>
<tr><td><code id="getActivations_+3A_cueset">cueset</code></td>
<td>
<p>String, specifying the cue set for which to calculate 
change in activation. Only will be used when <code>data</code> is set to NULL.</p>
</td></tr>
<tr><td><code id="getActivations_+3A_split">split</code></td>
<td>
<p>String, separator between cues and/or outcomes.</p>
</td></tr>
<tr><td><code id="getActivations_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit 
(or expand) the number of activations that are returned. See examples 
for how to use this argument in combination with <code>data</code> 
and <code>cueset</code>. 
When <code>data</code> is provided, the value of NULL (default) will only 
return the activations for each learning event (i.e., only for the 
observed cues and outcomes). 
When <code>data</code> is provided, the value TRUE will return the 
activations for all outcomes in <code>data</code> given the cues observed 
in the learning events. 
When <code>cueset</code> is specified, the values of NULL (default) or TRUE 
will return the activations for all outcomes in <code>wmlist</code>. 
Note that specified values that are not in 
the weightmatrix will return the initial value without error or 
warning. Please use <code><a href="#topic+getValues">getValues</a></code> for returning all 
outcomes in the data.</p>
</td></tr>
<tr><td><code id="getActivations_+3A_init.value">init.value</code></td>
<td>
<p>Value of activations for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="getActivations_+3A_normalize">normalize</code></td>
<td>
<p>Logical: whether or not the activation is normalized by 
dividing the total activation by the number of cues. Default is FALSE. If 
set to TRUE, the activation reflects the average activation per cue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List: when <code>data</code> is provided, a list is returned with 
the outcome activations for each learning event; 
when <code>cueset</code> is provided, a list is returned with data frames 
of outcome activations. See examples.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>,
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>
<p>Other functions for calculating activations: 
<code><a href="#topic+activationsCueSet">activationsCueSet</a>()</code>,
<code><a href="#topic+activationsEvents">activationsEvents</a>()</code>,
<code><a href="#topic+activationsMatrix">activationsMatrix</a>()</code>,
<code><a href="#topic+activationsOutcomes">activationsOutcomes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat &lt;- droplevels(dat[1:3,])
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)


# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)
head(train)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# With this data we illustrate four different 
# ways to retrieve activation changes.

# Situation I: return activations for each event 
act1 &lt;- getActivations(wm, data=train)
head(act1)
# plotting activations for each event doesn't provide very 
# useful info:
plot(act1$Activation, type='l', ylim=c(0,1), col=alpha(1),
    ylab='Activation')
# these lines may be more interpretable:
n &lt;- which(act1$Outcomes=="animal")
lines(n, act1$Activation[n], col=alpha(2), lwd=2)
n &lt;- which(act1$Outcomes=="plant")
lines(n, act1$Activation[n], col=alpha(3), lwd=2)

# Situation II: return activations for each events
# for all outcomes
act2 &lt;- getActivations(wm, data=train, select.outcomes=TRUE)
head(act2)

plot(act2$plant, type='l', ylim=c(0,1), col=alpha(1),
    ylab='Activation')
n &lt;- which(act2$Outcomes=="plant")
rug(n, side=1)
lines(n, act2$plant[n], lwd=2, col=alpha(3))
n &lt;- which(act2$Outcomes!="plant")
lines(n, act2$plant[n], lwd=2, col=alpha(2))
legend('topright', 
    legend=c("all events", "outcome present", "outcome absent"),
	   col=c(1,alpha(3),alpha(2)), lwd=c(1,2,2),
    bty='n')

# Situation III: return activations for specific cuesets
# for all outcomes
act3 &lt;- getActivations(wm, cueset=c("BG_cat_brown", "BG_flower_brown"))
str(act3) 

a31 &lt;- act3[["BG_flower_brown"]] # or act3[[1]]
plot(a31$plant, type='l', ylim=c(0,1), col=alpha(1),
    main="BG_flower_brown", ylab='Activation')
lines(a31$animal,col=2)
rug(which(train$Cues == "BG_flower_brown"), side=1)
legend('topright', 
    legend=c("plant", "animal"),
	   col=c(1,2), lwd=1, bty='n')

# Situation IV: return activations for a static weight matrix
# Note: only with cueset
(final &lt;- getWM(wm))
act4 &lt;- getActivations(final, cueset=unique(train$Cues))
act4

</code></pre>

<hr>
<h2 id='getCues'>Extract cues from list of weightmatrices.</h2><span id='topic+getCues'></span>

<h3>Description</h3>

<p>Extract cues from list of weightmatrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCues(wmlist, extra.check = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCues_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="getCues_+3A_extra.check">extra.check</code></td>
<td>
<p>Logical: whether or not to collect all cues from all 
weightmatrices in the list. Note that this slows down the process and 
should not result in different findings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with cues.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getOutcomes">getOutcomes</a></code>, <code><a href="#topic+getValues">getValues</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)
# prepare training data:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
train &lt;- createTrainingData(dat)
# learning:
wm &lt;- RWlearning(train)
# retrieve cues from wm list:
getCues(wm)
# or this version (which takes more time):
system.time({getCues(wm, extra.check=TRUE)})
system.time({getCues(wm)})

</code></pre>

<hr>
<h2 id='getLambda'>Retrieve the lambda values for all or specific outcomes 
for each learning event.</h2><span id='topic+getLambda'></span>

<h3>Description</h3>

<p>For a given set of training data, 
the lambda values are returned for each or specific outcomes. 
The values are returned as data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLambda(data, lambda = 1, split = "_", select.outcomes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getLambda_+3A_data">data</code></td>
<td>
<p>Data with columns <code>Cues</code> and <code>Outcomes</code>,
as generated with <code><a href="#topic+createTrainingData">createTrainingData</a></code>.</p>
</td></tr>
<tr><td><code id="getLambda_+3A_lambda">lambda</code></td>
<td>
<p>Numeric, value of lambda parameter. Defaults to 1.</p>
</td></tr>
<tr><td><code id="getLambda_+3A_split">split</code></td>
<td>
<p>String, separator between cues or outcomes.</p>
</td></tr>
<tr><td><code id="getLambda_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the number of 
activations that are returned. The value of NULL (default) will 
return all activations. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use  <code><a href="#topic+getValues">getValues</a></code> for returning all outcomes in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
head(dat)
dim(dat)
test &lt;- getLambda(dat)
# only outcomes that do not occur in data results in 0:
test2 &lt;- getLambda(dat, select.outcomes=c("a", "b", "C"))

</code></pre>

<hr>
<h2 id='getOutcomes'>Extract outcomes from list of weightmatrices.</h2><span id='topic+getOutcomes'></span>

<h3>Description</h3>

<p>Extract outcomes from list of weightmatrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getOutcomes(wmlist, extra.check = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getOutcomes_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="getOutcomes_+3A_extra.check">extra.check</code></td>
<td>
<p>Logical: whether or not to collect all cues from all 
weightmatrices in the list. Note that this slows down the process and 
should not result in different findings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with outcomes.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getCues">getCues</a></code>, <code><a href="#topic+getValues">getValues</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)
# prepare training data:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
train &lt;- createTrainingData(dat)
# learning:
wm &lt;- RWlearning(train)
# retrieve cues from wm list:
getOutcomes(wm)
# or this version (which takes more time):
system.time({getOutcomes(wm, extra.check=TRUE)})
system.time({getOutcomes(wm)})

</code></pre>

<hr>
<h2 id='getUpdate'>Retrieve the weight updates and their change for each learning event.</h2><span id='topic+getUpdate'></span>

<h3>Description</h3>

<p>For a given set of training data, 
the weight updating values are returned for each or specific outcomes. 
The values are returned as data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getUpdate(
  wmlist,
  data,
  select.outcomes = NULL,
  split = "_",
  present.outcome = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getUpdate_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="getUpdate_+3A_data">data</code></td>
<td>
<p>Data with columns <code>Cues</code> and <code>Outcomes</code>,
as generated with <code><a href="#topic+createTrainingData">createTrainingData</a></code>.</p>
</td></tr>
<tr><td><code id="getUpdate_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the number of 
activations that are returned. The value of NULL (default) will 
return all activations. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use  <code><a href="#topic+getValues">getValues</a></code> for returning all outcomes in the data.</p>
</td></tr>
<tr><td><code id="getUpdate_+3A_split">split</code></td>
<td>
<p>String, separator between cues or outcomes.</p>
</td></tr>
<tr><td><code id="getUpdate_+3A_present.outcome">present.outcome</code></td>
<td>
<p>Logical: whether or not to output the update 
for the present output only. Defaults to FALSE. Note that if set to true,
this parameter cancels the effect of <code>select.outcomes</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat &lt;- droplevels(dat[1:3,])
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)


# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)
head(train)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# retrieve update values for all outcomes:
updates1 &lt;- getUpdate(data=train, wmlist=wm)
head(updates1)

# retrieve update values for observed outcomes:
updates2 &lt;- getUpdate(data=train, wmlist=wm, present.outcome=TRUE)
head(updates2)

# plot:
n &lt;- which("animal" == train$Outcomes)
plot(n, updates2[n], type='l', 
    ylim=c(0,.1), 
    ylab="Weight updates", xlab="Learning event")

</code></pre>

<hr>
<h2 id='getValues'>Retrieve all cues from a vector of text strings.</h2><span id='topic+getValues'></span>

<h3>Description</h3>

<p>Retrieve all cues from a vector of text strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getValues(text, split = "_", unique = FALSE, decreasing = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getValues_+3A_text">text</code></td>
<td>
<p>A vector with text strings containing cues or outcomes, 
separated by a symbol specified by <code>split</code>.</p>
</td></tr>
<tr><td><code id="getValues_+3A_split">split</code></td>
<td>
<p>separator between cues.</p>
</td></tr>
<tr><td><code id="getValues_+3A_unique">unique</code></td>
<td>
<p>Logical: only return unique values (TRUE) or all values 
(FALSE, default). When unique values are bein returned, they are sorted.</p>
</td></tr>
<tr><td><code id="getValues_+3A_decreasing">decreasing</code></td>
<td>
<p>Logical: sorting in alphabetical order (FALSE, default) or the reverse order (TRUE)? Only applies when <code>unique</code> is set to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with strings
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strsplit">strsplit</a></code>, <code><a href="base.html#topic+sort">sort</a></code>, <code><a href="base.html#topic+unique">unique</a></code>, 
<code><a href="#topic+getOutcomes">getOutcomes</a></code>, <code><a href="#topic+getCues">getCues</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load example data:
data(dat)
# prepare training data:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
train &lt;- createTrainingData(dat)

# find all cues in trainingdata:
cues &lt;- getValues(train$Cues)
table(cues)
# find all outcomes in data:
out &lt;- getValues(train$Outcomes)
table(out)
# find (sorted) unique cues and outcomes:
getValues(dat$Cues, unique=TRUE)
getValues(dat$Outcomes, unique=TRUE)

</code></pre>

<hr>
<h2 id='getWeightsByCue'>Extract the change of connection weights between a specific cue and all 
outcomes.</h2><span id='topic+getWeightsByCue'></span>

<h3>Description</h3>

<p>Extract the change of connection weights between all cues and 
a specific outcome. The values are returned as data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWeightsByCue(wmlist, cue, select.outcomes = NULL, init.value = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getWeightsByCue_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="getWeightsByCue_+3A_cue">cue</code></td>
<td>
<p>String: cue for which to extract the connection weights.</p>
</td></tr>
<tr><td><code id="getWeightsByCue_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the number of 
connection weights that are returned. The value of NULL (default) will 
return all connection weights. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use <code><a href="#topic+getOutcomes">getOutcomes</a></code> for returning all outcomes from the data, and 
<code><a href="#topic+getValues">getValues</a></code> for returning all outcomes in the data.</p>
</td></tr>
<tr><td><code id="getWeightsByCue_+3A_init.value">init.value</code></td>
<td>
<p>Value of connection weights for non-existing connections. 
Typically set to 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotCueWeights">plotCueWeights</a></code>, <code><a href="#topic+plotOutcomeWeights">plotOutcomeWeights</a></code>, 
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# final weight matrix:
getWM(wm)

# Inspect the change in connection weights 
# for cue=car
cueweights &lt;- getWeightsByCue(wm, cue='car')
head(cueweights)
emptyPlot(nrow(cueweights), c(-.5,1), h0=0,
    main="Cue='car'", ylab='connection weights', xlab='learning events')
lines(cueweights$vehicle)
lines(cueweights$plant, col='red', lty=4)
lines(cueweights$animal, col='red', lty=2)
legend_margin('topright', legend=c('animal', 'plant', 'vehicle'),
    col=c(2,2,1), lty=c(2,4,1), lwd=1, bty='n')

</code></pre>

<hr>
<h2 id='getWeightsByOutcome'>Extract the change of connection weights between all cues and a specific 
outcome.</h2><span id='topic+getWeightsByOutcome'></span>

<h3>Description</h3>

<p>Extract the change of connection weights between all cues and 
a specific outcome. The values are returned as data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWeightsByOutcome(wmlist, outcome, select.cues = NULL, init.value = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getWeightsByOutcome_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="getWeightsByOutcome_+3A_outcome">outcome</code></td>
<td>
<p>String: outcome for which to extract the connection weights.</p>
</td></tr>
<tr><td><code id="getWeightsByOutcome_+3A_select.cues">select.cues</code></td>
<td>
<p>Optional selection of cues to limit the number of 
connection weights that are returned. The value of NULL (default) will 
return all connection weights. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use <code><a href="#topic+getCues">getCues</a></code> for returning all cues from the data, and 
<code><a href="#topic+getValues">getValues</a></code> for returning all cues in the data.</p>
</td></tr>
<tr><td><code id="getWeightsByOutcome_+3A_init.value">init.value</code></td>
<td>
<p>Value of connection weights for non-existing connections. 
Typically set to 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotCueWeights">plotCueWeights</a></code>, <code><a href="#topic+plotOutcomeWeights">plotOutcomeWeights</a></code>, 
<code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# final weight matrix:
getWM(wm)

# Inspect the change in connection weights 
# for cue=car
outweights &lt;- getWeightsByOutcome(wm, outcome='vehicle')
head(outweights)
emptyPlot(nrow(outweights), range(outweights), h0=0,
    main="Outcome='vehicle'", ylab='connection weights', xlab='learning events')
lines(outweights$BG)
lines(outweights$car, lty=4)
lines(outweights$bicycle, lty=2)
lines(outweights$cat, col=2)
lines(outweights$red, col='blue', lty=4)
lines(outweights$gray, col='blue', lty=2)
legend('bottomright', legend=c('BG', 'car', 'bicycle', 'cat', 'red', 'gray'),
    col=c(1,1,1,2,'blue', 'blue'), lty=c(1,4,2,1,4,2), lwd=1)

</code></pre>

<hr>
<h2 id='getWM'>Retrieve all cues from a vector of text strings.</h2><span id='topic+getWM'></span>

<h3>Description</h3>

<p>Retrieve all cues from a vector of text strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWM(wmlist, event = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getWM_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices for each learning event, 
generated by <code><a href="#topic+RWlearning">RWlearning</a></code>.</p>
</td></tr>
<tr><td><code id="getWM_+3A_event">event</code></td>
<td>
<p>Numeric: for which event to return the weight matrix. 
Defaults to NULL, which wil return the last weight matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with connection weights between cues (rows) and outcomes.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RWlearning">RWlearning</a></code>, <code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>, 
<code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# final weight matrix:
getWM(wm)
# ... which is the same as:
wm[[length(wm)]]
# 25th learning event:
getWM(wm, event=25)
# ... which is the same as:
wm[[25]]

</code></pre>

<hr>
<h2 id='luceChoice'>Function implementing the Luce choice rule.</h2><span id='topic+luceChoice'></span>

<h3>Description</h3>

<p>Function implementing the Luce choice rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luceChoice(value, all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="luceChoice_+3A_value">value</code></td>
<td>
<p>A positive value specifying a weight or activation 
(or comparable measure) of the choice option for which the choice probability 
is calculated</p>
</td></tr>
<tr><td><code id="luceChoice_+3A_all">all</code></td>
<td>
<p>A positive array of the weights or activations of all possible 
choice options, including <code>value</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value between [0,1]
</p>


<h3>Author(s)</h3>

<p>Dorothee Hoppe
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies:
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# caculate activations of outcomes given the cue set blue_car
red_rabbit &lt;- getActivations(getWM(wm), cueset = "red_rabbit")$red_rabbit

# caculate choice probability of outcomes given the cue set blue_car after 
# normalizing with rectified linear unit
luceChoice(red_rabbit["vehicle"], red_rabbit)
luceChoice(red_rabbit["plant"], red_rabbit)
luceChoice(red_rabbit["animal"], red_rabbit)

# note that when some activations are negative, this rule either should not be 
# applied, or negative values have to be corrected for, e.g., with applying a 
# rectified linear unit (relu)
blue_car &lt;- getActivations(getWM(wm), cueset = "blue_car")$blue_car

## Not run: 
# this is should not be done without correction
luceChoice(blue_car["vehicle"], blue_car)
# use, e.g., function relu() on the raw values

## End(Not run)

</code></pre>

<hr>
<h2 id='plotActivations'>Visualize the change of connection weights between a specific outcome and all 
cues.</h2><span id='topic+plotActivations'></span>

<h3>Description</h3>

<p>Visualize the activation or the change of activation per 
event.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotActivations(
  wmlist,
  cueset,
  split = "_",
  select.outcomes = NULL,
  init.value = 0,
  add.labels = TRUE,
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotActivations_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_cueset">cueset</code></td>
<td>
<p>String, which contains the combination of cues for which to 
calculate the activations for per learning event.</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_split">split</code></td>
<td>
<p>String, separator between cues.</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the number of 
activations that are returned. The value of NULL (default) will 
return all activations. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use  <code><a href="#topic+getValues">getValues</a></code> for returning all outcomes in the data.</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_init.value">init.value</code></td>
<td>
<p>Value of connection weights for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_add.labels">add.labels</code></td>
<td>
<p>Logical: whether or not to add labels for the lines. 
Defaults to TRUE, see examples.</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_add">add</code></td>
<td>
<p>Logical: whether or not to add the lines to an existing plot. 
Defaults to FALSE (starting a new plot).</p>
</td></tr>
<tr><td><code id="plotActivations_+3A_...">...</code></td>
<td>
<p>Optional graphical arguments, as specified in 
<code><a href="graphics.html#topic+par">par</a></code>. These parameters are forwarded to the functions 
<code><a href="plotfunctions.html#topic+emptyPlot">emptyPlot</a></code>, <code><a href="graphics.html#topic+lines">lines</a></code>, and 
<code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optionally a list with label specifications is returned, which 
allows to plot your own labels. This may be helpful for very long labels, 
and for overlapping lines.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotCueWeights">plotCueWeights</a></code>, <code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>, 
<code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can be used train network:
wm &lt;- RWlearning(train)

# plot connection weights for cue = 'cat':
plotActivations(wm, cueset="BG_cat_brown")
plotActivations(wm, cueset="BG_cat")

# plot your own labels:
labels &lt;- plotActivations(wm, cues="BG_cat", add.labels=FALSE)
legend_margin('topright', legend=labels$labels, col=labels$col, 
    lwd=1, bty='n')

# change color and select outcomes:
out &lt;- getValues(train$Outcomes, unique=TRUE)
out &lt;- out[! out %in% "animal"]
labels &lt;- plotActivations(wm, cues="BG_cat", 
    select.outcome=out, add.labels=FALSE, 
	   ylim=c(-.25,1),col=alpha(1))
lab2 &lt;- plotActivations(wm, cues="BG_cat", add.labels=FALSE, 
    select.outcomes="animal", add=TRUE, col=2, lwd=2, xpd=TRUE)
legend('topright', legend=c("animal", labels$labels), 
    col=c(lab2$col, labels$col), lwd=c(lab2$lwd, labels$lwd), 
    lty=c(lab2$lty, labels$lty), bty="n")

</code></pre>

<hr>
<h2 id='plotCueWeights'>Visualize the change of connection weights between a specific cue and all 
outcomes.</h2><span id='topic+plotCueWeights'></span>

<h3>Description</h3>

<p>Visualize the change of connection weights between a specific 
cue and all outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCueWeights(
  wmlist,
  cue,
  select.outcomes = NULL,
  init.value = 0,
  add.labels = TRUE,
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCueWeights_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="plotCueWeights_+3A_cue">cue</code></td>
<td>
<p>String: cue for which to extract the connection weights.</p>
</td></tr>
<tr><td><code id="plotCueWeights_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the number 
of connection weights that are returned. The value of NULL (default) will 
return all connection weights. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use <code><a href="#topic+getOutcomes">getOutcomes</a></code> for returning all outcomes from the 
data, and <code><a href="#topic+getValues">getValues</a></code> for returning all outcomes in the data.</p>
</td></tr>
<tr><td><code id="plotCueWeights_+3A_init.value">init.value</code></td>
<td>
<p>Value of connection weights for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="plotCueWeights_+3A_add.labels">add.labels</code></td>
<td>
<p>Logical: whether or not to add labels for the lines. 
Defaults to TRUE, see examples.</p>
</td></tr>
<tr><td><code id="plotCueWeights_+3A_add">add</code></td>
<td>
<p>Logical: whether or not to add the lines to an existing plot. 
Defaults to FALSE (starting a new plot).</p>
</td></tr>
<tr><td><code id="plotCueWeights_+3A_...">...</code></td>
<td>
<p>Optional graphical arguments, as specified in 
<code><a href="graphics.html#topic+par">par</a></code>. These parameters are forwarded to the functions 
<code><a href="plotfunctions.html#topic+emptyPlot">emptyPlot</a></code>, <code><a href="graphics.html#topic+lines">lines</a></code>, and 
<code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optionally a list with label specifications is returned, which 
allows to plot your own labels. This may be helpful for very long labels, 
and for overlapping lines.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotOutcomeWeights">plotOutcomeWeights</a></code>, <code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>, 
<code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# plot connection weights for cue = 'car':
plotCueWeights(wm, cue="car")

# plot your own labels:
labels &lt;- plotCueWeights(wm, cue="car", add.labels=FALSE)
legend_margin('topright', legend=labels$labels, col=labels$col, 
    lwd=1, bty='n')

# change color and select outcomes:
out &lt;- getValues(train$Outcomes, unique=TRUE)
out &lt;- out[out != "vehicle"]
labels &lt;- plotCueWeights(wm, cue="car", add.labels=FALSE, 
    col=alphaPalette(c(1,2), f.seq=rep(.5,length(out))), 
    select.outcomes=out)
lab2 &lt;- plotCueWeights(wm, cue="car", add.labels=FALSE, 
    select.outcomes="vehicle", add=TRUE, col=1, lwd=2)
legend_margin('topright', legend=c(labels$labels, "vehicle"), 
    col=c(labels$col, lab2$col), lwd=c(labels$lwd, lab2$lwd), 
    lty=c(labels$lty, lab2$lty))

</code></pre>

<hr>
<h2 id='plotNetwork'>Return strong weights.</h2><span id='topic+plotNetwork'></span>

<h3>Description</h3>

<p>Return strong weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNetwork(
  wm,
  select.outcomes = NULL,
  select.cues = NULL,
  color = NULL,
  zlim = NULL,
  add.color.legend = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotNetwork_+3A_wm">wm</code></td>
<td>
<p>a weightmatrix (matrix, not list) with connection 
weights between cues (rows) and outcomes (columns).</p>
</td></tr>
<tr><td><code id="plotNetwork_+3A_select.outcomes">select.outcomes</code></td>
<td>
<p>Optional selection of outcomes to limit the number 
of connection weights that are returned. The value of NULL (default) will 
return all connection weights. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use <code><a href="#topic+getOutcomes">getOutcomes</a></code> for returning all cues from the data, 
and <code><a href="#topic+getValues">getValues</a></code> for returning all cues in the data.</p>
</td></tr>
<tr><td><code id="plotNetwork_+3A_select.cues">select.cues</code></td>
<td>
<p>Optional selection of cues to limit the number of 
connection weights that are returned. The value of NULL (default) will 
return all connection weights. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use <code><a href="#topic+getCues">getCues</a></code> for returning all cues from the data, and 
<code><a href="#topic+getValues">getValues</a></code> for returning all cues in the data.</p>
</td></tr>
<tr><td><code id="plotNetwork_+3A_color">color</code></td>
<td>
<p>The color scheme to use for plots, a list of colors such as 
that generated by <code><a href="grDevices.html#topic+rainbow">rainbow</a></code>, 
<code><a href="grDevices.html#topic+heat.colors">heat.colors</a></code>, 
<code><a href="grDevices.html#topic+colors">colors</a></code>, 
<code><a href="grDevices.html#topic+topo.colors">topo.colors</a></code>, 
<code><a href="grDevices.html#topic+terrain.colors">terrain.colors</a></code> or similar functions. 
Alternatively a vector with some colors can be provided for a 
custom color palette.</p>
</td></tr>
<tr><td><code id="plotNetwork_+3A_zlim">zlim</code></td>
<td>
<p>z-limits for the plot.</p>
</td></tr>
<tr><td><code id="plotNetwork_+3A_add.color.legend">add.color.legend</code></td>
<td>
<p>Logical: whether or not to add a color legend 
(see also <code><a href="plotfunctions.html#topic+gradientLegend">gradientLegend</a></code>).</p>
</td></tr>
<tr><td><code id="plotNetwork_+3A_...">...</code></td>
<td>
<p>Optional graphical arguments, as specified in 
<code><a href="graphics.html#topic+par">par</a></code>. These parameters are forwarded to the functions 
<code><a href="plotfunctions.html#topic+emptyPlot">emptyPlot</a></code>, <code><a href="graphics.html#topic+lines">lines</a></code>, and 
<code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>

<hr>
<h2 id='plotOutcomeWeights'>Visualize the change of connection weights between a specific outcome and all 
cues.</h2><span id='topic+plotOutcomeWeights'></span>

<h3>Description</h3>

<p>Visualize the change of connection weights between a specific 
outcome and all cues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotOutcomeWeights(
  wmlist,
  outcome,
  select.cues = NULL,
  init.value = 0,
  add.labels = TRUE,
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotOutcomeWeights_+3A_wmlist">wmlist</code></td>
<td>
<p>A list with weightmatrices, generated by 
<code><a href="#topic+RWlearning">RWlearning</a></code> or <code><a href="#topic+updateWeights">updateWeights</a></code>.</p>
</td></tr>
<tr><td><code id="plotOutcomeWeights_+3A_outcome">outcome</code></td>
<td>
<p>String: outcome for which to extract the connection weights.</p>
</td></tr>
<tr><td><code id="plotOutcomeWeights_+3A_select.cues">select.cues</code></td>
<td>
<p>Optional selection of outcomes to limit the number 
of connection weights that are returned. The value of NULL (default) will 
return all connection weights. Note that specified values that are not in 
the weightmatrices will return the initial value without error or warning. 
Please use <code><a href="#topic+getOutcomes">getOutcomes</a></code> for returning all outcomes from the 
data, and <code><a href="#topic+getValues">getValues</a></code> for returning all outcomes in the data.</p>
</td></tr>
<tr><td><code id="plotOutcomeWeights_+3A_init.value">init.value</code></td>
<td>
<p>Value of connection weights for non-existing connections. 
Typically set to 0.</p>
</td></tr>
<tr><td><code id="plotOutcomeWeights_+3A_add.labels">add.labels</code></td>
<td>
<p>Logical: whether or not to add labels for the lines. 
Defaults to TRUE, see examples.</p>
</td></tr>
<tr><td><code id="plotOutcomeWeights_+3A_add">add</code></td>
<td>
<p>Logical: whether or not to add the lines to an existing plot. 
Defaults to FALSE (starting a new plot).</p>
</td></tr>
<tr><td><code id="plotOutcomeWeights_+3A_...">...</code></td>
<td>
<p>Optional graphical arguments, as specified in 
<code><a href="graphics.html#topic+par">par</a></code>. These parameters are forwarded to the functions 
<code><a href="plotfunctions.html#topic+emptyPlot">emptyPlot</a></code>, <code><a href="graphics.html#topic+lines">lines</a></code>, and 
<code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optionally a list with label specifications is returned, which 
allows to plot your own labels. This may be helpful for very long labels, 
and for overlapping lines.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotCueWeights">plotCueWeights</a></code>, <code><a href="#topic+getWeightsByOutcome">getWeightsByOutcome</a></code>, 
<code><a href="#topic+getWeightsByCue">getWeightsByCue</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# plot connection weights for cue = 'car':
plotOutcomeWeights(wm, outcome="vehicle")


# plot your own labels:
labels &lt;- plotOutcomeWeights(wm, outcome="vehicle", add.labels=FALSE)
legend_margin('topright', legend=labels$labels, col=labels$col, 
    lwd=1, bty='n')

# change color and select outcomes:
out &lt;- getValues(train$Cues, unique=TRUE)
out &lt;- out[! out %in% c("car", "bicycle")]
labels &lt;- plotOutcomeWeights(wm, outcome="vehicle", add.labels=FALSE, 
	   ylim=c(-.5,1),col=alpha(1), select.cues=out)
lab2 &lt;- plotOutcomeWeights(wm, outcome="vehicle", add.labels=FALSE, 
    select.cues=c("car", "bicycle"), add=TRUE, col=2, lwd=2, xpd=TRUE)
legend_margin('topright', legend=c(labels$labels, c("car", "bicycle")), 
    col=c(labels$col, lab2$col), lwd=c(labels$lwd, lab2$lwd), 
    lty=c(labels$lty, lab2$lty))

</code></pre>

<hr>
<h2 id='RWlearning'>Function implementing the Rescorla-Wagner learning.</h2><span id='topic+RWlearning'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWlearning(
  data,
  wm = NULL,
  eta = 0.01,
  lambda = 1,
  alpha = 0.1,
  beta1 = 0.1,
  beta2 = 0.1,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RWlearning_+3A_data">data</code></td>
<td>
<p>A data frame with columns <code>Cues</code> and <code>Outcomes</code>.</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix, or a list with weight matrices. 
If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the weightmatrix: 
if not present, they will be added.</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_eta">eta</code></td>
<td>
<p>Learning parameter, typically set to 0.01. 
If <code>eta</code> is not specified and set to the value NULL, 
the values of <code>alpha</code>, <code>beta1</code>, and <code>beta2</code> 
determine the learning rate. However, changing these settings 
is generally not very useful (see Hoppe et al, submitted).</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1. Only used if 
<code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1. Only used if <code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1. Only used if <code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_progress">progress</code></td>
<td>
<p>Logical: whether or not showing a progress bar 
(may slow down the process).</p>
</td></tr>
<tr><td><code id="RWlearning_+3A_...">...</code></td>
<td>
<p>Parameters for the function <code><a href="#topic+getValues">getValues</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with weightmatrices for each learning event.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, <code><a href="#topic+updateWeights">updateWeights</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)

# in R markdown or knitr reports the progress bar should be turned off:
wm &lt;- RWlearning(train, progress=FALSE)

# Learning in steps is also possible:
wm &lt;- RWlearning(train[1:20,])
getWM(wm)
length(wm)

train[21,c("Cues", "Outcomes")]
wm &lt;- RWlearning(train[21,], wm=wm)
getWM(wm)
length(wm)

</code></pre>

<hr>
<h2 id='RWlearningMatrix'>Function implementing the Rescorla-Wagner learning.</h2><span id='topic+RWlearningMatrix'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWlearningMatrix(
  data,
  wm = NULL,
  alpha = 0.1,
  lambda = 1,
  beta1 = 0.1,
  beta2 = 0.1,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RWlearningMatrix_+3A_data">data</code></td>
<td>
<p>A data frame with columns <code>Cues</code> and <code>Outcomes</code>.</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix, or a list with weight matrices. 
If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the weightmatrix: 
if not present, they will be added.</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1.</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1.</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1.</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_progress">progress</code></td>
<td>
<p>Logical: whether or not showing a progress bar 
(may slow down the process).</p>
</td></tr>
<tr><td><code id="RWlearningMatrix_+3A_...">...</code></td>
<td>
<p>Parameters for the function <code><a href="#topic+getValues">getValues</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A weightmatrix.
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, <code><a href="#topic+updateWeights">updateWeights</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm1 &lt;- RWlearningMatrix(train)
# comparison with a list:
wm2 &lt;- RWlearning(train)
length(wm2)
getWM(wm2)

# in R markdown or knitr reports the progress bar should be turned off:
wm &lt;- RWlearningMatrix(train, progress=FALSE)

# Learning in steps is also possible:
wm &lt;- RWlearningMatrix(train[1:20,])

train[21,c("Cues", "Outcomes")]
wm &lt;- RWlearningMatrix(train[21,], wm=wm)

</code></pre>

<hr>
<h2 id='RWlearningNoCueCompetition'>Function implementing the Rescorla-Wagner learning equations without cue 
competition (for illustration purposes).</h2><span id='topic+RWlearningNoCueCompetition'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning equations without cue 
competition (for illustration purposes).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWlearningNoCueCompetition(
  data,
  wm = NULL,
  eta = 0.01,
  lambda = 1,
  alpha = 0.1,
  beta1 = 0.1,
  beta2 = 0.1,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RWlearningNoCueCompetition_+3A_data">data</code></td>
<td>
<p>A data frame with columns <code>Cues</code> and <code>Outcomes</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix, or a list with weight matrices. 
If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the 
weightmatrix: if not present, they will be added.</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_eta">eta</code></td>
<td>
<p>Learning parameter, typically set to 0.01. 
If <code>eta</code> is not specified and set to the value NULL, 
the values of <code>alpha</code>, <code>beta1</code>, and <code>beta2</code> 
determine the learning rate. However, changing these settings 
is generally not very useful (see Hoppe et al, submitted).</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1. Only used if 
<code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1. Only used if <code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1. Only used if <code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_progress">progress</code></td>
<td>
<p>Logical: whether or not showing a progress bar 
(may slow down the process).</p>
</td></tr>
<tr><td><code id="RWlearningNoCueCompetition_+3A_...">...</code></td>
<td>
<p>Parameters for the function <code><a href="#topic+getValues">getValues</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with weightmatrices for each learning event.
</p>


<h3>Author(s)</h3>

<p>Dorothee Hoppe
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, 
<code><a href="#topic+updateWeightsNoCueCompetition">updateWeightsNoCueCompetition</a></code>
</p>
<p>Other functions for explaining error-driven learning: 
<code><a href="#topic+RWlearningNoOutcomeCompetition">RWlearningNoOutcomeCompetition</a>()</code>,
<code><a href="#topic+updateWeightsNoCueCompetition">updateWeightsNoCueCompetition</a>()</code>,
<code><a href="#topic+updateWeightsNoOutcomeCompetition">updateWeightsNoOutcomeCompetition</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearningNoCueCompetition(train)

# in R markdown or knitr reports the progress bar should be turned off:
wm &lt;- RWlearningNoCueCompetition(train, progress=FALSE)

# Learning in steps is also possible:
wm &lt;- RWlearningNoCueCompetition(train[1:20,])
getWM(wm)
length(wm)

train[21,c("Cues", "Outcomes")]
wm &lt;- RWlearningNoCueCompetition(train[21,], wm=wm)
getWM(wm)
length(wm)

</code></pre>

<hr>
<h2 id='RWlearningNoOutcomeCompetition'>Function implementing the Rescorla-Wagner learning equetions without 
outcome competition (for illustration purposes).</h2><span id='topic+RWlearningNoOutcomeCompetition'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning equetions without 
outcome competition (for illustration purposes).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWlearningNoOutcomeCompetition(
  data,
  wm = NULL,
  eta = 0.01,
  lambda = 1,
  alpha = 0.1,
  beta1 = 0.1,
  beta2 = 0.1,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_data">data</code></td>
<td>
<p>A data frame with columns <code>Cues</code> and <code>Outcomes</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix, or a list with weight matrices. 
If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the 
weightmatrix: 
if not present, they will be added.</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_eta">eta</code></td>
<td>
<p>Learning parameter, typically set to 0.01. 
If <code>eta</code> is not specified and set to the value NULL, 
the values of <code>alpha</code>, <code>beta1</code>, and <code>beta2</code> 
determine the learning rate. However, changing these settings 
is generally not very useful (see Hoppe et al, submitted).</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1. Only used if 
<code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1. Only used if <code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1. Only used if <code>eta=NULL</code>.</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_progress">progress</code></td>
<td>
<p>Logical: whether or not showing a progress bar 
(may slow down the process).</p>
</td></tr>
<tr><td><code id="RWlearningNoOutcomeCompetition_+3A_...">...</code></td>
<td>
<p>Parameters for the function <code><a href="#topic+getValues">getValues</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with weightmatrices for each learning event.
</p>


<h3>Author(s)</h3>

<p>Dorothee Hoppe
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, 
<code><a href="#topic+updateWeightsNoOutcomeCompetition">updateWeightsNoOutcomeCompetition</a></code>
</p>
<p>Other functions for explaining error-driven learning: 
<code><a href="#topic+RWlearningNoCueCompetition">RWlearningNoCueCompetition</a>()</code>,
<code><a href="#topic+updateWeightsNoCueCompetition">updateWeightsNoCueCompetition</a>()</code>,
<code><a href="#topic+updateWeightsNoOutcomeCompetition">updateWeightsNoOutcomeCompetition</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearningNoOutcomeCompetition(train)

# in R markdown or knitr reports the progress bar should be turned off:
wm &lt;- RWlearningNoOutcomeCompetition(train, progress=FALSE)

# Learning in steps is also possible:
wm &lt;- RWlearningNoOutcomeCompetition(train[1:20,])
getWM(wm)
length(wm)

train[21,c("Cues", "Outcomes")]
wm &lt;- RWlearningNoOutcomeCompetition(train[21,], wm=wm)
getWM(wm)
length(wm)

</code></pre>

<hr>
<h2 id='setBackground'>Set value background cue.</h2><span id='topic+setBackground'></span>

<h3>Description</h3>

<p>Set value background cue.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setBackground(value)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setBackground_+3A_value">value</code></td>
<td>
<p>A string specifying the background cue. 
NULL or FALSE or a number &lt; 0 indicates to remove the background cue, 
whereas the values TRUE or a number &gt; 0 set the value to &quot;***&quot;, and a 
string can specify the value for the background cue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value
</p>

<hr>
<h2 id='updateWeights'>Function implementing the Rescorla-Wagner learning for a single learning 
event.</h2><span id='topic+updateWeights'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning for a 
single learning event. A set of cues and outcomes are provided, and a 
weightmatrix that needs to be updated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateWeights(
  cur.cues,
  cur.outcomes,
  wm = NULL,
  eta = 0.01,
  lambda = 1,
  alpha = 0.1,
  beta1 = 0.1,
  beta2 = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="updateWeights_+3A_cur.cues">cur.cues</code></td>
<td>
<p>A vector with cues.</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_cur.outcomes">cur.outcomes</code></td>
<td>
<p>A vector with outcomes.</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix. If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the weightmatrix: 
if not present, they will be added.</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_eta">eta</code></td>
<td>
<p>Learning parameter, typically set to 0.01. 
If <code>eta</code> is not specified and set to the value NULL, 
the values of <code>alpha</code>, <code>beta1</code>, and <code>beta2</code> 
determine the learning rate. However, changing these settings 
is generally not very useful (see Hoppe et al, submitted).</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1.</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1.</p>
</td></tr>
<tr><td><code id="updateWeights_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A weightmatrix (matrix)
</p>


<h3>Author(s)</h3>

<p>Jacolien van Rij, based on <code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, <code><a href="#topic+RWlearning">RWlearning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearning(train)
# retrieve trained network:
new &lt;- getWM(wm)

train2 &lt;- createTrainingData(dat)
updateWeights(getValues(train2$Cues[1]), 
    getValues(train2$Outcomes[1]), wm=new)

# comparison between eta and alpha, beta1, beta2:
check.cues &lt;- c("BG", "car", "red")
new[check.cues,]
tmp1 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new)
tmp2 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new, eta=NULL)
tmp3 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new, beta1=0.2)
tmp4 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new, eta=NULL, beta1=0.2)
# these two should be the same:
tmp1[check.cues,]
tmp2[check.cues,]
# now we change beta2, but this does not change anything,
# because eta is being used:
tmp3[check.cues,]
# when we turn eta off, beta2 changes the values:
tmp4[check.cues,]

</code></pre>

<hr>
<h2 id='updateWeightsNoCueCompetition'>Function implementing the Rescorla-Wagner learning equations without cue 
competition for a single learning event.</h2><span id='topic+updateWeightsNoCueCompetition'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning equations 
without cue competition (for illustration purposes) for a single learning 
event. A set of cues and outcomes are provided, and a weightmatrix that 
needs to be updated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateWeightsNoCueCompetition(
  cur.cues,
  cur.outcomes,
  wm = NULL,
  eta = 0.01,
  lambda = 1,
  alpha = 0.1,
  beta1 = 0.1,
  beta2 = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="updateWeightsNoCueCompetition_+3A_cur.cues">cur.cues</code></td>
<td>
<p>A vector with cues.</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_cur.outcomes">cur.outcomes</code></td>
<td>
<p>A vector with outcomes.</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix. If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the 
weightmatrix: if not present, they will be added.</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_eta">eta</code></td>
<td>
<p>Learning parameter, typically set to 0.01. 
If <code>eta</code> is not specified and set to the value NULL, 
the values of <code>alpha</code>, <code>beta1</code>, and <code>beta2</code> 
determine the learning rate. However, changing these settings 
is generally not very useful (see Hoppe et al, submitted).</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1.</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1.</p>
</td></tr>
<tr><td><code id="updateWeightsNoCueCompetition_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A weightmatrix (matrix)
</p>


<h3>Author(s)</h3>

<p>Dorothee Hoppe, based on <code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, <code><a href="#topic+RWlearning">RWlearning</a></code>
</p>
<p>Other functions for explaining error-driven learning: 
<code><a href="#topic+RWlearningNoCueCompetition">RWlearningNoCueCompetition</a>()</code>,
<code><a href="#topic+RWlearningNoOutcomeCompetition">RWlearningNoOutcomeCompetition</a>()</code>,
<code><a href="#topic+updateWeightsNoOutcomeCompetition">updateWeightsNoOutcomeCompetition</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearningNoCueCompetition(train)
# retrieve trained network:
new &lt;- getWM(wm)

train2 &lt;- createTrainingData(dat)
updateWeightsNoCueCompetition(getValues(train2$Cues[1]), 
    getValues(train2$Outcomes[1]), wm=new)

# comparison between eta and alpha, beta1, beta2:
check.cues &lt;- c("BG", "car", "red")
new[check.cues,]
tmp1 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new)
tmp2 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new, eta=NULL)
tmp3 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new, beta1=0.2)
tmp4 &lt;- updateWeights(check.cues, 
    c("vehicle", "animal"), wm=new, eta=NULL, beta1=0.2)
# these two should be the same:
tmp1[check.cues,]
tmp2[check.cues,]
# now we change beta2, but this does not change anything,
# because eta is being used:
tmp3[check.cues,]
# when we turn eta off, beta2 changes the values:
tmp4[check.cues,]

</code></pre>

<hr>
<h2 id='updateWeightsNoOutcomeCompetition'>Function implementing the Rescorla-Wagner learning equations without 
outcome competition (for illustration purposes) for a single learning 
event.</h2><span id='topic+updateWeightsNoOutcomeCompetition'></span>

<h3>Description</h3>

<p>Function implementing the Rescorla-Wagner learning equations 
without outcome competition (for illustration purposes) for a single 
learning event. A set of cues and outcomes are provided, 
and a weightmatrix that needs to be updated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateWeightsNoOutcomeCompetition(
  cur.cues,
  cur.outcomes,
  wm = NULL,
  eta = 0.01,
  lambda = 1,
  alpha = 0.1,
  beta1 = 0.1,
  beta2 = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_cur.cues">cur.cues</code></td>
<td>
<p>A vector with cues.</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_cur.outcomes">cur.outcomes</code></td>
<td>
<p>A vector with outcomes.</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_wm">wm</code></td>
<td>
<p>A weightmatrix of class matrix. If not provided a new 
weightmatrix is returned. Note that the cues and outcomes do not 
necessarily need to be available as cues and outcomes in the 
weightmatrix: if not present, they will be added.</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_eta">eta</code></td>
<td>
<p>Learning parameter, typically set to 0.01. 
If <code>eta</code> is not specified and set to the value NULL, 
the values of <code>alpha</code>, <code>beta1</code>, and <code>beta2</code> 
determine the learning rate. However, changing these settings 
is generally not very useful (see Hoppe et al, submitted).</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_lambda">lambda</code></td>
<td>
<p>Constant constraining the connection strength.</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_alpha">alpha</code></td>
<td>
<p>Learning parameter (scaling both positive and negative 
evidence adjustments), typically set to 0.1.</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_beta1">beta1</code></td>
<td>
<p>Learning parameter for positive evidence, typically set to 
0.1.</p>
</td></tr>
<tr><td><code id="updateWeightsNoOutcomeCompetition_+3A_beta2">beta2</code></td>
<td>
<p>Learning parameter for negative evidence, typically set to 
0.1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A weightmatrix (matrix)
</p>


<h3>Author(s)</h3>

<p>Dorothee Hoppe, based on <code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="ndl.html#topic+RescorlaWagner">RescorlaWagner</a></code>, <code><a href="#topic+RWlearning">RWlearning</a></code>
</p>
<p>Other functions for explaining error-driven learning: 
<code><a href="#topic+RWlearningNoCueCompetition">RWlearningNoCueCompetition</a>()</code>,
<code><a href="#topic+RWlearningNoOutcomeCompetition">RWlearningNoOutcomeCompetition</a>()</code>,
<code><a href="#topic+updateWeightsNoCueCompetition">updateWeightsNoCueCompetition</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load example data:
data(dat)

# add obligatory columns Cues, Outcomes, and Frequency:
dat$Cues &lt;- paste("BG", dat$Shape, dat$Color, sep="_")
dat$Outcomes &lt;- dat$Category
dat$Frequency &lt;- dat$Frequency1
head(dat)
dim(dat)

# now use createTrainingData to sample from the specified frequencies: 
train &lt;- createTrainingData(dat)

# this training data can actually be used train network:
wm &lt;- RWlearningNoOutcomeCompetition(train)
# retrieve trained network:
new &lt;- getWM(wm)

train2 &lt;- createTrainingData(dat)
updateWeightsNoOutcomeCompetition(getValues(train2$Cues[1]), 
    getValues(train2$Outcomes[1]), wm=new)

# comparison between eta and alpha, beta1, beta2:
check.cues &lt;- c("BG", "car", "red")
new[check.cues,]
tmp1 &lt;- updateWeightsNoOutcomeCompetition(check.cues, 
    c("vehicle", "animal"), wm=new)
tmp2 &lt;- updateWeightsNoOutcomeCompetition(check.cues, 
    c("vehicle", "animal"), wm=new, eta=NULL)
tmp3 &lt;- updateWeightsNoOutcomeCompetition(check.cues, 
    c("vehicle", "animal"), wm=new, beta1=0.2)
tmp4 &lt;- updateWeightsNoOutcomeCompetition(check.cues, 
    c("vehicle", "animal"), wm=new, eta=NULL, beta1=0.2)
# these two should be the same:
tmp1[check.cues,]
tmp2[check.cues,]
# now we change beta2, but this does not change anything,
# because eta is being used:
tmp3[check.cues,]
# when we turn eta off, beta2 changes the values:
tmp4[check.cues,]

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
