<!DOCTYPE html><html><head><title>Help for package snapKrig</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {snapKrig}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#[.sk'><p>Extract a sk list element (single-bracket access)</p></a></li>
<li><a href='#[[.sk&lt;-'><p>sk_methods.R</p>
Dean Koch, 2022
S3 methods for sk grid list objects</a></li>
<li><a href='#[&lt;-.sk'><p>Single-bracket assign</p></a></li>
<li><a href='#anyNA.sk'><p>Check for presence of grid points with missing data (NAs)</p></a></li>
<li><a href='#as.double.sk'><p>Coerce grid values to numeric (double type)</p></a></li>
<li><a href='#as.integer.sk'><p>Coerce grid values to integer</p></a></li>
<li><a href='#as.logical.sk'><p>Coerce grid values to logical</p></a></li>
<li><a href='#as.matrix.sk'><p>convert to matrix</p></a></li>
<li><a href='#as.vector.sk'><p>Convert grid data to vector of specified mode</p></a></li>
<li><a href='#dim.sk'><p>Grid dimensions</p></a></li>
<li><a href='#is.na.sk'><p>Indices of grid points with missing data (NAs)</p></a></li>
<li><a href='#length.sk'><p>The number of grid-points</p></a></li>
<li><a href='#Math.sk'><p>Math group generics</p></a></li>
<li><a href='#mean.sk'><p>Calculate the mean value in a grid</p></a></li>
<li><a href='#Ops.sk'><p>Operations group generics</p></a></li>
<li><a href='#plot.sk'><p>Heatmap plots</p></a></li>
<li><a href='#print.sk'><p>Auto-printing</p></a></li>
<li><a href='#sk'><p>Make a snapKrig grid list object</p></a></li>
<li><a href='#sk_add_bins'><p>Add bin labels to a variogram data frame</p></a></li>
<li><a href='#sk_bds'><p>Set default parameter covariance parameter bounds for a Kronecker covariance model</p></a></li>
<li><a href='#sk_cmean'><p>Compute kriging predictor (or variance) for an sk grid</p></a></li>
<li><a href='#sk_coords'><p>Return coordinates of a grid of points in column-vectorized order</p></a></li>
<li><a href='#sk_corr'><p>Stationary 1D correlation kernels</p></a></li>
<li><a href='#sk_corr_mat'><p>Construct 1D stationary correlation matrices for regularly spaced data</p></a></li>
<li><a href='#sk_export'><p>Convert &quot;sk&quot; grid to SpatRaster</p></a></li>
<li><a href='#sk_fit'><p>Fit a covariance model to an sk grid by maximum likelihood</p></a></li>
<li><a href='#sk_GLS'><p>Generalized least squares (GLS) with Kronecker covariances for sk grids</p></a></li>
<li><a href='#sk_kp'><p>Return named vector of Kronecker covariance parameters initialized to NA</p></a></li>
<li><a href='#sk_LL'><p>Likelihood of covariance model <code>pars</code> given the data in sk grid <code>g</code></p></a></li>
<li><a href='#sk_make'><p>Make a sk grid object</p></a></li>
<li><a href='#sk_mat2vec'><p>Column-vectorization indices</p></a></li>
<li><a href='#sk_nLL'><p>Negative log-likelihood for parameter vector <code>p</code></p></a></li>
<li><a href='#sk_pars'><p>Initialize Kronecker covariance function parameters for a sk grid</p></a></li>
<li><a href='#sk_pars_make'><p>Build a parameter list defining the 2d spatial Kronecker covariance model</p></a></li>
<li><a href='#sk_pars_update'><p>Convert covariance parameter list to/from vectorized form</p></a></li>
<li><a href='#sk_plot'><p>Plot grid data</p></a></li>
<li><a href='#sk_plot_pars'><p>Plot the covariance structure of a snapKrig model</p></a></li>
<li><a href='#sk_plot_semi'><p>Plot a semi-variogram</p></a></li>
<li><a href='#sk_rescale'><p>Up or down-scale a sk grid by an integer factor</p></a></li>
<li><a href='#sk_sample_pt'><p>Sub-grid point sampler for grid data</p></a></li>
<li><a href='#sk_sample_vg'><p>Sample point pair absolute differences for use in semi-variogram estimation</p></a></li>
<li><a href='#sk_sim'><p>Random draw from multivariate normal distribution for sk grids</p></a></li>
<li><a href='#sk_snap'><p>Snap a set of points to a &quot;sk&quot; grid</p></a></li>
<li><a href='#sk_sub'><p>Return a sub-grid of a sk grid object</p></a></li>
<li><a href='#sk_sub_find'><p>Find complete regular sub-grids in a sk grid object</p></a></li>
<li><a href='#sk_sub_idx'><p>Find column-vectorized index of a sub-grid</p></a></li>
<li><a href='#sk_to_string'><p>Extract Kronecker covariance  parameters as plot-friendly strings</p></a></li>
<li><a href='#sk_toep_mult'><p>Efficiently compute yzx for symmetric Toeplitz matrices y and x</p></a></li>
<li><a href='#sk_validate'><p>Check compatibility of entries in a sk grid object, and fill in any missing ones</p></a></li>
<li><a href='#sk_var'><p>Generate a covariance matrix or its factorization</p></a></li>
<li><a href='#sk_var_mult'><p>Multiply a vector by a power of the covariance matrix</p></a></li>
<li><a href='#sk_vario_fun'><p>Theoretical variogram function</p></a></li>
<li><a href='#sk_vec2mat'><p>Invert column-vectorization indices</p></a></li>
<li><a href='#summary.sk'><p>Grid summary</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Fast Kriging and Geostatistics on Grids with Kronecker
Covariance</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Geostatistical modeling and kriging with
    gridded data using spatially separable covariance functions (Kronecker
    covariances). Kronecker products in these models provide shortcuts for
    solving large matrix problems in likelihood and conditional mean,
    making 'snapKrig' computationally efficient with large grids. The package
    supplies its own S3 grid object class, and a host of methods including
    plot, print, Ops, square bracket replace/assign, and more. Our computational
    methods are described in Koch, Lele, Lewis (2020) &lt;<a href="https://doi.org/10.7939%2Fr3-g6qb-bq70">doi:10.7939/r3-g6qb-bq70</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/deankoch/snapKrig">https://github.com/deankoch/snapKrig</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/deankoch/snapKrig/issues">https://github.com/deankoch/snapKrig/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, methods, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, terra, raster, sf, units, sp,</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-06 01:21:32 UTC; deank</td>
</tr>
<tr>
<td>Author:</td>
<td>Dean Koch <a href="https://orcid.org/0000-0002-8849-859X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dean Koch &lt;dkoch@ualberta.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-06 04:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+5B.sk'>Extract a sk list element (single-bracket access)</h2><span id='topic++5B.sk'></span>

<h3>Description</h3>

<p>Copies the specified list element or grid point value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
x[i = NULL, j = NULL, drop = FALSE, ...]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="+2B5B.sk_+3A_i">i</code></td>
<td>
<p>column-vectorized index</p>
</td></tr>
<tr><td><code id="+2B5B.sk_+3A_j">j</code></td>
<td>
<p>index of layer (only for multi-layer x)</p>
</td></tr>
<tr><td><code id="+2B5B.sk_+3A_drop">drop</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="+2B5B.sk_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Behavior depends on the class of i. For character vectors this extracts the named list
entries of x. For numeric, it accesses the vectorized grid data values. For multi-layer
objects, a layer can be specified in j.
</p>
<p>the default <code>NULL</code> for <code>i</code> and <code>j</code> is treated as numeric, and is shorthand for all
indices. For example if <code>x</code> has a single-layer <code>x[]</code> returns all grid data in a vector.
If <code>x</code> is multi-layer <code>x[,1]</code> all grid data from the first layer, and <code>x[]</code> returns all
layers, as a matrix.
</p>


<h3>Value</h3>

<p>a list, vector, or matrix (see description)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># define a sk list and extract two of its elements
g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
g[c('gdim', 'gres')]

# display all the grid data as a vector or a matrix
g[]
matrix(g[], dim(g))

# extract a particular grid point or a subset
g[1]
g[seq(5)]

</code></pre>

<hr>
<h2 id='+5B+5B.sk+26lt+3B-'>sk_methods.R
Dean Koch, 2022
S3 methods for sk grid list objects</h2><span id='topic++5B+5B.sk+3C-'></span>

<h3>Description</h3>

<p>Replace a sk list element (double-bracket assign)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class ''sk&lt;-''
x[[value]]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B+2B5B.sk+2B26lt+2B3B-_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B.sk+2B26lt+2B3B-_+3A_value">value</code></td>
<td>
<p>the replacement object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Replaces entries in the sk list object. This does no validation. If it did, then
<code>sk_validate</code> would have an infinite recursion problem (it uses <code style="white-space: pre;">&#8288;[[&lt;-&#8288;</code>). Users should
pass the results to <code>sk_validate</code> afterwards unless they know what they're doing.
</p>


<h3>Value</h3>

<p>a &quot;sk&quot; object
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sk list elements are interrelated - for example gres must match spacing in gyx
g = sk_validate(list(gval=stats::rnorm(10^2), gdim=10, gres=0.5))
g[['gres']] = 2 * g[['gres']]
g[['gyx']] = lapply(g[['gyx']], function(x) 2*x)
sk_validate(g)

</code></pre>

<hr>
<h2 id='+5B+26lt+3B-.sk'>Single-bracket assign</h2><span id='topic++5B+3C-.sk'></span>

<h3>Description</h3>

<p>Behavior depends on the class of i. For character vectors, this assigns to
the named list entries of x (as usual). For numeric indices, it assigns
vectorized grid data values. For multi-layer objects, specify the layer in j
and supply a matrix for replacement
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 replacement method for class 'sk'
x[i = NULL, j = NULL] &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B+2B26lt+2B3B-.sk_+3A_x">x</code></td>
<td>
<p>an sk object</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.sk_+3A_i">i</code></td>
<td>
<p>column-vectorized index</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.sk_+3A_j">j</code></td>
<td>
<p>index of layer (only for multi-layer x)</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.sk_+3A_value">value</code></td>
<td>
<p>the replacement values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the &quot;sk&quot; object with the specified subset replaced by value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
print(g)
g[1] = NA
print(g)

</code></pre>

<hr>
<h2 id='anyNA.sk'>Check for presence of grid points with missing data (NAs)</h2><span id='topic+anyNA.sk'></span>

<h3>Description</h3>

<p>Returns a logical indicating if any of the grid points are NA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
anyNA(x, recursive)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anyNA.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="anyNA.sk_+3A_recursive">recursive</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
anyNA(g)
g[1] = NA
anyNA(g)

</code></pre>

<hr>
<h2 id='as.double.sk'>Coerce grid values to numeric (double type)</h2><span id='topic+as.double.sk'></span>

<h3>Description</h3>

<p>This also adds support for as.numeric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
as.double(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.double.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="as.double.sk_+3A_...">...</code></td>
<td>
<p>further arguments to as.double</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an &quot;sk&quot; object with numeric data values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=sample(c(FALSE, TRUE), 4^2, replace=TRUE), gdim=4, gres=0.5))
g[]
as.numeric(g)[]

</code></pre>

<hr>
<h2 id='as.integer.sk'>Coerce grid values to integer</h2><span id='topic+as.integer.sk'></span>

<h3>Description</h3>

<p>Coerce grid values to integer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
as.integer(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.integer.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="as.integer.sk_+3A_...">...</code></td>
<td>
<p>further arguments to as.integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an &quot;sk&quot; object with integer data values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
g[]
as.integer(g)[]
</code></pre>

<hr>
<h2 id='as.logical.sk'>Coerce grid values to logical</h2><span id='topic+as.logical.sk'></span>

<h3>Description</h3>

<p>Coerce grid values to logical
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
as.logical(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.logical.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="as.logical.sk_+3A_...">...</code></td>
<td>
<p>further arguments to as.logical</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a &quot;sk&quot; object with logical data values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=sample(c(0,1), 4^2, replace=TRUE), gdim=4, gres=0.5))
g[]
as.logical(g)[]

# "range" for logical is reported as integer
summary(as.logical(g))

</code></pre>

<hr>
<h2 id='as.matrix.sk'>convert to matrix</h2><span id='topic+as.matrix.sk'></span>

<h3>Description</h3>

<p>Returns a matrix representation of the grid data. This is shorthand for
extracting the data using <code>x[]</code> (single layer) or <code>x[,j]</code> (multi-layer),
then passing the result to <code>matrix</code> along with <code>dim(x)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
as.matrix(x, rownames.force = NA, layer = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="as.matrix.sk_+3A_rownames.force">rownames.force</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="as.matrix.sk_+3A_layer">layer</code></td>
<td>
<p>integer, for multi-layer grids, the layer number to return</p>
</td></tr>
<tr><td><code id="as.matrix.sk_+3A_...">...</code></td>
<td>
<p>further arguments to as.matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the grid data as a matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
plot(g)
as.matrix(g)
</code></pre>

<hr>
<h2 id='as.vector.sk'>Convert grid data to vector of specified mode</h2><span id='topic+as.vector.sk'></span>

<h3>Description</h3>

<p>Returns a vector of the specified mode, representing the vectorized grid data.
For multi-layer <code>x</code>, the first layer is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
as.vector(x, mode = "any")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.vector.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="as.vector.sk_+3A_mode">mode</code></td>
<td>
<p>passed to as.vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For single layer <code>x</code>, and with default <code>mode='any'</code>, this is the same as <code>x[]</code>
</p>


<h3>Value</h3>

<p>a vector of the specified mode
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
as.vector(g)
</code></pre>

<hr>
<h2 id='dim.sk'>Grid dimensions</h2><span id='topic+dim.sk'></span>

<h3>Description</h3>

<p>Returns <code>gdim</code>, the number of y and x grid lines, in that order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>integer vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
dim(g)
</code></pre>

<hr>
<h2 id='is.na.sk'>Indices of grid points with missing data (NAs)</h2><span id='topic+is.na.sk'></span>

<h3>Description</h3>

<p>Returns a logical vector indicating which grid points have NA values assigned
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
is.na(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.na.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logical vector the same length as x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
g[c(1,3)] = NA
is.na(g)
</code></pre>

<hr>
<h2 id='length.sk'>The number of grid-points</h2><span id='topic+length.sk'></span>

<h3>Description</h3>

<p>Returns the total number of points in the grid, which is the product of the
number of y and x grid lines (<code>gdim</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="length.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>integer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
length(g)
</code></pre>

<hr>
<h2 id='Math.sk'>Math group generics</h2><span id='topic+Math.sk'></span>

<h3>Description</h3>

<p>All except the <code>cumsum</code> family are supported
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
Math(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Math.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="Math.sk_+3A_...">...</code></td>
<td>
<p>further arguments to Math</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the &quot;sk&quot; object with data values transformed accordingly
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
summary(g)
summary(abs(g))
summary(exp(g))

</code></pre>

<hr>
<h2 id='mean.sk'>Calculate the mean value in a grid</h2><span id='topic+mean.sk'></span>

<h3>Description</h3>

<p>This calculates the mean over all layers (if any)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
mean(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="mean.sk_+3A_...">...</code></td>
<td>
<p>further arguments to default mean method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
mean(g) == mean(g[])

</code></pre>

<hr>
<h2 id='Ops.sk'>Operations group generics</h2><span id='topic+Ops.sk'></span>

<h3>Description</h3>

<p>Applies the operation point-wise to grid data values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
Ops(e1, e2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ops.sk_+3A_e1">e1</code></td>
<td>
<p>a &quot;sk&quot; object, vector or matrix</p>
</td></tr>
<tr><td><code id="Ops.sk_+3A_e2">e2</code></td>
<td>
<p>a &quot;sk&quot; object, vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function extracts the grid data <code>x[]</code> from all sk class arguments <code>x</code>, prior to
calling the default method. Before returning, the result is copied back to the grid object
of the second argument (or the first, if the second is not of class &quot;sk&quot;).
</p>
<p>Note that the compatibility of the two arguments is not checked beyond matching
dimension (with vectors recycled as needed). This means for example you can do
operations on two grids representing different areas, so long as they have the
same <code>gdim</code>.
</p>


<h3>Value</h3>

<p>a &quot;sk&quot; object (a copy of <code>e1</code> or <code>e2</code>) with modified data values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))

# verify a trig identity using Ops and Math
summary( cos(g)^2 + sin(g)^2 )

# create a logical grid indicating points satisfying a condition
plot(g &lt; 0)
all( !(g &gt; 0) == (g[] &lt; 0) )

# test negation
all( (-g)[] == -(g[]) )

</code></pre>

<hr>
<h2 id='plot.sk'>Heatmap plots</h2><span id='topic+plot.sk'></span>

<h3>Description</h3>

<p>A wrapper for sk_plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="plot.sk_+3A_...">...</code></td>
<td>
<p>other arguments passed to sk_plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing
</p>


<h3>See Also</h3>

<p>sk_plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
plot(g)
</code></pre>

<hr>
<h2 id='print.sk'>Auto-printing</h2><span id='topic+print.sk'></span>

<h3>Description</h3>

<p>Prints dimensions and indicates if the grid has values assigned
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sk_+3A_x">x</code></td>
<td>
<p>a sk object</p>
</td></tr>
<tr><td><code id="print.sk_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This prints &quot;(not validated)&quot; if the sk object has no <code>is_na</code> entry,
to remind users to run <code>sk_validate</code>.
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sk_make(list(gdim=10, gres=0.5))
sk_validate(sk_make(list(gdim=10, gres=0.5)))
</code></pre>

<hr>
<h2 id='sk'>Make a snapKrig grid list object</h2><span id='topic+sk'></span>

<h3>Description</h3>

<p>Constructs snapKrig (&quot;sk&quot;) class list, representing a 2-dimensional regular spatial grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk(..., vals = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_+3A_...">...</code></td>
<td>
<p>raster, matrix, numeric vector, or list of named arguments (see details)</p>
</td></tr>
<tr><td><code id="sk_+3A_vals">vals</code></td>
<td>
<p>logical indicating to include the data vector <code>gval</code> in return list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function accepts 'RasterLayer' and 'RasterStack' inputs from the <code>raster</code> package,
'SpatRaster' objects from <code>terra</code>, as well as any non-complex matrix, or a set of arguments
defining the vectorization of one. It returns a sk class list containing at least the
following three elements:
</p>

<ul>
<li> <p><code>gdim</code>: vector of two positive integers, the number of grid lines (n = their product)
</p>
</li>
<li> <p><code>gres</code>: vector of two positive scalars, the resolution (in distance between grid lines)
</p>
</li>
<li> <p><code>gyx</code>: list of two numeric vectors (lengths matching gdim), the grid line intercepts
</p>
</li></ul>

<p>and optionally,
</p>

<ul>
<li> <p><code>crs</code>: character, the WKT representation of the CRS for the grid (optional)
</p>
</li>
<li> <p><code>gval</code>: numeric vector or matrix, the grid data
</p>
</li>
<li> <p><code>is_obs</code>: logical vector indicating non-NA entries in the grid data
</p>
</li>
<li> <p><code>idx_grid</code>: length-n numeric vector mapping rows of <code>gval</code> to grid points
</p>
</li></ul>

<p>Supply some/all of these elements (including at least one of <code>gdim</code> or <code>gyx</code>) as named
arguments to <code>...</code>. The function will fill in missing entries wherever possible.
</p>
<p>If <code>gres</code> is missing, it is computed from the first two grid lines in <code>gyx</code>; If <code>gyx</code> is
missing, it is assigned the sequence <code>1:n</code> (scaled by <code>gres</code>, if available) for each <code>n</code>
in <code>gdim</code>; and if <code>gdim</code> is missing, it is set to the number of grid lines specified in
<code>gyx</code>. <code>gyx</code> should be sorted (ascending order), regularly spaced (with spacing <code>gres</code>),
and have lengths matching <code>gdim</code>.
</p>
<p>Scalar inputs to <code>gdim</code>, <code>gres</code> are duplicated for both dimensions. For example the call
<code>sk(gdim=c(5,5))</code> can be simplified to <code>sk(gdim=5)</code>, or <code>sk(5)</code>.
</p>
<p>For convenience, arguments can also be supplied together in a named list passed to <code>...</code>.
If a single unnamed argument is supplied (and it is not a list) the function expects it to
be either a numeric vector (<code>gdim</code>), a matrix, or a raster object.
</p>
<p>Alternatively, you can supply an <code>sk</code> object as (unnamed) first argument, followed by
individual named arguments. This replaces the named elements in the <code>sk</code> object then does
a validity check.
</p>
<p>Empty grids - with all data <code>NA</code> - can be initialized by setting <code>vals=FALSE</code>, in which case
<code>gval</code> will be absent from the returned list). Otherwise <code>gval</code> is the
column-vectorized grid data, either as a numeric vector (single layer case only) or as a
matrix with grid data in columns. <code>gval</code> is always accompanied by <code>is_obs</code>, which supplies
an index of <code>NA</code> entries (or rows)
</p>
<p>A sparse representation is used when <code>gval</code> is a matrix, where only the non-<code>NA</code> entries (or
rows) are stored. <code>idx_grid</code> in this case contains <code>NA</code>'s were <code>is_obs</code> is <code>FALSE</code>, and
otherwise contains the integer index of the corresponding row in <code>gval</code>. In the matrix case
it is assumed that each layer (ie column) has the same <code>NA</code> structure. <code>idx_grid</code> is only
computed for the first layer. If a point is missing from one layer, it should be missing
from all layers.
</p>


<h3>Value</h3>

<p>a &quot;sk&quot; class list object
</p>


<h3>See Also</h3>

<p>Other sk constructors: 
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_snap">sk_snap</a>()</code>,
<code><a href="#topic+sk_sub">sk_sub</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# simple grid construction from dimensions
gdim = c(12, 10)
g = sk(gdim)
summary(g)

# pass result to sk and get the same thing back
identical(g, sk(g))

# supply grid lines as named argument instead and get the same result
all.equal(g, sk(gyx=lapply(gdim, function(x) seq(x)-1L)))

# display coordinates and grid line indices
plot(g)
plot(g, ij=TRUE)

# same dimensions, different resolution, affecting aspect ratio in plot
gres_new = c(3, 4)
plot(sk(gdim=gdim, gres=gres_new))

# single argument (unnamed) can be grid dimensions, with shorthand for square grids
all.equal(sk(gdim=c(2,2)), sk(c(2,2)))
all.equal(sk(2), sk(gdim=c(2,2)))

# example with matrix data
gdim = c(25, 25)
gyx = as.list(expand.grid(lapply(gdim, seq)))
eg_vec = as.numeric( gyx[[2]] %% gyx[[1]] )
eg_mat = matrix(eg_vec, gdim)
g = sk(eg_mat)
plot(g, ij=TRUE, zlab='j mod i')

# y is in descending order
plot(g, xlab='x = j', ylab='y = 26 - i', zlab='j mod i')

# this is R's default matrix vectorization order
all.equal(eg_vec, as.vector(eg_mat))
all.equal(g, sk(gdim=gdim, gval=as.vector(eg_mat)))

# multi-layer example from matrix
n_pt = prod(gdim)
n_layer = 3
mat_multi = matrix(stats::rnorm(n_pt*n_layer), n_pt, n_layer)
g_multi = sk(gdim=gdim, gval=mat_multi)
summary(g_multi)

# repeat with missing data (note all columns must have consistent NA structure)
mat_multi[sample.int(n_pt, 0.5*n_pt),] = NA
g_multi_miss = sk(gdim=gdim, gval=mat_multi)
summary(g_multi_miss)

# only observed data points are stored, idx_grid maps them to the full grid vector
max(abs( g_multi[['gval']] - g_multi_miss[['gval']][g_multi_miss[['idx_grid']],] ), na.rm=TRUE)

# single bracket indexing magic does the mapping automatically
max(abs( g_multi[] - g_multi_miss[] ), na.rm=TRUE)

# vals=FALSE drops multi-layer information
sk(gdim=gdim, gval=mat_multi, vals=FALSE)

# raster import examples skipped to keep CMD check time &lt; 5s on slower machines

if( requireNamespace('raster') ) {

# open example file as RasterLayer
r_path = system.file('external/rlogo.grd', package='raster')
r = raster::raster(r_path)

# convert to sk (notice only first layer was loaded by raster)
g = sk(r)
summary(g)
plot(g)

# open a RasterStack - gval becomes a matrix with layers in columns
r_multi = raster::stack(r_path)
g_multi = sk(r_multi)
summary(g_multi)
plot(g_multi, layer=1)
plot(g_multi, layer=2)
plot(g_multi, layer=3)

# repeat with terra
if( requireNamespace('terra') ) {

# open example file as SpatRaster (all layers loaded by default)
r_multi = terra::rast(r_path)
g_multi = sk(r_multi)
summary(g_multi)

# open first layer only
g = sk(r[[1]])
summary(g)

}
}

</code></pre>

<hr>
<h2 id='sk_add_bins'>Add bin labels to a variogram data frame</h2><span id='topic+sk_add_bins'></span>

<h3>Description</h3>

<p>Helper function for grouping the rows of input data frame <code>vg</code> into <code>n_bins</code> bins
according to the value of the (numeric) distance column <code>d</code>. This uses either <code>base::cut</code>
or, if <code>probs</code> is supplied, <code>stats::quantile</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_add_bins(vg, n_bin = 25, probs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_add_bins_+3A_vg">vg</code></td>
<td>
<p>data frame with numeric column 'd'</p>
</td></tr>
<tr><td><code id="sk_add_bins_+3A_n_bin">n_bin</code></td>
<td>
<p>integer number of distance bins to assign</p>
</td></tr>
<tr><td><code id="sk_add_bins_+3A_probs">probs</code></td>
<td>
<p>numeric vector of quantile probabilities to establish breakpoints (length <code>n_bin+1</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, the function sets <code>probs</code> to a sequence of length <code>1+n_bin</code> evenly splitting
the interval [0,1] to ensure approximately equal sample sizes for each bin. Setting
<code>probs=NA</code> instead sets the bin endpoints such that the range of distances is split
evenly (note this may produce empty bins)
</p>
<p>The function is called by <code>sk_sample_vg</code> and <code>sk_plot_semi</code> (when column <code>bin</code> is
missing). It can also be used to recompute bins after an <code>rbind</code> of multiple variogram
data frames.
</p>


<h3>Value</h3>

<p>same as input <code>vg</code> but with integer column <code>bin</code> added/modified
</p>


<h3>See Also</h3>

<p>Other variogram functions: 
<code><a href="#topic+sk_vario_fun">sk_vario_fun</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>distance_df = data.frame(d=runif(25))
sk_add_bins(distance_df)

# specify fewer bins and set up quantiles explicitly
sk_add_bins(distance_df, n_bin = 5) # same as ...
sk_add_bins(distance_df, n_bin = 5, probs=seq(0, 1, length.out=6))

# break range of distances into evenly spaced bins (of varying sample sizes)
sk_add_bins(distance_df, n_bin = 5, probs=NULL)

</code></pre>

<hr>
<h2 id='sk_bds'>Set default parameter covariance parameter bounds for a Kronecker covariance model</h2><span id='topic+sk_bds'></span>

<h3>Description</h3>

<p>Returns a data-frame of initial values and upper/lower bounds on covariance
parameters for the Kronecker covariance model defined by the correlation function
names in <code>pars</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_bds(pars, g, var_obs = NULL, var_mult = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_bds_+3A_pars">pars</code></td>
<td>
<p>list or character vector of 1-2 kernel names (see <code>sk_pars</code>)</p>
</td></tr>
<tr><td><code id="sk_bds_+3A_g">g</code></td>
<td>
<p>a sk grid (or any object accepted by <code>sk</code>)</p>
</td></tr>
<tr><td><code id="sk_bds_+3A_var_obs">var_obs</code></td>
<td>
<p>positive numeric, the sample variance of data <code>g$gval</code></p>
</td></tr>
<tr><td><code id="sk_bds_+3A_var_mult">var_mult</code></td>
<td>
<p>numeric &gt; 1, constant to multiply by <code>var_obs</code> to get upper bounds</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Range parameters (<code>y.rho</code> and <code>x.rho</code>) are bounded by the shortest and longest
inter-point distances along the corresponding dimension (y or x). This is
computed by taking the element-wise product of dimensions and resolution, ie
<code>g$gres * dim(g)</code>. Ranges are initialized to the geometric mean of the upper
and lower bounds.
</p>
<p>Variance bounds are centered around <code>var_obs</code>, which by default is set to the sample
variance of the data in <code>g</code>. <code>eps</code> (measurement variance) and <code>psill</code> (partial
sill) are both initialized to one half of <code>var_obs</code>, bounded above by <code>var_obs</code>
times <code>var_mult</code>, and bounded below by a small positive number (<code>1e-6</code>). Note that
while <code>eps=0</code> produces valid models in theory, in practice <code>eps&gt;0</code> is often
necessary for numerical stability.
</p>
<p>Shape parameter bounds are hard-coded, and are set conservatively to avoid problems
with numerical precision in functions like <code>exp</code> and <code>gamma</code> when evaluating very
large or small distances.
</p>


<h3>Value</h3>

<p>a data frame of initial values and lower/upper bounds for the parameters in <code>pars</code>
</p>


<h3>See Also</h3>

<p>sk
</p>
<p>Other parameter managers: 
<code><a href="#topic+sk_fit">sk_fit</a>()</code>,
<code><a href="#topic+sk_kp">sk_kp</a>()</code>,
<code><a href="#topic+sk_pars_make">sk_pars_make</a>()</code>,
<code><a href="#topic+sk_pars_update">sk_pars_update</a>()</code>,
<code><a href="#topic+sk_pars">sk_pars</a>()</code>,
<code><a href="#topic+sk_to_string">sk_to_string</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdim = c(10, 15)
g = sk(gdim)
g[] = stats::rnorm(length(g))
sk_bds('mat', g)

# same result by passing in observed variance
sk_bds('mat', g, stats::var(g[]))

# a less conservative bound for variance (only eps and psill affected)
sk_bds('mat', g, var_mult=1)
</code></pre>

<hr>
<h2 id='sk_cmean'>Compute kriging predictor (or variance) for an sk grid</h2><span id='topic+sk_cmean'></span>

<h3>Description</h3>

<p>Evaluates the kriging prediction equations to find the expected value (mean) of
the spatial process for <code>g</code> at all grid points, including unobserved ones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_cmean(
  g,
  pars,
  X = NA,
  what = "p",
  out = "s",
  fac_method = "chol",
  fac = NULL,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_cmean_+3A_g">g</code></td>
<td>
<p>an sk grid or list accepted by <code>sk</code> (with entries 'gdim', 'gres', 'gval')</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_pars">pars</code></td>
<td>
<p>list of form returned by <code>sk_pars</code> (with entries 'y', 'x', 'eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_x">X</code></td>
<td>
<p>sk grid, numeric, vector, matrix, or NA: the mean, or its linear predictors</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_what">what</code></td>
<td>
<p>character, what to compute: one of 'p' (predictor), 'v' (variance), or 'm' (more)</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_out">out</code></td>
<td>
<p>character, the return object, either 's' (sk grid) or 'v' (vector)</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_fac_method">fac_method</code></td>
<td>
<p>character, either 'chol' or 'eigen'</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_fac">fac</code></td>
<td>
<p>(optional) pre-computed factorization of covariance matrix scaled by partial sill</p>
</td></tr>
<tr><td><code id="sk_cmean_+3A_quiet">quiet</code></td>
<td>
<p>logical indicating to suppress console output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This predicts a noiseless version of the random process from which grid <code>g</code> was
sampled, conditional on the observed data, and possibly a set of covariates. It is
optimal in the sense of minimizing mean squared prediction error under the covariance
model specified by <code>pars</code>, and assuming the predictions are a linear combination of
the observed data.
</p>
<p>The estimation method is determined by <code>X</code>. Set this to <code>0</code> and supply a de-trended
<code>g</code> to do simple kriging. Set it to <code>NA</code> to estimate a spatially uniform mean (ordinary
kriging). Or pass covariates to <code>X</code>, either as multi-layer sk grid or matrix, to do
universal kriging. See <code>sk_GLS</code> for details on specifying <code>X</code> in this case.
</p>
<p>Set <code>what='v'</code> to return the point-wise kriging variance. This usually takes much
longer to evaluate than the prediction, but the computer memory demands are similar.
A progress bar will be printed to console in this case unless <code>quiet=TRUE</code>.
</p>
<p>Technical notes
</p>
<p>All calculations returned by <code>sk_cmean</code> are exact. Our implementation is based on the
variance decomposition suggested in section 3.4 (p. 153-155) of Cressie (1993), and uses a
loop over eigen-vectors (for observed locations) to compute variance iteratively.
</p>
<p>In technical terms, <code>sk_cmean</code> estimates the mean of the signal process behind the data.
The nugget effect (<code>eps</code>) is therefore added to the diagonals of the covariance matrix for
the observed points, but NOT to the corresponding entries of the cross-covariance matrix.
This has the effect of smoothing (de-noising) predictions at observed locations, which means
<code>sk_cmean</code> is not an exact interpolator (except in the limit <code>eps</code> -&gt; <code>0</code>). Rather it makes
a correction to the observed data to make it consistent with the surrounding signal.
</p>
<p>This is a good thing - real spatial datasets are almost always noisy, and we are typically
interested in the signal, not some distorted version of it. For more on this see section 3
of Cressie (1993), and in particular the discussion in 3.2.1 on the nugget effect.
</p>
<p>The covariance factorization <code>fac</code> can be pre-computed using <code>sk_var</code> with arguments
<code>scaled=TRUE</code> (and, if computing variance, <code>fac_method='eigen'</code>). This will speed up
subsequent calls where only the observed data values have changed (same covariance structure
<code>pars</code>, and same <code>NA</code> structure in the data). The kriging variance does not change
in this case and only needs to be computed once.
</p>
<p>reference: &quot;Statistics for Spatial Data&quot; by Noel Cressie (1993)
</p>


<h3>Value</h3>

<p>numeric matrix, the predicted values (or their variance)
</p>


<h3>See Also</h3>

<p>sk sk_pars
</p>
<p>Other estimators: 
<code><a href="#topic+sk_GLS">sk_GLS</a>()</code>
</p>
<p>Other variance-related functions: 
<code><a href="#topic+sk_GLS">sk_GLS</a>()</code>,
<code><a href="#topic+sk_LL">sk_LL</a>()</code>,
<code><a href="#topic+sk_nLL">sk_nLL</a>()</code>,
<code><a href="#topic+sk_sim">sk_sim</a>()</code>,
<code><a href="#topic+sk_var">sk_var</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## set up very simple example problem

# make example grid and covariance parameters
g_all = sk_sim(10)
pars = sk_pars(g_all)
plot(g_all)

# remove most of the data
n = length(g_all)
p_miss = 0.90
is_miss = seq(n) %in% sample.int(n, round(p_miss*n))
is_obs = !is_miss
g_miss = g_all
g_miss[is_miss] = NA
plot(g_miss)


## simple kriging

# estimate the missing data conditional on what's left over
g_simple = sk_cmean(g_miss, pars, X=0)
plot(g_simple)

# variance of the estimator
g_simple_v = sk_cmean(g_miss, pars, X=0, what='v', quiet=TRUE)
plot(g_simple_v)

# get the same results with pre-computed variance
var_pc = sk_var(g_miss, pars, scaled=TRUE, fac_method='eigen')
g_simple_v_compare = sk_cmean(g_miss, pars, X=0, what='v', fac=var_pc, quiet=TRUE)
max(abs(g_simple_v_compare - g_simple_v))

## ordinary kriging

# estimate spatially uniform mean - true value is 0
sk_GLS(g_miss, pars, out='b')

# ordinary kriging automatically adjusts for the trend
g_ok = sk_cmean(g_miss, pars, X=NA)

# additional uncertainty in estimation means variance goes up a bit
g_ok_v = sk_cmean(g_miss, pars, X=NA, what='v', quiet=TRUE)
range(g_ok_v - g_simple_v)


## universal kriging

# introduce some covariates
n_betas = 3
betas = stats::rnorm(n_betas, 0, 10)
g_X = sk_sim(g_all, pars, n_layer=n_betas-1L)
g_lm_all = g_all + as.vector(cbind(1, g_X[]) %*% betas)
g_lm_miss = g_lm_all
g_lm_miss[is_miss] = NA

# prediction
g_uk = sk_cmean(g_lm_miss, pars, g_X)
g_uk_v = sk_cmean(g_lm_miss, pars, g_X, what='v', quiet=TRUE)


## repeat with special subgrid case (faster!)

# make g_all a subgrid of a larger example
g_super = sk_rescale(g_all, down=2)

# re-generate the covariates for the larger extent
g_X_super = sk_sim(g_super, pars, n_layer=n_betas-1L)
g_lm_super = g_super + as.vector(cbind(1, g_X_super[]) %*% betas)

# prediction
g_super_uk = sk_cmean(g_lm_super, pars, g_X_super)
g_super_uk_v = sk_cmean(g_lm_super, pars, g_X_super, what='v', quiet=TRUE)


## verification

# get observed variance and its inverse
V_full = sk_var(g_all, pars)
is_obs = !is.na(g_miss)
Vo = V_full[is_obs, is_obs]
Vo_inv = solve(Vo)

# get cross covariance
is_diag = as.logical(diag(nrow=length(g_all))[is_obs,])
Vc = V_full[is_obs,]

# nugget adjustment to diagonals (corrects the output at observed locations)
Vc[is_diag] = Vc[is_diag] - pars[['eps']]

# get covariates matrix and append intercept column
X = g_X[]
X_all = cbind(1, X)
X_obs = X_all[is_obs,]

# simple kriging the hard way
z = g_miss[is_obs]
z_trans = Vo_inv %*% z
z_pred_simple = c(t(Vc) %*% z_trans)
z_var_simple = pars[['psill']] - diag( t(Vc) %*% Vo_inv %*% Vc )

# ordinary kriging the hard way
x_trans = ( 1 - colSums( Vo_inv %*% Vc ) )
m_ok = x_trans / sum(Vo_inv)
z_pred_ok = c( (t(Vc) + m_ok) %*% z_trans )
z_var_ok = z_var_simple + diag( x_trans %*% t(m_ok) )

# universal kriging the hard way
z_lm = g_lm_miss[is_obs]
z_lm_trans = Vo_inv %*% z_lm
x_lm_trans = X_all - t( t(X_obs) %*% Vo_inv %*% Vc )
m_uk = x_lm_trans %*% solve(t(X_obs) %*% Vo_inv %*% X_obs)
z_pred_uk = c( (t(Vc) + t(X_obs %*% t(m_uk)) ) %*% z_lm_trans )
z_var_uk = z_var_simple + diag( x_lm_trans %*% t(m_uk) )

# check that these results agree with sk_cmean
max(abs(z_pred_simple - g_simple), na.rm=TRUE)
max(abs(z_var_simple - g_simple_v))
max(abs(z_pred_ok - g_ok), na.rm=TRUE)
max(abs(z_var_ok - g_ok_v))
max(abs(z_pred_uk - g_uk), na.rm=TRUE)
max(abs(z_var_uk - g_uk_v))


## repeat verification for sub-grid case

# rebuild matrices
V_full = sk_var(g_super_uk, pars)
is_obs = !is.na(g_super)
Vo = V_full[is_obs, is_obs]
Vo_inv = solve(Vo)
is_diag = as.logical(diag(nrow=length(g_super))[is_obs,])
Vc = V_full[is_obs,]
Vc[is_diag] = Vc[is_diag] - pars[['eps']]
X = g_X_super[]
X_all = cbind(1, X)
X_obs = X_all[is_obs,]
z = g_miss[is_obs]

# universal kriging the hard way
z_var_simple = pars[['psill']] - diag( t(Vc) %*% Vo_inv %*% Vc )
z_lm = g_lm_super[is_obs]
z_lm_trans = Vo_inv %*% z_lm
x_lm_trans = X_all - t( t(X_obs) %*% Vo_inv %*% Vc )
m_uk = x_lm_trans %*% solve(t(X_obs) %*% Vo_inv %*% X_obs)
z_pred_uk = c( (t(Vc) + t(X_obs %*% t(m_uk)) ) %*% z_lm_trans )
z_var_uk = z_var_simple + diag( x_lm_trans %*% t(m_uk) )

# verification
max(abs(z_pred_uk - g_super_uk), na.rm=TRUE)
max(abs(z_var_uk - g_super_uk_v))

</code></pre>

<hr>
<h2 id='sk_coords'>Return coordinates of a grid of points in column-vectorized order</h2><span id='topic+sk_coords'></span>

<h3>Description</h3>

<p>Expands a set of y and x grid line numbers in the column-vectorized order returned
by <code>sk</code>. This is similar to <code>base::expand.grid</code> but with the first dimension (y)
descending instead of ascending.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_coords(g, out = "matrix", corner = FALSE, na_omit = FALSE, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_coords_+3A_g">g</code></td>
<td>
<p>any object accepted by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_coords_+3A_out">out</code></td>
<td>
<p>character indicating return value type, either 'list', 'matrix', or 'sf'</p>
</td></tr>
<tr><td><code id="sk_coords_+3A_corner">corner</code></td>
<td>
<p>logical, indicates to return only the four corner points</p>
</td></tr>
<tr><td><code id="sk_coords_+3A_na_omit">na_omit</code></td>
<td>
<p>logical, indicates to return only locations of observed points</p>
</td></tr>
<tr><td><code id="sk_coords_+3A_quiet">quiet</code></td>
<td>
<p>logical, suppresses console output</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>out='sf'</code> returns an <code>sf</code> simple features object containing points in the same order,
with data (if any) copied from <code>g[['gval']]</code> into column 'gval'. Note that <code>length(g)</code>
points are created, which can be slow for large grids.
</p>
<p>If <code>na_omit</code> is <code>TRUE</code> the function omits points with <code>NA</code> data (in <code>gval</code>) and only
returns the coordinates for observations. This argument is ignored when <code>corners=TRUE</code>
(which always returns the four corner points) or when the grid contains no observations
(all points returned).
</p>


<h3>Value</h3>

<p>a matrix, list, or sf point collection in column vectorized order
</p>


<h3>See Also</h3>

<p>sk sk_snap base::expand.grid
</p>
<p>Other exporting functions: 
<code><a href="#topic+sk_export">sk_export</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdim = c(5,3)
g_complete = sk(gdim=gdim, gres=c(0.5, 0.7), gval=seq(prod(gdim)))
sk_coords(g_complete)
sk_coords(g_complete, out='list')

# missing data example
idx_obs =  sort(sample.int(length(g_complete), 5))
g = sk(gdim=gdim, gres=c(0.5, 0.7))
g[idx_obs] = g_complete[idx_obs]
all.equal(sk_coords(g, na_omit=TRUE), sk_coords(g_complete)[idx_obs,])

# corner points
sk_coords(g, corner=TRUE)
sk_coords(g, corner=TRUE, out='list')

# repeat with multi-layer example
g_multi = sk(utils::modifyList(g, list(gval = cbind(g[], 2*g[]))))
all.equal(sk_coords(g_multi, na_omit=TRUE), sk_coords(g_complete)[idx_obs,])
sk_coords(g_multi, corner=TRUE)

# sf output type
if( requireNamespace('sf') ) {

# gather all points but don't copy data
sf_coords_all = sk_coords(sk(g, vals=FALSE), out='sf')

# extract non-NA data
sf_coords = sk_coords(g, out='sf', na_omit=TRUE)

# plot everything together
plot(g, reset=FALSE)
plot(sf_coords_all, add=TRUE)
plot(sf_coords, pch=16, cex=2, add=TRUE)

}

</code></pre>

<hr>
<h2 id='sk_corr'>Stationary 1D correlation kernels</h2><span id='topic+sk_corr'></span>

<h3>Description</h3>

<p>Computes stationary correlation function values for the n (non-negative) 1-dimensional
distances in <code>d</code>. Parameter list entry <code>pars$kp</code> supplies the kernel parameter(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_corr(pars, d = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_corr_+3A_pars">pars</code></td>
<td>
<p>list with elements 'k', the kernel name, and 'kp' the parameter vector</p>
</td></tr>
<tr><td><code id="sk_corr_+3A_d">d</code></td>
<td>
<p>numeric vector of length n, the distances to evaluate</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pars$k</code> must be one of the following kernel names:
</p>

<ul>
<li><p> 'exp': exponential (special case of 'gex' with shape p=1)
</p>
</li>
<li><p> 'gau': gaussian/stable (special case of 'gex' with shape p=2)
</p>
</li>
<li><p> 'sph': spherical (AKA stable/Gaussian for p=2)
</p>
</li>
<li><p> 'gex': gamma-exponential (with shape p)
</p>
</li>
<li><p> 'mat': Whittle-Matern (Handcock and Wallis parameterization, with shape kap)
</p>
</li></ul>

<p>where the first three kernels have only a range parameters, and the last two have both a
range and shape parameter.
</p>
<p>For the 1-parameter kernels, <code>pars$kp</code> is the range parameter value ('rho'); For the
2-parameter kernels, <code>pars$kp</code> is a vector whose first element is 'rho', and second
element is the shape parameter ('p' or 'kap'). The names in <code>pars$kp</code> are ignored and
only the order matters - the range parameter always comes first.
</p>
<p>Note that this function will not accept parameter lists <code>pars</code> of the form returned by
<code>sk_pars(...)</code> etc, as these include a pair of 1d kernels (however the sub-lists
<code>pars$y</code> and <code>pars$x</code> are accepted).
</p>


<h3>Value</h3>

<p>length-n vector or a list of parameters and bounds (see details)
</p>


<h3>See Also</h3>

<p>Other internal variance-related functions: 
<code><a href="#topic+sk_corr_mat">sk_corr_mat</a>()</code>,
<code><a href="#topic+sk_toep_mult">sk_toep_mult</a>()</code>,
<code><a href="#topic+sk_var_mult">sk_var_mult</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# define test distances, grid, and example kernel
n_test = 100
d_test = seq(n_test)-1
g_example = sk(n_test)
pars = sk_pars(g_example, c('mat', 'gau'))
pars_x = pars[['x']]

# compute and plot the x component of the correlogram function
corr_x_example = sk_corr(pars_x, d=d_test)
plot(d_test, corr_x_example, pch=NA)
lines(d_test, corr_x_example)

## show how this function gets used to build more complicated objects

# get the other component correlation, take product
pars_y = pars[['y']]
corr_y_example = sk_corr(pars_y, d=d_test)
corr_example = corr_y_example * corr_x_example

# variogram
variogram_example = sk_vario_fun(pars, d=list(y=d_test, x=d_test))
variogram_compare = 2 * pars$eps + pars$psill * (1 - corr_example)
max(abs( variogram_example - variogram_compare ))

# Toeplitz component matrices built entirely from these correlation vectors
variance_matrix_example = sk_var(g_example, pars, sep=TRUE)
str(variance_matrix_example)
max(abs( variance_matrix_example[['y']][,1L] - corr_y_example ))
max(abs( variance_matrix_example[['x']][,1L] - corr_x_example ))

</code></pre>

<hr>
<h2 id='sk_corr_mat'>Construct 1D stationary correlation matrices for regularly spaced data</h2><span id='topic+sk_corr_mat'></span>

<h3>Description</h3>

<p>The i,jth value of the returned correlation matrix is the marginal correlation between
the ith and jth points in a regularly spaced sequence of <code>n</code> 1-dimensional (1D) points,
given the correlation model with parameters defined in list <code>pars</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_corr_mat(pars, n, gres = 1, i = seq(n), j = seq(n))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_corr_mat_+3A_pars">pars</code></td>
<td>
<p>list of kernel parameters 'k' and 'kp' (see <code>sk_corr</code>)</p>
</td></tr>
<tr><td><code id="sk_corr_mat_+3A_n">n</code></td>
<td>
<p>positive integer, the number of points on the 1D line</p>
</td></tr>
<tr><td><code id="sk_corr_mat_+3A_gres">gres</code></td>
<td>
<p>positive numeric, the distance between adjacent grid lines</p>
</td></tr>
<tr><td><code id="sk_corr_mat_+3A_i">i</code></td>
<td>
<p>vector, a subset of <code>seq(n)</code> indicating rows to return</p>
</td></tr>
<tr><td><code id="sk_corr_mat_+3A_j">j</code></td>
<td>
<p>vector, a subset of <code>seq(n)</code> indicating columns to return</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This matrix is symmetric and Toeplitz as a result of the assumption of stationarity
of the random field and regularity of the grid.
</p>
<p>The distance between adjacent points is specified by <code>gres</code>. Subsets of
the correlation matrix can be requested by specifying <code>i</code> and/or <code>j</code> (default
behaviour is to include all).
</p>
<p>Like <code>sk_corr</code>, this function is for computing 1D components of a 2D process.
The product of two matrices returned by <code>sk_corr_mat</code> is the correlation
matrix for a spatially separable process (see examples).
</p>


<h3>Value</h3>

<p>the n x n correlation matrix, or its subset as specified in <code>i</code>, <code>j</code>
</p>


<h3>See Also</h3>

<p>Other internal variance-related functions: 
<code><a href="#topic+sk_corr">sk_corr</a>()</code>,
<code><a href="#topic+sk_toep_mult">sk_toep_mult</a>()</code>,
<code><a href="#topic+sk_var_mult">sk_var_mult</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# define test distances, grid, and example kernel
n_test = 10
g_example = sk(n_test)
pars = sk_pars(g_example, c('mat', 'gau'))

# compute the correlation matrices and their kronecker product
cx = sk_corr_mat(pars[['x']], n=n_test)
cy = sk_corr_mat(pars[['y']], n=n_test)
cxy = kronecker(cx, cy)

# sk_var can return these two matrices in a list
cxy_list = sk_var(g_example, pars, sep=TRUE)
max(abs( cxy_list[['y']] - cy ))
max(abs( cxy_list[['x']] - cx ))

# ... or it can compute the full covariance matrix for model pars (default)
var_matrix = sk_var(g_example, pars, sep=FALSE)
var_matrix_compare = (pars$psill*cxy) + diag(pars$eps, n_test^2)
max(abs( var_matrix - var_matrix_compare ))

# extract a subgrid without computing the whole thing
cx_sub = sk_corr_mat(pars[['x']], n=n_test, i=2:4, j=2:4)
cx_sub - cx[2:4, 2:4]

# gres scales distances. Increasing gres causes correlations to decrease
cx_long = sk_corr_mat(pars[['x']], n=n_test, gres=2*g_example$gres)
cx_long &lt; cx

</code></pre>

<hr>
<h2 id='sk_export'>Convert &quot;sk&quot; grid to SpatRaster</h2><span id='topic+sk_export'></span>

<h3>Description</h3>

<p>Convert &quot;sk&quot; grid to SpatRaster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_export(g, template = "terra")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_export_+3A_g">g</code></td>
<td>
<p>any object accepted or returned by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_export_+3A_template">template</code></td>
<td>
<p>character or RasterLayer/SpatRaster to set output type
</p>
<p>Converts a vector or matrix to a SpatRaster or RasterLayer. Multi-layer outputs are
supported for terra but not raster.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a RasterLayer or SpatRaster containing the data from <code>g</code> (or a sub-grid)
</p>


<h3>See Also</h3>

<p>sk
</p>
<p>Other exporting functions: 
<code><a href="#topic+sk_coords">sk_coords</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if( requireNamespace('raster') ) {

# open example file as RasterLayer
r_path = system.file('external/rlogo.grd', package='raster')
r = raster::raster(r_path, band=1)
g = sk(r)

# convert back to RasterLayer and compare
r_from_g = sk_export(g, 'raster')
print(r)
print(r_from_g)

# NOTE: layer name, band number, and various other metadata are lost
all.equal(r_from_g, r)

}

# same with terra
if( requireNamespace('terra') ) {

# convert all layers
r = terra::rast(r_path)
g = sk(r)
r_from_g = sk_export(g)

# NOTE: various metadata are lost
all.equal(r_from_g, r)

}

</code></pre>

<hr>
<h2 id='sk_fit'>Fit a covariance model to an sk grid by maximum likelihood</h2><span id='topic+sk_fit'></span>

<h3>Description</h3>

<p>This uses <code>stats::optim</code> to minimize the log-likelihood function for a grid dataset
<code>g</code> over the space of unknown parameters for the covariance function specified in <code>pars</code>.
If only one parameter is unknown, the function instead uses <code>stats::optimize</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_fit(
  g,
  pars = NULL,
  X = NA,
  iso = TRUE,
  n_max = 1000,
  quiet = FALSE,
  lower = NULL,
  initial = NULL,
  upper = NULL,
  log_scale = TRUE,
  method = "L-BFGS-B",
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_fit_+3A_g">g</code></td>
<td>
<p>an sk grid (or list with entries 'gdim', 'gres', 'gval')</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_pars">pars</code></td>
<td>
<p>covariance parameter list, with <code>NA</code>s indicating parameters to fit</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_x">X</code></td>
<td>
<p>numeric (or NA), matrix, or sk grid of linear predictors, passed to <code>sk_LL</code></p>
</td></tr>
<tr><td><code id="sk_fit_+3A_iso">iso</code></td>
<td>
<p>logical, indicating to constrain the y and x kernel parameters to be the same</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_n_max">n_max</code></td>
<td>
<p>integer, the maximum number of observations allowed</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_quiet">quiet</code></td>
<td>
<p>logical, indicating to suppress console output</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_lower">lower</code></td>
<td>
<p>numeric vector, lower bounds for parameters</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_initial">initial</code></td>
<td>
<p>numeric vector, initial values for parameters</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_upper">upper</code></td>
<td>
<p>numeric vector, upper bounds for parameters</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_log_scale">log_scale</code></td>
<td>
<p>logical, indicating to log-transform parameters for optimization</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_method">method</code></td>
<td>
<p>character, passed to <code>stats::optim</code> (default is 'L-BFGS-B')</p>
</td></tr>
<tr><td><code id="sk_fit_+3A_control">control</code></td>
<td>
<p>list, passed to <code>stats::optim</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>NA</code> entries in <code>pars</code> are treated as unknown parameters and fitted by the
function, whereas non-<code>NA</code> entries are treated as fixed parameters (and not fitted).
If none of the parameters in <code>pars</code> are <code>NA</code>, the function copies everything as initial
values, then treats all parameters as unknown. <code>pars</code> can also be a character vector
defining a pair of correlograms (see <code>?sk_pars</code>) in which case all covariance parameters
are treated as unknown.
</p>
<p>Bounds and initial values are set automatically using <code>sk_bds</code>, unless they are otherwise
specified in arguments <code>lower</code>, <code>initial</code>, <code>upper</code>. These should be vectors containing only
the unknown parameters, <em>ie.</em> they must exclude fixed parameters. Call
<code>sk_update_pars(pars, iso=iso)</code> to get a template with the expected names and order.
</p>
<p>All parameters in the covariance models supported by <code>snapKrig</code> are strictly positive.
Optimization is (by default) done on the parameter log-scale, and users can select a
non-constrained <code>method</code> if they wish (<code>?stats::optim</code>). As the default method 'L-BFGS-B'
is the only one that accepts bounds (<code>lower</code>, <code>initial</code>, <code>upper</code> are otherwise ignored)
<code>method</code> is ignored when <code>log_scale=FALSE</code>.
</p>
<p>Note that the 'gxp' and 'mat' correlograms behave strangely with very small or very large
shape parameters, so for them we recommended 'L-BFGS-B' only.
</p>
<p>When there is only one unknown parameter, the function uses <code>stats::optimize</code> instead of
<code>stats::optim</code>. In this case all entries of <code>control</code> with the exception of 'tol' are
ignored, as are bounds and initial values, and arguments to <code>method</code>.
</p>
<p>As a sanity check <code>n_max</code> sets a maximum for the number of observed grid points. This
is to avoid accidental calls with very large datasets that would cause R to hang or crash.
Set <code>n_max=Inf</code> (with caution) to bypass this check. Similarly the maximum number of
iterations is set to <code>1e3</code> but this can be changed by manually setting 'maxit' in
<code>control</code>.
</p>


<h3>Value</h3>

<p>A parameter list in the form returned by <code>sk_pars</code> containing both fixed and
fitted parameters. The data-frame of bounds and initial values is also included in the
attribute 'bds'
</p>


<h3>See Also</h3>

<p>sk sk_LL sk_nLL stats::optim stats::optimize
</p>
<p>Other parameter managers: 
<code><a href="#topic+sk_bds">sk_bds</a>()</code>,
<code><a href="#topic+sk_kp">sk_kp</a>()</code>,
<code><a href="#topic+sk_pars_make">sk_pars_make</a>()</code>,
<code><a href="#topic+sk_pars_update">sk_pars_update</a>()</code>,
<code><a href="#topic+sk_pars">sk_pars</a>()</code>,
<code><a href="#topic+sk_to_string">sk_to_string</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# define a grid
gdim = c(50, 51)
g_empty = sk(gdim)
pars_src = sk_pars(g_empty)
pars_src = utils::modifyList(pars_src, list(eps=runif(1, 0, 1e1), psill=runif(1, 0, 1e2)))
pars_src[['y']][['kp']] = pars_src[['x']][['kp']] = runif(1, 1, 50)

# generate example data
g_obs = sk_sim(g_empty, pars_src)
sk_plot(g_obs)

# fit (set maxit low to keep check time short)
fit_result = sk_fit(g_obs, pars='gau', control=list(maxit=25), quiet=TRUE)

# compare estimates with true values
rbind(true=sk_pars_update(pars_src), fitted=sk_pars_update(fit_result))

# extract bounds data frame
attr(fit_result, 'bds')

# non-essential examples skipped to stay below 5s exec time on slower machines

# check a sequence of other psill values
pars_out = fit_result
psill_test = ( 2^(seq(5) - 3) ) * pars_out[['psill']]
LL_test = sapply(psill_test, function(s) sk_LL(utils::modifyList(pars_out, list(psill=s)), g_obs) )
plot(psill_test, LL_test)
lines(psill_test, LL_test)
print(data.frame(psill=psill_test, likelihood=LL_test))

# repeat with most data missing
n = prod(gdim)
n_obs = 25
g_obs = sk_sim(g_empty, pars_src)
idx_miss = sample.int(length(g_empty), length(g_empty) - n_obs)
g_miss = g_obs
g_miss[idx_miss] = NA
sk_plot(g_miss)

# fit (set maxit low to keep check time short) and compare
fit_result = sk_fit(g_miss, pars='gau', control=list(maxit=25), quiet=TRUE)
rbind(true=sk_pars_update(pars_src), fitted=sk_pars_update(fit_result))


</code></pre>

<hr>
<h2 id='sk_GLS'>Generalized least squares (GLS) with Kronecker covariances for sk grids</h2><span id='topic+sk_GLS'></span>

<h3>Description</h3>

<p>Computes coefficients b of the linear model E(Z) = Xb using the GLS equation
for sk grid <code>g</code> and covariance model <code>pars</code>. By default the function returns the
linear predictor as an sk object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_GLS(g, pars, X = NA, out = "s", fac_method = "eigen", fac = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_GLS_+3A_g">g</code></td>
<td>
<p>a sk grid object (or list with entries 'gdim', 'gres', 'gval')</p>
</td></tr>
<tr><td><code id="sk_GLS_+3A_pars">pars</code></td>
<td>
<p>list of form returned by <code>sk_pars</code> (with entries 'y', 'x', 'eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_GLS_+3A_x">X</code></td>
<td>
<p>sk grid, matrix or NA, the linear predictors (in columns) excluding intercept</p>
</td></tr>
<tr><td><code id="sk_GLS_+3A_out">out</code></td>
<td>
<p>character, either 'b' (coefficients), 'z' or 's' (Xb), or 'a' (all)</p>
</td></tr>
<tr><td><code id="sk_GLS_+3A_fac_method">fac_method</code></td>
<td>
<p>character, factorization method: 'eigen' (default) or 'chol' (see <code>sk_var</code>)</p>
</td></tr>
<tr><td><code id="sk_GLS_+3A_fac">fac</code></td>
<td>
<p>matrix or list, (optional) pre-computed covariance matrix factorization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the maximum likelihood estimator for the linear trend Xb if we
assume the covariance parameters (in <code>pars</code>) are specified correctly.
</p>
<p>The GLS solution is: b = ( X^T V^-1 X )^-1 X^T V^-1 z,
</p>
<p>where V is the covariance matrix for data vector z (which is <code>g[!is.na(g)]</code>), and X
is a matrix of covariates. V is generated from the covariance model <code>pars</code> with grid
layout <code>g</code>.
</p>
<p>Operations with V^-1 are computed using the factorization <code>fac</code> (see <code>sk_var</code>), or
else as specified in <code>fac_method</code>.
</p>
<p>Argument <code>X</code> can be an sk grid (matching <code>g</code>) with covariates in layers; or it can be
a matrix of covariates. DO NOT include an intercept layer (all 1's) in argument <code>X</code> or
you will get collinearity errors. Matrix <code>X</code> should have independent columns, and its
rows should match the order of <code>g[]</code> or <code>g[!is.na(g)]</code>.
</p>
<p>Use <code>X=NA</code> to specify an intercept-only model; ie to fit a spatially constant mean. This
replaces X in the GLS equation by a vector of 1's.
</p>
<p>By default <code>out='s'</code> returns the linear predictor in an sk grid object. Change this to
<code>'z'</code> to return it as a vector, or <code>'b'</code> to get the GLS coefficients only. Set it to <code>'a'</code>
to get the second two return types (in a list) along with matrix <code>X</code> and its factorization.
</p>
<p>The length of the vector output for <code>out='z'</code> will match the number of rows in <code>X</code>.
This means that if <code>NA</code> grid points are excluded from <code>X</code>, they will not appear in
the output (and vice versa). In the <code>X=NA</code> case, the length is equal to the number of
non-<code>NA</code> points in <code>g</code>. Note that if a point is observed in <code>g</code>, the function will expect
its covariates to be included <code>X</code> (ie <code>X</code> should have no <code>NA</code>s corresponding to non-<code>NA</code>
points in <code>g</code>).
</p>
<p>If <code>g[]</code> is a matrix (a multi-layer grid), the covariates in <code>X</code> are recycled
for each layer. Layers are assumed mutually independent and the GLS equation is evaluated
using the corresponding block-diagonal V. This is equivalent to (but faster than) calling
<code>sk_GLS</code> separately on each layer with the same <code>X</code> and averaging the resulting b estimates.
</p>


<h3>Value</h3>

<p>linear predictor Xb as an sk grid, or numeric vector, or coefficients (see details)
</p>


<h3>See Also</h3>

<p>sk
</p>
<p>Other estimators: 
<code><a href="#topic+sk_cmean">sk_cmean</a>()</code>
</p>
<p>Other variance-related functions: 
<code><a href="#topic+sk_LL">sk_LL</a>()</code>,
<code><a href="#topic+sk_cmean">sk_cmean</a>()</code>,
<code><a href="#topic+sk_nLL">sk_nLL</a>()</code>,
<code><a href="#topic+sk_sim">sk_sim</a>()</code>,
<code><a href="#topic+sk_var">sk_var</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set up example grid and covariance parameters
gdim = c(45, 31)
g_empty = sk(gdim)
n = length(g_empty)
pars = utils::modifyList(sk_pars(g_empty, 'gau'), list(psill=2))

# generate spatial noise
g_noise = sk_sim(g_empty, pars)
plot(g_noise)

# generate more spatial noise to use as covariates
n_betas = 3
betas = stats::rnorm(n_betas, 0, 10)
g_X = sk_sim(g_empty, pars, n_layer=n_betas-1L)
X = g_X[]
X_all = cbind(1, X)
g_lm = g_empty
g_lm[] = as.vector(X_all %*% betas)
plot(g_lm)

# combine with noise to make "observed" data
g_obs = g_lm + g_noise
plot(g_obs)

# By default (out='s') the function returns the linear predictor
g_lm_est = sk_GLS(g_obs, pars, g_X, out='s')
g_lm_est
plot(g_lm_est)

# equivalent, but slightly faster to get vector output
max(abs( sk_GLS(g_obs, pars, g_X, out='z') - g_lm_est[] ))

# repeat with matrix X
max(abs( sk_GLS(g_obs, pars, g_X[], out='z') - g_lm_est[] ))

# return the GLS coefficients
betas_est = sk_GLS(g_obs, pars, g_X, out='b')
print(betas_est)
print(betas)

# compute trend manually as product of betas with X and intercept
lm_est = X_all %*% betas_est
max( abs(lm_est - g_lm_est[] ) )

# de-trend observations by subtracting linear predictor
plot(g_obs - g_lm_est)

# repeat with pre-computed eigen factorization (same result but faster)
fac_eigen = sk_var(g_obs, pars, fac_method='eigen', sep=TRUE)
betas_est_compare = sk_GLS(g_obs, pars, g_X, fac=fac_eigen, out='b')
max( abs( betas_est_compare - betas_est ) )

# missing data example
n_obs = 10
g_miss = g_obs
idx_miss = sort(sample.int(n, n-n_obs))
g_miss[idx_miss] = NA
is_obs = !is.na(g_miss)
plot(g_miss)

# coefficient estimates are still unbiased but less precise
betas_est = sk_GLS(g_miss, pars, g_X, out='b')
print(betas_est)
print(betas)

# set X to NA to estimate the spatially constant trend
b0 = sk_GLS(g_miss, pars, X=NA, out='b')

# matrix X does not need to include unobserved points, but output is filled to match X
X_obs = X[is_obs,]
sk_GLS(g_miss, pars, X=X_obs)
sk_GLS(g_miss, pars, X=X)

# verify GLS results manually
X_all_obs = cbind(1, X_obs)
V = sk_var(g_miss, pars)
z = g_miss[!is.na(g_miss)]
X_trans = t(X_all_obs) %*% solve(V)
betas_compare = solve( X_trans %*% X_all_obs ) %*% X_trans %*% z
betas_compare - betas_est

# multi-layer examples skipped to stay below 5s exec time on slower machines


# generate some extra noise for 10-layer example
g_noise_multi = sk_sim(g_empty, pars, n_layer=10)
g_multi = g_lm + g_noise_multi
betas_complete = sk_GLS(g_multi, pars, g_X, out='b')
print(betas_complete)
print(betas)

# multi-layer input shares covariates matrix X, and output is to a single layer
summary(sk_GLS(g_multi, pars, g_X))
summary(sk_GLS(g_multi, pars, X))
# note that X cannot be missing data where `g` is observed

# repeat with missing data
g_multi[!is_obs,] = NA
g_X_obs = g_X
g_X_obs[!is_obs,] = NA
betas_sparse = sk_GLS(g_multi, pars, X, out='b')
print(betas_sparse)
print(betas)
summary(sk_GLS(g_multi, pars, g_X))
summary(sk_GLS(g_multi, pars, X))
summary(sk_GLS(g_multi, pars, g_X_obs))
summary(sk_GLS(g_multi, pars, X_obs))


</code></pre>

<hr>
<h2 id='sk_kp'>Return named vector of Kronecker covariance parameters initialized to NA</h2><span id='topic+sk_kp'></span>

<h3>Description</h3>

<p>Convenience function for looking up the number of parameters for a given
Kronecker covariance model, and their names. Returns a vector of <code>NA</code>s that
can be used as a placeholder in kernel definition lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_kp(k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_kp_+3A_k">k</code></td>
<td>
<p>character, the kernel name, one of 'exp', 'gau', 'sph', 'gxp', 'mat'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named vector of NAs, a placeholder for kernel parameters
</p>


<h3>See Also</h3>

<p>Other parameter managers: 
<code><a href="#topic+sk_bds">sk_bds</a>()</code>,
<code><a href="#topic+sk_fit">sk_fit</a>()</code>,
<code><a href="#topic+sk_pars_make">sk_pars_make</a>()</code>,
<code><a href="#topic+sk_pars_update">sk_pars_update</a>()</code>,
<code><a href="#topic+sk_pars">sk_pars</a>()</code>,
<code><a href="#topic+sk_to_string">sk_to_string</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# there are only two possible return values
sk_kp('gau')
sk_kp('mat')
</code></pre>

<hr>
<h2 id='sk_LL'>Likelihood of covariance model <code>pars</code> given the data in sk grid <code>g</code></h2><span id='topic+sk_LL'></span>

<h3>Description</h3>

<p>This computes the log-likelihood for the Gaussian process covariance model <code>pars</code>,
given 2-dimensional grid data <code>g</code>, and, optionally, linear trend data in <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_LL(pars, g, X = 0, fac_method = "chol", fac = NULL, quiet = TRUE, out = "l")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_LL_+3A_pars">pars</code></td>
<td>
<p>list of form returned by <code>sk_pars</code> (with entries 'y', 'x', 'eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_LL_+3A_g">g</code></td>
<td>
<p>an sk grid (or list with entries 'gdim', 'gres', 'gval' and/or 'idx_grid')</p>
</td></tr>
<tr><td><code id="sk_LL_+3A_x">X</code></td>
<td>
<p>numeric, vector, matrix, or NA, a fixed mean value, or matrix of linear predictors</p>
</td></tr>
<tr><td><code id="sk_LL_+3A_fac_method">fac_method</code></td>
<td>
<p>character, the factorization to use: 'chol' (default) or 'eigen'</p>
</td></tr>
<tr><td><code id="sk_LL_+3A_fac">fac</code></td>
<td>
<p>matrix or list, (optional) pre-computed covariance factorization</p>
</td></tr>
<tr><td><code id="sk_LL_+3A_quiet">quiet</code></td>
<td>
<p>logical indicating to suppress console output</p>
</td></tr>
<tr><td><code id="sk_LL_+3A_out">out</code></td>
<td>
<p>character, either 'l' (likelihood), 'a' (AIC), 'b' (BIC), or 'more' (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function evaluates:
</p>
<p><code>-log( 2 * pi ) - ( 1/2 ) * ( log_det + quad_form )</code>,
</p>
<p>where <code>log_det</code> is the logarithm of the determinant of covariance matrix V, and
<code>quad_form</code> is z^T V^-1 z, for the observed response vector z, which is constructed
by subtracting the trend specified in <code>X</code> (if any) from the non-NA values in <code>g</code>.
</p>
<p>If the trend spatially uniform and known, it can be supplied in argument <code>X</code> as a
numeric scalar. The default is zero-mean model <code>X=0</code>, which assumes users has
subtracted the trend from <code>g</code> beforehand.
</p>
<p>If the trend is unknown, the function will automatically use GLS to estimate it.
This is profile likelihood on the covariance function parameters (not REML). To
estimate a spatially constant mean, set <code>X=NA</code>. To estimate a spatially variable mean,
supply linear predictors as columns of a matrix argument to <code>X</code> (see <code>sk_GLS</code>). Users
can also pass a multi-layer bk grid <code>X</code> with covariates in layers.
</p>
<p><code>fac_method</code> specifies how to factorize V; either by using the Cholesky factor ('chol')
or eigen-decomposition ('eigen'). A pre-computed factorization <code>fac</code> can be supplied by
first calling <code>sk_var(..., scaled=TRUE)</code> (in which case <code>fac_method</code> is ignored).
</p>
<p>When <code>out='a'</code>, the function instead returns the AIC value and when <code>out='b'</code> it returns
the BIC (see <code>stats::AIC</code>). This adjusts the likelihood for the number of covariance
and trend parameters (and in the case of BIC, the sample size), producing an index that
can be used for model comparison (lower is better).
</p>
<p>When <code>out='more'</code>, the function returns a list containing the log-likelihood and both
information criteria, along with several diagnostics: the number of observations, the
number of parameters, the log-determinant <code>log_det</code>, and the quadratic form <code>quad_form</code>.
</p>


<h3>Value</h3>

<p>numeric, the likelihood of <code>pars</code> given <code>g_obs</code> and <code>X</code>, or list (if <code>more=TRUE</code>)
</p>


<h3>See Also</h3>

<p>sk sk_GLS sk_var stats::AIC
</p>
<p>Other likelihood functions: 
<code><a href="#topic+sk_nLL">sk_nLL</a>()</code>
</p>
<p>Other variance-related functions: 
<code><a href="#topic+sk_GLS">sk_GLS</a>()</code>,
<code><a href="#topic+sk_cmean">sk_cmean</a>()</code>,
<code><a href="#topic+sk_nLL">sk_nLL</a>()</code>,
<code><a href="#topic+sk_sim">sk_sim</a>()</code>,
<code><a href="#topic+sk_var">sk_var</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set up example grid, covariance parameters
gdim = c(25, 12)
n = prod(gdim)
g_empty = g_lm = sk(gdim)
pars = utils::modifyList(sk_pars(g_empty, 'gau'), list(psill=0.7, eps=5e-2))

# generate some coefficients
n_betas = 3
betas = stats::rnorm(n_betas)

# generate covariates and complete data in grid and vector form
g_X = sk_sim(g_empty, pars, n_layer=n_betas-1L)
X = g_X[]
X_all = cbind(1, X)
g_lm = g_empty
g_lm[] = c(X_all %*% betas)

# add some noise
g_all = sk_sim(g_empty, pars) + g_lm
z = g_all[]

# two methods for likelihood
LL_chol = sk_LL(pars, g_all, fac_method='chol')
LL_eigen = sk_LL(pars, g_all, fac_method='eigen')

# compare to working directly with matrix inverse
V = sk_var(g_all, pars, fac_method='none', sep=FALSE)
V_inv = chol2inv(chol(V))
quad_form = as.numeric( t(z) %*% crossprod(V_inv, z) )
log_det = as.numeric( determinant(V, logarithm=TRUE) )[1]
LL_direct = (-1/2) * ( n * log( 2 * pi ) + log_det + quad_form )

# relative errors
abs( LL_direct - LL_chol ) / max(LL_direct, LL_chol)
abs( LL_direct - LL_eigen ) / max(LL_direct, LL_eigen)

# get AIC or BIC directly
sk_LL(pars, g_all, out='a')
sk_LL(pars, g_all, out='b')

# repeat with pre-computed variance factorization
fac_eigen = sk_var(g_all, pars, fac_method='eigen', sep=TRUE)
sk_LL(pars, g_all, fac=fac_eigen) - LL_eigen

# repeat with multi-layer example
n_layer = 10
g_noise_multi = sk_sim(g_empty, pars, n_layer)
g_multi = g_lm + g_noise_multi
LL_chol = sk_LL(pars, g_multi, fac_method='chol')
LL_eigen = sk_LL(pars, g_multi, fac_method='eigen')
LL_direct = sum(sapply(seq(n_layer), function(j) {
 quad_form = as.numeric( t(g_multi[,j]) %*% crossprod(V_inv, g_multi[,j]) )
 (-1/2) * ( n * log( 2 * pi ) + log_det + quad_form )
}))

# relative errors
abs( LL_direct - LL_chol ) / max(LL_direct, LL_chol)
abs( LL_direct - LL_eigen ) / max(LL_direct, LL_eigen)

# repeat with most data missing
is_obs = seq(n) %in% sort(sample.int(n, 50))
n_obs = sum(is_obs)
g_obs = g_empty
z_obs = g_all[is_obs]
g_obs[is_obs] = z_obs

# take subsets of covariates
g_X_obs = g_X
g_X_obs[!is_obs,] = NA
X_obs = X[is_obs,]

LL_chol_obs = sk_LL(pars, g_obs, fac_method='chol')
LL_eigen_obs = sk_LL(pars, g_obs, fac_method='eigen')

# working directly with matrix inverse
V_obs = sk_var(g_obs, pars, fac_method='none')
V_obs_inv = chol2inv(chol(V_obs))
quad_form_obs = as.numeric( t(z_obs) %*% crossprod(V_obs_inv, z_obs) )
log_det_obs = as.numeric( determinant(V_obs, logarithm=TRUE) )[1]
LL_direct_obs = (-1/2) * ( n_obs * log( 2 * pi ) + log_det_obs + quad_form_obs )
abs( LL_direct_obs - LL_chol_obs ) / max(LL_direct_obs, LL_chol_obs)
abs( LL_direct_obs - LL_eigen_obs ) / max(LL_direct_obs, LL_eigen_obs)

# again using a pre-computed variance factorization
fac_chol_obs = sk_var(g_obs, pars, fac_method='chol', scaled=TRUE)
fac_eigen_obs = sk_var(g_obs, pars, fac_method='eigen', scaled=TRUE)
sk_LL(pars, g_obs, fac=fac_chol_obs) - LL_chol_obs
sk_LL(pars, g_obs, fac=fac_eigen_obs) - LL_eigen_obs

# detrend the data by hand, with and without covariates then compute likelihood
g_obs_dtr = g_obs - sk_GLS(g_obs, pars)
g_obs_X_dtr = g_obs - sk_GLS(g_obs, pars, g_X)
LL_dtr = sk_LL(pars, g_obs_dtr, X=0)
LL_X_dtr = sk_LL(pars, g_obs_X_dtr, X=0)

# or pass a covariates grid (or matrix) to de-trend automatically
LL_dtr - sk_LL(pars, g_obs, X=NA)
LL_X_dtr - sk_LL(pars, g_obs, X=g_X)

# note that this introduce new unknown parameter(s), so AIC and BIC increase (worsen)
sk_LL(pars, g_obs, X=NA, out='a') &gt; sk_LL(pars, g_obs_dtr, X=0, out='a')
sk_LL(pars, g_obs, X=g_X, out='a') &gt; sk_LL(pars, g_obs_X_dtr, X=0, out='a')

# X can be the observed subset, or the full grid (as sk grid or as matrix)
sk_LL(pars, g_obs, X=X)
sk_LL(pars, g_obs, X=X_obs)
sk_LL(pars, g_obs, X=g_X)
sk_LL(pars, g_obs, X=g_X_obs)

# equivalent sparse input specification
g_sparse = g_all
g_sparse[] = matrix(g_obs[], ncol=1)
g_sparse = sk(gval=matrix(g_obs[], ncol=1), gdim=gdim)
LL_chol_obs - sk_LL(pars, g_sparse)
LL_eigen_obs - sk_LL(pars, g_sparse)
LL_dtr - sk_LL(pars, g_sparse, X=NA)
LL_X_dtr - sk_LL(pars, g_sparse, X=g_X)

## repeat with complete data

# the easy way to get likelihood
LL_X_chol = sk_LL(pars, g_all, g_X)
LL_X_eigen = sk_LL(pars, g_all, g_X, fac_method='eigen')

# the hard way
V = sk_var(g_all, pars, sep=FALSE)
V_inv = chol2inv(chol(V))
X_tilde_inv = chol2inv(chol( crossprod(crossprod(V_inv, X_all), X_all) ))
betas_gls = X_tilde_inv %*% crossprod(X_all, (V_inv %*% z))
z_gls = z - (X_all %*% betas_gls)
z_gls_trans = crossprod(V_inv, z_gls)
quad_form = as.numeric( t(z_gls) %*% z_gls_trans )
log_det = as.numeric( determinant(V, logarithm=TRUE) )[1]
LL_direct = (-1/2) * ( n * log( 2 * pi ) + log_det + quad_form )
abs( LL_direct - LL_X_chol ) / max(LL_direct, LL_X_chol)
abs( LL_direct - LL_X_eigen ) / max(LL_direct, LL_X_eigen)

# return detailed list of components with out='more'
LL_result = sk_LL(pars, g_all, X=X, out='more')
LL_result[['LL']] - LL_X_chol
LL_result[['quad_form']] - quad_form
LL_result[['log_det']] - log_det
LL_result[['n_obs']] - n

</code></pre>

<hr>
<h2 id='sk_make'>Make a sk grid object</h2><span id='topic+sk_make'></span>

<h3>Description</h3>

<p>This constructs a &quot;sk&quot; object from a named list containing at least the element <code>gdim</code>
or <code>gyx</code>. Users can optionally provide other list elements <code>gres</code>, <code>gval</code>, <code>crs</code>, <code>is_obs</code>,
and <code>idx_grid</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_make(g)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_make_+3A_g">g</code></td>
<td>
<p>list with any of the seven named arguments mentioned above (<code>gdim</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input classes and lengths are checked before returning. <code>gdim</code> and <code>gres</code> are length-2
vectors (with y and x elements) but they can each be specified by a single number, as
shorthand to use the same value for y and x. <code>gval</code> should be a matrix or vector of grid
data, and <code>crs</code> should be a character string (the WKT representation).
</p>


<h3>Value</h3>

<p>a &quot;sk&quot; object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# auto-print reminds users to validate
sk_make(list(gdim=10, gres=0.5))

</code></pre>

<hr>
<h2 id='sk_mat2vec'>Column-vectorization indices</h2><span id='topic+sk_mat2vec'></span>

<h3>Description</h3>

<p>Maps matrix indices i, j to a single vectorized index, k
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_mat2vec(ij, gdim, simplified = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_mat2vec_+3A_ij">ij</code></td>
<td>
<p>n x 2 matrix, the row and column indices</p>
</td></tr>
<tr><td><code id="sk_mat2vec_+3A_gdim">gdim</code></td>
<td>
<p>integer (or vector with first element equal to) the number of rows in the matrix</p>
</td></tr>
<tr><td><code id="sk_mat2vec_+3A_simplified">simplified</code></td>
<td>
<p>if FALSE, the function returns an n x 1 matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Column vectorization (as in <code>base::as.vector</code>) builds a length(mn) vector by stacking
the columns of an m X n matrix, with the leftmost column appearing first in the vector
and the rightmost column last. Matrix element i,j gets mapped to element k = i + m * (j-1)
in the vector. This function returns that index.
</p>
<p><code>ij</code> can be a matrix or a list of length-n vectors 'i' and 'j', or a vector
representing a single point at the given row (i) and column (j) number (in that order).
</p>
<p><code>gdim</code> should either be an integer number of rows in the matrix, or a vector of the form
<code>c(ni, nj)</code> (the return value of <code>dim</code> for example) in which case its first element is used.
</p>


<h3>Value</h3>

<p>integer vector, the vectorized <code>ij</code> indices
</p>


<h3>See Also</h3>

<p>Other indexing functions: 
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_sub_find">sk_sub_find</a>()</code>,
<code><a href="#topic+sk_sub_idx">sk_sub_idx</a>()</code>,
<code><a href="#topic+sk_vec2mat">sk_vec2mat</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># define matrix dimensions and look up a specific index
gdim = c(4, 5)
ij = c(i=3, j=2)
sk_mat2vec(ij, gdim)

# display all matrix indices in column-vectorized order
gyx = expand.grid(i=seq(gdim[1]), j=seq(gdim[2]))
result = sk_mat2vec(gyx, gdim)
data.frame(k=result, gyx)

</code></pre>

<hr>
<h2 id='sk_nLL'>Negative log-likelihood for parameter vector <code>p</code></h2><span id='topic+sk_nLL'></span>

<h3>Description</h3>

<p>Returns the negative log-likelihood of covariance model <code>pars_fix</code>, given the observations
in data grid <code>g_obs</code>. Parameter values are copied from the first argument, vector <code>p</code>, so
that the function can be passed to numerical optimizers (etc).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_nLL(p, g_obs, pars_fix, X = 0, iso = FALSE, quiet = TRUE, log_scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_nLL_+3A_p">p</code></td>
<td>
<p>numeric vector of covariance parameters accepted by <code>sk_pars_update</code></p>
</td></tr>
<tr><td><code id="sk_nLL_+3A_g_obs">g_obs</code></td>
<td>
<p>sk object or list with entries 'gdim', 'gres', 'gval'</p>
</td></tr>
<tr><td><code id="sk_nLL_+3A_pars_fix">pars_fix</code></td>
<td>
<p>list of form returned by <code>sk_pars</code> (with entries 'y', 'x', 'eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_nLL_+3A_x">X</code></td>
<td>
<p>numeric, vector, matrix, or NA, the mean or its linear predictors, passed to <code>sk_LL</code></p>
</td></tr>
<tr><td><code id="sk_nLL_+3A_iso">iso</code></td>
<td>
<p>logical, indicates to use identical kernels for x and y (<code>pars$x</code> is ignored)</p>
</td></tr>
<tr><td><code id="sk_nLL_+3A_quiet">quiet</code></td>
<td>
<p>logical indicating to suppress console output</p>
</td></tr>
<tr><td><code id="sk_nLL_+3A_log_scale">log_scale</code></td>
<td>
<p>logical, indicates that <code>pars_fix</code> contains log-parameter values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper for <code>sk_LL</code> (times -1) that allows parameters to be passed as a numeric
vector instead of a list. Parameters in <code>p</code> are copied to <code>pars_fix</code> and passed to the
likelihood computer.
</p>
<p><code>p</code> is the vector of covariance parameters to test. Names in <code>p</code> are ignored; Its length
and order should correspond with the pattern of NAs in <code>pars_fix</code>. Users should check that
the desired parameter list is being constructed correctly by testing with:
<code>sk_pars_update(pars_fix, p, iso=iso, na_omit=TRUE)</code>.
</p>


<h3>Value</h3>

<p>numeric, the negative log-likelihood of <code>p</code> given data <code>g_obs</code>
</p>


<h3>See Also</h3>

<p>sk sk_GLS sk_var sk_pars_update
</p>
<p>Other likelihood functions: 
<code><a href="#topic+sk_LL">sk_LL</a>()</code>
</p>
<p>Other variance-related functions: 
<code><a href="#topic+sk_GLS">sk_GLS</a>()</code>,
<code><a href="#topic+sk_LL">sk_LL</a>()</code>,
<code><a href="#topic+sk_cmean">sk_cmean</a>()</code>,
<code><a href="#topic+sk_sim">sk_sim</a>()</code>,
<code><a href="#topic+sk_var">sk_var</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set up example grid and data
g = sk(gdim=10, gval=stats::rnorm(10^2))

# get some default parameters and vectorize them
pars = sk_pars(g, 'gau')
p = sk_pars_update(pars)
sk_nLL(p, g, pars)

# change a parameter in the numeric vector and re-evaluate
p_compare = p
p_compare[1] = 2 * p_compare[1]
sk_nLL(p_compare, g, pars)

# repeat by calling sk_LL directly with modified parameters list
pars_compare = pars
pars_compare[['eps']] = 2 * pars_compare[['eps']]
-sk_LL(pars_compare, g)

# set up a subset of parameters to replace - eg when fitting those parameters
pars_fix = pars
pars_fix[['eps']] = NA
pars_fix[['y']][['kp']] = NA

# names in p_fit are for illustration only (only the order matters)
p_fit = c(eps=1, y.rho=1)

# replace NA parameter values in pars_fix to get completed parameters list
sk_pars_update(pars_fix, p_fit, na_omit=TRUE)

# make the replacement and evaluate likelihood in one call
sk_nLL(p_fit, g, pars_fix)

# equivalently:
pars_fit = pars
pars_fit[['eps']] = p_fit[1]
pars_fit[['y']][['kp']] = p_fit[2]
-sk_LL(pars_fit, g)

</code></pre>

<hr>
<h2 id='sk_pars'>Initialize Kronecker covariance function parameters for a sk grid</h2><span id='topic+sk_pars'></span>

<h3>Description</h3>

<p>Returns a parameter list defining the Kronecker covariance model for <code>g</code>, with
default initial values assigned to parameters based on the grid dimensions and sample
variance of observed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_pars(g, pars = "gau", fill = "initial")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_pars_+3A_g">g</code></td>
<td>
<p>list, a sk grid list (or any other object accepted by <code>sk</code>)</p>
</td></tr>
<tr><td><code id="sk_pars_+3A_pars">pars</code></td>
<td>
<p>character or list defining kernels accepted by <code>sk_pars_make</code></p>
</td></tr>
<tr><td><code id="sk_pars_+3A_fill">fill</code></td>
<td>
<p>character, either 'initial', 'lower' or 'upper'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Swap <code>fill='initial'</code> with 'lower' and 'upper' to get default lower and upper bounds.
</p>


<h3>Value</h3>

<p>a list defining the Kronecker covariance parameters
</p>


<h3>See Also</h3>

<p>sk sk_corr
</p>
<p>Other parameter managers: 
<code><a href="#topic+sk_bds">sk_bds</a>()</code>,
<code><a href="#topic+sk_fit">sk_fit</a>()</code>,
<code><a href="#topic+sk_kp">sk_kp</a>()</code>,
<code><a href="#topic+sk_pars_make">sk_pars_make</a>()</code>,
<code><a href="#topic+sk_pars_update">sk_pars_update</a>()</code>,
<code><a href="#topic+sk_to_string">sk_to_string</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sk_pars(g=10)
sk_pars(c(10,15))
sk_pars(c(10,15), 'mat')
sk_pars(c(10,15), 'mat', 'upper')
</code></pre>

<hr>
<h2 id='sk_pars_make'>Build a parameter list defining the 2d spatial Kronecker covariance model</h2><span id='topic+sk_pars_make'></span>

<h3>Description</h3>

<p>Constructs a nested list naming the expected covariance parameters for the supplied
correlation function names in <code>pars</code>. If <code>pars</code> is already such a list, the function
checks that parameter names and lengths are valid and returns a copy containing only the
expected parameters, properly named, with <code>NA</code>s assigned to any missing parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_pars_make(pars = "gau")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_pars_make_+3A_pars">pars</code></td>
<td>
<p>character vector of kernel name(s) or list of parameters (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pars</code> should be a correlation function name accepted by <code>sk_kp</code> ('exp', 'gau','sph', or
'gex', 'mat'), or a vector or list of two of them in the order y, x.
</p>


<h3>Value</h3>

<p>parameter list containing sub-lists 'y', 'x', and scalars 'psill' and 'eps'
</p>


<h3>See Also</h3>

<p>sk_corr
</p>
<p>Other parameter managers: 
<code><a href="#topic+sk_bds">sk_bds</a>()</code>,
<code><a href="#topic+sk_fit">sk_fit</a>()</code>,
<code><a href="#topic+sk_kp">sk_kp</a>()</code>,
<code><a href="#topic+sk_pars_update">sk_pars_update</a>()</code>,
<code><a href="#topic+sk_pars">sk_pars</a>()</code>,
<code><a href="#topic+sk_to_string">sk_to_string</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># pass a correlation function name to get 2d version with NAs for all parameters
sk_pars_make('mat')

# pass a vector or list of correlation function names in order y, x (or else specify)
sk_pars_make(c('gau', 'mat'))
sk_pars_make(list(x='gau', y='mat'))

# if the the x definition is missing it is copied from y, and vice versa
sk_pars_make(list(k='exp', kp=c(rho=1)))

# when unnamed, kernel range and shape parameters are assigned expected names
sk_pars_make(list(psill=1, x=list(k='mat', kp=c(1,2))))

# incorrectly named parameters raise errors

sk_pars_make(list(psill=1, x=list(k='exp', kp=c(foo=1))))


# complete parameter definition lists are returned unchanged
k_list = list(k='exp', kp=c(rho=1))
pars = list(y=k_list, x=k_list, eps=0, psill=1)
identical(pars, sk_pars_make(pars))

</code></pre>

<hr>
<h2 id='sk_pars_update'>Convert covariance parameter list to/from vectorized form</h2><span id='topic+sk_pars_update'></span>

<h3>Description</h3>

<p>Converts parameter list <code>pars</code> to vector <code>p</code> and back again. A convenience function for
numerical optimization where objective functions accept numeric vectors only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_pars_update(
  pars,
  p = NULL,
  iso = FALSE,
  eps_scaled = FALSE,
  na_omit = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_pars_update_+3A_pars">pars</code></td>
<td>
<p>list of kernel parameters (in form understood by <code>sk_pars_make</code>)</p>
</td></tr>
<tr><td><code id="sk_pars_update_+3A_p">p</code></td>
<td>
<p>numeric vector (optional) kernel parameters to update in <code>pars</code></p>
</td></tr>
<tr><td><code id="sk_pars_update_+3A_iso">iso</code></td>
<td>
<p>logical, indicating to treat y and x kernel parameters as equal (see details)</p>
</td></tr>
<tr><td><code id="sk_pars_update_+3A_eps_scaled">eps_scaled</code></td>
<td>
<p>logical, indicates to drop partial sill from input/output</p>
</td></tr>
<tr><td><code id="sk_pars_update_+3A_na_omit">na_omit</code></td>
<td>
<p>logical, toggles handling of <code>NA</code>s (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>p</code> is not supplied, the function un-lists the numeric values of <code>pars</code>, returning
them as a vector. When <code>na_omit=TRUE</code>, only the non-NA values are returned; and when
<code>iso=TRUE</code> the x kernel parameters are also omitted from the output vector.
</p>
<p>When <code>p</code> is supplied, the function copies its values to the corresponding entries in
<code>pars</code>, returning the result as a list. In this case, when <code>na_omit=TRUE</code>, only the
NA entries of <code>pars</code> are filled; and when <code>iso=TRUE</code>, parameters for the y kernel
are recycled to fill entries for the x kernel.
</p>
<p>The order returned (and expected in <code>p</code>, if supplied) is:
</p>
<p>'eps', 'psill', 'y.rho', ('y.kap'), 'x.rho', ('x.kap')
</p>
<p>where 'y.kap' and 'x.kap' are omitted in kernels without shape parameters (see
<code>sk_corr</code>). Only the order matters here, as names are ignored in <code>p</code>.
</p>
<p>With <code>na_omit=FALSE</code>, <code>p</code> should have length 3-6, the same as the vector returned by
<code>sk_pars_update(pars)</code>; NAs in <code>p</code> are copied over in this case, effectively inverting
the vectorization.
</p>
<p>With <code>na_omit=TRUE</code>, values in <code>p</code> are copied only to the NA entries of <code>pars</code>; ie the
length of <code>p</code> should equal the number of NA entries in <code>pars</code> (less any redundant x
kernel parameters when <code>iso=TRUE</code>). Note that this does NOT invert the vectorization
<code>p=sk_pars_update(pars, na_omit=TRUE)</code>, which returns non-NA entries of <code>pars</code>.
</p>


<h3>Value</h3>

<p>numeric vector of parameters, or, if <code>p</code> is supplied, the updated <code>pars</code> list
</p>


<h3>See Also</h3>

<p>Other parameter managers: 
<code><a href="#topic+sk_bds">sk_bds</a>()</code>,
<code><a href="#topic+sk_fit">sk_fit</a>()</code>,
<code><a href="#topic+sk_kp">sk_kp</a>()</code>,
<code><a href="#topic+sk_pars_make">sk_pars_make</a>()</code>,
<code><a href="#topic+sk_pars">sk_pars</a>()</code>,
<code><a href="#topic+sk_to_string">sk_to_string</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># initialize a parameter list and pass to sk_pars_update
k = c('gau', 'mat')
pars_empty = sk_pars_make(k)
sk_pars_update(pars_empty)

# pars can be a character vector passed directly to sk_pars_update
sk_pars_update(k)

# single kernel definitions are duplicated
sk_pars_update('mat')

# example parameter vector to illustrate ordering
p_update = seq(5)

# (inverse) pass a modified vector back to the function to update pars
pars_filled = sk_pars_update(pars_empty, p_update)
print(pars_filled)

# p_update is unchanged by round trip
sk_pars_update(pars_filled)

# NAs in pars can be filtered out with na_omit=TRUE
pars_filled$eps = NA
pars_filled$x$kp[1] = NA
sk_pars_update(pars_filled)
sk_pars_update(pars_filled, na_omit=TRUE)

# when updating parameters, NAs in pars identify parameters to receive the new values
p_update = abs(stats::rnorm(2))
sk_pars_update(pars_filled, p_update, na_omit=TRUE)

# when na_omit=FALSE, all parameters in pars are updated
p_update = stats::rnorm(5)
sk_pars_update(pars_filled, p_update)

# iso=TRUE is for when x kernel parameters are assigned values from the y kernel
pars_empty = sk_pars_make('mat')
p_update = seq(length(sk_pars_update(pars_empty, iso=TRUE)))
pars_filled = sk_pars_update(pars_empty, p_update, iso=TRUE)
print(pars_filled)

# notice NA shape parameter in x ignored while NA in eps is copied
pars_filled$eps = NA
pars_filled$x$kp[2] = NA
sk_pars_update(pars_filled, iso=TRUE)

# update calls with iso=TRUE should omit the x kernel parameters (p is shorter)
sk_pars_update(pars_filled, seq(4), iso=TRUE)

# if eps_scaled=TRUE, psill is ignored (useful for when eps is scaled by psill)
sk_pars_update(pars_filled)
sk_pars_update(pars_filled, eps_scaled=TRUE)

# notice value of psill not updated
sk_pars_update(pars_filled, -seq(5), eps_scaled=TRUE)

# compare/combine with other modes
pars_filled$y$kp[2] = NA
sk_pars_update(pars_filled)
sk_pars_update(pars_filled, -seq(2), iso=TRUE, na_omit=TRUE)
sk_pars_update(pars_filled, -seq(4), iso=TRUE)
sk_pars_update(pars_filled, -seq(3), iso=TRUE, eps_scaled=TRUE)
sk_pars_update(pars_filled, -seq(3), na_omit=TRUE)

</code></pre>

<hr>
<h2 id='sk_plot'>Plot grid data</h2><span id='topic+sk_plot'></span>

<h3>Description</h3>

<p>Plots a matrix or raster as a heatmap with an optional color bar legend. This is a wrapper
for <code>graphics::image</code> similar to <code>terra::plot</code> but with tighter margins to increase the
image area on screen; and with a different layout for heat-maps of matrices, which are
plotted with i and j axes (row and column numbers) replacing y and x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_plot(g, gdim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_plot_+3A_g">g</code></td>
<td>
<p>vector, matrix, or any object understood by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_plot_+3A_gdim">gdim</code></td>
<td>
<p>numeric vector, (optional) grid dimensions of the data when <code>g</code> is a vector</p>
</td></tr>
<tr><td><code id="sk_plot_+3A_...">...</code></td>
<td>
<p>plotting parameters (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is called automatically when a &quot;sk&quot; object is passed to <code>plot</code>.
</p>
<p><code>g</code> can be a vector, in which case <code>gdim</code> supplies the y, x dimensions (ie number
of rows, number of columns), in that order. <code>g</code> can also can be a matrix, raster or any
other object understood by <code>sk</code> (in which case <code>gdim</code> can be omitted).
</p>
<p>The data in <code>g</code> can be of numeric, integer, logical, or factor class. The numeric class is
plotted with a continuous color bar legend, while the others get a categorical legend.
</p>
<p>Category names (ie tick labels) for the legend can be supplied in argument <code>breaks</code>, with
one character string for each unique non-NA value in <code>g</code>, as integer, in ascending order.
If the data are continuous, <code>breaks</code> can either be the desired number of bins for coloring,
or a vector of break points delineating bins (passed to <code>graphics::image</code>). Note that a set
of <code>n</code> bins has <code>n+1</code> break points.
</p>
<p><code>pal</code> should be one of the palette names returned by <code>grDevices::hcl.pals</code>, or else a
vector of color names with length one fewer than the number of break points.
</p>
<p>If the data are all <code>NA</code>, the function omits the heatmap and legend, and draws grid lines
instead. <code>col_grid</code> can be specified to enable/disable grid lines more generally. These
lines can sometimes appear misaligned due to anti-aliasing. If this is a problem, try
switching to a different graphics device back-end (eg. in Windows Rstudio, try changing from
the default to Cairo with <code>options(RStudioGD.backend = 'cairo')</code>).
</p>
<p>The function sets the graphical parameters 'oma' (to <code>c(0,0,0,0)</code>) and 'mar' (to values
between 1.1 and 5.1, depending on whether titles, axes, and legend are plotted), then calls
<code>graphics::image</code>, which sets other graphical parameters such as 'usr'. By default all
graphical parameters are reset to their original values at the end of the function call.
<code>reset=FALSE</code> prevents this, so that additional elements can be added to the plot later
(such as by calling <code>sf::st_plot(.., add=TRUE)</code> or <code>graphics:lines</code>).
</p>


<h3>Value</h3>

<p>The function returns a vector of suggested plot height and width values in units of
inches which minimize the unused margin space. For example to save a trim version of your
plot as png, call <code>sk_plot</code> first to get the suggested height and width, say <code>y</code> and <code>x</code>,
then pass the result to <code>png(filename, height=m*y, width=m*x, pointsize=m*12, ...)</code>,
where <code>m</code> is any positive scaling factor.
</p>


<h3>Plotting parameters</h3>

<p>The following style parameters are optional:
</p>

<dl>
<dt>adj, leg_just</dt><dd><p>numeric in [0,1]: respectively, the horizontal justification
of the title and vertical justification of the color bar legend (default 0.5 for both) </p>
</dd>
<dt>asp</dt><dd><p> numeric or NA: the aspect ratio parameter passed to graphics::image (default 1) </p>
</dd>
<dt>axes, leg</dt><dd><p>logical: respectively indicates to draw axes (y and x, or i and j),
the color bar legend (default TRUE)</p>
</dd>
<dt>axes_w, leg_w, lab_w, main_w, oma_w</dt><dd><p>numeric: respectively, the number of lines of
margin to reserve for axes (default 2), legend (default 5), axis labels (default 2), main
title (default 2), and outer white-space (default 0.5)</p>
</dd>
<dt>breaks</dt><dd><p>numeric (vector) or character vector: the color break points (see details)</p>
</dd>
<dt>cex, cex.main, cex.x, cex.y, cex.z</dt><dd><p>numeric: controls the size of text elements in
the plot (default 1), those for title, x/y labels and ticks, and legend title and ticks
all inherit the value assigned to cex (unless otherwise specified).</p>
</dd>
<dt>col_box, col_grid</dt><dd><p>character: respectively, the colors to use for drawing a box
around the image border and for drawing grid cell boundaries (NA to omit)</p>
</dd>
<dt>col_invert, col_rev</dt><dd><p>logical: respectively, inverts (default FALSE), and reverses
the color scale (default TRUE</p>
</dd>
<dt>ij</dt><dd><p>logical: enables/disables matrix style plot with j axis annotations on top
(default TRUE for vector and matrix input, otherwise FALSE)</p>
</dd>
<dt>layer</dt><dd><p>integer: the layer (column) to plot (default 1)</p>
</dd>
<dt>lwd_axis, lwd_ticks, lwd_grid</dt><dd><p>numeric: respectively, line widths for the axis
lines, ticks, and grid lines (default 1)</p>
</dd>
<dt>main, zlab, ylab, xlab</dt><dd><p>character: respectively, a title to put on top in bold,
a legend title to put over the color bar, and axis titles for dimensions y and x.
Setting to &rdquo; omits both the label and its margin space</p>
</dd>
<dt>minimal</dt><dd><p>logical: produces a stripped down plot showing only the grid data. This
omits all annotation (unless otherwise specified by <code>axes</code> and/or <code>leg</code>) and removes
all margin space (unless otherwise specified by <code>leg_w</code> and/or <code>mar_w</code>)</p>
</dd>
<dt>pal</dt><dd><p>character (vector): one of <code>grDevices::hcl.pals()</code> (default 'Spectral')</p>
</dd>
<dt>pxmax</dt><dd><p>integer: the maximum number of pixels to draw along each dimension
(default 2000). If either x or y dimension exceeds this limit, the grid is up-scaled
before plotting</p>
</dd>
<dt>reset</dt><dd><p>logical: indicates to restore original graphical parameters after plot is
finished (default TRUE)</p>
</dd>
<dt>zlim</dt><dd><p>numeric vector: range in the data to plot (ignored for discrete plots)</p>
</dd>
<dt>x_ontop</dt><dd><p>logical: toggles the placement of the horizontal dimension axis on
top vs bottom </p>
</dd>
</dl>



<h3>See Also</h3>

<p>sk
</p>
<p>Other plotting functions: 
<code><a href="#topic+sk_plot_pars">sk_plot_pars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example grid
gdim = c(50, 100)
n = prod(gdim)
g = sk(gdim)

# plot the grid layout as raster then as matrix
plot(g)
plot(g, ij=TRUE)

# example data: cosine of squared distance to top left corner
z = apply(expand.grid(g$gyx), 1, \(z) cos( 2*sum(z^2) ) )
g_example = utils::modifyList(g, list(gval=z))
plot(g_example)

# plot as matrix (changes default palette)
plot(g_example, ij=TRUE)

# alignment
plot(g_example, ij=TRUE, main='Centered title and legend by default')
plot(g_example, ij=TRUE, main='adj: left-right justification of title', adj=0)
plot(g_example, ij=TRUE, main='leg_just: top-bottom justification of color bar', leg_just=0)

# set the palette - see hcl.pals() for valid names
pal = 'Zissou 1'
plot(g_example, pal=pal, main=pal)
plot(g_example, pal=pal, main=pal, col_invert=TRUE)
plot(g_example, pal=pal, main=pal, col_invert=TRUE, col_rev=TRUE)

# example data: cosine of distance to top left corner
g[] = apply(expand.grid(g$gyx), 1, \(z) cos( sqrt(sum(z^2))/50 ) )
plot(g)

# specify the layer for multi-layer objects (default is first layer)
g_multi = sk(list(gdim=gdim, gval=cbind(z, z^2)))
plot(g_multi)
plot(g_multi, layer=2)

# reduce number of color breaks or specify a factor for discrete value plots
plot(g, breaks=50)
plot(g, breaks=3)
g[] = cut(g[], breaks=3, dig.lab=1)
plot(g)

# pass color bar labels for discrete plots in breaks (in order low to high)
plot(g, breaks=c('a', 'b', 'c'), zlab='group')

# select some "observed" points and make a covariance matrix
idx_obs = match(seq(n), sort(sample.int(prod(gdim), 1e2)))
g[] = idx_obs
plot(g)
v = sk_var(g)

# matrix display mode is automatic when first argument is a matrix or vector
sk_plot(v, zlab=expression(V[ij]))
sk_plot(c(v), dim(v), zlab=expression(V[ij]))

# or pass the matrix to `sk` first to turn it into a sk grid object
g_v = sk(v)
plot(g_v, zlab=expression(V[ij]))

# minimal versions
plot(g_v, minimal=TRUE)
plot(g_v, minimal=TRUE, leg=TRUE)
plot(g_v, minimal=TRUE, col_grid='white', leg=TRUE)

# logical matrix plots are gray-scale by default
plot(g_v &gt; 1e-2, main='logical matrix')

# logical, integer and factor class matrices get a discrete color-bar
interval = 1e-2 # try also 1e-3 to see behaviour with large number of bins
v_discrete = cut(v, seq(0, ceiling(max(v)), by=interval), dig.lab=2)
g_v[] = cut(v, seq(0, ceiling(max(v)), by=interval), dig.lab=2)
plot(g_v)

# labels are preserved for character matrices
z_char = rep(c('foo', 'bar'), n/2)
z_char[sample.int(n, n/2)] = NA
sk_plot(z_char, gdim)

# multi-pane plot
g_sim = sk_sim(c(100, 50), n_layer=3)
split.screen(c(1,3))
screen(1)
plot(g_sim, main='layer 1', layer=1, minimal=TRUE, col_box='black')
screen(2)
plot(g_sim, main='layer 2', layer=2, minimal=TRUE, col_box='black')
screen(3)
plot(g_sim, main='layer 3', layer=3, minimal=TRUE, col_box='black')

</code></pre>

<hr>
<h2 id='sk_plot_pars'>Plot the covariance structure of a snapKrig model</h2><span id='topic+sk_plot_pars'></span>

<h3>Description</h3>

<p>Visualization of the footprint of a covariance kernel as a heatmap of approximate
size <code>dim(g)</code>, where each grid cell is colored according to its covariance with
the central grid point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_plot_pars(pars, g = NULL, simple = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_plot_pars_+3A_pars">pars</code></td>
<td>
<p>list of the form returned by <code>sk_pars</code> with entries 'y', 'x', ('eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_plot_pars_+3A_g">g</code></td>
<td>
<p>any object understood by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_plot_pars_+3A_simple">simple</code></td>
<td>
<p>logical, if FALSE the function adds some annotation</p>
</td></tr>
<tr><td><code id="sk_plot_pars_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>sk_plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>g</code> is not supplied, the function sets a default with dimensions 100 x 100.
A default resolution is computed such that the maximum nugget-free covariance along
the outer edge of the plot is 5% of <code>pars$psill</code>.
</p>
<p>When <code>simple=FALSE</code> (the default), covariance parameters are printed in the
title and axis labels with values rounded to 3 decimal places. This can be
customized by passing arguments 'main', 'ylab', 'xlab' (and any others
accepted <code>sk_plot</code> apart from <code>gdim</code>).
</p>


<h3>Value</h3>

<p>the same as <code>sk_plot</code>
</p>


<h3>See Also</h3>

<p>sk sk_pars
</p>
<p>Other plotting functions: 
<code><a href="#topic+sk_plot">sk_plot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdim = c(100, 100)
g = sk(gdim)
pars = sk_pars(g, 'mat')

# plot with default grid
sk_plot_pars(pars)

# plot with a predefined grid
sk_plot_pars(pars, g)

# zoom in/out by passing a grid object with suitably modified resolution
gres = g[['gres']]
sk_plot_pars(pars, sk(gdim=gdim, gres=0.5*gres))
sk_plot_pars(pars, sk(gdim=gdim, gres=2*gres))

# change plot style settings (all parameters of sk_plot accepted)
sk_plot_pars(pars, simple=TRUE)
sk_plot_pars(pars, minimal=TRUE)

</code></pre>

<hr>
<h2 id='sk_plot_semi'>Plot a semi-variogram</h2><span id='topic+sk_plot_semi'></span>

<h3>Description</h3>

<p>Plots a sample semi-variogram using the point pair difference data in <code>vg</code>.
Binned summary statistics are drawn as circles with size scaled to the sample sizes.
A covariance model (<code>pars</code>) is optionally drawn over the sample data as a ribbon plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_plot_semi(vg, pars = NULL, add = FALSE, fun = "classical", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_plot_semi_+3A_vg">vg</code></td>
<td>
<p>data frame of sample absolute differences, with columns 'dabs', 'd' (and 'bin')</p>
</td></tr>
<tr><td><code id="sk_plot_semi_+3A_pars">pars</code></td>
<td>
<p>list of the form returned by <code>sk_pars</code> with entries 'y', 'x', 'eps', 'psill'</p>
</td></tr>
<tr><td><code id="sk_plot_semi_+3A_add">add</code></td>
<td>
<p>logical, indicates to draw on an existing plot rather than create a new one</p>
</td></tr>
<tr><td><code id="sk_plot_semi_+3A_fun">fun</code></td>
<td>
<p>character or function, the aggregation function (see details)</p>
</td></tr>
<tr><td><code id="sk_plot_semi_+3A_...">...</code></td>
<td>
<p>further plotting parameters (see below)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>vg</code> is a data frame, it should contain absolute differences (numeric 'dabs'),
inter-point distances (numeric 'd'), and, optionally, an assignment into distance bins
(integer 'bin') for a sample of point pairs. If 'bin' is missing, the function calls
<code>sk_add_bins</code> to assign them automatically.
</p>
<p>Function <code>fun</code> is the statistic to use for estimating the variogram (ie twice the
semi-variogram) from the distance-binned absolute differences in <code>vg</code>. If <code>fun</code> is a
function, it must accept sub-vectors of the numeric <code>vg$dabs</code> as its only argument,
returning a non-negative numeric scalar. <code>fun</code> can also be set to one of the names
'root_median', 'root_mean' (the default), or 'classical', as shorthand for the robust
fourth-root-based methods in section 2.4 of Cressie (1993), or the classical mean of
squares method of Matheron.
</p>
<p>Optional list <code>pars</code> defines a theoretical semi-variogram to draw over the sample data.
When <code>add=TRUE</code>, the function overlays it on an existing plot (without changing the
legend, plot limits etc). Anisotropic models, which may assume a range of semi-variances
for any given distance, are drawn as a ribbon plot.
</p>
<p><code>add=TRUE</code> can only be used in combination with an earlier call to <code>sk_plot_semi</code>
where <code>reset=FALSE</code> (which allows the function to change R's graphical parameters)
</p>
<p><code>vg</code> can be a grid object (anything understood by <code>sk</code>) rather than a
variogram data frame. When <code>add=FALSE</code>, the function uses it to set the distance limits
for an initial empty plot (the model semi-variance is then drawn if <code>pars</code> is supplied).
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>Plotting parameters</h3>

<p>The following style parameters are optional:
</p>

<dl>
<dt>alpha_bin, alpha_model, alpha_bin_b, alpha_model_b</dt><dd><p>numeric in [0,1]: respectively,
the transparency of the fill color for circles and ribbons (default 0.3), and their borders
(default 0.5 )</p>
</dd>
<dt>bty</dt><dd><p>character: plot frame border type, passed to base::plot (default 'n' for no border)</p>
</dd>
<dt>col_bin, col_model</dt><dd><p>character: respectively, the color to use for circles (default
'black') and ribbons (default 'blue')</p>
</dd>
<dt>cex_bin</dt><dd><p>numeric &gt; 0: scaling factor for circles (default 1.5)</p>
</dd>
<dt>d_max</dt><dd><p>numeric &gt; 0: x (distance) limit for plotting in input units</p>
</dd>
<dt>leg</dt><dd><p>logical: adds a sample bin legend</p>
</dd>
<dt>leg_main</dt><dd><p>character: title for the sample bin legend (default 'model')</p>
</dd>
<dt>lwd</dt><dd><p>numeric: line width for the model semi-variance</p>
</dd>
<dt>main</dt><dd><p>character: a title</p>
</dd>
<dt>n_bin, n_test</dt><dd><p>integer: respectively, the number of distance bins for the sample
(optional if <code>vg</code> has a 'bin' column, and ignored if <code>vg</code> is a grid object), and the
number of distances at which to evaluate the semi-variogram for model <code>pars</code> (default 5e3,
ignored if <code>pars</code> not supplied)</p>
</dd>
<dt>reset</dt><dd><p>logical: indicates to reset graphical parameters to their original values
when finished (default TRUE)</p>
</dd>
<dt>xlab, ylab</dt><dd><p>character: titles for the y and x axes. The default for y is
'semi-variance (gamma)', and for x 'distance'</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# make example grid and reference covariance model
gdim = c(10, 15)
g_empty = sk(gdim)
pars = sk_pars(g_empty, 'mat')

# plot a semivariance model
sk_plot_semi(g_empty)
sk_plot_semi(g_empty, pars)

# change annotations, sharpen ribbon border
sk_plot_semi(g_empty, pars, main='title', xlab='x', ylab='y')
sk_plot_semi(g_empty, pars, alpha_model_b=1, main='example title', xlab='x', ylab='y')

# generate sample data and sample semivariogram
g_obs = sk_sim(g_empty, pars)
vg = sk_sample_vg(g_obs)
sk_plot_semi(vg)

# different aggregation methods produce variety of results
sk_plot_semi(vg, fun='root_median')
sk_plot_semi(vg, fun='root_mean')
sk_plot_semi(vg, fun='classical') # default
sk_plot_semi(vg, fun=function(x) mean(x^2)) # same as classical

# plot again with reference model and adjust distance limits, number of bins
sk_plot_semi(vg, pars)
sk_plot_semi(vg, pars, d_max=10)
sk_plot_semi(vg, pars, d_max=10, n_bin=1e2)

# add dashed line for half sample variance (this tends to underestimate the sill)
sk_plot_semi(vg, pars)
sample_var = var(g_obs[['gval']], na.rm=TRUE)
abline(h=sample_var/2, lty='dashed')

# initial call with reset=FALSE, then use add=TRUE to overlay the same model with a green fill
sk_plot_semi(vg, pars, lwd=2, reset=FALSE)
sk_plot_semi(vg, pars, add=TRUE, col_model='green', alpha_model_b=0)

# overlay several models with varying nugget effect
pars_vary = pars
for(i in seq(3))
{
  pars_vary$eps = 0.8 * pars_vary$eps
  sk_plot_semi(vg, pars_vary, add=TRUE, alpha_model_b=0)
}
dev.off()

</code></pre>

<hr>
<h2 id='sk_rescale'>Up or down-scale a sk grid by an integer factor</h2><span id='topic+sk_rescale'></span>

<h3>Description</h3>

<p>Changes the resolution of a sk grid by a factor of <code>up</code> or <code>down</code>. For down-scaling, this
introduces <code>NA</code>s at unobserved grid points (and does no interpolation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_rescale(g, up = NULL, down = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_rescale_+3A_g">g</code></td>
<td>
<p>a sk grid or any grid object accepted by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_rescale_+3A_up">up</code></td>
<td>
<p>integer &gt; 0, or vector of two, the up-scaling factors</p>
</td></tr>
<tr><td><code id="sk_rescale_+3A_down">down</code></td>
<td>
<p>integer &gt; 0, or vector of two, the down-scaling factors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users should specify a sk grid <code>g</code> to re-scale and an integer scaling factor; either <code>up</code>
or <code>down</code> (and not both). This effects the scaling of resolution (<code>g[['gres']]</code>) by <code>up</code>
or <code>1/down</code>.
</p>
<p><code>up</code> (or <code>down</code>) should be a vector of two positive integers, the desired re-scaling
factors in the y and x dimensions, in that order, or a single value to be used for both.
</p>
<p>When <code>up</code> is supplied, a lower resolution grid is returned comprising every <code>up</code>th grid
line of <code>g</code> along each dimension. All other grid lines, and any data values lying on them,
are ignored. <code>up</code> should be no greater than <code>dim(g) - 1</code>. Note that if <code>up</code> does not
evenly divide this number, the bounding box will shrink slightly.
</p>
<p>When <code>down</code> is supplied, the function returns a higher resolution grid (say <code>g_fine</code>) with
the same bounding box as <code>g</code>. Along each dimension, every <code>down</code>th grid line of <code>g_fine</code>
coincides with a grid line of <code>g</code>. Any non-NA values found in <code>g[]</code> are copied to <code>g_fine</code>,
and <code>g</code> can be recovered from <code>g_fine</code> with <code>sk_rescale(g_fine, up=down)</code>.
</p>


<h3>Value</h3>

<p>a sk grid of the requested resolution
</p>


<h3>See Also</h3>

<p>sk sk_cmean
</p>
<p>Other indexing functions: 
<code><a href="#topic+sk_mat2vec">sk_mat2vec</a>()</code>,
<code><a href="#topic+sk_sub_find">sk_sub_find</a>()</code>,
<code><a href="#topic+sk_sub_idx">sk_sub_idx</a>()</code>,
<code><a href="#topic+sk_vec2mat">sk_vec2mat</a>()</code>
</p>
<p>Other sk constructors: 
<code><a href="#topic+sk_snap">sk_snap</a>()</code>,
<code><a href="#topic+sk_sub">sk_sub</a>()</code>,
<code><a href="#topic+sk">sk</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example data
gdim = c(50, 53)
pars = utils::modifyList(sk_pars(gdim), list(eps=1e-2))
g = sk_sim(gdim, pars)
plot(g)

# upscale
plot(sk_rescale(g, up=1)) # does nothing
plot(sk_rescale(g, up=2))

# downscale
sk_plot(sk_rescale(g, down=1)) # does nothing
sk_plot(sk_rescale(g, down=2))

# length-2 vectors to rescale differently in x and y directions
plot(sk_rescale(g, up=c(2,3)))
plot(sk_rescale(g, down=c(2,3)))

# invert a down-scaling
g_compare = sk_rescale(sk_rescale(g, down=c(5,3)), up=c(5,3))
all.equal(g, g_compare)

# multi-layer example with about 50% of points missing
idx_miss = sample.int(length(g), round(0.5*length(g)))
g_multi = sk_sim(gdim, pars, n_layer=3)
g_multi[idx_miss,] = NA

# plot third layer, then down-scaled and up-scaled versions
sk_plot(g_multi, layer=3)
sk_plot(sk_rescale(g=g_multi, down=2), layer=3)
sk_plot(sk_rescale(g=g_multi, up=2), layer=3)

</code></pre>

<hr>
<h2 id='sk_sample_pt'>Sub-grid point sampler for grid data</h2><span id='topic+sk_sample_pt'></span>

<h3>Description</h3>

<p>Sample <code>n</code> locations from the non-NA points in the input grid <code>g</code>, optionally using
them as centers to place <code>n</code> sub-grids of the specified size and resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_sample_pt(
  g,
  n = 100,
  lag_max = 0,
  up = 0,
  over = FALSE,
  sk_out = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_sample_pt_+3A_g">g</code></td>
<td>
<p>an sk grid object or any other object accepted by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_sample_pt_+3A_n">n</code></td>
<td>
<p>integer &gt; 0, the maximum number of center points to sample</p>
</td></tr>
<tr><td><code id="sk_sample_pt_+3A_lag_max">lag_max</code></td>
<td>
<p>integer, Moore neighborhood radius (ie the maximum queen's distance)</p>
</td></tr>
<tr><td><code id="sk_sample_pt_+3A_up">up</code></td>
<td>
<p>integer, the up-scaling factor for sampling sub-grids of <code>g</code></p>
</td></tr>
<tr><td><code id="sk_sample_pt_+3A_over">over</code></td>
<td>
<p>logical, indicates to allow overlapping sub-grids (when they can be avoided)</p>
</td></tr>
<tr><td><code id="sk_sample_pt_+3A_sk_out">sk_out</code></td>
<td>
<p>logical, if TRUE (the default) the function returns an sk grid</p>
</td></tr>
<tr><td><code id="sk_sample_pt_+3A_seed">seed</code></td>
<td>
<p>integer seed, passed to <code>base::set.seed</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>sk_out=TRUE</code> (the default), the function returns an sk grid containing the sampled
points. If multiple samples are requested, a multi-layer grid is returned. When
<code>sk_out=FALSE</code>, the function returns the vector index of the sampled grid points,
or if multiple samples are requested, a list of vectors.
</p>
<p>By default the function simply draws a sample of <code>n</code> locations (uniformly at random)
from the non-NA points in the input grid <code>g</code>.
</p>
<p>When <code>lag_max &gt; 1</code>, the function instead returns the the Moore neighbourhood of
radius <code>lag_max</code> around each of the sample points (including the center point). These
sub-grids are returned as distinct layers (or list entries, if <code>sk_out=FALSE</code>). Their
resolution can be coarsened (up-scaled) by increasing <code>up</code> from its default 0. <code>up</code>
must either be 0 or else a positive integer that evenly divides <code>lag_max</code>
(see <code>sk_rescale</code>).
</p>
<p>For a given <code>up</code>, the grid <code>g</code> can be partitioned into <code>(up+1)^2</code> distinct
non-overlapping sub-grids. When <code>over=FALSE</code> (the default), the function apportions
its <code>n</code> point samples as evenly as possible among these disjoint subsets. This ensures
that if <code>n</code> is less than or equal to <code>(up+1)^2</code>, and there are no <code>NA</code>s, there can be
no repetition (overlap) of points in the returned sub-grids.
</p>
<p>Note that with the default <code>sk_out=TRUE</code>, <code>lag_max &gt; 1</code> is only supported for complete
grids <code>g</code>. This is because with missing data it is hard (and sometimes impossible) to
ensure that the Moore neighborhoods have identical <code>NA</code> structure (and this is a
requirement for multi-layer sk grids).
</p>
<p>Note also that multi-layer sk grids are not fully supported yet. If you pass a
multi-layer grid to g, the function returns results for the first layer only.
</p>


<h3>Value</h3>

<p>If <code>lag_max == 0</code> (the default), the function returns a single-layer sk grid when
<code>sk_out=TRUE</code>, or else the sample indices in <code>g</code> as a length-<code>n</code> integer vector. If
<code>lag_max &gt; 0</code>, the function returns a multi-layer sk grid <code>sk_out=TRUE</code>, or else a list of
<code>n</code> vectors indexing the sampled points in each sub-grid of <code>g</code>.
</p>


<h3>See Also</h3>

<p>sk sk_sample_vg
</p>


<h3>Examples</h3>

<pre><code class='language-R'># define an empty grid
g_empty = sk(gdim = c(100, 100))

# get an ordinary random sample with default settings
g_sample = sk_sample_pt(g_empty)
plot(g_sample)

# same call with index return mode
idx_sample = sk_sample_pt(g_empty, sk_out=FALSE)
str(idx_sample)

# reduce or increase number of center points from default 100
g_sample = sk_sample_pt(g_empty, n=10)
plot(g_sample)

# add some data to g and repeat
pars = sk_pars(g_empty)
pars$eps = 1e-6
g = sk_sim(g_empty, pars)
plot(g)
g_sample = sk_sample_pt(g)
plot(g_sample)

# sample 3 subgrids from Moore neighbourhoods of radius 6 (index output mode)
n = 3
idx_sample = sk_sample_pt(g, n=n, lag_max=6L, sk_out=FALSE, seed=42)

# plot each list element a different color
group_sample = rep(0L, length(g))
for(i in seq(n)) group_sample[ idx_sample[[i]] ] = i
sk_plot(group_sample, dim(g), breaks=c('not sampled', seq(n)), zlab='sub-grid')

# plot all the sub-grid data
g_plot = g_empty
g_plot[unlist(idx_sample)] = g[unlist(idx_sample)]
plot(g_plot)

# default sk_out=TRUE returns them as multi-layer grid object
g_sample = sk_sample_pt(g, n=n, lag_max=6L, seed=42)
plot(g_sample, layer=1, zlim=range(g_plot, na.rm=TRUE))
plot(g_sample, layer=2, zlim=range(g_plot, na.rm=TRUE))
plot(g_sample, layer=3, zlim=range(g_plot, na.rm=TRUE))



# When up &gt; 0 the function will attempts to avoid overlap whenever possible
up = 1
n = (up+1)^2 # to get disjoint results n must be less than or equal to (up+1)^2
lag_max = 10 * (up+1) # vary to get larger/smaller subsets. max allowable: min(gdim)/2
idx_sample = sk_sample_pt(g, n=n, up=up, lag_max=lag_max, sk_out=FALSE)
idx_overlap = rowSums( sapply(idx_sample, function(i) seq_along(g) %in% i) )

# plot each list element a different color
group_sample = rep(0L, length(g))
for(i in seq(n)) group_sample[ idx_sample[[i]] ] = i
sk_plot(group_sample, dim(g), breaks=c('not sampled', seq(n)), zlab='sub-grid')

# no overlap
sk_plot(as.integer(idx_overlap), dim(g), zlab='times sampled')

# compare with over=TRUE (usually results in overlap - try running a few times)
idx_sample_compare = sk_sample_pt(g, n=n, up=up, lag_max=lag_max, over=TRUE, sk_out=FALSE)
idx_overlap_compare = rowSums( sapply(idx_sample_compare, function(i) seq_along(g) %in% i) )
sk_plot(as.integer(idx_overlap_compare), dim(g), zlab='times sampled')

# incomplete input data example
g_sample = sk_sample_pt(g, n=10)
sk_plot(g_sample)

# draw a sample of center points and indicate sub-grids in color
idx_sample = sk_sample_pt(g_sample, n=10, lag_max=6, up=1, over=FALSE, sk_out=FALSE)
g_sample_grid = g_empty
g_sample_grid[] = rep('not sampled', length(g_empty))
g_sample_grid[unlist(idx_sample)] = 'sub-grid sample'
plot(g_sample_grid)

</code></pre>

<hr>
<h2 id='sk_sample_vg'>Sample point pair absolute differences for use in semi-variogram estimation</h2><span id='topic+sk_sample_vg'></span>

<h3>Description</h3>

<p>Compute the absolute differences for point pairs in <code>g</code>, along with their separation
distances. If no sample point index is supplied (in <code>idx</code>), the function samples points
at random using <code>sk_sample_pt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_sample_vg(
  g,
  n_pp = 10000,
  idx = NULL,
  n_bin = 25,
  n_layer_max = NA,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_sample_vg_+3A_g">g</code></td>
<td>
<p>any grid object accepted or returned by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_sample_vg_+3A_n_pp">n_pp</code></td>
<td>
<p>integer maximum number of point pairs to sample</p>
</td></tr>
<tr><td><code id="sk_sample_vg_+3A_idx">idx</code></td>
<td>
<p>optional integer vector indexing the points to sample</p>
</td></tr>
<tr><td><code id="sk_sample_vg_+3A_n_bin">n_bin</code></td>
<td>
<p>integer number of distance bins to assign (passed to <code>sk_add_bins</code>)</p>
</td></tr>
<tr><td><code id="sk_sample_vg_+3A_n_layer_max">n_layer_max</code></td>
<td>
<p>integer, maximum number of layers to sample (for multi-layer <code>g</code>)</p>
</td></tr>
<tr><td><code id="sk_sample_vg_+3A_quiet">quiet</code></td>
<td>
<p>logical, suppresses console output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a set of n points there are n_pp(n) = (n^2-n)/2 possible point pairs. This
expression is inverted to determine the maximum number of sample points in <code>g</code> to use
in order to satisfy the argument <code>n_pp</code>, the maximum number of point pairs to sample.
A random sub-sample of <code>idx</code> is taken as needed. By default <code>n_pp=1e4</code> which results
in <code>n=141</code>.
</p>
<p>The mean of the point pair absolute values ('dabs') for a given distance interval is the
classical estimator of the variogram. This and two other robust methods are implemented
in <code>sk_plot_semi</code>. These statistics are sensitive to the choice of distance bins. They
are added automatically by a call to <code>sk_add_bins</code> (with <code>n_bin</code>) but users can also set
up bins manually by adjusting the 'bin' column of the output.
</p>
<p>For multi-layer <code>g</code>, the function samples observed point locations once and re-uses this
selection in all layers. At most <code>n_layer_max</code> layers are sampled in this way (default is
the square root of the number of layers, rounded up)
</p>


<h3>Value</h3>

<p>A data frame with a row for each sampled point pair. Fields include 'dabs' and 'd',
the absolute difference in point values and the separation distance, along with the vector
index, row and column numbers, and component (x, y) distances for each point pair. 'bin'
indicates membership in one of <code>n_bin</code> categories.
</p>


<h3>See Also</h3>

<p>sk sk_sample_pt sk_add_bins
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# make example grid and reference covariance model
gdim = c(22, 15)
n = prod(gdim)
g_empty = sk(gdim)
pars = sk_pars(g_empty, 'mat')

# generate sample data and sample semi-variogram
g_obs = sk_sim(g_empty, pars)
vg = sk_sample_vg(g_obs)
str(vg)

# pass to plotter and overlay the model that generated the data
sk_plot_semi(vg, pars)

# repeat with smaller sample sizes
sk_plot_semi(sk_sample_vg(g_obs, 1e2), pars)
sk_plot_semi(sk_sample_vg(g_obs, 1e3), pars)

# use a set of specific points
n_sp = 10
( n_sp^2 - n_sp ) / 2 # the number of point pairs
vg = sk_sample_vg(g_obs, idx=sample.int(n, n_sp))
sk_plot_semi(vg, pars)

# non-essential examples skipped to stay below 5s exec time on slower machines


# repeat with all point pairs sampled (not recommended for big data sets)
vg = sk_sample_vg(g_obs, n_pp=Inf)
sk_plot_semi(vg, pars)
( n^2 - n ) / 2 # the number of point pairs

## example with multiple layers

# generate five layers
g_obs_multi = sk_sim(g_empty, pars, n_layer=5)

# by default, a sub-sample of sqrt(n_layers) is selected
vg = sk_sample_vg(g_obs_multi)
sk_plot_semi(vg, pars)

# change this behaviour with n_layer_max
vg = sk_sample_vg(g_obs_multi, n_layer_max=5)
sk_plot_semi(vg, pars)



</code></pre>

<hr>
<h2 id='sk_sim'>Random draw from multivariate normal distribution for sk grids</h2><span id='topic+sk_sim'></span>

<h3>Description</h3>

<p>Generates a random draw from the multivariate Gaussian distribution for the
covariance model <code>pars</code> on grid <code>g</code>, with mean zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_sim(g, pars = sk_pars(g), n_layer = 1, fac = NULL, sk_out = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_sim_+3A_g">g</code></td>
<td>
<p>an sk object or any grid object accepted by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_sim_+3A_pars">pars</code></td>
<td>
<p>list, covariance parameters in form returned by <code>sk_pars</code></p>
</td></tr>
<tr><td><code id="sk_sim_+3A_n_layer">n_layer</code></td>
<td>
<p>positive integer, the number of draws to return</p>
</td></tr>
<tr><td><code id="sk_sim_+3A_fac">fac</code></td>
<td>
<p>list, optional pre-computed factorization of component correlation matrices</p>
</td></tr>
<tr><td><code id="sk_sim_+3A_sk_out">sk_out</code></td>
<td>
<p>logical, if TRUE an sk grid is returned</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pars</code> and <code>g</code> define the model's covariance matrix V. This function uses <code>base::rnorm</code>
to get a vector of independent standard normal variates, which it multiplies by the square
root of the covariance matrix, V, for the desired model (as defined by <code>pars</code> and <code>g</code>). The
result has a multivariate normal distribution with mean zero and covariance V.
</p>
<p>Multiple independent draws can be computed more efficiently by reusing the factorization
of V. This can be pre-computed with <code>sk_var</code> and supplied in <code>fac</code>, or users can set
<code>n_layer</code> and the function will do this automatically.
</p>


<h3>Value</h3>

<p>sk grid or its vectorized form (vector for single-layer case, matrix for multi-layer case)
</p>


<h3>See Also</h3>

<p>sk sk_pars base::rnorm
</p>
<p>Other variance-related functions: 
<code><a href="#topic+sk_GLS">sk_GLS</a>()</code>,
<code><a href="#topic+sk_LL">sk_LL</a>()</code>,
<code><a href="#topic+sk_cmean">sk_cmean</a>()</code>,
<code><a href="#topic+sk_nLL">sk_nLL</a>()</code>,
<code><a href="#topic+sk_var">sk_var</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example grid and covariance parameters
gdim = c(100, 200)
g = sk(gdim)
pars_gau = sk_pars(g)

# this example has a large nugget effect
g_sim = sk_sim(g, pars_gau)
plot(g_sim)

# repeat with smaller nugget effect for less noisy data
pars_smooth = utils::modifyList(pars_gau, list(eps=1e-2))
g_sim = sk_sim(g, pars_smooth)
plot(g_sim)

# the nugget effect can be very small, but users should avoid eps=0
pars_smoother = utils::modifyList(pars_gau, list(eps=1e-12))
g_sim = sk_sim(g, pars_smoother)
plot(g_sim)

# multi-layer example
g_sim_multi = sk_sim(g, pars_smoother, n_layer=3)
plot(g_sim_multi, layer=1)
plot(g_sim_multi, layer=2)
plot(g_sim_multi, layer=3)

</code></pre>

<hr>
<h2 id='sk_snap'>Snap a set of points to a &quot;sk&quot; grid</h2><span id='topic+sk_snap'></span>

<h3>Description</h3>

<p>Maps the input points in <code>from</code> to the closest grid points in the lattice of which
<code>g</code> is a sub-grid. In cases of duplicate mappings, the function returns the first
matches only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_snap(from, g = nrow(from), crop_from = FALSE, crop_g = FALSE, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_snap_+3A_from">from</code></td>
<td>
<p>matrix, data frame, or points object from <code>sp</code> or <code>sf</code>, the source points</p>
</td></tr>
<tr><td><code id="sk_snap_+3A_g">g</code></td>
<td>
<p>any object accepted or returned by <code>sk</code>, the destination grid</p>
</td></tr>
<tr><td><code id="sk_snap_+3A_crop_from">crop_from</code></td>
<td>
<p>logical, indicating to omit points not overlying <code>g</code>.</p>
</td></tr>
<tr><td><code id="sk_snap_+3A_crop_g">crop_g</code></td>
<td>
<p>logical, indicating to trim <code>g</code> to the extent of <code>from</code>.</p>
</td></tr>
<tr><td><code id="sk_snap_+3A_quiet">quiet</code></td>
<td>
<p>logical, suppresses console output</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>from</code> can be a geometry collection from packages <code>sf</code> or <code>sp</code>, or a matrix or list
of y and x coordinates. When <code>from</code> is a matrix, its first two columns should be the
y and x coordinates (in that order), and the (optional) third column should be the
data. When <code>from</code> is a list, the function expects (two or three) vectors of equal
length, ordered as above.
</p>
<p>When <code>from</code> is a geometry collection with a coordinates reference system (CRS) string,
points are first transformed to the CRS of <code>g</code>. If one or both of <code>from</code> and <code>g</code> are
missing a CRS definition, the function assumes the same one is shared in both.
</p>
<p><code>g</code> can be a raster geometry object (such as SpatRaster), in which case the function
behaves like <code>terra::rasterize</code>, or an sk grid object. It can also be a matrix (supplying
dimensions) or a list containing either <code>gdim</code> or<code>gres</code>, from which an appropriately
spaced set of grid lines is derived, centered under the bounding box of the points.
If <code>g</code> is not supplied, it is automatically set to equal <code>nrow(from)</code>, so that there
there is one grid line along each dimension for each input point.
</p>
<p><code>crop_from</code> and <code>crop_g</code> control the extent of the output grid. If both are <code>FALSE</code>
(the default) the function returns the smallest regular grid containing both <code>g</code>
and the snapped <code>from</code> points. If <code>crop_from=TRUE</code> and <code>crop_g=FALSE</code> the output
grid will match <code>g</code> exactly. If <code>crop_from=FALSE</code> and <code>crop_g=TRUE</code> the output
grid will include all snapped points, and possibly omit some or all of <code>g</code>. And if
both are <code>TRUE</code>, the output grid encloses the intersection of the points with the
bounding box of <code>g</code>.
</p>


<h3>Value</h3>

<p>sk object, a grid containing the snapped points. These are assigned
the corresponding data value in <code>from</code>, or if  <code>from</code> has no data, an integer mapping
to the points in <code>from</code>. Un-mapped grid points are set to NA.
</p>


<h3>See Also</h3>

<p>sk sk_coords
</p>
<p>Other sk constructors: 
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_sub">sk_sub</a>()</code>,
<code><a href="#topic+sk">sk</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# functions to scale arbitrary inverval to (1, 2,... 100) and make color palettes
num_to_cent = function(x) 1L + floor(99*( x-min(x) ) / diff(range(x)))
my_pal = function(x) grDevices::hcl.colors(x, 'Spectral', rev=TRUE)
my_col = function(x) my_pal(1e2)[ num_to_cent(x) ]

# create a grid object
gdim = c(40, 30)
g = sk(gdim=gdim, gres=1.1)

# randomly position points within bounding box of g
n_pts = 10
from = lapply(g$gyx, function(yx) runif(n_pts, min(yx), max(yx)) )

# translate away from g (no overlap is required)
from[['y']] = from[['y']] + 5
from[['x']] = from[['x']] + 15

# add example data values and plot
from[['z']] = stats::rnorm(length(from[['y']]))
plot(g, reset=FALSE)
graphics::points(from[c('x', 'y')], pch=16, col=my_col(from[['z']]))
graphics::points(from[c('x', 'y')])

# snap only the points overlying the input grid
g_snap = sk_snap(from, g, crop_from=TRUE)
plot(g_snap, col_grid='black', reset=FALSE, leg=FALSE)
graphics::points(from[c('x', 'y')], pch=16, col=my_col(from[['z']]))
graphics::points(from[c('x', 'y')])

# snap all points to grid extension (default settings)
g_snap = sk_snap(from, g, crop_from=FALSE, crop_g=FALSE)
plot(g_snap, col_grid='black', reset=FALSE)
graphics::points(from[c('x', 'y')], pch=16, col=my_col(from[['z']]))
graphics::points(from[c('x', 'y')])

# find smallest subgrid enclosing all snapped grid points
g_snap = sk_snap(from, g, crop_g=TRUE)
plot(g_snap, col_grid='black', reset=FALSE)
graphics::points(from[c('x', 'y')], pch=16, col=my_col(from[['z']]))
graphics::points(from[c('x', 'y')])

# create a new grid of different resolution enclosing all input points
g_snap = sk_snap(from, g=list(gres=c(0.5, 0.5)))
plot(g_snap, reset=FALSE, col_grid='black')
graphics::points(from[c('x', 'y')], pch=16, col=my_col(from[['z']]))
graphics::points(from[c('x', 'y')])

if( requireNamespace('sf') ) {

# a different example, snapping mis-aligned subgrid
g_pts = sk(list(gdim=c(15, 8), gres=1.7), vals=FALSE)
g_pts[['gyx']][['y']] = g_pts[['gyx']][['y']] + 5
g_pts[['gyx']][['x']] = g_pts[['gyx']][['x']] + 5
from = sk_coords(g_pts, out='list')

# convert to sf
eg_sfc = sf::st_geometry(sk_coords(g_pts, out='sf'))
plot(g, reset=FALSE)
plot(eg_sfc, add=TRUE)

# generate example data and plot
eg_sf = sf::st_sf(data.frame(z=stats::rnorm(length(g_pts))), geometry=eg_sfc)
plot(g, reset=FALSE)
plot(eg_sf, pch=16, add=TRUE, pal=my_pal)
plot(eg_sfc, add=TRUE)

# snap points
g_snap = sk_snap(from=eg_sf, g)
plot(g_snap, reset=FALSE, col_grid='black')
plot(eg_sf, pch=16, add=TRUE, pal=my_pal)
plot(eg_sfc, add=TRUE)

# snapping points without data produces the mapping (non-NA values index "from")
g_snap = sk_snap(from=eg_sfc, g)
plot(g_snap, ij=TRUE, reset=FALSE, col_grid='black')
plot(eg_sfc, add=TRUE)

# with crop_g=TRUE)
g_snap = sk_snap(from=eg_sfc, g, crop_g=TRUE)
plot(g_snap, reset=FALSE, col_grid='black')
plot(eg_sfc, add=TRUE)

# test with sp class
eg_sp = as(eg_sf,'Spatial')
g_snap = sk_snap(from=eg_sp, g)
plot(g_snap, reset=FALSE, col_grid='black')
plot(eg_sf, pch=16, add=TRUE, pal=my_pal)
plot(eg_sfc, add=TRUE)

}

</code></pre>

<hr>
<h2 id='sk_sub'>Return a sub-grid of a sk grid object</h2><span id='topic+sk_sub'></span>

<h3>Description</h3>

<p>Creates a &quot;sk&quot; object containing only the grid-lines specified in <code>idx_keep</code>. Alternatively,
grid lines to remove can be specified in <code>idx_rem</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_sub(g, ij_keep = NULL, ij_rem = NULL, idx = FALSE, mirror = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_sub_+3A_g">g</code></td>
<td>
<p>sk grid or any grid-like object accepted by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_sub_+3A_ij_keep">ij_keep</code></td>
<td>
<p>list of grid line numbers (&quot;i&quot; and &quot;j&quot;) forming regular sub-grid</p>
</td></tr>
<tr><td><code id="sk_sub_+3A_ij_rem">ij_rem</code></td>
<td>
<p>list of grid line numbers (&quot;i&quot; and &quot;j&quot;) whose exclusion forms regular sub-grid</p>
</td></tr>
<tr><td><code id="sk_sub_+3A_idx">idx</code></td>
<td>
<p>logical, if TRUE the function returns a list containing <code>ij_keep</code> and <code>ij_rem</code></p>
</td></tr>
<tr><td><code id="sk_sub_+3A_mirror">mirror</code></td>
<td>
<p>logical, whether to mirror the selection in <code>ij_rem</code> (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One of <code>idx_keep</code> or <code>idx_rem</code> (but not both) can be specified, and the grid line numbers
(not intercepts) should be supplied in ascending order in list entries named &quot;i&quot; and &quot;j&quot;.
</p>
<p>If <code>idx_rem</code> is specified, <code>mirror=TRUE</code> will cause the selection in <code>idx_rem</code> to be
reflected about the central grid line (useful for specifying outer grid lines). <code>mirror</code>
is ignored if <code>idx_keep</code> is specified instead.
</p>
<p>Default <code>idx=FALSE</code> causes the function to return the sub-grid as a sk grid object.
If <code>idx=TRUE</code>, the function instead returns a list containing <code>idx_keep</code> and <code>idx_rem</code> as
specified above.
</p>
<p>If neither <code>idx_keep</code> nor <code>idx_rem</code> is supplied, the function removes outer grid lines
iteratively (selecting the one with highest proportion of <code>NA</code>s), attempting to find a
complete sub-grid (having no <code>NA</code>s) somewhere in the interior. This heuristic is designed
for rasters with few <code>NA</code>s, all located around the perimeter.
</p>


<h3>Value</h3>

<p>an sk grid object, the requested sub-grid of <code>g</code>
</p>


<h3>See Also</h3>

<p>Other sk constructors: 
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_snap">sk_snap</a>()</code>,
<code><a href="#topic+sk">sk</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# make an example grid
g = sk(c(50, 100))
g[] = apply(expand.grid(g[['gyx']]), 1, \(z) cos( 2*sum(z^2) ) )
plot(g)

# subset by specifying grid lines to keep
ij_keep = list(i=seq(1, 50, by=2), j=seq(1, 50, by=2))
g_keep = sk_sub(g, ij_keep)
plot(g_keep)

# get the indices kept and removed
idx = sk_sub(g, ij_keep, idx=TRUE)

# equivalent call specifying grid lines to omit
g_rem = sk_sub(g, ij_rem=idx[['rem']])
identical(g_rem, g_keep)

# remove some data around the edges of the grid
idx = sk_sub(g, ij_rem=list(i=seq(10), j=seq(10)), mirror=TRUE, idx=TRUE)
idx_y_pts = sk_sub_idx(dim(g), idx[['rem']]['i'], idx=TRUE)
idx_x_pts = sk_sub_idx(dim(g), idx[['rem']]['j'], idx=TRUE)
idx_pts = c(idx_y_pts, idx_x_pts)
idx_na = sort(sample(idx_pts, 0.6*length(idx_pts)))
g[idx_na] = NA
plot(g)

# identify the interior sub-grid that is complete
g_sub = sk_sub(g)
print(g_sub)
plot(g_sub)

# verify it is as large as expected
( dim(g) - dim(g_sub) ) == sapply(idx[['rem']], length)

</code></pre>

<hr>
<h2 id='sk_sub_find'>Find complete regular sub-grids in a sk grid object</h2><span id='topic+sk_sub_find'></span>

<h3>Description</h3>

<p>If a sk grid <code>g</code> has missing values (<code>NA</code>s) but the set of non-<code>NA</code> points form a
complete (regular) sub-grid, this function finds its grid lines, resolution, and
dimensions. If no eligible sub-grids are found, the function returns <code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_sub_find(g, gdim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_sub_find_+3A_g">g</code></td>
<td>
<p>logical vector, sk grid, or any grid object accepted by <code>sk</code></p>
</td></tr>
<tr><td><code id="sk_sub_find_+3A_gdim">gdim</code></td>
<td>
<p>integer vector, the grid dimensions (in order 'y', 'x')</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A sub-grid is only eligible if it contains ALL of the non-<code>NA</code> points in <code>g</code> and none
of the <code>NA</code>s. For example if a single point missing from the sub-grid, or a single non-<code>NA</code>
point lies outside the sub-grid, the function will fail to detect any sub-grids and return
<code>NULL</code>. If no points are <code>NA</code>, the function returns indices for the full grid.
</p>
<p>The returned list contains the following named elements:
</p>

<ul>
<li> <p><code>ij</code> the grid line numbers of the sub-grid with respect to <code>g</code>
</p>
</li>
<li> <p><code>res_scale</code> the resolution scaling factor (relative increase in grid line spacing of <code>g</code>)
</p>
</li>
<li> <p><code>gdim</code> the number of y and x grid lines in the sub-grid
</p>
</li></ul>

<p>As in <code>sk</code>, each of these is given in the 'y', 'x' order.
</p>
<p>Users can also pass the logical vector returned by <code>!is.na(g)</code> instead of <code>g</code>, in which
case argument <code>gdim</code> must also be specified. This can be much faster with large grids.
</p>


<h3>Value</h3>

<p><code>NULL</code> or list of information about the location and spacing of the sub-grid
within <code>g</code> (see details)
</p>


<h3>See Also</h3>

<p>Other indexing functions: 
<code><a href="#topic+sk_mat2vec">sk_mat2vec</a>()</code>,
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_sub_idx">sk_sub_idx</a>()</code>,
<code><a href="#topic+sk_vec2mat">sk_vec2mat</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# define a grid and example data
gdim = c(50, 53)
pars = utils::modifyList(sk_pars(gdim), list(eps=1e-12))
g = sk_sim(gdim, pars)
plot(g)

# define a super-grid containing the original data and make sure we can find it
g_big = sk_rescale(g, down=3)
plot(g_big)
print(sk_sub_find(g_big))

# define a smaller sub-grid at random
spacing = sapply(floor(gdim/10), function(x) 1 + sample.int(x, 1))
gdim_sg = sapply(floor( (gdim - 1) / spacing), function(x) sample.int(x, 1))
ij_first = sapply(gdim - ( spacing * gdim_sg ), function(x) sample.int(x, 1))

# find index of sub-grid lines and vectorized index of points
ij_sg = Map(function(idx, r, n) seq(idx, by=r, length.out=n), idx=ij_first, r=spacing, n=gdim_sg)
names(ij_sg) = c('i', 'j')
is_sg = sk_sub_idx(gdim, ij_sg, idx=FALSE)

# assign values to the sub-grid points
g_sub = sk(gdim)
g_sub[is_sg] = g[is_sg]
plot(g_sub, zlab='sub-grid')

# call the function and check for expected results
sub_result = sk_sub_find(g_sub)
all.equal(unname(sub_result[['gdim']]), gdim_sg)
all.equal(unname(sub_result[['ij']]), unname(ij_sg))

# sub grids with side length 1 have no spacing defined along that dimension
spacing[gdim_sg==1] = NA

# check consistency in spacing
all.equal(unname(sub_result[['res_scale']]), spacing)

# can also call on the vector and supply gdim separately
identical(sub_result, sk_sub_find(!is.na(g_sub), dim(g_sub)))

</code></pre>

<hr>
<h2 id='sk_sub_idx'>Find column-vectorized index of a sub-grid</h2><span id='topic+sk_sub_idx'></span>

<h3>Description</h3>

<p>Returns a logical vector indicating all grid points lying on the specified sub-grid.
A grid point is <code>TRUE</code> only if both its i and j grid lines are found in <code>ij</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_sub_idx(gdim, ij = NULL, idx = FALSE, nosort = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_sub_idx_+3A_gdim">gdim</code></td>
<td>
<p>integer vector, the number rows and columns in the full grid (in that order)</p>
</td></tr>
<tr><td><code id="sk_sub_idx_+3A_ij">ij</code></td>
<td>
<p>list containing vectors &quot;i&quot; and &quot;j&quot;, the sub-grid row and column numbers</p>
</td></tr>
<tr><td><code id="sk_sub_idx_+3A_idx">idx</code></td>
<td>
<p>logical, indicates to return indices (default TRUE) versus logical vector</p>
</td></tr>
<tr><td><code id="sk_sub_idx_+3A_nosort">nosort</code></td>
<td>
<p>logical, skips sorting the input vectors in <code>ij</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ij</code> should be a list containing integer vectors named 'i', 'j', enumerating the
i and j grid lines of the desired sub-grid. If 'i' (or 'j') is missing, the function
automatically specifies all rows (or columns).
</p>
<p>If <code>idx=TRUE</code>, the function computes the vectorized index of the sub-grid points
with respect to the full grid <code>gdim</code> (see <code>sk_mat2vec</code>). Letting <code>i = c(i1, i2, ...im)</code>
and <code>j = c(j1, j2, ...in)</code> the function orders the sub-grid points as follows:
</p>
<p>(i1, j1), (i2, j1), ... (im, j1), (i1, j2), (i2, j2), ..., (i1, j3), ... (in, jm)
</p>
<p>This is the column-major vectorized order for the sub-grid (with y descending and
x ascending), provided the input grid line numbers in <code>ij</code> are in ascending order.
When <code>nosort=FALSE</code>, the function orders the input grid lines automatically.
</p>


<h3>Value</h3>

<p>integer or logical vector
</p>


<h3>See Also</h3>

<p>Other indexing functions: 
<code><a href="#topic+sk_mat2vec">sk_mat2vec</a>()</code>,
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_sub_find">sk_sub_find</a>()</code>,
<code><a href="#topic+sk_vec2mat">sk_vec2mat</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example grid and a particular grid point
gdim = c(i=10, j=13)
ij_list = list(i=6, j=3)

# sk_sub_idx returns a logical vector indexing the point (or the index itself)
is_pt = sk_sub_idx(gdim, ij_list)
idx_sub = sk_sub_idx(gdim, ij_list, idx=TRUE)
sk_plot(is_pt, gdim, col_grid='white', ij=TRUE,  zlab='index', breaks=c('other', idx_sub))

# equivalent call when ij_list is a single point
sk_mat2vec(ij_list, gdim) == idx_sub

# if i or j are omitted from ij, the function returns the full row or column
is_col2 = sk_sub_idx(gdim, ij_list['i'])
is_row3 = sk_sub_idx(gdim, ij_list['j'])
sk_plot(is_col2, gdim, col_grid='white', ij=TRUE, breaks=c('other', paste('row', ij_list['i'])))
sk_plot(is_row3, gdim, col_grid='white', ij=TRUE, breaks=c('other', paste('col', ij_list['j'])))

# indices in column-vectorized order
sk_sub_idx(gdim, list(i=2), idx=TRUE)
sk_sub_idx(gdim, list(j=3), idx=TRUE)
sk_sub_idx(gdim, idx=TRUE) # call without arguments returns all indices

# bigger sub-grid example
origin_sg = c(5, 2) # assign i,j of top left point
gdim_sg = c(3, 4) # sub-grid dimensions (make sure this fits in gdim!)
ij_list = list(i = origin_sg[1] + seq(gdim_sg[1]) - 1, j = origin_sg[2] + seq(gdim_sg[2]) - 1)
is_sg = sk_sub_idx(gdim, ij=ij_list)
sk_plot(is_sg, gdim, col_grid='white', ij=TRUE, zlab='sub-grid')

# plot the index values: column major vectorization with y descending, x ascending
idx_sg = sk_sub_idx(gdim, ij=ij_list, idx=TRUE)
vec_order = rep(NA, prod(gdim))
vec_order[is_sg] = as.character(idx_sg)
sk_plot(vec_order, gdim, col_grid='black', ij=TRUE, zlab='vector idx')

# example with j indices supplied in reverse (descending) order
ij_list_xflip = utils::modifyList(ij_list, list(j=rev(ij_list[['j']])))

# ordering in the vectors ij$i and ij$j doesn't matter if `nosort=FALSE` or `idx=FALSE`
identical(is_sg, sk_sub_idx(gdim, ij=ij_list, nosort=TRUE))
all.equal(which(is_sg), sk_sub_idx(gdim, ij=ij_list_xflip, idx=TRUE))

# when `nosort=TRUE` and `idx=TRUE` we get the same indices but in a different order
idx_sg_xflip = sk_sub_idx(gdim, ij=ij_list_xflip, idx=TRUE, nosort=TRUE)
all.equal(sort(idx_sg), sort(idx_sg_xflip))
all.equal(idx_sg, idx_sg_xflip)
vec_order[is_sg] = as.character(idx_sg_xflip)
sk_plot(vec_order, gdim, col_grid='black', ij=TRUE, zlab='vector index')

</code></pre>

<hr>
<h2 id='sk_to_string'>Extract Kronecker covariance  parameters as plot-friendly strings</h2><span id='topic+sk_to_string'></span>

<h3>Description</h3>

<p>Generate strings describing the model and parameter values in a Kronecker covariance
parameter list <code>pars</code>. These are used to fill out titles and axis labels in calls to
<code>sk_plot_pars</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_to_string(pars, nsig = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_to_string_+3A_pars">pars</code></td>
<td>
<p>character, character vector, or list (see details)</p>
</td></tr>
<tr><td><code id="sk_to_string_+3A_nsig">nsig</code></td>
<td>
<p>number of significant figures to print</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>pars</code> is a parameter list (of the form returned by <code>sk_pars</code>), the
function returns a list of strings: a kernel family string ('k'), dimension-wise kernel
parameters (sub-list 'kp', with entries 'y' and 'x'), and a title containing the
kernel family, nugget effect, and partial sill.
</p>
<p>When <code>pars</code> is a character string, the function returns it unchanged. When <code>pars</code>
is a vector of two character strings, it concatenates them with separator &quot; x &quot;.
When <code>pars</code> is a list of kernel parameters for a single dimension, it returns a named
list of two character strings: the kernel name (named entry 'k') and the parameter(s)
(named entry 'kp'), parenthesized, in &quot;name = value&quot; format where &quot;value&quot; is rounded
to <code>nsig</code> significant digits).
</p>


<h3>Value</h3>

<p>a character string or list of them
</p>


<h3>See Also</h3>

<p>sk_plot_pars
</p>
<p>Other parameter managers: 
<code><a href="#topic+sk_bds">sk_bds</a>()</code>,
<code><a href="#topic+sk_fit">sk_fit</a>()</code>,
<code><a href="#topic+sk_kp">sk_kp</a>()</code>,
<code><a href="#topic+sk_pars_make">sk_pars_make</a>()</code>,
<code><a href="#topic+sk_pars_update">sk_pars_update</a>()</code>,
<code><a href="#topic+sk_pars">sk_pars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kname = 'mat'
sk_to_string(kname)
sk_to_string(rep(kname, 2))
sk_to_string(list(k=kname))

gdim = c(10, 15)
pars = sk_pars(gdim, kname)
sk_to_string(pars)

</code></pre>

<hr>
<h2 id='sk_toep_mult'>Efficiently compute yzx for symmetric Toeplitz matrices y and x</h2><span id='topic+sk_toep_mult'></span>

<h3>Description</h3>

<p>Computes the product <code>y %*% z</code> or <code>y %*% z %*% x</code> for symmetric Toeplitz matrices
<code>y</code> and <code>x</code> and any numeric matrix <code>z</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_toep_mult(y, z = NULL, x = NULL, idx_obs = NULL, gdim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_toep_mult_+3A_y">y</code></td>
<td>
<p>numeric matrix or vector, the symmetric Toeplitz matrix y or its first row</p>
</td></tr>
<tr><td><code id="sk_toep_mult_+3A_z">z</code></td>
<td>
<p>numeric matrix or vector with dimensionality conforming with y (and x)</p>
</td></tr>
<tr><td><code id="sk_toep_mult_+3A_x">x</code></td>
<td>
<p>numeric matrix or vector, the symmetric Toeplitz matrix x or its first row</p>
</td></tr>
<tr><td><code id="sk_toep_mult_+3A_idx_obs">idx_obs</code></td>
<td>
<p>integer vector, indices of the observed grid points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Argument(s) <code>y</code> (and <code>x</code>) can be vector(s) supplying the first row of the matrix.
By default, <code>z</code> is the identity matrix, so for matrix <code>y</code>, sk_toep_mult(<code>y</code>) returns
its argument, and for vector <code>y</code>, it returns the Toeplitz matrix generated by <code>y</code>, the
same as <code>stats::toeplitz(y)</code>.
</p>
<p>Fast Fourier transforms are used to reduce the memory footprint of computations,
The first row(s) of <code>y</code> (and <code>x</code>) are embedded in a zero-padded vector representing a
circulant matrix, whose action on the zero-padded version of <code>z</code> is equivalent to
element-wise product in Fourier space. This allows the desired matrix product to be
computed without explicitly creating matrices <code>y</code> or <code>x</code> in memory.
</p>
<p>The function is optimized for grid data <code>z</code> that are sparse (many zeros). Before
computing any transformations it first scans for and removes columns and rows of
z which are all zero, replacing them afterwards.
</p>
<p>To avoid unnecessarily copying large sparse matrices, <code>z</code> can be the vector of
non-zero matrix entries only, where <code>gdim</code> specifies the full matrix dimensions and
<code>idx_obs</code> the indices of the non-zero entries.
</p>


<h3>Value</h3>

<p>numeric matrix, the product of yzx or yz (if x is NULL)
</p>


<h3>See Also</h3>

<p>base::toeplitz stats::fft
</p>
<p>Other internal variance-related functions: 
<code><a href="#topic+sk_corr_mat">sk_corr_mat</a>()</code>,
<code><a href="#topic+sk_corr">sk_corr</a>()</code>,
<code><a href="#topic+sk_var_mult">sk_var_mult</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># define example matrix from 1D exponential variogram
n = 10
y = exp(1-seq(n))
y_mat = sk_toep_mult(y)
max( abs(y_mat - stats::toeplitz(y))  )

# multiply by random matrix and compare with default matrix multiply
z = matrix(stats::rnorm(n^2), n)
result_default = y_mat %*% z
max( abs( result_default - sk_toep_mult(y_mat, z) ) )

# save memory by passing only the first row of the Toeplitz matrix
max( abs( result_default - sk_toep_mult(y, z) ) )

# sparsify z and repeat
idx_sparse = sample.int(n^2, n^2 - n)
z[idx_sparse] = 0
result_default = y_mat %*% z
max( abs( result_default - sk_toep_mult(y, z) ) )

# right-multiply with another kernel
x = exp( 2 *( 1-seq(n) ) )
x_mat = sk_toep_mult(x)
result_default = result_default %*% x_mat
max( abs( result_default - sk_toep_mult(y, z, x) ) )

# z can also be supplied as vector of nonzero grid values
idx_obs = which(z != 0)
gdim = c(y=n, x=n)
max( abs( result_default - sk_toep_mult(y, z=z[idx_obs], x, idx_obs, gdim) ) )

</code></pre>

<hr>
<h2 id='sk_validate'>Check compatibility of entries in a sk grid object, and fill in any missing ones</h2><span id='topic+sk_validate'></span>

<h3>Description</h3>

<p>This constructs the object and fills missing entries. It then does some sanity checks
and computes the index of NA points (in list entry <code>is_obs</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_validate(g, res_tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_validate_+3A_g">g</code></td>
<td>
<p>a &quot;sk&quot; object or a list accepted by <code>sk_make</code></p>
</td></tr>
<tr><td><code id="sk_validate_+3A_res_tol">res_tol</code></td>
<td>
<p>positive numeric, tolerance validating resolution (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function removes/introduces <code>idx_grid</code> depending on whether <code>gval</code> is a vector
(single-layer case) or a matrix (usually a multi-layer case). If <code>idx_grid</code> is missing
and <code>gval</code> is a matrix, it is assumed to contain all grid-points (including NAs)
</p>
<p>The function also assigns dimension names in the order 'y', 'x' (unless otherwise
specified) for <code>gdim</code>, <code>gres</code>, and <code>gyx</code>.
</p>
<p><code>res_tol</code> is used to check if the resolution <code>gres</code> is consistent with the spacing
of the grid lines. Only the spacing of the first two lines is computed - if the
relative error along either dimensions is greater <code>res_tol</code>, the function throws
an error.
</p>


<h3>Value</h3>

<p>a validated &quot;sk&quot; object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sk_validate(list(gdim=10, gres=0.5))
sk_validate(list(gval=stats::rnorm(10^2), gdim=10, gres=0.5))
</code></pre>

<hr>
<h2 id='sk_var'>Generate a covariance matrix or its factorization</h2><span id='topic+sk_var'></span>

<h3>Description</h3>

<p>Computes the covariance matrix V (or one of its factorizations) for the non-NA points
in sk grid <code>g</code>, given the model parameters list <code>pars</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_var(
  g,
  pars = NULL,
  scaled = FALSE,
  fac_method = "none",
  X = NULL,
  fac = NULL,
  sep = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_var_+3A_g">g</code></td>
<td>
<p>a sk grid object or a list with entries 'gdim', 'gres', 'gval'</p>
</td></tr>
<tr><td><code id="sk_var_+3A_pars">pars</code></td>
<td>
<p>list of form returned by <code>sk_pars</code> (with entries 'y', 'x', 'eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_var_+3A_scaled">scaled</code></td>
<td>
<p>logical, whether to scale by <code>1/pars$psill</code></p>
</td></tr>
<tr><td><code id="sk_var_+3A_fac_method">fac_method</code></td>
<td>
<p>character, the factorization to return, one of 'none', 'chol', 'eigen'</p>
</td></tr>
<tr><td><code id="sk_var_+3A_x">X</code></td>
<td>
<p>numeric matrix, the <code>X</code> in <code>t(X) %*% V %*% X</code> (default is identity, see details)</p>
</td></tr>
<tr><td><code id="sk_var_+3A_fac">fac</code></td>
<td>
<p>matrix or list of matrices, the variance factorization (only used with X)</p>
</td></tr>
<tr><td><code id="sk_var_+3A_sep">sep</code></td>
<td>
<p>logical, indicating to return correlation components instead of full covariance matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default the output matrix is V. Alternatively, if <code>X</code> is supplied, the function
returns the quadratic form X^T V^-1 X.
</p>
<p>When <code>fac_method=='eigen'</code> the function instead returns the eigen-decomposition of the
output matrix, and when <code>fac_method=='chol'</code> its lower triangular Cholesky factor is
returned. Supplying this factorization in argument <code>fac</code> in a subsequent call with <code>X</code>
can speed up calculations. <code>fac</code> is ignored when <code>X</code> is not supplied.
</p>
<p><code>scaled=TRUE</code> returns the matrix scaled by the reciprocal of the partial sill,
<code>1/pars$psill</code>, before factorization. This is the form expected by functions
<code>sk_var_mult</code> and <code>sk_LL</code> in argument <code>fac</code>.
</p>
<p>Numerical precision issues with poorly conditioned covariance matrices can often be
resolved by using 'eigen' factorization method (instead 'chol') and making sure that
<code>pars$eps &gt; 0</code>.
</p>
<p>If all grid points are observed, then the output V becomes separable. Setting <code>sep=TRUE</code>
in this case causes the function to return the x and y component correlation matrices (or
their factorizations, as requested in <code>fac_method</code>) separately, in a list. <code>scaled</code> has no
effect in this output mode. Note also that <code>sep</code> has no effect when <code>X</code> is supplied.
</p>
<p>If the function is passed an empty grid <code>g</code> (all points <code>NA</code>) it returns results for the
complete case (no <code>NA</code>s). If it is passed a list that is not a sk grid object, it must
include entries 'gdim', 'gres', 'gval' and/or 'idx_grid' (as they are specified in
<code>sk</code>), all other entries are ignored in this case.
</p>


<h3>Value</h3>

<p>either matrix <code>V</code>, or X^T V^-1 X, or a factorization ('chol' or 'eigen')
</p>


<h3>See Also</h3>

<p>sk
</p>
<p>Other variance-related functions: 
<code><a href="#topic+sk_GLS">sk_GLS</a>()</code>,
<code><a href="#topic+sk_LL">sk_LL</a>()</code>,
<code><a href="#topic+sk_cmean">sk_cmean</a>()</code>,
<code><a href="#topic+sk_nLL">sk_nLL</a>()</code>,
<code><a href="#topic+sk_sim">sk_sim</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># define example grid with NAs and example predictors matrix
gdim = c(12, 13)
n = prod(gdim)
n_obs = floor(n/3)
idx_obs = sort(sample.int(n, n_obs))
g = g_empty = sk(gdim)
g[idx_obs] = stats::rnorm(n_obs)
plot(g)

# example kernel
psill = 0.3
pars = utils::modifyList(sk_pars(g), list(psill=psill))

# plot the covariance matrix for observed data, its cholesky factor and eigen-decomposition
V_obs = sk_var(g, pars)
V_obs_chol = sk_var(g, pars, fac_method='chol')
V_obs_eigen = sk_var(g, pars, fac_method='eigen')
sk_plot(V_obs)
sk_plot(V_obs_chol)
sk_plot(V_obs_eigen$vectors)

# empty and complete cases are treated the same

# get the full covariance matrix with sep=FALSE (default)
V_full = sk_var(g_empty, pars)

# check that the correct sub-matrix is there
max(abs( V_obs - V_full[idx_obs, idx_obs] ))

# get 1d correlation matrices with sep=TRUE...
corr_components = sk_var(g_empty, pars, sep=TRUE)
str(corr_components)
sk_plot(corr_components[['x']])

# ... these are related to the full covariance matrix through psill and eps
corr_mat = kronecker(corr_components[['x']], corr_components[['y']])
V_full_compare = pars$psill * corr_mat + diag(pars$eps, n)
max(abs(V_full - V_full_compare))

# ... their factorizations can be returned as (nested) lists
str(sk_var(g_empty, pars, fac_method='chol', sep=TRUE))
str(sk_var(g_empty, pars, fac_method='eigen', sep=TRUE))

# compare to the full covariance matrix factorizations (default sep=FALSE)
str(sk_var(g_empty, pars, fac_method='chol'))
str(sk_var(g_empty, pars, fac_method='eigen'))

# test quadratic form with X
nX = 3
X_all = cbind(1, matrix(stats::rnorm(nX * n), ncol=nX))
cprod_all = crossprod(X_all, chol2inv(chol(V_full))) %*% X_all
abs(max(sk_var(g_empty, pars, X=X_all) - cprod_all ))

# test products with inverse of quadratic form with X
mult_test = stats::rnorm(nX + 1)
cprod_all_inv = chol2inv(chol(cprod_all))
cprod_all_inv_chol = sk_var(g_empty, pars, X=X_all, scaled=TRUE, fac_method='eigen')
sk_var_mult(mult_test, pars, fac=cprod_all_inv_chol) - cprod_all_inv %*% mult_test

# repeat with missing data
X_obs = X_all[idx_obs,]
cprod_obs = crossprod(X_obs, chol2inv(chol(V_obs))) %*% X_obs

abs(max(sk_var(g, pars, X=X_obs) - cprod_obs ))
cprod_obs_inv = chol2inv(chol(cprod_obs))
cprod_obs_inv_chol = sk_var(g, pars, X=X_obs, scaled=TRUE, fac_method='eigen')
sk_var_mult(mult_test, pars, fac=cprod_obs_inv_chol) - cprod_obs_inv %*% mult_test

# `scaled` indicates to divide matrix by psill
print( pars[['eps']]/pars[['psill']] )
diag(sk_var(g, pars, scaled=TRUE)) # diagonal elements equal to 1 + eps/psill
( sk_var(g, pars) - psill * sk_var(g, pars, scaled=TRUE) ) |&gt; abs() |&gt; max()
( sk_var(g, pars, X=X_obs, scaled=TRUE) - ( cprod_obs/psill ) ) |&gt; abs() |&gt; max()

# in Cholesky factor this produces a scaling by square root of psill
max(abs( V_obs_chol - sqrt(psill) * sk_var(g, pars, fac_method='chol', scaled=TRUE) ))

# and in the eigendecomposition, a scaling of the eigenvalues
vals_scaled = sk_var(g, pars, fac_method='eigen', scaled=TRUE)$values
max(abs( sk_var(g, pars, fac_method='eigen')$values - psill*vals_scaled ))

</code></pre>

<hr>
<h2 id='sk_var_mult'>Multiply a vector by a power of the covariance matrix</h2><span id='topic+sk_var_mult'></span>

<h3>Description</h3>

<p>Computes <code>W %*% z</code>, where <code>z</code> is the vector of non-NA data in <code>g</code>,
and <code>W</code> is the <code>p</code>th power of <code>V</code>, the covariance matrix for <code>z</code>. By default,
<code>p=-1</code>, so the function computes products with the inverse covariance matrix.
Alternatively, <code>out='quad'</code> computes the quadratic form <code>t(z) %*% W %*% z</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_var_mult(g, pars, fac_method = "eigen", fac = NULL, quad = FALSE, p = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_var_mult_+3A_g">g</code></td>
<td>
<p>a sk grid object or (if fac supplied) numeric vector or matrix of non-NA data</p>
</td></tr>
<tr><td><code id="sk_var_mult_+3A_pars">pars</code></td>
<td>
<p>list of form returned by <code>sk_pars</code> (with entries 'y', 'x', 'eps', 'psill')</p>
</td></tr>
<tr><td><code id="sk_var_mult_+3A_fac_method">fac_method</code></td>
<td>
<p>either 'eigen' (the default) or 'chol'</p>
</td></tr>
<tr><td><code id="sk_var_mult_+3A_fac">fac</code></td>
<td>
<p>factorization of scaled covariance matrix of z (V divided by psill)</p>
</td></tr>
<tr><td><code id="sk_var_mult_+3A_quad">quad</code></td>
<td>
<p>logical, if TRUE the function returns the quadratic form <code>t(z) %*% V_inv %*% z</code></p>
</td></tr>
<tr><td><code id="sk_var_mult_+3A_p">p</code></td>
<td>
<p>numeric, the matrix power of V^p to multiply (ignored when <code>method=='chol'</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fac_method</code> specifies the covariance matrix factorization to use: either 'chol'
(Cholesky factorization), which only supports <code>p=-1</code>; or 'eigen' (eigen-decomposition),
which supports any integer or numeric power for <code>p</code>. By default, the 'eigen' method
is used, unless a Cholesky decomposition (matrix) is passed in <code>fac</code>.
</p>
<p>The 'eigen' method is required when <code>g</code> has complete data (ie no NA values). Note
that the structure of any supplied <code>fac</code> overrules the <code>fac_method</code> argument, so if your
<code>g</code> is complete and you supply the Cholesky decomposition, the function will halt with
an error even if you have set <code>fac_method='eigen'</code>.
</p>
<p>factorization is often the slow part of the computations, so we allow it to be pre-computed
using <code>sk_var(..., scaled=TRUE)</code> and passed in argument <code>fac</code>.
This must be the factorization of the covariance matrix after dividing by the partial sill
(see <code>?sk_var</code>); either the lower Cholesky factor (eg the transposed output of
<code>base::chol</code>), or a list of eigen-vectors and eigen-values (eg. the output of <code>base::eigen</code>).
In the separable case, the eigen-decomposition is done on each of the x and y components
separately, and <code>fac</code> should be a list with elements 'x' and 'y', each one a list of
eigen-vectors and eigen-values.
</p>
<p>When a factorization is supplied, all entries in <code>pars</code>, except for <code>psill</code>, are ignored,
as they are baked into the factorization already. <code>g</code> can in this case be a numeric vector
or matrix, containing one or more layers of observed data, with <code>NA</code>s omitted.
</p>


<h3>Value</h3>

<p>numeric matrix
</p>


<h3>See Also</h3>

<p>sk base::eigen base::chol
</p>
<p>Other internal variance-related functions: 
<code><a href="#topic+sk_corr_mat">sk_corr_mat</a>()</code>,
<code><a href="#topic+sk_corr">sk_corr</a>()</code>,
<code><a href="#topic+sk_toep_mult">sk_toep_mult</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># relative error comparing output x to reference y
rel_err = \(x, y) ifelse(y == 0, 0, abs( (x - y) / y ) )

# define example grid and data
gdim = c(10, 15)
g = sk(gdim)
n = length(g)
g[] = stats::rnorm(n)

# define covariance parameters
pars = utils::modifyList(sk_pars(g, 'gau'), list(psill=2, eps=0.5))

# COMPLETE CASE

# compute the full covariance matrix
V = sk_var(g, pars, sep=FALSE)
V_inv = chol2inv(chol(V))
out_reference = V_inv %*% g[]
out_reference_quad = t(g[]) %*% out_reference
max( rel_err(sk_var_mult(g, pars), out_reference) )
rel_err(sk_var_mult(g, pars, quad=TRUE), out_reference_quad)

# pre-computed factorization on separable components of correlation matrix
fac_corr = sk_var(utils::modifyList(g, list(gval=NULL)), pars, fac_method='eigen', sep=TRUE)
max( rel_err(sk_var_mult(g, pars, fac=fac_corr), out_reference) )
rel_err(sk_var_mult(g, pars, fac=fac_corr, quad=TRUE), out_reference_quad)

# matrix powers
out_reference = V %*% g[]
max( rel_err(sk_var_mult(g, pars, fac_method='eigen', p=1), out_reference) )
rel_err(sk_var_mult(g, pars, fac_method='eigen', p=1, quad=TRUE), t(g[]) %*% out_reference)

# INCOMPLETE CASE

n_sample = floor(n/10)
idx_sampled = sort(sample.int(n, n_sample))
g_miss = sk(gdim)
g_miss[idx_sampled] = g[idx_sampled]
V = sk_var(g_miss, pars)
sk_plot(V)

# correctness check (eigen used by default)
z = matrix(g[idx_sampled], ncol=1)
V_inv = chol2inv(chol(V))
out_reference = (V_inv %*% z)
out_reference_quad = t(z) %*% out_reference
max(rel_err(sk_var_mult(g_miss, pars), out_reference))
rel_err(sk_var_mult(g_miss, pars, quad=TRUE), out_reference_quad)

# check non-default Cholesky method
max( rel_err(sk_var_mult(g_miss, pars, fac_method='chol'), out_reference) )
rel_err(sk_var_mult(g_miss, pars, quad=TRUE, fac_method='chol'), out_reference_quad)

# supply data as a vector instead of list by pre-computing factorization
fac_chol = sk_var(g_miss, pars, scaled=TRUE, fac_method='chol')
fac_eigen = sk_var(g_miss, pars, scaled=TRUE, fac_method='eigen')
max(rel_err(sk_var_mult(z, pars, fac=fac_chol), out_reference))
max(rel_err(sk_var_mult(g_miss, pars, fac=fac_eigen), out_reference))
rel_err(sk_var_mult(z, pars, fac=fac_chol, quad=TRUE), out_reference_quad)
rel_err(sk_var_mult(g_miss, pars, fac=fac_eigen, quad=TRUE), out_reference_quad)

# matrix powers in eigen mode
out_reference = V %*% z
max(rel_err(sk_var_mult(g_miss, pars, p=1), out_reference))
rel_err(sk_var_mult(g_miss, pars, p=1, quad=TRUE), t(z) %*% out_reference)
max(rel_err(sk_var_mult(g_miss, pars, p=2), V %*% out_reference))

# verify that multiplying g_miss twice by a square root of V is same as multiplying by V
g_miss_sqrt = g_miss
g_miss_sqrt[!is.na(g_miss)] = sk_var_mult(g_miss, pars, p=1/2)
max( rel_err(sk_var_mult(g_miss_sqrt, pars, p=1/2), out_reference) )

</code></pre>

<hr>
<h2 id='sk_vario_fun'>Theoretical variogram function</h2><span id='topic+sk_vario_fun'></span>

<h3>Description</h3>

<p>Computes the value of the variogram function w, defined by covariance model <code>pars</code>
at the component y and x lags supplied in <code>d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_vario_fun(pars, d = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_vario_fun_+3A_pars">pars</code></td>
<td>
<p>list of the form returned by <code>sk_pars</code> with entries 'y', 'x', 'eps', 'psill'</p>
</td></tr>
<tr><td><code id="sk_vario_fun_+3A_d">d</code></td>
<td>
<p>numeric vector or list with vector entries 'y' and 'x', the distances to evaluate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By definition w is Var( Z(s1) - Z(s2) ), where s1 and s2 are a pair of spatial
locations, and Z is the spatial process value. If Z is second-order stationary
then w only depends on the relative displacement, s1 - s2 = (dx, dy). <code>snapKrig</code>
models the variogram as W = 2 ( <code>eps</code> + <code>psill</code> ( 1 - cy(dy) cx(dx) ) ).
</p>
<p><code>sk_vario_fun</code> evaluates this function using the correlogram functions (cy and cx),
partial sill (<code>psill</code>) and nugget (<code>eps</code>) defined in <code>pars</code>, over the displacement
(dy and dx) supplied in <code>d</code>.
</p>
<p>NOTE: w is twice the semi-variogram, usually denoted by greek letter gamma. Variogram
w is therefore often written 2<em>gamma. This can (and does) lead to confusion in the
literature about whether to include a factor 2 in downstream calculations.
This function multiplies the semi-variogram function by 2, returning the variogram w
(ie 2</em>gamma), NOT the semi-variogram.
</p>
<p>If <code>d</code> is a list, its 'y' and 'x' components should supply the y and x component distances.
These must be equal-length non-negative numeric vectors. The function returns the corresponding
variogram values in a vector of the same length.
</p>
<p>If <code>d</code> is a numeric vector, it is interpreted as a set of distances at which to
evaluate the range of the variogram function. Anisotropic variograms will exhibit a range
of values for a given distance (depending on the relative sizes of the x and y components).
The function returns this range in a data frame with columns 'min' and 'max'.
</p>


<h3>Value</h3>

<p>data frame (for list <code>d</code>) or numeric vector (for vector <code>d</code>) of variogram values
</p>


<h3>See Also</h3>

<p>sk_pars
</p>
<p>Other variogram functions: 
<code><a href="#topic+sk_add_bins">sk_add_bins</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set up example grid and parameters
gdim = c(10, 15)
d_max = sqrt(sum(gdim^2))
pars = sk_pars(gdim, 'mat')

# set up test distances
d_test = seq(0, d_max, length.out=1e2)

# evaluate and plot the variogram values for equal displacements along x and y
d_equal = stats::setNames(rep(list(sqrt(1/2)*d_test), 2), c('y', 'x'))
vario = sk_vario_fun(pars, d=d_equal)
plot(d_test, vario, pch=NA)
lines(d_test, vario, col='blue')

# evaluate and plot the range of variogram values (for all possible x and y displacements)
vario_lims = sk_vario_fun(pars, d=d_test)
lines(d_test, vario_lims[,1])
lines(d_test, vario_lims[,2])

</code></pre>

<hr>
<h2 id='sk_vec2mat'>Invert column-vectorization indices</h2><span id='topic+sk_vec2mat'></span>

<h3>Description</h3>

<p>Inverts the function <code>sk_mat2vec</code>, returning matrix row and column numbers i, j,
given the column-vectorized index <code>k</code> and matrix dimensions <code>gdim</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sk_vec2mat(k, gdim, out = "matrix")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sk_vec2mat_+3A_k">k</code></td>
<td>
<p>a vector of positive integers, the vector indices to look up</p>
</td></tr>
<tr><td><code id="sk_vec2mat_+3A_gdim">gdim</code></td>
<td>
<p>integer (or vector with first element equal to) the number of rows in the matrix</p>
</td></tr>
<tr><td><code id="sk_vec2mat_+3A_out">out</code></td>
<td>
<p>either 'matrix' or 'list'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Output indices are returned in a matrix with columns 'i', 'j' and rows in same
order as the input <code>k</code>. When <code>out='list'</code> list of vectors 'i' and 'j' (with entries
in the same order) is returned instead.
</p>
<p>The entries of <code>k</code> can be any permutation with replacement from <code>seq(prod(gdim))</code>
</p>


<h3>Value</h3>

<p>a two column matrix of integers (row and column numbers) with <code>length(k)</code> rows
</p>


<h3>See Also</h3>

<p>Other indexing functions: 
<code><a href="#topic+sk_mat2vec">sk_mat2vec</a>()</code>,
<code><a href="#topic+sk_rescale">sk_rescale</a>()</code>,
<code><a href="#topic+sk_sub_find">sk_sub_find</a>()</code>,
<code><a href="#topic+sk_sub_idx">sk_sub_idx</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# show how elements are ordered in `base::matrix`
gdim = c(5, 6)
matrix_order = matrix(1:prod(gdim), gdim)
print(matrix_order)

# identify the row and column numbers for specific entry, or several
sk_vec2mat(2, gdim)
sk_vec2mat(c(2, 10, 5), gdim)
sk_vec2mat(c(2, 10, 5), gdim, out='list')

</code></pre>

<hr>
<h2 id='summary.sk'>Grid summary</h2><span id='topic+summary.sk'></span>

<h3>Description</h3>

<p>Prints detailed information about a grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sk'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.sk_+3A_object">object</code></td>
<td>
<p>an sk object</p>
</td></tr>
<tr><td><code id="summary.sk_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All dimensional information (<code>gdim</code>, <code>gres</code>, <code>gyx</code>) is printed in the order y, x
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g = sk_validate(list(gval=stats::rnorm(4^2), gdim=4, gres=0.5))
summary(g)
g[1] = NA
summary(g)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
