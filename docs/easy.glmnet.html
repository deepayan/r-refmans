<!DOCTYPE html><html lang="en"><head><title>Help for package easy.glmnet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {easy.glmnet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#assign.folds'><p>Assign observations to folds in a balanced way</p></a></li>
<li><a href='#cv'><p>Conduct cross-validation</p></a></li>
<li><a href='#data.frame2glmnet.matrix'><p>Convert a data.frame into a matrix ready for glmnet</p></a></li>
<li><a href='#glmnet_fit'><p>Obtain and use a glmnet prediction model</p></a></li>
<li><a href='#glmnet_get.items.relevance'><p>Get the relevance of the model items</p></a></li>
<li><a href='#glmnet_get.main.model'><p>Get the main glmnet model across imputations and folds</p></a></li>
<li><a href='#impute.glmnet.matrix_fit'><p>Impute missing variables in a glmnet matrix multiple times</p></a></li>
<li><a href='#surv2binary'><p>Convert a &quot;Surv&quot; object into binary variables at different time points</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions to Simplify the Use of 'glmnet' for Machine Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-06</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides several functions to simplify using the 'glmnet' package: converting data frames into matrices ready for 'glmnet'; b) imputing missing variables multiple times; c) fitting and applying prediction models straightforwardly; d) assigning observations to folds in a balanced way; e) cross-validate the models; f) selecting the most representative model across imputations and folds; and g) getting the relevance of the model regressors; as described in several publications: Solanes et al. (2022) &lt;<a href="https://doi.org/10.1038%2Fs41537-022-00309-w">doi:10.1038/s41537-022-00309-w</a>&gt;, Palau et al. (2023) &lt;<a href="https://doi.org/10.1016%2Fj.rpsm.2023.01.001">doi:10.1016/j.rpsm.2023.01.001</a>&gt;, Sobregrau et al. (2024) &lt;<a href="https://doi.org/10.1016%2Fj.jpsychores.2024.111656">doi:10.1016/j.jpsychores.2024.111656</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach, glmnet, parallel, survival</td>
</tr>
<tr>
<td>Suggests:</td>
<td>pROC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-06 15:33:58 UTC; team</td>
</tr>
<tr>
<td>Author:</td>
<td>Joaquim Radua <a href="https://orcid.org/0000-0003-1240-5438"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Joaquim Radua &lt;quimradua@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-11 12:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='assign.folds'>Assign observations to folds in a balanced way</h2><span id='topic+assign.folds'></span>

<h3>Description</h3>

<p>Function to assign observations to folds, ensuring a similar distribution across folds (and sites).</p>


<h3>Usage</h3>

<pre><code class='language-R'>assign.folds(y, family = c("binomial", "cox", "gaussian"), site = NULL, nfolds = 10)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assign.folds_+3A_y">y</code></td>
<td>
<p>response to be predicted. A binary vector for <code>"binomial"</code>, an object of class <code>"Surv"</code> for <code>"cox"</code>, or a numeric vector for <code>"gaussian"</code>.</p>
</td></tr>
<tr><td><code id="assign.folds_+3A_family">family</code></td>
<td>
<p>distribution of y: <code>"binomial"</code>, <code>"cox"</code>, or <code>"gaussian"</code>.</p>
</td></tr>
<tr><td><code id="assign.folds_+3A_site">site</code></td>
<td>
<p>vector with the sites' names, or NULL for studies conducted in a single site.</p>
</td></tr>
<tr><td><code id="assign.folds_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>family</code> is <code>"binomial"</code>, the function randomly assigns the folds separately for the two outcomes. If <code>family</code> is <code>"gaussian"</code>, the function randomly assigns the folds separately for ranges of the outcome. If <code>family</code> is <code>"gaussian"</code>, the function randomly assigns the folds separately for ranges of time and censorship. If <code>site</code> is not null, the function randomly assigns the folds separately for each site.</p>


<h3>Value</h3>

<p>A numeric vector with the fold assigned to each observation</p>


<h3>Author(s)</h3>

<p>Joaquim Radua and Aleix Solanes</p>


<h3>References</h3>

<p>Solanes, A., Mezquida, G., Janssen, J., Amoretti, S., Lobo, A., Gonzalez-Pinto, A., Arango, C., Vieta, E., Castro-Fornieles, J., Berge, D., Albacete, A., Gine, E., Parellada, M., Bernardo, M.; PEPs group (collaborators); Pomarol-Clotet, E., Radua, J. (2022)
Combining MRI and clinical data to detect high relapse risk after the first episode of psychosis.
<em>Schizophrenia</em>, <b>8</b>, 100, doi:10.1038/s41537-022-00309-w.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create random y (numeric)
y = rnorm(200, sample(c(1, 10), 200, replace = TRUE))

# Assign folds
fold = assign.folds(y, "gaussian", nfolds = 4)

# Check that the distribution of y is similar across folds
oldpar = par(mfrow = c(2, 2))
for (i in 1:4) {
  hist(y[which(fold == i)], main = paste("Fold", i), xlab = "y")
}
par(oldpar)
</code></pre>

<hr>
<h2 id='cv'>Conduct cross-validation</h2><span id='topic+cv'></span>

<h3>Description</h3>

<p>Function to easily cross-validate (including fold assignation, merging fold outputs, etc).</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(x, y, family = c("binomial", "cox", "gaussian"), fit_fun, predict_fun, site = NULL,
covar = NULL, nfolds = 10, pred.format = NA, verbose = TRUE, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_+3A_x">x</code></td>
<td>
<p>input matrix for glmnet of dimension nobs x nvars; each row is an observation vector. It can be easily obtained with <code><a href="#topic+data.frame2glmnet.matrix">data.frame2glmnet.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="cv_+3A_y">y</code></td>
<td>
<p>response to be predicted. A binary vector for &quot;binomial&quot;, a &quot;Surv&quot; object for &quot;cox&quot;, or a numeric vector for &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="cv_+3A_family">family</code></td>
<td>
<p>distribution of y: &quot;binomial&quot;, &quot;cox&quot;, or &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="cv_+3A_fit_fun">fit_fun</code></td>
<td>
<p>function to create the prediction model using the training subsets. It can have between two and four arguments(the first two are compulsory): <code>x_training</code> (training X data.frame), <code>y_training</code> (training Y outcomes), <code>site_training</code> (training site names), and <code>covar_training</code> (training covariates). It must return the overall prediction model, which may be a list of the different submodels used in different steps and/or derived from different imputations.</p>
</td></tr>
<tr><td><code id="cv_+3A_predict_fun">predict_fun</code></td>
<td>
<p>function to apply the prediction model to the test sets. It can have between two and four arguments (the first two are compulsory): <code>model</code> (the overall prediction model), <code>x_test</code> (test X data.frame), <code>site_test</code> (test site names), and <code>covar_test</code> (test covariates). It must return the predictions.</p>
</td></tr>
<tr><td><code id="cv_+3A_site">site</code></td>
<td>
<p>vector with the sites' names, or NULL for studies conducted in a single site.</p>
</td></tr>
<tr><td><code id="cv_+3A_covar">covar</code></td>
<td>
<p>other covariates that can be passed to fit_fun and predict_fun.</p>
</td></tr>
<tr><td><code id="cv_+3A_...">...</code></td>
<td>
<p>other arguments that can be passed to fit_fun and predict_fun.</p>
</td></tr>
<tr><td><code id="cv_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds, only used if <code>folds</code> is NULL.</p>
</td></tr>
<tr><td><code id="cv_+3A_pred.format">pred.format</code></td>
<td>
<p>format of the predictions returned by each fold. E.g., if the prediction is an array, use NA.</p>
</td></tr>
<tr><td><code id="cv_+3A_verbose">verbose</code></td>
<td>
<p>(optional) logical, whether to print some messages during execution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function iteratively divides the dataset into a training dataset, with which fits the model using the function <code>fit_fun</code>, and a test dataset, to which applies the model using the function <code>predict_fun</code>. It saves the models fit with the training datasets and the predictions obtained in the test datasets. The fols are assigned automatically using <code><a href="#topic+assign.folds">assign.folds</a></code>, accounting for the <code>site</code> is this is not null.</p>


<h3>Value</h3>

<p>A list with the predictions and the models used.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmnet_predict">glmnet_predict</a></code> for obtaining predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create random x (predictors) and y (binary)
x = matrix(rnorm(25000), ncol = 50)
y = 1 * (plogis(apply(x[,1:5], 1, sum) + rnorm(500, 0, 0.1)) &gt; 0.5)

# Predict y via cross-validation
fit_fun = function (x_training, y_training) {
  list(
    lasso = glmnet_fit(x_training, y_training, family = "binomial")
  )
}
predict_fun = function (m, x_test) {
  glmnet_predict(m$lasso, x_test)
}
# Only 2 folds to ensure the example runs quickly
res = cv(x, y, family = "binomial", fit_fun = fit_fun, predict_fun = predict_fun, nfolds = 2)

# Show accuracy
se = mean(res$predictions$y.pred[res$predictions$y == 1] &gt; 0.5)
sp = mean(res$predictions$y.pred[res$predictions$y == 0] &lt; 0.5)
bac = (se + sp) / 2
cat("Sensitivity:", round(se, 2), "\n")
cat("Specificity:", round(sp, 2), "\n")
cat("Balanced accuracy:", round(bac, 2), "\n")
</code></pre>

<hr>
<h2 id='data.frame2glmnet.matrix'>Convert a data.frame into a matrix ready for glmnet</h2><span id='topic+data.frame2glmnet.matrix'></span><span id='topic+data.frame2glmnet.matrix_fit'></span>

<h3>Description</h3>

<p>Function to convert categorical variables into dummy variables ready for <code><a href="#topic+glmnet_fit">glmnet_fit</a></code> and  <code><a href="#topic+glmnet_predict">glmnet_predict</a></code>. Additionally, it also removes constant columns.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.frame2glmnet.matrix_fit(x)
data.frame2glmnet.matrix(m, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data.frame2glmnet.matrix_+3A_m">m</code></td>
<td>
<p>model to conduct the conversion, obtained with <code><a href="#topic+data.frame2glmnet.matrix_fit">data.frame2glmnet.matrix_fit</a></code>.</p>
</td></tr>
<tr><td><code id="data.frame2glmnet.matrix_+3A_x">x</code></td>
<td>
<p>data.frame to be converted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the returned matrix might differ from the design matrix of a linear model because for categoric variables with more than two levels, it creates as many dummy variables as levels (which is ok for lasso).</p>


<h3>Value</h3>

<p>A matrix ready for <code><a href="#topic+glmnet_fit">glmnet_fit</a></code> and <code><a href="#topic+glmnet_predict">glmnet_predict</a></code>.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua and Aleix Solanes</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmnet_predict">glmnet_predict</a></code> for obtaining predictions,
<code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create random x (predictors) and y (binary)
x = cbind(
  as.data.frame(matrix(rnorm(10000), ncol = 20)),
  matrix(sample(letters, 2500, TRUE), ncol = 5)
)
y = 1 * (plogis(apply(x[,1:5], 1, sum) + rnorm(500, 0, 0.1)) &gt; 0.5)

# Predict y via cross-validation, including conversion to matrix
fit_fun = function (x_training, y_training) {
  m = list(
    matrix = data.frame2glmnet.matrix_fit(x_training)
  )
  x_mat = data.frame2glmnet.matrix(m$matrix, x_training)
  m$lasso = glmnet_fit(x_mat, y_training, family = "binomial")
  m
}
predict_fun = function (m, x_test) {
  x_mat = data.frame2glmnet.matrix(m$matrix, x_test)
  glmnet_predict(m$lasso, x_mat)
}
# Only 2 folds to ensure the example runs quickly
res = cv(x, y, family = "binomial", fit_fun = fit_fun, predict_fun = predict_fun, nfolds = 2)

# Show accuracy
se = mean(res$predictions$y.pred[res$predictions$y == 1] &gt; 0.5)
sp = mean(res$predictions$y.pred[res$predictions$y == 0] &lt; 0.5)
bac = (se + sp) / 2
cat("Sensitivity:", round(se, 2), "\n")
cat("Specificity:", round(sp, 2), "\n")
cat("Balanced accuracy:", round(bac, 2), "\n")
</code></pre>

<hr>
<h2 id='glmnet_fit'>Obtain and use a glmnet prediction model</h2><span id='topic+glmnet_fit'></span><span id='topic+glmnet_predict'></span>

<h3>Description</h3>

<p>Function to easily fit and apply glmnet models (including best lambda estimation, etc).</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet_fit(x, y, family = c("binomial", "cox", "gaussian"),
           nfolds = 10, standardize = TRUE, min.beta = 1e-12)
glmnet_predict(m, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glmnet_fit_+3A_x">x</code></td>
<td>
<p>input matrix of dimension nobs x nvars; each row is an observation vector. It can be easily obtained with <code><a href="#topic+data.frame2glmnet.matrix">data.frame2glmnet.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="glmnet_fit_+3A_y">y</code></td>
<td>
<p>response to be predicted. A binary vector for &quot;binomial&quot;, a &quot;Surv&quot; object for &quot;cox&quot;, or a numeric vector for &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="glmnet_fit_+3A_family">family</code></td>
<td>
<p>distribution of y: &quot;binomial&quot;, &quot;cox&quot;, or &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="glmnet_fit_+3A_m">m</code></td>
<td>
<p>lasso model to conduct the prediction, obtained with <code><a href="#topic+glmnet_fit">glmnet_fit</a></code>.</p>
</td></tr>
<tr><td><code id="glmnet_fit_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds.</p>
</td></tr>
<tr><td><code id="glmnet_fit_+3A_standardize">standardize</code></td>
<td>
<p>logical flag for x variable standardization. The coefficients are always returned on the original scale.</p>
</td></tr>
<tr><td><code id="glmnet_fit_+3A_min.beta">min.beta</code></td>
<td>
<p>minimum value of betas.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>glmnet_fit</code> mainly calls the function <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> to fit a generalized linear model with lasso regularization, though with some extra code to make the call easier: it allow <code>x</code> to have a single column, it conducts an internal cross-validation using the function <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> to select the regularization parameter <code>lambda</code> automatically, and it removes the negligible coefficients.</p>


<h3>Value</h3>

<p>An object of class <code>"glmnet_fit"</code>, which is briefly a list with the intercept (<code>"a0"</code>) and regressors (<code>"beta"</code>) of the model; it also includes the indices of the regressors (<code>"i"</code>) and the <code>"family"</code> of the response.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua and Aleix Solanes</p>


<h3>References</h3>

<p>Solanes, A., Mezquida, G., Janssen, J., Amoretti, S., Lobo, A., Gonzalez-Pinto, A., Arango, C., Vieta, E., Castro-Fornieles, J., Berge, D., Albacete, A., Gine, E., Parellada, M., Bernardo, M.; PEPs group (collaborators); Pomarol-Clotet, E., Radua, J. (2022)
Combining MRI and clinical data to detect high relapse risk after the first episode of psychosis.
<em>Schizophrenia</em>, <b>8</b>, 100, doi:10.1038/s41537-022-00309-w.
</p>
<p>Palau, P., Solanes, A., Madre, M., Saez-Francas, N., Sarro, S., Moro, N., Verdolini, N., Sanchez, M., Alonso-Lana, S., Amann, B.L., Romaguera, A., Martin-Subero, M., Fortea, L., Fuentes-Claramonte, P., Garcia-Leon, M.A., Munuera, J., Canales-Rodriguez, E.J., Fernandez-Corcuera, P., Brambilla, P., Vieta, E., Pomarol-Clotet, E., Radua, J. (2023)
Improved estimation of the risk of manic relapse by combining clinical and brain scan data.
<em>Spanish Journal of Psychiatry and Mental Health</em>, <b>16</b>, 235&ndash;243, doi:10.1016/j.rpsm.2023.01.001.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create random x (predictors) and y (binary)
x = matrix(rnorm(25000), ncol = 50)
y = 1 * (plogis(apply(x[,1:5], 1, sum) + rnorm(500, 0, 0.1)) &gt; 0.5)

# Predict y via cross-validation
fit_fun = function (x_training, y_training) {
  list(
    lasso = glmnet_fit(x_training, y_training, family = "binomial")
  )
}
predict_fun = function (m, x_test) {
  glmnet_predict(m$lasso, x_test)
}
# Only 2 folds to ensure the example runs quickly
res = cv(x, y, family = "binomial", fit_fun = fit_fun, predict_fun = predict_fun, nfold = 2)

# Show accuracy
se = mean(res$predictions$y.pred[res$predictions$y == 1] &gt; 0.5)
sp = mean(res$predictions$y.pred[res$predictions$y == 0] &lt; 0.5)
bac = (se + sp) / 2
cat("Sensitivity:", round(se, 2), "\n")
cat("Specificity:", round(sp, 2), "\n")
cat("Balanced accuracy:", round(bac, 2), "\n")
</code></pre>

<hr>
<h2 id='glmnet_get.items.relevance'>Get the relevance of the model items</h2><span id='topic+glmnet_get.items.relevance'></span>

<h3>Description</h3>

<p>Function to calculate the relevance of the items of a model or of a list of models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet_get.items.relevance(x, childname = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glmnet_get.items.relevance_+3A_x">x</code></td>
<td>
<p>an object of class <code>"glmnet_fit"</code>, a list of objects of class <code>"glmnet_fit"</code>, or a list of objects that have a child of class <code>"glmnet_fit"</code>.</p>
</td></tr>
<tr><td><code id="glmnet_get.items.relevance_+3A_childname">childname</code></td>
<td>
<p>name of the child of class <code>"glmnet_fit"</code> (if <code>x</code>) is a list of objects that have a child of class <code>"glmnet_fit"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relevance is calculated as <code>abs( standardized_coefficient ) / sum(abs( standardized_coefficients ))</code>, as in the function <code><a href="lares.html#topic+lasso_vars">lasso_vars</a></code>.</p>


<h3>Value</h3>

<p>A numeric vector representing the relevance of the items of the model.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua, based on the previous work of others (see Details)</p>


<h3>References</h3>

<p>Palau, P., Solanes, A., Madre, M., Saez-Francas, N., Sarro, S., Moro, N., Verdolini, N., Sanchez, M., Alonso-Lana, S., Amann, B.L., Romaguera, A., Martin-Subero, M., Fortea, L., Fuentes-Claramonte, P., Garcia-Leon, M.A., Munuera, J., Canales-Rodriguez, E.J., Fernandez-Corcuera, P., Brambilla, P., Vieta, E., Pomarol-Clotet, E., Radua, J. (2023)
Improved estimation of the risk of manic relapse by combining clinical and brain scan data.
<em>Spanish Journal of Psychiatry and Mental Health</em>, <b>16</b>, 235&ndash;243, doi:10.1016/j.rpsm.2023.01.001.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmnet_predict">glmnet_predict</a></code> for obtaining predictions,
<code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create random x (predictors) and y (binary)
x = matrix(rnorm(25000), ncol = 50)
y = 1 * (plogis(apply(x[,1:5], 1, sum) + rnorm(500, 0, 0.1)) &gt; 0.5)

# Predict y via cross-validation
fit_fun = function (x_training, y_training) {
  list(
    lasso = glmnet_fit(x_training, y_training, family = "binomial")
  )
}
predict_fun = function (m, x_test) {
  glmnet_predict(m$lasso, x_test)
}
# Only 2 folds to ensure the example runs quickly
res = cv(x, y, family = "binomial", fit_fun = fit_fun, predict_fun = predict_fun, nfolds = 2)

# Show the relevance of the predictors
relevance = glmnet_get.items.relevance(res$models, "lasso")
relevance = relevance[which(relevance &gt;= 0.01)] # Select items with &gt;=1% relevance
round(relevance, 2)
</code></pre>

<hr>
<h2 id='glmnet_get.main.model'>Get the main glmnet model across imputations and folds</h2><span id='topic+glmnet_get.main.model'></span>

<h3>Description</h3>

<p>Function to choose the <code>glmnet</code> model most similar to the other models on the list according to the Dice coefficient.</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet_get.main.model(x, childname = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glmnet_get.main.model_+3A_x">x</code></td>
<td>
<p>a list of objects of class <code>"glmnet_fit"</code> or a list of objects that have a child of class <code>"glmnet_fit"</code>.</p>
</td></tr>
<tr><td><code id="glmnet_get.main.model_+3A_childname">childname</code></td>
<td>
<p>name of the child of class <code>"glmnet_fit"</code> (if <code>x</code>) is a list of objects that have a child of class <code>"glmnet_fit"</code>).</p>
</td></tr>
<tr><td><code id="glmnet_get.main.model_+3A_verbose">verbose</code></td>
<td>
<p>(optional) logical, whether to print some messages during execution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are several instances of the most similar model, it averages them.</p>


<h3>Value</h3>

<p>An object of class <code>"glmnet_fit"</code>, representing the model most similar to the other models of the list according to the Dice coefficient.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua</p>


<h3>References</h3>

<p>Sobregrau, P., Bailles, E., Radua, J., Carreno, M., Donaire, A., Setoain, X., Bargallo, N., Rumia, J., Sanchez-Vives, M.V., Pintor, L. (2024)
Design and validation of a diagnostic suspicion checklist to differentiate epileptic from psychogenic nonepileptic seizures (PNES-DSC).
<em>Journal of Psychosomatic Research</em>, <b>180</b>, 111656, doi:10.1016/j.jpsychores.2024.111656.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmnet_predict">glmnet_predict</a></code> for obtaining predictions.
<code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create random x (predictors) and y (binary)
x = matrix(rnorm(25000), ncol = 50)
y = 1 * (plogis(apply(x[,1:5], 1, sum) + rnorm(500, 0, 0.1)) &gt; 0.5)

# Predict y via cross-validation
fit_fun = function (x_training, y_training) {
  list(
    lasso = glmnet_fit(x_training, y_training, family = "binomial")
  )
}
predict_fun = function (m, x_test) {
  glmnet_predict(m$lasso, x_test)
}
# Only 2 folds to ensure the example runs quickly
res = cv(x, y, family = "binomial", fit_fun = fit_fun, predict_fun = predict_fun, nfolds = 2)

# Show the main model
lasso = glmnet_get.main.model(res$models, "lasso")
cat(
  "Model: ~plogis(", round(lasso$a0, 2), "+",
  paste0(round(lasso$beta, 2), "*", names(lasso$beta), collapse = " + "),
  ")\n"
)
</code></pre>

<hr>
<h2 id='impute.glmnet.matrix_fit'>Impute missing variables in a glmnet matrix multiple times</h2><span id='topic+impute.glmnet.matrix'></span><span id='topic+impute.glmnet.matrix_fit'></span>

<h3>Description</h3>

<p>Function to impute, multiple times, the missing variables in a <code>glmnet.matrix</code>. <code>impute.glmnet.matrix_fit</code> finds the &quot;lasso&quot; models to conduct the imputations, and <code>impute.glmnet.matrix</code> does the imputations (in the same or a different dataset).</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute.glmnet.matrix_fit(x, ncores = 1, verbose = TRUE)
impute.glmnet.matrix(m, x, nimp = 20, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="impute.glmnet.matrix_fit_+3A_m">m</code></td>
<td>
<p>model to conduct the imputations, obtained with <code><a href="#topic+impute.glmnet.matrix_fit">impute.glmnet.matrix_fit</a></code>.</p>
</td></tr>
<tr><td><code id="impute.glmnet.matrix_fit_+3A_x">x</code></td>
<td>
<p>input matrix for glmnet of dimension nobs x nvars; each row is an observation vector. It can be easily obtained with <code><a href="#topic+data.frame2glmnet.matrix">data.frame2glmnet.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="impute.glmnet.matrix_fit_+3A_ncores">ncores</code></td>
<td>
<p>number of number of worker nodes (for parallelization).</p>
</td></tr>
<tr><td><code id="impute.glmnet.matrix_fit_+3A_nimp">nimp</code></td>
<td>
<p>number of imputations</p>
</td></tr>
<tr><td><code id="impute.glmnet.matrix_fit_+3A_verbose">verbose</code></td>
<td>
<p>(optional) logical, whether to print some messages during execution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can then obtain a prediction from each dataset and combine the predictions using Rubin's rules (which usually means just averaging them). Note also that this function may take a lot of time.</p>


<h3>Value</h3>

<p>A list of complete matrixes ready for <code><a href="#topic+glmnet_fit">glmnet_fit</a></code> and <code><a href="#topic+glmnet_predict">glmnet_predict</a></code>.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua and Aleix Solanes</p>


<h3>References</h3>

<p>Solanes, A., Mezquida, G., Janssen, J., Amoretti, S., Lobo, A., Gonzalez-Pinto, A., Arango, C., Vieta, E., Castro-Fornieles, J., Berge, D., Albacete, A., Gine, E., Parellada, M., Bernardo, M.; PEPs group (collaborators); Pomarol-Clotet, E., Radua, J. (2022)
Combining MRI and clinical data to detect high relapse risk after the first episode of psychosis.
<em>Schizophrenia</em>, <b>8</b>, 100, doi:10.1038/s41537-022-00309-w.
</p>
<p>Palau, P., Solanes, A., Madre, M., Saez-Francas, N., Sarro, S., Moro, N., Verdolini, N., Sanchez, M., Alonso-Lana, S., Amann, B.L., Romaguera, A., Martin-Subero, M., Fortea, L., Fuentes-Claramonte, P., Garcia-Leon, M.A., Munuera, J., Canales-Rodriguez, E.J., Fernandez-Corcuera, P., Brambilla, P., Vieta, E., Pomarol-Clotet, E., Radua, J. (2023)
Improved estimation of the risk of manic relapse by combining clinical and brain scan data.
<em>Spanish Journal of Psychiatry and Mental Health</em>, <b>16</b>, 235&ndash;243, doi:10.1016/j.rpsm.2023.01.001.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmnet_predict">glmnet_predict</a></code> for obtaining predictions.
<code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Quick example

# Create random x with missing values
x = matrix(rnorm(300), ncol = 3)
x = x + rnorm(1) * x[,sample(1:3)] + rnorm(1) * x[,sample(1:3)]
x[sample(1:300, 30)] = NA

# Impute missing values
m_impute = impute.glmnet.matrix_fit(x, ncores = 2)
x_imputed = impute.glmnet.matrix(m_impute, x)


# Complete example (it might take some time even if the example is simple...)

  # Create random x (predictors) and y (binary)
  x = matrix(rnorm(4000), ncol = 20)
  x = x + rnorm(1) * x[,sample(1:20)] + rnorm(1) * x[,sample(1:20)]
  y = 1 * (plogis(x[,1] - x[,2] + rnorm(200, 0, 0.1)) &gt; 0.5)
  
  # Make some x missing values
  x[sample(1:4000, 400)] = NA
  
  # Predict y via cross-validation, including imputations
  fit_fun = function (x_training, y_training) {
    m = list(
      impute = impute.glmnet.matrix_fit(x_training, ncores = pmax(1, parallel::detectCores() - 2)),
      lasso = list()
    )
    x_imputed = impute.glmnet.matrix(m$impute, x_training)
    for (imp in 1:length(x_imputed)) {
      m$lasso[[imp]] = glmnet_fit(x_imputed[[imp]], y_training, family = "binomial")
    }
    m
  }
  predict_fun = function (m, x_test) {
    x_imputed = impute.glmnet.matrix(m$impute, x_test)
    y_pred = NULL
    for (imp in 1:length(x_imputed)) {
      y_pred = cbind(y_pred, glmnet_predict(m$lasso[[imp]], x_imputed[[imp]]))
    }
    apply(y_pred, 1, mean)
  }
  # Only 2 folds to ensure the example runs quickly
  res = cv(x, y, family = "binomial", fit_fun = fit_fun, predict_fun = predict_fun, nfolds = 2)
  
  # Show accuracy
  se = mean(res$predictions$y.pred[res$predictions$y == 1] &gt; 0.5)
  sp = mean(res$predictions$y.pred[res$predictions$y == 0] &lt; 0.5)
  bac = (se + sp) / 2
  cat("Sensitivity:", round(se, 2), "\n")
  cat("Specificity:", round(sp, 2), "\n")
  cat("Balanced accuracy:", round(bac, 2), "\n")

</code></pre>

<hr>
<h2 id='surv2binary'>Convert a &quot;Surv&quot; object into binary variables at different time points</h2><span id='topic+surv2binary'></span>

<h3>Description</h3>

<p>Function to convert a <code>"Surv"</code> object (e.g., the predictions obtained from <code><a href="#topic+glmnet_predict">glmnet_predict</a></code> using a <code>"cox"</code> model) into a list of binary variables (e.g., as obtained from <code><a href="#topic+glmnet_predict">glmnet_predict</a></code> using a <code>"binomial"</code> model) at different time points.</p>


<h3>Usage</h3>

<pre><code class='language-R'>surv2binary(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="surv2binary_+3A_x">x</code></td>
<td>
<p>a <code>"Surv"</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is useful, for instance, to estimate the AUC at different timepoints from <code>"cox"</code> predictions.</p>


<h3>Value</h3>

<p>A list of times and binary variables.</p>


<h3>Author(s)</h3>

<p>Joaquim Radua</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmnet_predict">glmnet_predict</a></code> for obtaining <code>"cox"</code> predictions.
<code><a href="#topic+cv">cv</a></code> for conducting a cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
library(pROC)

# Create random x (predictors) and y (survival)
x = matrix(rnorm(5000), ncol = 10)
time = rexp(500)
y = Surv(time, plogis(x[,1] / pmax(1, time^2) + rnorm(500)) &gt; 0.5)

# Predict y via cross-validation
fit_fun = function (x, y) {
  glmnet_fit(x, y, family = "cox")
}
predict_fun = function (m, x) {
  glmnet_predict(m, x)
}
res = cv(x, y, family = "cox", fit_fun = fit_fun, predict_fun = predict_fun)

# Convert y to binary
y.binary = surv2binary(y)

# Calculate and plot AUC for binary y at each timepoint
time_auc = NULL
for (i in 1:length(y.binary)) {
  status_i = y.binary[[i]]$status
  if (length(unique(na.omit(status_i))) == 2) {
    time_auc = rbind(time_auc, data.frame(
      time = y.binary[[i]]$time,
      auc = roc(status_i ~ res$predictions$y.pred, levels = 0:1, direction = "&lt;")$auc
    ))
  }
}
plot(time_auc$time, time_auc$auc, type = "l", xlab = "Time", ylab = "AUC", ylim = 0:1)
abline(h = 0.5)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
