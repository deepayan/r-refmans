<!DOCTYPE html><html><head><title>Help for package ldt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ldt}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjust_indices_after_remove'><p>Adjust Indices in a List</p></a></li>
<li><a href='#AIC.ldt.estim'><p>Akaike Information Criterion</p></a></li>
<li><a href='#BIC.ldt.estim'><p>Bayesian Information Criterion</p></a></li>
<li><a href='#boxCoxTransform'><p>Box-Cox Transformation of Numeric Matrix</p></a></li>
<li><a href='#coef.ldt.estim'><p>Extract Coefficients Matrix</p></a></li>
<li><a href='#coefs.table'><p>Create Table of Coefficients</p></a></li>
<li><a href='#combine.search'><p>Combine a List of <code>ldt.search</code> Objects</p></a></li>
<li><a href='#data.berka'><p>Berka and Sochorova (1993) Dataset for Loan Default</p></a></li>
<li><a href='#data.pcp'><p>IMF's Primary Commodity Prices</p></a></li>
<li><a href='#data.wdi'><p>Long-run Growth from World Development Indicator Dataset</p></a></li>
<li><a href='#endogenous'><p>Extract Endogenous Variable(s) Data</p></a></li>
<li><a href='#eqList2Matrix'><p>Convert a List of Equations to a Matrix</p></a></li>
<li><a href='#estim.bin'><p>Estimate a Binary Choice Model</p></a></li>
<li><a href='#estim.binary.model.string'><p>Get Model Name</p></a></li>
<li><a href='#estim.sur'><p>Estimate a SUR Model</p></a></li>
<li><a href='#estim.varma'><p>Estimate a VARMA Model</p></a></li>
<li><a href='#estim.varma.model.string'><p>Get the Specification of an <code>ldt.estim.varma</code> Model</p></a></li>
<li><a href='#exogenous'><p>Extract Exogenous Variable(s) Data</p></a></li>
<li><a href='#fan.plot'><p>Fan Plot Function</p></a></li>
<li><a href='#fitted.ldt.estim'><p>Extract Fitted Data</p></a></li>
<li><a href='#get.combinations'><p>Define Combinations for Search Process</p></a></li>
<li><a href='#get.data'><p>Transform and Prepare Data for Analysis</p></a></li>
<li><a href='#get.data.append.newX'><p>Append <code>newX</code> to <code>data$data</code> matrix.</p></a></li>
<li><a href='#get.data.check.discrete'><p>Check if a column is discrete</p></a></li>
<li><a href='#get.data.check.intercept'><p>Check for an intercept in a matrix</p></a></li>
<li><a href='#get.data.keep.complete'><p>Remove Rows with Missing Observations from Data</p></a></li>
<li><a href='#get.indexation'><p>Get Numeric Indices in a Combination</p></a></li>
<li><a href='#get.options.lbfgs'><p>Get Options for L-BFGS Optimization</p></a></li>
<li><a href='#get.options.neldermead'><p>Options for Nelder-Mead Optimization</p></a></li>
<li><a href='#get.options.newton'><p>Get Options for Newton Optimization</p></a></li>
<li><a href='#get.options.pca'><p>Get Options for PCA</p></a></li>
<li><a href='#get.options.roc'><p>Get Options for ROC and AUC Calculations</p></a></li>
<li><a href='#get.search.items'><p>Specify the Purpose of the Model Search Process</p></a></li>
<li><a href='#get.search.metrics'><p>Get Options for Measuring Performance</p></a></li>
<li><a href='#get.search.modelchecks'><p>Set Options to Exclude a Model Subset</p></a></li>
<li><a href='#get.search.options'><p>Get Extra Options for Model Search Process</p></a></li>
<li><a href='#get.varma.params'><p>Split VARMA parameter into its Components</p></a></li>
<li><a href='#logLik.ldt.estim'><p>Extract Maximum Log-Likelihood</p></a></li>
<li><a href='#plot.ldt.estim'><p>Plot Diagnostics for <code>ldt.estim</code> Object</p></a></li>
<li><a href='#plot.ldt.varma.prediction'><p>Plot Predictions from a VARMA model</p></a></li>
<li><a href='#predict.ldt.estim'><p>Extract Prediction Results</p></a></li>
<li><a href='#predict.ldt.estim.varma'><p>Extract Prediction Results from a <code>ldt.estim.varma</code> Object</p></a></li>
<li><a href='#print.ldt.estim'><p>Prints an <code>ldt.estim</code> object</p></a></li>
<li><a href='#print.ldt.estim.projection'><p>Prints an <code>ldt.estim.projection</code> object</p></a></li>
<li><a href='#print.ldt.list'><p>Prints an <code>ldt.list</code> object</p></a></li>
<li><a href='#print.ldt.search'><p>Prints an <code>ldt.search</code> object</p></a></li>
<li><a href='#print.ldt.varma.prediction'><p>Prints an <code>ldt.varma.prediction</code> object</p></a></li>
<li><a href='#rand.mnormal'><p>Generate Random Samples from a Multivariate Normal Distribution</p></a></li>
<li><a href='#residuals.ldt.estim'><p>Extract Residuals Data</p></a></li>
<li><a href='#s.cluster.h'><p>Hierarchical Clustering</p></a></li>
<li><a href='#s.cluster.h.group'><p>Group Variables with Hierarchical Clustering</p></a></li>
<li><a href='#s.combine.stats4'><p>Combine Mean, Variance, Skewness, and Kurtosis</p>
This function combines two sets of mean, variance, skewness, and kurtosis and generates the combined statistics.</a></li>
<li><a href='#s.distance'><p>Get the Distances Between Variables</p></a></li>
<li><a href='#s.gld.density.quantile'><p>GLD Density-Quantile Function</p></a></li>
<li><a href='#s.gld.from.moments'><p>Get the GLD Parameters from the moments</p></a></li>
<li><a href='#s.gld.quantile'><p>GLD Quantile Function</p></a></li>
<li><a href='#s.metric.from.weight'><p>Convert a Weight to Metric</p></a></li>
<li><a href='#s.pca'><p>Principal Component Analysis</p></a></li>
<li><a href='#s.roc'><p>Get ROC Curve Data for Binary Classification</p></a></li>
<li><a href='#s.weight.from.metric'><p>Convert a Metric to Weight</p></a></li>
<li><a href='#search.bin'><p>Create a Model Set for Binary Choice Models</p></a></li>
<li><a href='#search.rfunc'><p>Create a Model Set for an R Function</p></a></li>
<li><a href='#search.steps'><p>Step-wise estimation</p></a></li>
<li><a href='#search.sur'><p>Create a Model Set for SUR Models</p></a></li>
<li><a href='#search.varma'><p>Create Model Set for VARMA Models</p></a></li>
<li><a href='#sim.bin'><p>Generate Random Sample from a DC Model</p></a></li>
<li><a href='#sim.sur'><p>Generate Random Sample from an SUR Model</p></a></li>
<li><a href='#sim.varma'><p>Generate Random Sample from a VARMA Model</p></a></li>
<li><a href='#summary.ldt.search'><p>Summary for an <code>ldt.search</code> object</p></a></li>
<li><a href='#summary.ldt.search.item'><p>Summary for an <code>ldt.search.item</code> object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Automated Uncertainty Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods and tools for model selection and multi-model inference (Burnham and Anderson (2002) &lt;<a href="https://doi.org/10.1007%2Fb97636">doi:10.1007/b97636</a>&gt;, among others). 
             'SUR' (for parameter estimation), 'logit'/'probit' (for binary classification), and 'VARMA' (for time-series forecasting) are implemented.
             Evaluations are both in-sample and out-of-sample. 
             It is designed to be efficient in terms of CPU usage and memory consumption.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/rmojab63/LDT">https://github.com/rmojab63/LDT</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, tdata, Rdpack (&ge; 0.7), MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, testthat, rmarkdown, kableExtra, moments, systemfit</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, Rcpp</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-19 16:56:57 UTC; rmoja</td>
</tr>
<tr>
<td>Author:</td>
<td>Ramin Mojab [aut, cre],
  Stephen Becker [cph] (BSD 3-clause license. Original code for L-BFGS-B
    algorithm. The L-BFGS-B algorithm was written in the 1990s (mainly
    1994, some revisions 1996) by Ciyou Zhu (in collaboration with R.H.
    Byrd, P. Lu-Chen and J. Nocedal). L-BFGS-B Version 3.0 is an
    algorithmic update from 2011, with coding changes by J. L. Morales)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ramin Mojab &lt;rmojab63@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-21 09:00:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjust_indices_after_remove'>Adjust Indices in a List</h2><span id='topic+adjust_indices_after_remove'></span>

<h3>Description</h3>

<p>This function adjusts a list of indices after certain indices have been removed.
The new indices will point to the same elements as the original indices.
If an index is removed, it will also be removed from the indices list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_indices_after_remove(indicesList, removedIndices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust_indices_after_remove_+3A_indiceslist">indicesList</code></td>
<td>
<p>A list of integer vectors, each representing a set of indices.</p>
</td></tr>
<tr><td><code id="adjust_indices_after_remove_+3A_removedindices">removedIndices</code></td>
<td>
<p>A vector of integers representing the indices to be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of adjusted indices. Each set of indices is adjusted separately.
</p>

<hr>
<h2 id='AIC.ldt.estim'>Akaike Information Criterion</h2><span id='topic+AIC.ldt.estim'></span>

<h3>Description</h3>

<p>This function extracts Akaike information criterion from an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
AIC(object, ..., k = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AIC.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code></p>
</td></tr>
<tr><td><code id="AIC.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="AIC.ldt.estim_+3A_k">k</code></td>
<td>
<p>Unused parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of AIC for the whole system.
#' @importFrom stats AIC
</p>

<hr>
<h2 id='BIC.ldt.estim'>Bayesian Information Criterion</h2><span id='topic+BIC.ldt.estim'></span>

<h3>Description</h3>

<p>This function extracts Baysian information criterion from an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
BIC(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code></p>
</td></tr>
<tr><td><code id="BIC.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of BIC for the whole system.
</p>

<hr>
<h2 id='boxCoxTransform'>Box-Cox Transformation of Numeric Matrix</h2><span id='topic+boxCoxTransform'></span>

<h3>Description</h3>

<p>This function applies the Box-Cox transformation to the columns of a numeric matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boxCoxTransform(data, lambdas, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boxCoxTransform_+3A_data">data</code></td>
<td>
<p>A numeric matrix to be transformed.</p>
</td></tr>
<tr><td><code id="boxCoxTransform_+3A_lambdas">lambdas</code></td>
<td>
<p>A numeric vector, a single number, NA, or NULL indicating the lambda parameter(s) for the Box-Cox transformation.
Use <code>NULL</code> for no transformation, <code>NA</code> for estimating the lambda parameter for each variable,
a single number for equal lambda parameter for all variables, and a numeric vector for distinct lambda parameters for the corresponding variables.</p>
</td></tr>
<tr><td><code id="boxCoxTransform_+3A_...">...</code></td>
<td>
<p>additional parameters for <code>MASS::boxcox</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>data</code></td>
<td>
<p>transformed data</p>
</td></tr>
<tr><td><code>lambdas</code></td>
<td>
<p>final lambda vector used in the calculations.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- matrix(rnorm(40), ncol = 2)
result &lt;- ldt:::boxCoxTransform(data, c(0.5, 0.5))

</code></pre>

<hr>
<h2 id='coef.ldt.estim'>Extract Coefficients Matrix</h2><span id='topic+coef.ldt.estim'></span>

<h3>Description</h3>

<p>This function extracts coefficient matrix from an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
coef(object, equations = NULL, removeZeroRest = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code></p>
</td></tr>
<tr><td><code id="coef.ldt.estim_+3A_equations">equations</code></td>
<td>
<p>A number, a numeric array or a string array specifying the indices or names of the endogenous variables in the equations.
<code>NULL</code> means all equations.</p>
</td></tr>
<tr><td><code id="coef.ldt.estim_+3A_removezerorest">removeZeroRest</code></td>
<td>
<p>If <code>TRUE</code> and model is restricted, zero restrictions are removed.</p>
</td></tr>
<tr><td><code id="coef.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If zero restrictions are not removed, it is a matrix containing the coefficients of the system.
Each column of the matrix belongs to an equation. Explanatory variables are in the rows.
Otherwise, coefficients of different equations are reported in a list.
</p>

<hr>
<h2 id='coefs.table'>Create Table of Coefficients</h2><span id='topic+coefs.table'></span>

<h3>Description</h3>

<p>This function summarizes a list of estimated models (output of <code>estim.?</code> functions) and creates
a table of coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefs.table(
  estimList,
  depList = NULL,
  tableFun = "coef_star",
  formatNumFun = NULL,
  regInfo = NULL,
  textFun = NULL,
  textFun_sub = NULL,
  textFun_max = 20,
  expList = NA,
  latex = TRUE,
  numFormat = "%.2f"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefs.table_+3A_estimlist">estimList</code></td>
<td>
<p>A named list where each element is output from a <code>estim.?</code> function, all belonging to a common analysis.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_deplist">depList</code></td>
<td>
<p>List of endogenous variable name to be included in the columns of the table. If <code>NULL</code>, everything is added.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_tablefun">tableFun</code></td>
<td>
<p>Function with arguments <code>coef</code>, <code>std</code>, <code>pvalue</code>, <code>minInColm</code>, <code>maxInCol</code> for formatting estimated coefficients.
Can also use one of the following character strings for predefined formatting: <code>sign</code>, <code>sign_star</code>, <code>coef</code>, <code>coef_star</code>, <code>coef_star_std</code>.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_formatnumfun">formatNumFun</code></td>
<td>
<p>Function to format numbers if <code>tableFun</code> uses predefined formatting. It takes two arguments: <code>colIndex</code> (determines the column index) and <code>x</code> (determines the value).</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_reginfo">regInfo</code></td>
<td>
<p>List of keys (such as <code>num_eq</code>, <code>num_dep</code>, ...) to determine information at bottom of table. Use &quot;&quot; (empty) for empty rows.
A list of available options is given in the details section.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_textfun">textFun</code></td>
<td>
<p>Function to change any text in columns or rows of the table to a more informative text.
It has two arguments: <code>text</code> and <code>type</code>.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_textfun_sub">textFun_sub</code></td>
<td>
<p>List for replacing special characters. If <code>NULL</code>, 'list(c(&quot;%&quot;, &quot;\\%&quot;), c(&quot;<em>&quot;, &quot;\\</em>&quot;))' is used.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_textfun_max">textFun_max</code></td>
<td>
<p>Maximum length for texts in the table.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_explist">expList</code></td>
<td>
<p>Determines the name of the explanatory variables to insert in table.
If <code>NA</code>, it inserts all coefficients.
If it is an integer, it insert that number of explanatory variables in the table.
It can be a list of available explanatory variables.
Use <code>...</code> for empty rows.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_latex">latex</code></td>
<td>
<p>If <code>TRUE</code>, default options are for 'latex', otherwise, 'html'.</p>
</td></tr>
<tr><td><code id="coefs.table_+3A_numformat">numFormat</code></td>
<td>
<p>default formatting for the numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first part of the table is the header, followed by the coefficients. At the bottom, you can insert
the following items by specifying <code>regInfo</code>:
</p>

<ul>
<li><p> An empty character string (i.e., &quot;&quot;) for inserting empty line.
</p>
</li>
<li> <p><code>"sigma2"</code> for the covariance of regression, if it is available.
</p>
</li>
<li><p> An available metric name in the row names of <code>estimList[[...]]$metrics</code>.
</p>
</li></ul>

<p>Furthermore, second argument in <code>textFun</code> can be:
</p>

<ul>
<li> <p><code>hname</code>: shows that the text is a header name from the <code>estimList</code> elements.
</p>
</li>
<li> <p><code>dname</code>: shows that the text is an endogenous variable name from the columns of <code>coefs</code> matrix.
</p>
</li>
<li> <p><code>rname</code>: shows that the text is a key given in <code>regInfo</code>.
</p>
</li>
<li> <p><code>ename</code>: shows that the text is an explanatory variable name from the rows of <code>coefs</code> matrix.
</p>
</li>
<li> <p><code>NULL</code>: shows that the text is a specific code or something else.
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame with (formatted) requested information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See 'search.?' or 'estim.?' functions for some examples.

</code></pre>

<hr>
<h2 id='combine.search'>Combine a List of <code>ldt.search</code> Objects</h2><span id='topic+combine.search'></span>

<h3>Description</h3>

<p>Combine a List of <code>ldt.search</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine.search(list, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combine.search_+3A_list">list</code></td>
<td>
<p>A list of <code>ldt.search</code> objects</p>
</td></tr>
<tr><td><code id="combine.search_+3A_method">method</code></td>
<td>
<p>Method in objects</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the combined <code>ldtsearch</code> object
</p>

<hr>
<h2 id='data.berka'>Berka and Sochorova (1993) Dataset for Loan Default</h2><span id='topic+data.berka'></span>

<h3>Description</h3>

<p>This dataset is a part of the Berka and Sochorova (1993) study, which contains information on loan defaults. The data was generated using the code in the '/data-raw/data-berka.R' file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.berka
</code></pre>


<h3>Format</h3>

<p>A list with the following items:
</p>

<dl>
<dt>y</dt><dd><p>A vector representing the labels. It contains 1 for default and 0 for non-default. Any observation with default (i.e., 'default' and 'finished with default') is considered to be a positive.</p>
</dd>
<dt>x</dt><dd><p>A matrix with explanatory variables in the columns.</p>
</dd>
<dt>w</dt><dd><p>A vector with the weight of each observation. This is mathematically generated to balance the observations.</p>
</dd>
<dt>descriptions</dt><dd><p>A list that describes the column names.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Berka and Sochorova (1993)
</p>

<hr>
<h2 id='data.pcp'>IMF's Primary Commodity Prices</h2><span id='topic+data.pcp'></span>

<h3>Description</h3>

<p>This is a subset of the IMF's Primary Commodity Prices dataset (non-index data is omitted).
The data was generated using the code in the '/data-raw/data-pcp.R' file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.pcp
</code></pre>


<h3>Format</h3>

<p>A list with the following items:
</p>

<dl>
<dt>data</dt><dd><p>A data frame with monthly variables in the columns.</p>
</dd>
<dt>descriptions</dt><dd><p>A list that describes the columns of <code>data</code>.</p>
</dd>
<dt>datatypes</dt><dd><p>A character array that describes the type of data in the columns of <code>data</code>.</p>
</dd>
<dt>start</dt><dd><p>A number that indicates the frequency of the first observation in <code>data</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>International Commodity Prices (2023)
</p>

<hr>
<h2 id='data.wdi'>Long-run Growth from World Development Indicator Dataset</h2><span id='topic+data.wdi'></span>

<h3>Description</h3>

<p>This dataset is derived from the World Development Indicator (WDI) dataset. It contains information on long-run output growth after 2006 and its potential explanatory variables before that year. The data was generated using the code in the '/data-raw/data-wdi.R' file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.wdi
</code></pre>


<h3>Format</h3>

<p>A list with the following items:
</p>

<dl>
<dt>y</dt><dd><p>A vector representing the long-run output growth after 2006. Each element represents a country.</p>
</dd>
<dt>x</dt><dd><p>A matrix with explanatory variables in the columns. Each row represents a country.</p>
</dd>
<dt>splitYear</dt><dd><p>A number that indicates how <code>y</code> and <code>x</code> are calculated.</p>
</dd>
<dt>names</dt><dd><p>A list of pairs that describe the code and the name of variables in <code>y</code> and <code>x</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>World Bank (2022)
</p>

<hr>
<h2 id='endogenous'>Extract Endogenous Variable(s) Data</h2><span id='topic+endogenous'></span>

<h3>Description</h3>

<p>This function extracts data of a endogenous variable(s) from an estimated model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>endogenous(object, equations = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="endogenous_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code>.</p>
</td></tr>
<tr><td><code id="endogenous_+3A_equations">equations</code></td>
<td>
<p>A number, a numeric array or a string array specifying the indices or names of the endogenous variables in the equations. <code>NULL</code> means all equations.</p>
</td></tr>
<tr><td><code id="endogenous_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the endogenous data.
</p>

<hr>
<h2 id='eqList2Matrix'>Convert a List of Equations to a Matrix</h2><span id='topic+eqList2Matrix'></span>

<h3>Description</h3>

<p>This function takes a list of equations and a data frame, and returns a matrix where the response variables are in the first columns, and the predictor variables are in the subsequent columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eqList2Matrix(equations, data, addIntercept = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eqList2Matrix_+3A_equations">equations</code></td>
<td>
<p>A formula or a list of formula objects representing the equations.</p>
</td></tr>
<tr><td><code id="eqList2Matrix_+3A_data">data</code></td>
<td>
<p>A matrix or a data frame containing the variables in the equations.</p>
</td></tr>
<tr><td><code id="eqList2Matrix_+3A_addintercept">addIntercept</code></td>
<td>
<p>Logical. If <code>TRUE</code>, an intercept column is added after the response variables. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function checks for duplicate response variables across equations and throws an error if any are found. It also ensures that predictor variables are not duplicated in the final matrix.
</p>


<h3>Value</h3>

<table>
<tr><td><code>result</code></td>
<td>
<p>A matrix with response variables in the first columns, predictor variables in subsequent columns, and optionally an intercept column. The matrix does not contain duplicate columns.</p>
</td></tr>
<tr><td><code>numResponse</code></td>
<td>
<p>Number of response variables in the first columns.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- data.frame(income = c(50000, 60000, 80000, 85000, 65000),
                   age = c(25, 32, 47, 51, 36),
                   education = c(16, 18, 20, 20, 16),
                   savings = c(20000, 25000, 30000, 35000, 40000))
equations &lt;- list(as.formula("income ~ age + education"),
                  as.formula("savings ~ age + education"))
matrix_data &lt;- ldt:::eqList2Matrix(equations, data, addIntercept = TRUE)
print(matrix_data)

</code></pre>

<hr>
<h2 id='estim.bin'>Estimate a Binary Choice Model</h2><span id='topic+estim.bin'></span>

<h3>Description</h3>

<p>Use this function to estimate a binary choice model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim.bin(
  data,
  linkFunc = c("logit", "probit"),
  pcaOptionsX = NULL,
  costMatrices = NULL,
  optimOptions = get.options.newton(),
  aucOptions = get.options.roc(),
  simFixSize = 0,
  simTrainFixSize = 0,
  simTrainRatio = 0.75,
  simSeed = 0,
  weightedEval = FALSE,
  simMaxConditionNumber = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estim.bin_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the model search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_linkfunc">linkFunc</code></td>
<td>
<p>A character string that shows the probability assumption. It can be <code>logit</code> or <code>probit</code>.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_pcaoptionsx">pcaOptionsX</code></td>
<td>
<p>A list of options to use principal components of the <code>x</code>, instead of the actual values. Set <code>NULL</code> to disable. Use <code><a href="#topic+get.options.pca">get.options.pca()</a></code> for initialization.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_costmatrices">costMatrices</code></td>
<td>
<p>A list of numeric matrices where each one determines how to score the calculated probabilities. See and use <a href="#topic+search.bin">search.bin</a> for more information and initialization.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_optimoptions">optimOptions</code></td>
<td>
<p>A list for Newton optimization options. Use <a href="#topic+get.options.newton">get.options.newton</a> function to get the options.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_aucoptions">aucOptions</code></td>
<td>
<p>A list of options for AUC calculation. See and use <code>[get.options.roc()]</code> for more information and initialization.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_simfixsize">simFixSize</code></td>
<td>
<p>An integer that determines the number of out-of-sample simulations. Use zero to disable the simulation.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_simtrainfixsize">simTrainFixSize</code></td>
<td>
<p>An integer representing the number of data points in the training sample in the out-of-sample simulation. If zero, <code>trainRatio</code> will be used.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_simtrainratio">simTrainRatio</code></td>
<td>
<p>A number representing the size of the training sample relative to the available size, in the out-of-sample simulation. It is effective if <code>trainFixSize</code> is zero.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_simseed">simSeed</code></td>
<td>
<p>A seed for the random number generator. Use zero for a random value.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_weightedeval">weightedEval</code></td>
<td>
<p>If <code>TRUE</code>, weights will be used in evaluations.</p>
</td></tr>
<tr><td><code id="estim.bin_+3A_simmaxconditionnumber">simMaxConditionNumber</code></td>
<td>
<p>A number for the maximum value for the condition number in the simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As documented in chapter 12 in Greene and Hensher (2010), binary regression is a statistical technique used to estimate the probability of one of two possible outcomes for a variable such as <code class="reqn">y</code>, i.e., <code class="reqn">p=P(y=1)</code> and <code class="reqn">q=P(y=0)</code>. The most commonly used binary regression models are the logit and probit models. In general, a binary regression model can be written as <code class="reqn">f(p) = z'\gamma+v</code>, where the first element in <code class="reqn">\gamma</code> is the intercept and <code class="reqn">f(p)</code> is a link function. For logit and probit models we have <code class="reqn">f(p) = \ln{\frac{p}{1-p}}</code> and <code class="reqn">f(p) = \Phi^{-1}(p)</code> respectively, where <code class="reqn">\Phi^{-1}</code> is the inverse cumulative distribution function of the standard normal distribution.
</p>
<p>Given an independent sample of length <code class="reqn">N</code>, the parameters of the binary regression model are estimated using maximum likelihood estimation. Assuming that some observations are more reliable or informative than others and <code class="reqn">w_i</code> for <code class="reqn">i=1,\ldots,N</code> reflects this fact, the likelihood function is given by:
</p>
<p style="text-align: center;"><code class="reqn">
L(\gamma) = \prod_{i=1}^N (p_i)^{w_i y_i} (1-p_i)^{w_i (1-y_i)},
</code>
</p>

<p>where <code class="reqn">p_i=\frac{\exp{\gamma z_i}}{1+\exp{\gamma z_i}}</code> for logit model and <code class="reqn">p_i=\Phi(\gamma z_i)</code> for probit model. <code>ldt</code> uses feasible GLS to calculate the initial value of the coefficients and a weighted least squares estimator to calculate the initial variance matrix of the error terms (see page 781 in Greene (2020)). The condition number of the estimation is calculated by multiplying 1-norm of the observed information matrix at the maximum likelihood estimator and its inverse (e.g., see page 94 in Trefethen and Bau (1997)). Furthermore, if <code class="reqn">x</code> is a new observations for the explanatory variables, the predicted probability of the positive class is estimated by <code class="reqn">p_i=\frac{\exp{\gamma x}}{1+\exp{\gamma x}}</code> for logit model and <code class="reqn">p_i=\Phi(\gamma x)</code> for probit model.
</p>
<p>Note that the focus in <code>ldt</code> is model uncertainty and the main purpose of exporting this method is to show the inner calculations of the search process in <a href="#topic+search.bin">search.bin</a> function.
</p>


<h3>References</h3>

<p>Greene WH (2020).
<em>Econometric analysis</em>, 8th edition.
Pearson Education Limited, New York.
ISBN 9781292231136.<br /><br /> Greene WH, Hensher DA (2010).
<em>Modeling ordered choices: A primer</em>.
Cambridge University Press.
ISBN 9780511845062, <a href="https://doi.org/10.1017/cbo9780511845062">doi:10.1017/cbo9780511845062</a>.<br /><br /> Trefethen LN, Bau D (1997).
<em>Numerical linear algebra</em>.
Society for Industrial and Applied Mathematics.
ISBN 9780898714876.
</p>


<h3>See Also</h3>

<p><a href="#topic+search.bin">search.bin</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1 (simulation, small model):
set.seed(123)
sample &lt;- sim.bin(3L, 100)
print(sample$coef)

data &lt;- data.frame(sample$y, sample$x)

#   Estimate using glm
fit &lt;- glm(Y ~ X1 + X2, data = data, family = binomial())
print(fit)

#   Estimate using 'ldt::estim.bin'
fit &lt;- estim.bin(data = get.data(data = data,
                                 equations = list(Y ~ X1 + X2)),
                  linkFunc = "logit")
print(fit)
plot_data &lt;- plot(fit, type = 1)
#   See 'plot.ldt.estim()' function documentation


# Example 2 (simulation, large model with PCA analysis):
sample &lt;- sim.bin(30L, 100, probit = TRUE)
data &lt;- data.frame(sample$y, sample$x)
colnames(data) &lt;- c(colnames(sample$y),colnames(sample$x))
pca_options &lt;- get.options.pca(ignoreFirst = 1, exactCount = 3)
fit &lt;- estim.bin(data = get.data(cbind(sample$y, sample$x),
                                  endogenous = ncol(sample$y),
                                  addIntercept = FALSE),
                  linkFunc = "probit",
                  pcaOptionsX = pca_options)
print(fit)
plot_data &lt;- plot(fit, type = 2)
</code></pre>

<hr>
<h2 id='estim.binary.model.string'>Get Model Name</h2><span id='topic+estim.binary.model.string'></span>

<h3>Description</h3>

<p>Get Model Name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim.binary.model.string(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estim.binary.model.string_+3A_object">object</code></td>
<td>
<p>A <code>estim.bin</code> object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model string
</p>

<hr>
<h2 id='estim.sur'>Estimate a SUR Model</h2><span id='topic+estim.sur'></span>

<h3>Description</h3>

<p>Use this function to estimate a Seemingly Unrelated Regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim.sur(
  data,
  searchSigMaxIter = 0,
  searchSigMaxProb = 0.1,
  restriction = NULL,
  pcaOptionsY = NULL,
  pcaOptionsX = NULL,
  simFixSize = 0,
  simTrainFixSize = 0,
  simTrainRatio = 0.75,
  simSeed = 0,
  simMaxConditionNumber = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estim.sur_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_searchsigmaxiter">searchSigMaxIter</code></td>
<td>
<p>An integer for the maximum number of iterations in searching for significant coefficients. Use 0 to disable the search.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_searchsigmaxprob">searchSigMaxProb</code></td>
<td>
<p>A number for the maximum value of type I error to be used in searching for significant coefficients. If p-value is less than this, it is interpreted as significant.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_restriction">restriction</code></td>
<td>
<p>A <code>km x q</code> matrix of restrictions where <code>m</code> is the number of endogenous data, <code>k</code> is the number of exogenous data, and <code>q</code> is the number of unrestricted coefficients.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_pcaoptionsy">pcaOptionsY</code></td>
<td>
<p>A list of options to use principal components of the endogenous data, instead of the actual values. Set <code>NULL</code> to disable. Use <code><a href="#topic+get.options.pca">get.options.pca()</a></code> for initialization.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_pcaoptionsx">pcaOptionsX</code></td>
<td>
<p>A list of options to use principal components of the exogenous data, instead of the actual values. Set <code>NULL</code> to disable. Use <code><a href="#topic+get.options.pca">get.options.pca()</a></code> for initialization.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_simfixsize">simFixSize</code></td>
<td>
<p>An integer that determines the number of out-of-sample simulations. Use zero to disable the simulation.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_simtrainfixsize">simTrainFixSize</code></td>
<td>
<p>An integer representing the number of data points in the training sample in the out-of-sample simulation. If zero, <code>trainRatio</code> will be used.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_simtrainratio">simTrainRatio</code></td>
<td>
<p>A number representing the size of the training sample relative to the available size, in the out-of-sample simulation. It is effective if <code>trainFixSize</code> is zero.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_simseed">simSeed</code></td>
<td>
<p>A seed for the random number generator. Use zero for a random value.</p>
</td></tr>
<tr><td><code id="estim.sur_+3A_simmaxconditionnumber">simMaxConditionNumber</code></td>
<td>
<p>A number for the maximum value for the condition number in the simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As described in section 10.2 in Greene (2020), this type of statistical model consists of multiple regression equations, where each equation may have a different set of exogenous variables and the disturbances between the equations are assumed to be correlated. The general form with <code class="reqn">m</code> equations can be written as <code class="reqn">y_i=z_i'\gamma_i+v_i</code> and <code class="reqn">E(v_i v_j)=\sigma_{ij}^2</code> for <code class="reqn">i=1,\ldots m</code>. Assuming that a sample of <code class="reqn">N</code> independent observations is available, we can stack the observations and use the following system for estimation:
</p>
<p style="text-align: center;"><code class="reqn">
Y = X B + V, \quad \mathrm{vec}B = R\gamma,
</code>
</p>

<p>where the columns of <code class="reqn">Y:N \times m</code> contain the endogenous variables for each equation and the columns of <code class="reqn">X: N\times k</code> contain the explanatory variables, with <code class="reqn">k</code> being the number of unique explanatory variables in all equations. Note that <code class="reqn">X</code> combines the <code class="reqn">z_i</code> variables, and the restrictions imposed by <code class="reqn">R:mk\times q</code> and <code class="reqn">\gamma:q\times 1</code> determine a set of zero constraints on <code class="reqn">B: k \times m</code>, resulting in a system of equations with different sets of exogenous variables.
</p>
<p>Imposing restrictions on the model using the <code class="reqn">R</code> matrix is not user-friendly, but it is suitable for use in this package, as users are not expected to specify such restrictions, but only to provide a list of potential regressors. Note that in this package, most procedures, including significance search, are supposed to be automated.
</p>
<p>The unrestricted estimators (i.e., <code class="reqn">\hat{B}=(X'X)^{-1}X'Y</code>, and <code class="reqn">\hat{\Sigma}=(\hat{V}'\hat{V})/N</code> where <code class="reqn">\hat{V}=Y-X\hat{B}</code>) are used to initialize the feasible GLS estimators:
</p>
<p style="text-align: center;"><code class="reqn">
    \tilde{B} = RW^{-1}R'[\hat{V}-1 \otimes x']\mathrm{vec}Y, \quad \tilde{\Sigma}=(\tilde{V}'\tilde{V})/N,
</code>
</p>

<p>where <code class="reqn">W = R'[\hat{V}^{-1} \otimes X'X]R</code> and <code class="reqn">\tilde{V}=Y-X\tilde{B}</code>. The properties of these estimators are discussed in proposition 5.3 in Lütkepohl (2005). See also section 10.2 in Greene (2020). The maximum likelihood value is calculated by <code class="reqn">-\frac{N}{2}(m(\ln 2\pi+1)+\ln|\tilde{\Sigma}|)</code>. The condition number is calculated by multiplying 1-norm of <code class="reqn">W</code> and its inverse (e.g., see page 94 in Trefethen and Bau (1997)). Furthermore, given an out-of-sample observation such as <code class="reqn">x:k\times 1</code>, the prediction is <code class="reqn">y^f = \tilde{B}'x</code>, and its variance is estimated by the following formula:
</p>
<p style="text-align: center;"><code class="reqn">
     \mathrm{var}y^f = \tilde{V} + (x' \otimes I_m)R W^{-1}R'(x \otimes I_m).
</code>
</p>

<p>Note that the focus in <code>ldt</code> is model uncertainty and for more sophisticated implementations of the FGLS estimator, you may consider using other packages such as <code>systemfit</code>.
</p>
<p>Finally, note that the main purpose of exporting this method is to show the inner calculations of the search process in <a href="#topic+search.sur">search.sur</a> function.
</p>


<h3>References</h3>

<p>Greene WH (2020).
<em>Econometric analysis</em>, 8th edition.
Pearson Education Limited, New York.
ISBN 9781292231136.<br /><br /> Lütkepohl H (2005).
<em>New introduction to multiple time series analysis</em>.
Springer, Berlin.
ISBN 3540401725, <a href="https://doi.org/10.1007/978-3-540-27752-1">doi:10.1007/978-3-540-27752-1</a>.<br /><br /> Trefethen LN, Bau D (1997).
<em>Numerical linear algebra</em>.
Society for Industrial and Applied Mathematics.
ISBN 9780898714876.
</p>


<h3>See Also</h3>

<p><a href="#topic+search.sur">search.sur</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1 (simulation, small model):
set.seed(123)
sample &lt;- sim.sur(sigma = 2L, coef = 3L, nObs = 100)
print(sample$coef)
print(sample$sigma)

data &lt;- data.frame(sample$y, sample$x)

#    Use systemfit to estimate:
exp_names &lt;- paste0(colnames(sample$x), collapse = " + ")
fmla &lt;- lapply(1:ncol(sample$y), function(i) as.formula(paste0("Y", i, " ~ -1 +", exp_names)))
fit &lt;- systemfit::systemfit(fmla, data = data, method = "SUR")
print(fit)

#    Use 'ldt::estim.sur' function
fit &lt;- estim.sur(data = get.data(cbind(sample$y, sample$x),
                                  endogenous = ncol(sample$y),
                                  addIntercept = FALSE))

# or, by using formula list:
fit &lt;- estim.sur(data = get.data(data = data,
                                 equations = fmla,
                                 addIntercept = FALSE))

print(fit)
print(fit$estimations$sigma)
plot_data &lt;- plot(fit, equation = 1)


# Example 2 (simulation, large model with significancy search):
num_obs &lt;- 100
sample &lt;- sim.sur(sigma = 2L, coef = 3L, nObs = num_obs)
print(sample$coef)

#   create irrelevant data:
num_x_ir &lt;- 20
x_ir &lt;- matrix(rnorm(num_obs * num_x_ir), ncol = num_x_ir)
data_x &lt;- data.frame(sample$x, x_ir)
colnames(data_x) &lt;- c(colnames(sample$x), paste0("z", 1:num_x_ir))

fit &lt;- estim.sur(data = get.data(cbind(sample$y, data_x),
                                 endogenous = ncol(sample$y),
                                 addIntercept = FALSE),
                 searchSigMaxIter = 100,
                 searchSigMaxProb = 0.05)

print(fit$estimations$coefs)
# coefficient matrix, with lots of zero restrictions

# Example 3 (simulation, large model with PCA):
#   by using data of the previous example
fit &lt;- estim.sur(data = get.data(cbind(sample$y, data_x),
                                 endogenous = ncol(sample$y),
                                 addIntercept = FALSE),
                 pcaOptionsX = get.options.pca(2,4))
print(fit$estimations$coefs)
#  coefficients are: intercept and the first exogenous variable and 4 PCs

</code></pre>

<hr>
<h2 id='estim.varma'>Estimate a VARMA Model</h2><span id='topic+estim.varma'></span>

<h3>Description</h3>

<p>Use this function to estimate a Vector Autoregressive Moving Average model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim.varma(
  data,
  params = NULL,
  seasonsCount = 0,
  lbfgsOptions = get.options.lbfgs(),
  olsStdMultiplier = 2,
  pcaOptionsY = NULL,
  pcaOptionsX = NULL,
  maxHorizon = 0,
  simFixSize = 0,
  simHorizons = NULL,
  simUsePreviousEstim = FALSE,
  simMaxConditionNumber = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estim.varma_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_params">params</code></td>
<td>
<p>An integer vector that determines the values for the parameters of the VARMA model: <code>(p,d,q,P,D,Q)</code>. If <code>NULL</code>, <code>c(1,0,0,0,0,0)</code> is used.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_seasonscount">seasonsCount</code></td>
<td>
<p>An integer value representing the number of observations per unit of time.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_lbfgsoptions">lbfgsOptions</code></td>
<td>
<p>A list containing L-BFGS optimization options. Use <a href="#topic+get.options.lbfgs">get.options.lbfgs</a> function for initialization.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_olsstdmultiplier">olsStdMultiplier</code></td>
<td>
<p>A number used as a multiplier for the standard deviation of OLS, used for restricting maximum likelihood estimation.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_pcaoptionsy">pcaOptionsY</code></td>
<td>
<p>A list of options to use principal components of <code>y</code>, instead of the actual values. Set to <code>NULL</code> to disable. Use <code><a href="#topic+get.options.pca">get.options.pca()</a></code> for initialization.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_pcaoptionsx">pcaOptionsX</code></td>
<td>
<p>A list of options to use principal components of <code>x</code>, instead of the actual values. Set to <code>NULL</code> to disable. Use <code><a href="#topic+get.options.pca">get.options.pca()</a></code> for initialization.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_maxhorizon">maxHorizon</code></td>
<td>
<p>An integer representing the maximum prediction horizon. Set to zero to disable prediction.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_simfixsize">simFixSize</code></td>
<td>
<p>An integer that determines the number of out-of-sample simulations. Use zero to disable simulation.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_simhorizons">simHorizons</code></td>
<td>
<p>An integer vector representing the prediction horizons to be used in out-of-sample simulations. See also <code><a href="#topic+get.search.metrics">get.search.metrics()</a></code>.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_simusepreviousestim">simUsePreviousEstim</code></td>
<td>
<p>If <code>TRUE</code>, parameters are initialized only in the first step of the simulation. The initial values of the n-th simulation (with one more observation) are the estimations from the previous step.</p>
</td></tr>
<tr><td><code id="estim.varma_+3A_simmaxconditionnumber">simMaxConditionNumber</code></td>
<td>
<p>A number representing the maximum value for the condition number in simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The VARMA model can be used to analyze multivariate time series data with seasonal or non-seasonal patterns. According to Lütkepohl (2005), it considers interdependencies between the series, making it a powerful tool for prediction. The specification of this model is given by:
</p>
<p style="text-align: center;"><code class="reqn">
\Delta^d \Delta_s^D y_t = c + \sum_{i=1}^p A_i y_{t-i} + \sum_{i=1}^q B_i \epsilon_{t-i} + C x_t + \sum_{i=1}^P A_{is} y_{t-is} + \sum_{i=1}^Q B_{is} v_{t-is} + v_t,
</code>
</p>

<p>where <code class="reqn">y_t:m\times 1</code> is the vector of endogenous variables, <code class="reqn">x_t:k\times 1</code> is the vector exogenous variables, <code class="reqn">s</code> is the number of seasons and <code class="reqn">(p,d,q,P,D,Q)</code> determines the lag structure of the model. Furthermore, <code class="reqn">c,C,A_i</code> and <code class="reqn">B_i</code> for all available <code class="reqn">i</code> determines the model’s parameters. <code class="reqn">v_t</code> is the disturbance vector and is contemporaneously correlated between different equations, i.e., <code class="reqn">E(v_tv_t')=\Sigma</code>.
Given a sample of size <code class="reqn">T</code>, the model can be estimated using maximum likelihood estimation. However, to ensure identifiability, it is necessary to impose additional constraints on the parameters (see chapter 12 in Lütkepohl (2005)). In this function, diagonal MA equation form is used (see Dufour and Pelletier (2022)).
In this function, the feasible GLS estimator is used to initialize the maximum likelihood, and the OLS estimator is used to calculate the initial value of the variance matrix of the error term. The condition number is calculated similar to the other models (see <a href="#topic+estim.sur">estim.sur</a> or e.g., page 94 in Trefethen and Bau (1997)). Furthermore, given a prediction horizon and required exogenous data, prediction is performed in a recursive schema, in which the actual estimated errors are used if available and zero otherwise. The variance of the predictions is also calculated recursively. Note that this function does not incorporate the coefficients uncertainty in calculation of the variance (see section 3.5 in Lütkepohl (2005)).
</p>
<p>Finally, note that the main purpose of exporting this method is to show the inner calculations of the search process in <a href="#topic+search.varma">search.varma</a> function.
</p>


<h3>Value</h3>

<p>A nested list with the following items:
</p>
<table>
<tr><td><code>counts</code></td>
<td>
<p>Information about different aspects of the estimation such as the number of observation, number of exogenous variables, etc.</p>
</td></tr>
<tr><td><code>estimations</code></td>
<td>
<p>Estimated coefficients, standard errors, z-statistics, p-values, etc.</p>
</td></tr>
<tr><td><code>metrics</code></td>
<td>
<p>Value of different goodness of fit and out-of-sample performance metrics. </p>
</td></tr>
<tr><td><code>prediction</code></td>
<td>
<p>Information on the predicted values.</p>
</td></tr>
<tr><td><code>simulation</code></td>
<td>
<p>Information on the simulations. </p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>Some other general information.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dufour J, Pelletier D (2022).
&ldquo;Practical methods for modeling weak VARMA processes: Identification, estimation and specification with a macroeconomic application.&rdquo;
<em>Journal of Business &amp; Economic Statistics</em>, <b>40</b>(3), 1140&ndash;1152.
<a href="https://doi.org/10.1080/07350015.2021.1904960">doi:10.1080/07350015.2021.1904960</a>.<br /><br /> Lütkepohl H (2005).
<em>New introduction to multiple time series analysis</em>.
Springer, Berlin.
ISBN 3540401725, <a href="https://doi.org/10.1007/978-3-540-27752-1">doi:10.1007/978-3-540-27752-1</a>.<br /><br /> Trefethen LN, Bau D (1997).
<em>Numerical linear algebra</em>.
Society for Industrial and Applied Mathematics.
ISBN 9780898714876.
</p>


<h3>See Also</h3>

<p><a href="#topic+search.varma">search.varma</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1 (simulation, ARMA):
num_eq &lt;- 1L
num_ar &lt;- 2L
num_ma &lt;- 1L
num_exo &lt;- 1L
sample &lt;- sim.varma(num_eq, arList = num_ar, maList = num_ma, exoCoef = num_exo, nObs = 110)
# estimate:
fit &lt;- estim.varma(data = get.data(cbind(sample$y, sample$x)[1:100,],
                                   endogenous = num_eq,
                                   newData = sample$x[101:110,, drop=FALSE]),
                   params = c(num_ar, 0, num_ma, 0, 0, 0),
                   maxHorizon = 10,
                   simFixSize = 5,
                   simHorizons = c(1:10))
print(fit)

pred &lt;- predict(fit, actualCount = 10)
plot(pred, simMetric = "mape")

# split coefficient matrix:
get.varma.params(fit$estimations$coefs, numAR = num_ar, numMA = num_ma, numExo = num_exo)

# Example 2 (simulation, VARMA):
num_eq &lt;- 3L
num_ar &lt;- 2L
num_ma &lt;- 1L
num_ma &lt;- 1L
num_exo &lt;- 2L
sample &lt;- sim.varma(num_eq, arList = num_ar, maList = num_ma, exoCoef = num_exo, nObs = 110)
# estimate:
fit &lt;- estim.varma(data = get.data(cbind(sample$y, sample$x)[1:100,],
                                   endogenous = num_eq,
                                   newData = sample$x[101:110,]),
                   params = c(num_ar, 0, num_ma, 0, 0, 0),
                   maxHorizon = 10,
                   simFixSize = 5,
                   simHorizons = c(1:10))

pred &lt;- predict(fit, actualCount = 10)
plot(pred, simMetric = "mape")

# split coefficient matrix:
get.varma.params(fit$estimations$coefs, numAR = num_ar, numMA = num_ma, numExo = num_exo)
</code></pre>

<hr>
<h2 id='estim.varma.model.string'>Get the Specification of an <code>ldt.estim.varma</code> Model</h2><span id='topic+estim.varma.model.string'></span>

<h3>Description</h3>

<p>Use this function to get the name of a VARMA model, such that:
If It is multivariate, it will be VAR, otherwise AR;
If moving average terms are present, it will be ARMA or VARMA;
If it is seasonal, it will be S-ARMA or S-VARMA;
If it is integrated, it will be S-ARMA (D=?,d=?); ..., and any possible combination.
Parameters will be reported in parenthesis after the name of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim.varma.model.string(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estim.varma.model.string_+3A_obj">obj</code></td>
<td>
<p>AN object of class <code>ldt.estim.varma</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string representing the specification of the model.
</p>

<hr>
<h2 id='exogenous'>Extract Exogenous Variable(s) Data</h2><span id='topic+exogenous'></span>

<h3>Description</h3>

<p>This function extracts data of an exogenous variable(s) in an equation from an estimated model.
It takes zero restrictions imposed into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exogenous(object, equation = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exogenous_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code>.</p>
</td></tr>
<tr><td><code id="exogenous_+3A_equation">equation</code></td>
<td>
<p>A number or a string specifying the equation with exogenous data.</p>
</td></tr>
<tr><td><code id="exogenous_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the exogenous data.
</p>

<hr>
<h2 id='fan.plot'>Fan Plot Function</h2><span id='topic+fan.plot'></span>

<h3>Description</h3>

<p>This function creates a fan plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fan.plot(
  data,
  dist = "normal",
  lambda = NA,
  quantiles = c(0.05, 0.1, 0.25, 0.75, 0.9, 0.95),
  gradient = FALSE,
  ylimSuggest = c(NA, NA),
  ylimExpand = 0.1,
  newPlot = TRUE,
  boundColor = "blue",
  plotArgs = list(),
  actualArgs = list(),
  medianArgs = list(),
  polygonArgs = list(border = NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fan.plot_+3A_data">data</code></td>
<td>
<p>A matrix where columns represent the parameters of distributions.
E.g., for normal distribution, the columns will be <code>mean</code> and <code>variance</code>.
The first rows can be actual values given in the first column.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_dist">dist</code></td>
<td>
<p>A string indicating the type of distribution. Currently, it can be either &quot;normal&quot; or &quot;log-normal&quot;. Default is &quot;normal&quot;.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_lambda">lambda</code></td>
<td>
<p>A numeric value for Box-Cox transformation. If <code>NA</code>, no transformation is applied. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_quantiles">quantiles</code></td>
<td>
<p>A numeric vector of quantiles for shading. Default is c(0.05, 0.1, 0.25, 0.75, 0.9, 0.95).</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_gradient">gradient</code></td>
<td>
<p>A logical value indicating whether to create a gradient fan plot. If FALSE, a standard fan plot is created. Default is FALSE.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_ylimsuggest">ylimSuggest</code></td>
<td>
<p>A numeric vector of length 2 indicating the suggested y-axis limits. Use <code>NA</code> for automatic calculation. Default is c(NA, NA).</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_ylimexpand">ylimExpand</code></td>
<td>
<p>A numeric value indicating the proportion to expand the y-axis limits. Default is 0.1.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_newplot">newPlot</code></td>
<td>
<p>A logical value indicating whether to create a new plot. If FALSE, the fan plot is added to the existing plot. Default is TRUE.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_boundcolor">boundColor</code></td>
<td>
<p>A string indicating the color of the boundary of the fan plot. Default is &quot;blue&quot;.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_plotargs">plotArgs</code></td>
<td>
<p>A list of additional arguments passed to the plot function when creating a new plot.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_actualargs">actualArgs</code></td>
<td>
<p>A list of additional arguments passed to the lines function when plotting actual values.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_medianargs">medianArgs</code></td>
<td>
<p>A list of additional arguments passed to the lines function when plotting median values.</p>
</td></tr>
<tr><td><code id="fan.plot_+3A_polygonargs">polygonArgs</code></td>
<td>
<p>A list of additional arguments passed to the polygon function when creating the fan plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return a value but creates a fan plot as a side effect.
</p>

<hr>
<h2 id='fitted.ldt.estim'>Extract Fitted Data</h2><span id='topic+fitted.ldt.estim'></span>

<h3>Description</h3>

<p>This function calculates and returns fitted values for an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
fitted(object, equations = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code>.</p>
</td></tr>
<tr><td><code id="fitted.ldt.estim_+3A_equations">equations</code></td>
<td>
<p>A number, a numeric array or a string array specifying the equations with residual data. If <code>NULL</code>, residuals in all equations are returned.</p>
</td></tr>
<tr><td><code id="fitted.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the exogenous data.
</p>

<hr>
<h2 id='get.combinations'>Define Combinations for Search Process</h2><span id='topic+get.combinations'></span>

<h3>Description</h3>

<p>This function defines a structure for a two-level nested loop used in a model search (or screening) process. The outer loop is defined by a vector of sizes and all the combinations of the variables are generated automatically. The inner loop is defined by a list of predefined combinations of the variables. Each variable can belong to either endogenous or exogenous variables based on their usage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.combinations(
  sizes = c(1),
  partitions = NULL,
  numFixPartitions = 0,
  innerGroups = list(c(1)),
  numTargets = 1,
  stepsNumVariables = c(NA),
  stepsFixedNames = NULL,
  stepsSavePre = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.combinations_+3A_sizes">sizes</code></td>
<td>
<p>A numeric vector or a list of numeric vectors that determines the sizes of outer loop combinations. For example, if the outer loop belongs to the endogenous variables, <code>c(1, 2)</code> means all models with 1 and 2 equations. If the outer loop belongs to exogenous variables, <code>c(1,2)</code> means all regressions with 1 and 2 exogenous variables. It can also be a list of numeric vectors for step-wise search. Each vector determines the size of the models in a step. In the next step, a subset of potential variables is selected by using <code>stepsNumVariables</code> argument.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_partitions">partitions</code></td>
<td>
<p>A list of numeric vectors or character vectors that partitions the outer loop variables. No model is estimated with two variables from the same partition.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_numfixpartitions">numFixPartitions</code></td>
<td>
<p>A single number that determines the number of partitions at the beginning of <code>partitions</code> to be included in all models.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_innergroups">innerGroups</code></td>
<td>
<p>A list of numeric vectors or character vectors that determines different combinations of the variables for the inner loop. For example, if the inner loop belongs to exogenous data, <code>list(c(1), c(1, 2))</code> means estimating all models with just the first exogenous variable and all models with both first and second exogenous variables.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_numtargets">numTargets</code></td>
<td>
<p>An integer for the number of target variables at the first columns of the data matrix. Results of a search process are specific to these variables. A model is not estimated if it does not contain a target variable.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_stepsnumvariables">stepsNumVariables</code></td>
<td>
<p>A numeric vector. If <code>sizes</code> is a list (i.e., a step-wise search), this vector must be of equal length and determines the number of variables (with best performance) in each step.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_stepsfixednames">stepsFixedNames</code></td>
<td>
<p>A character vector. If <code>sizes</code> is a list (i.e., a step-wise search), this vector determines the name of variables to be included in all steps.</p>
</td></tr>
<tr><td><code id="get.combinations_+3A_stepssavepre">stepsSavePre</code></td>
<td>
<p>A name for saving and loading progress, if <code>sizes</code> is a list. Each step's result is saved in a file (name=<code>paste0(stepsSavePre,i)</code>) where <code>i</code> is the index of the step.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>get.combinations</code> function in the <code>ldt</code> package uses a two-level nested loop to iterate over different combinations of endogenous and exogenous variables. This is similar to running the following code:
</p>
<pre>
for (endo in list(c(1), c(1, 2)))
  for (exo in list(c(1), c(1, 2)))
    Estimate a model using \code{endo} and \code{exo} indexation
</pre>
<p>However, predefining both loops is not memory efficient. Therefore, <code>ldt</code> uses a running algorithm to define the outer loop. It asks for the desired size of endogenous or exogenous variables in the model (i.e., <code>sizes</code>) and creates the outer groups using all possible combinations of the variables. The <code>partitions</code> and <code>numFixPartitions</code> parameters can be used to restrict this set.
</p>
<p>For the inner loop, you must provide the desired combination of variables (endogenous or exogenous). Given <code>m</code> as the number of variables, you can generate all possible combinations using the following code:
</p>
<pre>
m &lt;- 4
combinations &lt;- unlist(lapply(1:m, function(i) {
 t(combn(1:m, i, simplify = FALSE))
}), recursive = FALSE)
</pre>
<p>You can use this as the <code>innerGroups</code> argument. However, this might result in a large model set.
</p>
<p>Note that in <code>ldt</code>, if the data matrix does not have column names, default names for the endogenous variables are <code>Y1, Y2, ...</code>, and default names for the exogenous variables are <code>X1, X2, ...</code>. See <code><a href="#topic+get.data">get.data()</a></code> function for more details.
</p>
<p>Also note that <code>ldt</code> ensure that all possible models can be estimated with the given number of partitions and sizes. If it's not possible, it will stop with an error message.
</p>


<h3>Value</h3>

<p>A list suitable for use in <code>ldt::search.?</code> functions. The list contains:
</p>
<table>
<tr><td><code>sizes</code></td>
<td>
<p>The sizes of outer loop combinations.</p>
</td></tr>
<tr><td><code>partitions</code></td>
<td>
<p>The partitions of outer loop variables.</p>
</td></tr>
<tr><td><code>numFixPartitions</code></td>
<td>
<p>The number of fixed partitions at the beginning.</p>
</td></tr>
<tr><td><code>innerGroups</code></td>
<td>
<p>Different combinations of variables for inner loop.</p>
</td></tr>
<tr><td><code>numTargets</code></td>
<td>
<p>The number of target variables at first columns.</p>
</td></tr>
<tr><td><code>stepsNumVariables</code></td>
<td>
<p>The number of variables in each step for step-wise search.</p>
</td></tr>
<tr><td><code>stepsFixedNames</code></td>
<td>
<p>The names of fixed variables in each step for step-wise search.</p>
</td></tr>
<tr><td><code>stepsSavePre</code></td>
<td>
<p>The name for saving and loading progress for step-wise search.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Some basic examples are given in this section. However, more practical examples are available
# for the \code{search.?} functions.

# Example 1:
combinations1 &lt;- get.combinations(sizes = c(1, 2))
# The function will generate all possible combinations of sizes 1 and 2.

# Example 2: Using partitions
combinations2 &lt;- get.combinations(sizes = c(1, 2), partitions = list(c(1, 2), c(3, 4)))

# Here, we're specifying partitions for the variables.
# The function will generate combinations such that no model is estimated with two variables
# from the same partition.

# Example 3: Specifying inner groups
combinations3 &lt;- get.combinations(sizes = c(1, 2), innerGroups = list(c(1), c(1, 2)))

# In this example, we're specifying different combinations of variables for the inner loop.
# For instance, \code{list(c(1), c(1, 2))} means estimating all models with just the first
# variable and all models with both first and second variables.

# Example 4: Step-wise search
combinations4 &lt;- get.combinations(sizes = list(c(1), c(1, 2)), stepsNumVariables = c(NA, 1))

# This example demonstrates a step-wise search. In the first step (\code{sizes = c(1)}), all
# models with one variable are estimated.
# In the next step (\code{sizes = c(1, 2)}), a subset of potential variables is selected based
# on their performance in the previous step and all models with both first and second variables
# are estimated.

</code></pre>

<hr>
<h2 id='get.data'>Transform and Prepare Data for Analysis</h2><span id='topic+get.data'></span>

<h3>Description</h3>

<p>This function prepares a data matrix for analysis. It applies a Box-Cox transformation to the endogenous variables, adds an intercept column, and optionally includes new rows with exogenous data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.data(
  data,
  endogenous = 1,
  equations = NULL,
  weights = NULL,
  lambdas = NULL,
  newData = NULL,
  addIntercept = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.data_+3A_data">data</code></td>
<td>
<p>A data.frame or a numeric matrix that serves as the primary data source.</p>
</td></tr>
<tr><td><code id="get.data_+3A_endogenous">endogenous</code></td>
<td>
<p>A single number indicating the number of endogenous variables in the first columns, or a list of names specifying the endogenous variables. The remaining variables will be treated as exogenous.</p>
</td></tr>
<tr><td><code id="get.data_+3A_equations">equations</code></td>
<td>
<p>A formula or a list of formula objects that represent the equations to be used instead of <code>endogenous</code>. If provided, the final data will be a matrix where the response variables are in the first columns and the predictor variables are in the subsequent columns.</p>
</td></tr>
<tr><td><code id="get.data_+3A_weights">weights</code></td>
<td>
<p>A numeric vector or a column matrix representing weights of observations. Not all applications implement this parameter.</p>
</td></tr>
<tr><td><code id="get.data_+3A_lambdas">lambdas</code></td>
<td>
<p>A numeric vector, a single number, NA, or NULL indicating the lambda parameter(s) for the Box-Cox transformation. Use <code>NULL</code> for no transformation, <code>NA</code> for estimating the lambda parameter for each variable, a single number for an equal lambda parameter for all variables, and a numeric vector for distinct lambda parameters for corresponding variables.</p>
</td></tr>
<tr><td><code id="get.data_+3A_newdata">newData</code></td>
<td>
<p>A data.frame or a numeric matrix representing new data for exogenous variables. It should have a structure similar to <code>data</code>, excluding endogenous or response variables.</p>
</td></tr>
<tr><td><code id="get.data_+3A_addintercept">addIntercept</code></td>
<td>
<p>A logical value indicating whether to add an intercept column to the final matrix.</p>
</td></tr>
<tr><td><code id="get.data_+3A_...">...</code></td>
<td>
<p>Additional parameters for the <code>MASS::boxcox</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to prepare a data matrix for model search (or screening) analysis. It performs several operations to transform and structure the data appropriately.
</p>
<p>The function first checks if the input data is a matrix or a data frame. If new data is provided, it also checks its type. It then extracts the frequency of the first observation from the <code>ldtf</code> attribute of the data, if available.
</p>
<p>If no equations are provided, the function assumes that the endogenous variables are in the first columns of the data. It checks if an intercept is already present and throws an error if one is found and <code>addIntercept</code> is set to TRUE. It then validates the number of endogenous variables and converts the data to a numeric matrix.
</p>
<p>If column names are missing, they are added based on the number of endogenous and exogenous variables. If new data is provided, it checks its structure and matches it with the exogenous part of the original data.
</p>
<p>If equations are provided, they are used to transform the original data into a matrix where response variables are in the first columns and predictor variables in subsequent columns. The new data is also transformed accordingly.
</p>
<p>The function then applies a Box-Cox transformation to the endogenous variables if lambda parameters are provided. Weights are added if provided, and an intercept column is added if <code>addIntercept</code> is set to TRUE.
</p>
<p>Finally, the function returns a list containing all relevant information for further analysis. This includes the final data matrix, number of endogenous and exogenous variables, number of observations in original and new data, lambda parameters used in Box-Cox transformation, and flags indicating whether an intercept or weights were added.
</p>


<h3>Value</h3>

<p>A list suitable for use in <code>ldt::search.?</code> functions. The list contains:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The final data matrix. Endogenous variables are in the first columns, followed by weights (if provided), then the intercept (if added), and finally the exogenous variables.</p>
</td></tr>
<tr><td><code>numEndo</code></td>
<td>
<p>The number of endogenous variables in the data.</p>
</td></tr>
<tr><td><code>numExo</code></td>
<td>
<p>The number of exogenous variables in the data (including 'intercept' if it is added).</p>
</td></tr>
<tr><td><code>newX</code></td>
<td>
<p>The matrix of new observations for exogenous variables.</p>
</td></tr>
<tr><td><code>lambdas</code></td>
<td>
<p>The lambda parameters used in the Box-Cox transformation.</p>
</td></tr>
<tr><td><code>hasIntercept</code></td>
<td>
<p>Indicates whether an intercept column is added to the final matrix.</p>
</td></tr>
<tr><td><code>hasWeight</code></td>
<td>
<p>Indicates whether there is a weight column in the final matrix.</p>
</td></tr>
<tr><td><code>startFrequency</code></td>
<td>
<p>Frequency of the first observation, extracted from <code>ldtf</code> attribute of <code>data</code>, if available. This will be used in time-series analysis such as VARMA estimation.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1:
data &lt;- matrix(1:24, ncol = 6)
result &lt;- get.data(data, endogenous = 1)
print(result$data)

# Example 2:
data &lt;- matrix(1:24, ncol = 6,
               dimnames = list(NULL,c("V1", "V2", "V3", "V4", "V5", "V6")))
result &lt;- get.data(data, endogenous = c("V6", "V1"))
print(result$data)

# Example 3:
data &lt;- data.frame(matrix(1:24, ncol = 6))
colnames(data) &lt;- c("X1", "X2", "Y2", "X3", "Y1", "X4")
equations &lt;- list(
   Y1 ~ X2 + X1,
   Y2 ~ X4 + X3)
result &lt;- get.data(data, equations = equations)
print(result$data)

</code></pre>

<hr>
<h2 id='get.data.append.newX'>Append <code>newX</code> to <code>data$data</code> matrix.</h2><span id='topic+get.data.append.newX'></span>

<h3>Description</h3>

<p>Use it for VARMA estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.data.append.newX(data, maxHorizon = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.data.append.newX_+3A_data">data</code></td>
<td>
<p>The output of <a href="#topic+get.data">get.data</a> function.</p>
</td></tr>
<tr><td><code id="get.data.append.newX_+3A_maxhorizon">maxHorizon</code></td>
<td>
<p>Number of expected new data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>data</code> with updated data matrix
</p>

<hr>
<h2 id='get.data.check.discrete'>Check if a column is discrete</h2><span id='topic+get.data.check.discrete'></span>

<h3>Description</h3>

<p>For example, it checks if the endogenous variable in binary model is 0 and 1 (number of choices is 2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.data.check.discrete(data, colIndex = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.data.check.discrete_+3A_data">data</code></td>
<td>
<p>Output of <a href="#topic+get.data">get.data</a> function</p>
</td></tr>
<tr><td><code id="get.data.check.discrete_+3A_colindex">colIndex</code></td>
<td>
<p>The index of column to be checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Number of choices in the model, if no error occured.
This means, the maximum value for the discrete data will be the output minus one.
</p>

<hr>
<h2 id='get.data.check.intercept'>Check for an intercept in a matrix</h2><span id='topic+get.data.check.intercept'></span>

<h3>Description</h3>

<p>This function checks if any column in the matrix is intercept.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.data.check.intercept(matrix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.data.check.intercept_+3A_matrix">matrix</code></td>
<td>
<p>data matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The index of the intercept. '-1' in intercept is not found.
</p>

<hr>
<h2 id='get.data.keep.complete'>Remove Rows with Missing Observations from Data</h2><span id='topic+get.data.keep.complete'></span>

<h3>Description</h3>

<p>Remove Rows with Missing Observations from Data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.data.keep.complete(data, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.data.keep.complete_+3A_data">data</code></td>
<td>
<p>Output of <a href="#topic+get.data">get.data</a> function</p>
</td></tr>
<tr><td><code id="get.data.keep.complete_+3A_warn">warn</code></td>
<td>
<p>If true,  warning message about the indices of the removed rows is shown</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>data</code> but with updated <code>data$data</code> and <code>data$obsCount</code>
</p>

<hr>
<h2 id='get.indexation'>Get Numeric Indices in a Combination</h2><span id='topic+get.indexation'></span>

<h3>Description</h3>

<p>This function takes the output of the <a href="#topic+get.combinations">get.combinations</a> function and a numeric matrix with given column names.
It converts all character vectors in <code>innerGroups</code> or <code>partitions</code> to numeric vectors based on the index of the columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.indexation(combinations, data, isInnerExogenous)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.indexation_+3A_combinations">combinations</code></td>
<td>
<p>A list returned by the <a href="#topic+get.combinations">get.combinations</a> function.</p>
</td></tr>
<tr><td><code id="get.indexation_+3A_data">data</code></td>
<td>
<p>A list returned by <a href="#topic+get.data">get.data</a> function.</p>
</td></tr>
<tr><td><code id="get.indexation_+3A_isinnerexogenous">isInnerExogenous</code></td>
<td>
<p>Use <code>TRUE</code> if outer loop is defined over the endogenous variables and <code>FALSE</code> if it is for exogenous.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list similar to the input <code>combinations</code>, but with all character vectors in <code>innerGroups</code> or <code>partitions</code> converted to numeric vectors based on the index of the columns in the <code>data</code> matrix.
It sums the exogenous indexes with the number of endogenous variables and returns zero-based indexation for C code.
</p>

<hr>
<h2 id='get.options.lbfgs'>Get Options for L-BFGS Optimization</h2><span id='topic+get.options.lbfgs'></span>

<h3>Description</h3>

<p>Use this function to get optimization options in <a href="#topic+estim.varma">estim.varma</a> or <a href="#topic+search.varma">search.varma</a> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.options.lbfgs(
  maxIterations = 100,
  factor = 1e+07,
  projectedGradientTol = 0,
  maxCorrections = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.options.lbfgs_+3A_maxiterations">maxIterations</code></td>
<td>
<p>A positive integer representing the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="get.options.lbfgs_+3A_factor">factor</code></td>
<td>
<p>A number that determines the condition for stopping the iterations. Use, for example, 1e12 for low accuracy, 1e7 (default) for moderate accuracy, and 1e1 for extremely high accuracy. The default is 1e7.</p>
</td></tr>
<tr><td><code id="get.options.lbfgs_+3A_projectedgradienttol">projectedGradientTol</code></td>
<td>
<p>A number used to stop the iteration using the projected gradient. The default is zero.</p>
</td></tr>
<tr><td><code id="get.options.lbfgs_+3A_maxcorrections">maxCorrections</code></td>
<td>
<p>The maximum number of variable metric corrections allowed in the limited memory matrix. The default is 5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the given options.
</p>

<hr>
<h2 id='get.options.neldermead'>Options for Nelder-Mead Optimization</h2><span id='topic+get.options.neldermead'></span>

<h3>Description</h3>

<p>Use this function to get the required options when Nelder-Mead optimization is needed such as <a href="#topic+s.gld.from.moments">s.gld.from.moments</a> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.options.neldermead(
  maxIterations = 100,
  tolerance = 1e-06,
  reflection = 1,
  expansion = 2,
  contraction = 0.5,
  shrink = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.options.neldermead_+3A_maxiterations">maxIterations</code></td>
<td>
<p>(int) Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="get.options.neldermead_+3A_tolerance">tolerance</code></td>
<td>
<p>A small number to determine the convergence.
The algorithm terminates when the difference between the best and worst points in the simplex is less than this value.</p>
</td></tr>
<tr><td><code id="get.options.neldermead_+3A_reflection">reflection</code></td>
<td>
<p>A number for reflection coefficient.
It controls how far the worst point is reflected through the centroid of the remaining points.</p>
</td></tr>
<tr><td><code id="get.options.neldermead_+3A_expansion">expansion</code></td>
<td>
<p>A number that determines the expansion coefficient.
It controls how far the reflected point is expanded along the line connecting it to the centroid.</p>
</td></tr>
<tr><td><code id="get.options.neldermead_+3A_contraction">contraction</code></td>
<td>
<p>A number that determines the contraction coefficient.
It controls how far the worst point is contracted towards the centroid.</p>
</td></tr>
<tr><td><code id="get.options.neldermead_+3A_shrink">shrink</code></td>
<td>
<p>A number that determines the shrink coefficient.
It controls how much the simplex is shrunk towards the best point when all other moves are rejected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the given options.
</p>

<hr>
<h2 id='get.options.newton'>Get Options for Newton Optimization</h2><span id='topic+get.options.newton'></span>

<h3>Description</h3>

<p>Use this function to get optimization options in <a href="#topic+estim.bin">estim.bin</a> or <a href="#topic+search.bin">search.bin</a> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.options.newton(
  maxIterations = 100,
  functionTol = 1e-04,
  gradientTol = 0,
  useLineSearch = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.options.newton_+3A_maxiterations">maxIterations</code></td>
<td>
<p>An integer representing the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="get.options.newton_+3A_functiontol">functionTol</code></td>
<td>
<p>A small value used to test the convergence of the objective function.</p>
</td></tr>
<tr><td><code id="get.options.newton_+3A_gradienttol">gradientTol</code></td>
<td>
<p>A small value used to test the convergence of the gradient.</p>
</td></tr>
<tr><td><code id="get.options.newton_+3A_uselinesearch">useLineSearch</code></td>
<td>
<p>If <code>TRUE</code>, line search is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the given options.
</p>

<hr>
<h2 id='get.options.pca'>Get Options for PCA</h2><span id='topic+get.options.pca'></span>

<h3>Description</h3>

<p>Use this function to get PCA options in <a href="#topic+estim.bin">estim.bin</a>, <a href="#topic+estim.sur">estim.sur</a>, <a href="#topic+estim.varma">estim.varma</a>, or <a href="#topic+s.pca">s.pca</a> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.options.pca(ignoreFirst = 1, exactCount = 0, cutoffRate = 0.8, max = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.options.pca_+3A_ignorefirst">ignoreFirst</code></td>
<td>
<p>A number representing the number of variables to exclude at the beginning of data matrices (such as intercept) from PCA.</p>
</td></tr>
<tr><td><code id="get.options.pca_+3A_exactcount">exactCount</code></td>
<td>
<p>A number that determines the number of components to be used. If zero, the number of components is determined by the <code>cutoffRate</code>.</p>
</td></tr>
<tr><td><code id="get.options.pca_+3A_cutoffrate">cutoffRate</code></td>
<td>
<p>A number between 0 and 1 that determines the cutoff rate for the cumulative variance ratio in order to determine the number of PCA components. It is not used if <code>exactCount</code> is positive.</p>
</td></tr>
<tr><td><code id="get.options.pca_+3A_max">max</code></td>
<td>
<p>A number representing the maximum number of components when <code>cutoffRate</code> is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See details of <a href="#topic+s.pca">s.pca</a> function.
</p>


<h3>Value</h3>

<p>A list with the given options.
</p>


<h3>See Also</h3>

<p><a href="#topic+estim.bin">estim.bin</a>, <a href="#topic+estim.sur">estim.sur</a>, <a href="#topic+estim.varma">estim.varma</a>, <a href="#topic+s.pca">s.pca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See 's.pca' function.

</code></pre>

<hr>
<h2 id='get.options.roc'>Get Options for ROC and AUC Calculations</h2><span id='topic+get.options.roc'></span>

<h3>Description</h3>

<p>Use this function to get the required options for <a href="#topic+search.bin">search.bin</a>, <a href="#topic+estim.bin">estim.bin</a>, or <a href="#topic+s.roc">s.roc</a> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.options.roc(
  lowerThreshold = 0,
  upperThreshold = 1,
  epsilon = 1e-12,
  pessimistic = FALSE,
  costs = NULL,
  costMatrix = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.options.roc_+3A_lowerthreshold">lowerThreshold</code></td>
<td>
<p>A number representing the lower bound for calculating partial AUC.</p>
</td></tr>
<tr><td><code id="get.options.roc_+3A_upperthreshold">upperThreshold</code></td>
<td>
<p>A number representing the upper bound for calculating partial AUC.</p>
</td></tr>
<tr><td><code id="get.options.roc_+3A_epsilon">epsilon</code></td>
<td>
<p>A small number used to ignore small floating point differences when comparing scores.</p>
</td></tr>
<tr><td><code id="get.options.roc_+3A_pessimistic">pessimistic</code></td>
<td>
<p>If <code>TRUE</code>, sequences of equally scored instances are treated differently and a pessimistic metric is calculated (see Fawcett (2006) An introduction to ROC analysis, fig. 6).</p>
</td></tr>
<tr><td><code id="get.options.roc_+3A_costs">costs</code></td>
<td>
<p>The cost of each observation. If <code>NULL</code>, the cost of all observations will be 1.</p>
</td></tr>
<tr><td><code id="get.options.roc_+3A_costmatrix">costMatrix</code></td>
<td>
<p>A <code>2x2</code> cost matrix in which: (1,1) is the cost of TN,
(2,2) is the cost of TP, (1,2) is the cost of FP and (2,1) is the cost of FN. The first
column is multiplied by the corresponding value in the costs vector (see
Fawcett (2006), ROC graphs with instance-varying costs).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See details of <a href="#topic+s.roc">s.roc</a> function.
</p>


<h3>Value</h3>

<p>A list with the given options.
</p>


<h3>See Also</h3>

<p><a href="#topic+search.bin">search.bin</a>, <a href="#topic+estim.bin">estim.bin</a>, <a href="#topic+s.roc">s.roc</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See 's.roc' function.


</code></pre>

<hr>
<h2 id='get.search.items'>Specify the Purpose of the Model Search Process</h2><span id='topic+get.search.items'></span>

<h3>Description</h3>

<p>Use this function to list the required items and information that should be saved and retrieved from the model set search process in <code>search.?</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.search.items(
  model = TRUE,
  type1 = FALSE,
  type2 = FALSE,
  bestK = 1,
  all = FALSE,
  inclusion = FALSE,
  cdfs = numeric(0),
  extremeMultiplier = 0,
  mixture4 = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.search.items_+3A_model">model</code></td>
<td>
<p>If <code>TRUE</code>, some information about the models is saved.</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_type1">type1</code></td>
<td>
<p>If <code>TRUE</code> and implemented, extra information is saved. This can be the coefficients in the SUR search or predictions in the VARMA search.</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_type2">type2</code></td>
<td>
<p>If <code>TRUE</code> and implemented, extra information is saved. This is similar to <code>type1</code>. <strong>It is reserved for future updates.</strong></p>
</td></tr>
<tr><td><code id="get.search.items_+3A_bestk">bestK</code></td>
<td>
<p>The number of best items to be saved in <code>model</code>, <code>type1</code>, or <code>type2</code> information.</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_all">all</code></td>
<td>
<p>If <code>TRUE</code>, all models' information is saved.</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_inclusion">inclusion</code></td>
<td>
<p>If <code>TRUE</code>, inclusion weights are saved.</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_cdfs">cdfs</code></td>
<td>
<p>Weighted average of the CDFs at each given point is calculated (for <code>type1</code> and <code>type2</code> cases).</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_extrememultiplier">extremeMultiplier</code></td>
<td>
<p>A number that determines the multiplier in the extreme bound analysis (for <code>type1</code> and <code>type2</code> cases). Use zero to disable it.</p>
</td></tr>
<tr><td><code id="get.search.items_+3A_mixture4">mixture4</code></td>
<td>
<p>If <code>TRUE</code>, the first four moments of the average distributions are calculated in <code>type1</code> and <code>type2</code> cases.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the given options.
</p>

<hr>
<h2 id='get.search.metrics'>Get Options for Measuring Performance</h2><span id='topic+get.search.metrics'></span>

<h3>Description</h3>

<p>Use this function to get measuring options in <code>search.?</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.search.metrics(
  typesIn = c("aic"),
  typesOut = NULL,
  simFixSize = 2,
  trainRatio = 0.75,
  trainFixSize = 0,
  seed = 0,
  horizons = c(1L),
  weightedEval = FALSE,
  minMetrics = list(aic = 0)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.search.metrics_+3A_typesin">typesIn</code></td>
<td>
<p>A list of evaluation metrics when the model is estimated using all available data. It can be <code>aic</code>, <code>sic</code>, <code>frequencyCostIn</code>, <code>brierIn</code>, or <code>aucIn</code>. <code>NULL</code> means no metric.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_typesout">typesOut</code></td>
<td>
<p>A list of evaluation metrics in a out-of-sample simulation. It can be <code>sign</code>, <code>direction</code>, <code>rmse</code>, <code>rmspe</code>, <code>mae</code>, <code>mape</code>, <code>crps</code>, <code>frequencyCostOut</code>, <code>brierOut</code>, or <code>aucOut</code>. Null means no metric.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_simfixsize">simFixSize</code></td>
<td>
<p>An integer that determines the number of out-of-sample simulations. Use zero to disable the simulation.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_trainratio">trainRatio</code></td>
<td>
<p>A number representing the size of the training sample relative to the available size, in the out-of-sample simulation. It is effective if <code>trainFixSize</code> is zero.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_trainfixsize">trainFixSize</code></td>
<td>
<p>An integer representing the number of data points in the training sample in the out-of-sample simulation. If zero, <code>trainRatio</code> will be used.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_seed">seed</code></td>
<td>
<p>A seed for the random number generator. Use zero for a random value. It can be negative to get reproducible results between the <code>search.?</code> function and the <code>estim.?</code> function.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_horizons">horizons</code></td>
<td>
<p>An array of integers representing the prediction horizons to be used in out-of-sample simulations, if the model supports time-series prediction. If <code>NULL</code>, <code>c(1)</code> is used.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_weightedeval">weightedEval</code></td>
<td>
<p>If <code>TRUE</code>, weights are used in evaluating discrete-choice models.</p>
</td></tr>
<tr><td><code id="get.search.metrics_+3A_minmetrics">minMetrics</code></td>
<td>
<p>a list of minimum values for adjusting the weights when applying the AIC weight formula.
It can contain the following members: <code>aic</code>, <code>sic</code>, <code>brierIn</code>, <code>rmse</code>, <code>rmspe</code>, <code>mae</code>, <code>mape</code>, <code>crps</code>, <code>brierOut</code>.
Members can be numeric vectors for specifying a value for each target variable. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An important aspect of <code>ldt</code> is model evaluation during the screening process. This involves considering both in-sample and out-of-sample evaluation metrics. In-sample metrics are computed using data that was used in the estimation process, while out-of-sample metrics are computed using new data. These metrics are well documented in the literature, and I will provide an overview of the main computational aspects and relevant references.
</p>


<h3>Value</h3>

<p>A list with the given options.
</p>


<h3>AIC and SIC</h3>

<p>According to Burnham and Anderson (2002) or Greene (2020), AIC and SIC are two commonly used metrics for comparing and choosing among different models with the same endogenous variable(s). Given <code class="reqn">L^*</code> as the maximum value of the likelihood function in a regression analysis with <code class="reqn">k</code> estimated parameters and <code class="reqn">N</code> observations, AIC is calculated by <code class="reqn">2k-2\ln L^*</code> and SIC is calculated by <code class="reqn">k\ln N-2\ln L^*</code>. SIC includes a stronger penalty for increasing the number of estimated parameters in the model.
</p>
<p>These metrics can be converted into weights using the formula <code class="reqn">w=\exp (-0.5x)</code>, where <code class="reqn">x</code> is the value of the metric. When divided by the sum of all weights, <code class="reqn">w</code> can be interpreted as the probability that a given model is the best model among all members of the model set (see section 2.9 in Burnham and Anderson (2002)). Compared to the Burnham and Anderson (2002) discussion and since <code class="reqn">f(x)=exp(-0.5x)</code> transformation is invariant to translation, the minimum AIC part is removed in the screening process. This is an important property because it enables the use of running statistics and parallel computation.
</p>


<h3>MSE, RMSE, MSPE, and RMSPE</h3>

<p>According to Hyndman and Athanasopoulos (2018), MSE and RMSE are two commonly used scale-dependent metrics, while MAPE is a commonly used unit-free metric. <code>ldt</code> also calculates the less common RMSPE metric. If there are <code class="reqn">n</code> predictions and <code class="reqn">e_i=y_i-\hat{y}_i</code> for <code class="reqn">i=1\ldots n</code> is the prediction error, i.e., the distance between actual values (<code class="reqn">y_i</code>) and predictions (<code class="reqn">\hat{y}_i</code>), these metrics can be expressed analytically by the following formulas:
</p>
<p style="text-align: center;"><code class="reqn">
\mathrm{MAE} = \frac{1}{n}\sum_{i=1}^{n}|e_i|
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\mathrm{MAPE} = \frac{1}{n}\sum_{i=1}^{n}\left|\frac{e_i}{y_i}\right|\times 100
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\mathrm{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(e_i)^2}
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\mathrm{RMSPE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}\left(\frac{e_i}{y_i}\right)^2}\times 100
</code>
</p>

<p>Note that, first MAPE and RMSPE are not defined if <code class="reqn">y_i</code> is zero and may not be meaningful or useful if it is near zero or negative. Second, although these metrics cannot be directly interpreted as weights, they are treated in a manner similar to AIC in the <code>ldt</code> package.. Third, caution is required when target variables are transformed, for example to a logarithmic scale. <code>ldt</code> provides an option to transform the data back when calculating these metrics.
</p>


<h3>Brier</h3>

<p>The Brier score measures the accuracy of probabilistic predictions for binary outcomes. It is calculated as the mean squared difference between the actual values (<code class="reqn">y_i</code>) and the predicted probabilities (<code class="reqn">p_i</code>). Assuming that there are <code class="reqn">n</code> predictions, its formula is given by:
</p>
<p><code class="reqn">
\mathrm{Brier} = \frac{\sum (y_i-\hat{p}_i)^2}{n},
</code>
</p>
<p>where <code class="reqn">p_i</code> is the predicted probability that the <code class="reqn">i</code>-th observation is positive. The value of this metric ranges from 0 to 1, with lower values indicating better predictions. In the screening process in <code>ldt</code>, both in-sample and out-of-sample observations can be used to calculate this metric. Although this metric cannot be directly interpreted as a weight, it is treated in a manner similar to AIC.
</p>


<h3>AUC</h3>

<p>As described by Fawcett (2006), the receiver operating characteristic curve (ROC) plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at different classification thresholds. The area under this curve is known as the AUC. Its value ranges from 0 to 1, with higher values indicating that the model is better at distinguishing between the two classes Fawcett (2006, 2006). In the screening process in <code>ldt</code>, both in-sample and out-of-sample observations can be used to calculate this metric. There is also an option to calculate the pessimistic or an instance-varying costs version of this metric. Although this metric does not have a direct interpretation as weights, in <code>ldt</code> its value is considered as weight.
</p>


<h3>CRPS</h3>

<p>According to Gneiting et al. (2005), the continuous ranked probability score (CRPS) is a metric used to measure the accuracy of probabilistic predictions. Unlike MAE, RMSE, etc., CRPS takes into account the entire distribution of the prediction, rather than focusing on a specific point of the probability distribution. For <code class="reqn">n</code> normally distributed predictions with mean <code class="reqn">\hat{y}_i</code> and variance <code class="reqn">\mathrm{var}(\hat{y}_i)</code>, this metric can be expressed analytically as:
</p>
<p><code class="reqn">
\mathrm{CRPS}=\sum_{i=1}^{n} \sigma \left(\frac{1}{\sqrt{\pi}} - 2\Phi(z_i) + z_i (2\phi(z_i)-1)\right),
</code>
</p>
<p>where <code class="reqn">z_i=(y_i-\hat{y}_i)/\sqrt{\mathrm{var}(\hat{y}_i)}</code>, and <code class="reqn">\Phi</code> and <code class="reqn">\phi</code> are CDF and density functions of standard normal distribution. Although this metric cannot be directly interpreted as a weight, it is treated in a manner similar to AIC in the <code>ldt</code> package.
</p>


<h3>Other metrics</h3>

<p>There are some other metrics in <code>ldt</code>. One is &ldquo;directional prediction accuracy&rdquo;, which is calculated as the proportion of predictions that correctly predict the direction of change relative to the previous observation. Its value ranges from 0 to 1, with higher values indicating better performance of the model. Its value is used as the weight of a model. Note that this is applicable only to time-series data.
</p>
<p>Another similar metric is &ldquo;sign prediction accuracy&rdquo;, which reports the proportion of predictions that have the same sign as the actual values. It is calculated as the number of correct sign predictions divided by the total number of predictions. Its value ranges from 0 to 1, with higher values indicating better performance of the model. Its value is used as the weight of a model.
</p>


<h3>References</h3>

<p>Burnham KP, Anderson DR (2002).
<em>Model selection and multimodel inference</em>.
Springer, New York.
ISBN 0387953647, <a href="https://doi.org/10.1007/b97636">doi:10.1007/b97636</a>.<br /><br /> Fawcett T (2006).
&ldquo;An introduction to ROC analysis.&rdquo;
<em>Pattern Recognition Letters</em>, <b>27</b>(8), 861&ndash;874.
<a href="https://doi.org/10.1016/j.patrec.2005.10.010">doi:10.1016/j.patrec.2005.10.010</a>.<br /><br /> Fawcett T (2006).
&ldquo;ROC graphs with instance-varying costs.&rdquo;
<em>Pattern Recognition Letters</em>, <b>27</b>(8), 882&ndash;891.
<a href="https://doi.org/10.1016/j.patrec.2005.10.012">doi:10.1016/j.patrec.2005.10.012</a>.<br /><br /> Gneiting T, Raftery AE, Westveld AH, Goldman T (2005).
&ldquo;Calibrated probabilistic forecasting using ensemble model output statistics and minimum CRPS estimation.&rdquo;
<em>Monthly Weather Review</em>, <b>133</b>(5), 1098&ndash;1118.
<a href="https://doi.org/10.1175/mwr2904.1">doi:10.1175/mwr2904.1</a>.<br /><br /> Greene WH (2020).
<em>Econometric analysis</em>, 8th edition.
Pearson Education Limited, New York.
ISBN 9781292231136.<br /><br /> Hyndman RJ, Athanasopoulos G (2018).
<em>Forecasting: Principles and practice</em>.
OTexts.
<a href="https://otexts.com/fpp2/">https://otexts.com/fpp2/</a>.
</p>

<hr>
<h2 id='get.search.modelchecks'>Set Options to Exclude a Model Subset</h2><span id='topic+get.search.modelchecks'></span>

<h3>Description</h3>

<p>Use this function to determine which models should be skipped in the search process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.search.modelchecks(
  estimation = TRUE,
  maxConditionNumber = Inf,
  minObsCount = 0,
  minDof = 0,
  minOutSim = 0,
  minR2 = -Inf,
  maxAic = Inf,
  maxSic = Inf,
  prediction = FALSE,
  predictionBound = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.search.modelchecks_+3A_estimation">estimation</code></td>
<td>
<p>If <code>TRUE</code>, the model is estimated with all data and is ignored if this estimation fails. If <code>FALSE</code>, you might get a 'best model' that cannot be estimated.</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_maxconditionnumber">maxConditionNumber</code></td>
<td>
<p>A number used to ignore an estimation that has a high condition number (if implemented in the search).</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_minobscount">minObsCount</code></td>
<td>
<p>An integer used to ignore an estimation where the number of observations (after dealing with <code>NA</code>) is low. Use 0 to disable this check.</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_mindof">minDof</code></td>
<td>
<p>An integer used to ignore an estimation with low degrees of freedom (equation-wise). Use 0 to disable this check.</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_minoutsim">minOutSim</code></td>
<td>
<p>An integer used to ignore estimations with a low number of out-of-sample simulations (if implemented in the search).</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_minr2">minR2</code></td>
<td>
<p>A number used to ignore estimations with a low value for 'R2' (if implemented in the search).</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_maxaic">maxAic</code></td>
<td>
<p>A number used to ignore estimations with a high 'AIC' (if implemented in the search).</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_maxsic">maxSic</code></td>
<td>
<p>A number used to ignore estimations with a high 'SIC' (if implemented in the search).</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_prediction">prediction</code></td>
<td>
<p>If <code>TRUE</code>, model data is predicted given all data and is ignored if this process fails. If <code>FALSE</code>, you might get a 'best model' that cannot be used for prediction.</p>
</td></tr>
<tr><td><code id="get.search.modelchecks_+3A_predictionbound">predictionBound</code></td>
<td>
<p>A list containing two matrices: <code>lower</code> and <code>upper</code>, which represent the bounds for checking predictions. Each column corresponds to a target variable, and each row corresponds to a horizon. If the data has been transformed using a Box-Cox transformation, these bounds will be compared with the transformed data.
Alternatively, <code>predictionBound</code> can be a numeric value. In this case, the bounds are created by creating a confidence interval, assuming normality and using mean and standard errors of the growth rates.
Any model that produces a prediction outside of these bounds will be ignored. To disable this check, set <code>predictionBound</code> to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the given options.
</p>

<hr>
<h2 id='get.search.options'>Get Extra Options for Model Search Process</h2><span id='topic+get.search.options'></span>

<h3>Description</h3>

<p>Use this function to determine how the model search is performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.search.options(parallel = FALSE, reportInterval = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.search.options_+3A_parallel">parallel</code></td>
<td>
<p>If <code>TRUE</code>, a parallel search algorithm is used. This generally changes the speed and memory usage.</p>
</td></tr>
<tr><td><code id="get.search.options_+3A_reportinterval">reportInterval</code></td>
<td>
<p>An integer representing the time interval (in seconds) for reporting progress (if any significant change has occurred). Set to zero to disable reporting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the given options.
</p>

<hr>
<h2 id='get.varma.params'>Split VARMA parameter into its Components</h2><span id='topic+get.varma.params'></span>

<h3>Description</h3>

<p>Use this function to extract AR, MA, intercept, and exogenous coefficients from the VARMA estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.varma.params(
  coef,
  numAR = 1,
  numMA = 0,
  numExo = 0,
  intercept = TRUE,
  numAR_s = 0,
  numMA_s = 0,
  numSeasons = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.varma.params_+3A_coef">coef</code></td>
<td>
<p>A matrix of coefficients with dimensions <code>numEq</code> x <code>numAR * numEq + numMA * numEq + numExo + ifelse(intercept, 1, 0)</code>.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_numar">numAR</code></td>
<td>
<p>A non-negative integer scalar specifying the number of AR lags.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_numma">numMA</code></td>
<td>
<p>A non-negative integer scalar specifying the number of MA lags.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_numexo">numExo</code></td>
<td>
<p>A non-negative integer scalar specifying the number of exogenous variables.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_intercept">intercept</code></td>
<td>
<p>A logical scalar indicating whether an intercept is included in the model.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_numar_s">numAR_s</code></td>
<td>
<p>A non-negative integer scalar specifying the number of seasonal AR lags.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_numma_s">numMA_s</code></td>
<td>
<p>A non-negative integer scalar specifying the number of seasonal MA lags.</p>
</td></tr>
<tr><td><code id="get.varma.params_+3A_numseasons">numSeasons</code></td>
<td>
<p>A non-negative integer scalar specifying the number of seasons.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following items:
</p>

<ul>
<li> <p><code>arList</code>: A list containing the AR coefficients for each lag.
</p>
</li>
<li> <p><code>intercept</code>: A numeric vector of length <code>numEq</code> containing the intercept, or <code>NULL</code> if <code>intercept = FALSE</code>.
</p>
</li>
<li> <p><code>exoCoef</code>: A matrix of dimensions <code>numEq</code> x <code>numExo</code> containing the exogenous coefficients, or <code>NULL</code> if <code>numExo = 0</code>.
</p>
</li>
<li> <p><code>maList</code>: A list containing the MA coefficients for each lag.
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="#topic+estim.varma">estim.varma</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see 'search.varma' or 'estim.varma' functions.

</code></pre>

<hr>
<h2 id='logLik.ldt.estim'>Extract Maximum Log-Likelihood</h2><span id='topic+logLik.ldt.estim'></span>

<h3>Description</h3>

<p>This function extracts maximum log-likelihood from an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code></p>
</td></tr>
<tr><td><code id="logLik.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the maximum log-likelihood for the whole system.
</p>

<hr>
<h2 id='plot.ldt.estim'>Plot Diagnostics for <code>ldt.estim</code> Object</h2><span id='topic+plot.ldt.estim'></span>

<h3>Description</h3>

<p>This function creates diagnostic plots for estimated regression models of <code>ldt.estim</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
plot(
  x,
  equation = 1,
  type = c(1, 2, 3, 4, 5, 6),
  ablineArgs = list(col = "lightblue"),
  textArgs = list(pos = 3, cex = 0.7, col = "red"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ldt.estim_+3A_x">x</code></td>
<td>
<p>An object of type <code>ldt.estim</code>.</p>
</td></tr>
<tr><td><code id="plot.ldt.estim_+3A_equation">equation</code></td>
<td>
<p>A number or a name of endogenous variable specifying an equation in the estimated system.</p>
</td></tr>
<tr><td><code id="plot.ldt.estim_+3A_type">type</code></td>
<td>
<p>One of these numbers: 1, 2, 3, or 5. See <code>which</code> argument in <a href="stats.html#topic+plot.lm">plot.lm</a> documentation.</p>
</td></tr>
<tr><td><code id="plot.ldt.estim_+3A_ablineargs">ablineArgs</code></td>
<td>
<p>A list of additional arguments to customize the &quot;text&quot; function used for labeling influential observations.</p>
</td></tr>
<tr><td><code id="plot.ldt.estim_+3A_textargs">textArgs</code></td>
<td>
<p>A list of additional arguments to customize the &quot;abline&quot; function.</p>
</td></tr>
<tr><td><code id="plot.ldt.estim_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to &quot;plot&quot; (or &quot;qqnorm&quot; function for <code>type=2</code>, or &quot;barplot&quot; for <code>type=4</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to be similar to <a href="stats.html#topic+plot.lm">plot.lm</a> function.
However, note that an <code>ldt.estim</code> object might be a system estimation.
</p>
<p>Some plots use standardized residuals. Note that they are not calculated in a system estimation context. See <a href="#topic+residuals.ldt.estim">residuals.ldt.estim</a> documentation for a description.
Cook's distance is also calculated equation-wise. Its formula is:
</p>
<p style="text-align: center;"><code class="reqn">
d = \frac{r_i^2}{k*var(r)}\frac{h_{ii}}{(1-h_{ii})^2}
</code>
</p>

<p>where <code class="reqn">r_i</code> and <code class="reqn">h_{ii}</code> are residual and leverage in <code class="reqn">i</code>-th observation, respectively. <code class="reqn">var(r)</code> is variance of residuals and <code class="reqn">k</code> is the number of estimated coefficients in the equation.
Note that Cook's distance is not implemented for weighted observations.
</p>


<h3>Value</h3>

<p>This function creates diagnostic plots for regression models.
It also returns a list with <code>x</code> and <code>y</code> data used in plot functions.
</p>

<hr>
<h2 id='plot.ldt.varma.prediction'>Plot Predictions from a VARMA model</h2><span id='topic+plot.ldt.varma.prediction'></span>

<h3>Description</h3>

<p>Plot Predictions from a VARMA model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.varma.prediction'
plot(
  x,
  variable = 1,
  xAxisArgs = list(),
  fanPlotArgs = list(),
  simMetric = NULL,
  simLineArgs = list(),
  simPointsArgs = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ldt.varma.prediction_+3A_x">x</code></td>
<td>
<p>An object of class <code>ldt.varma.prediction</code>, which is the output of <a href="#topic+predict.ldt.estim.varma">predict.ldt.estim.varma</a> function.</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_variable">variable</code></td>
<td>
<p>Index or name of the variable to be plotted.</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_xaxisargs">xAxisArgs</code></td>
<td>
<p>Arguments to pass to <code>axis</code> function</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_fanplotargs">fanPlotArgs</code></td>
<td>
<p>Additional arguments for the <a href="#topic+fan.plot">fan.plot</a> function. <code>lambda</code> is added automatically.</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_simmetric">simMetric</code></td>
<td>
<p>Name of metric to plot its details, provided that simulation details are available. If <code>NULL</code>, simulation details are not plotted.</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_simlineargs">simLineArgs</code></td>
<td>
<p>Arguments to pass to <code>line</code> function for simulation lines (if available).</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_simpointsargs">simPointsArgs</code></td>
<td>
<p>Arguments to pass to <code>points</code> function for simulation points (if available).</p>
</td></tr>
<tr><td><code id="plot.ldt.varma.prediction_+3A_...">...</code></td>
<td>
<p>Additional parameters (unused)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return a value.
</p>

<hr>
<h2 id='predict.ldt.estim'>Extract Prediction Results</h2><span id='topic+predict.ldt.estim'></span>

<h3>Description</h3>

<p>This function extracts predicted mean and its variance from an <code>ldt.estim</code> object.
new data must be provided while estimating the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code></p>
</td></tr>
<tr><td><code id="predict.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the predicted (projected) means and variances.
</p>

<hr>
<h2 id='predict.ldt.estim.varma'>Extract Prediction Results from a <code>ldt.estim.varma</code> Object</h2><span id='topic+predict.ldt.estim.varma'></span>

<h3>Description</h3>

<p>This function extracts predicted mean and its variance from an <code>ldt.estim.varma</code> object.
new data must be provided while estimating the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim.varma'
predict(object, actualCount = 0, startFrequency = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ldt.estim.varma_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim.varma</code></p>
</td></tr>
<tr><td><code id="predict.ldt.estim.varma_+3A_actualcount">actualCount</code></td>
<td>
<p>Number of actual observations to be included in the result.</p>
</td></tr>
<tr><td><code id="predict.ldt.estim.varma_+3A_startfrequency">startFrequency</code></td>
<td>
<p>Frequency of the first observation used in the estimation.
This is object of class <code>ldtf</code>.</p>
</td></tr>
<tr><td><code id="predict.ldt.estim.varma_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If estimation data undergoes a Box-Cox transformation, the resulting values will not be transformed accordingly.
</p>


<h3>Value</h3>

<p>An object of class <code>ldt.varma.prediction</code>, which is a list with predicted <code>means</code> and (if available) <code>variances</code>.
</p>

<hr>
<h2 id='print.ldt.estim'>Prints an <code>ldt.estim</code> object</h2><span id='topic+print.ldt.estim'></span>

<h3>Description</h3>

<p>Prints the main results in an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ldt.estim_+3A_x">x</code></td>
<td>
<p>An object of class <code>ldt.estim</code></p>
</td></tr>
<tr><td><code id="print.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code>ldt.search</code> object is an output from one of the <code>search.?</code> functions (see <code>search.sur</code>, <code>search.varma</code>, or <code>search.bin</code>).
</p>


<h3>Value</h3>

<p>This function has no output.
</p>

<hr>
<h2 id='print.ldt.estim.projection'>Prints an <code>ldt.estim.projection</code> object</h2><span id='topic+print.ldt.estim.projection'></span>

<h3>Description</h3>

<p>An <code>ldt.estim.projection</code> object is the output of <code><a href="#topic+predict.ldt.estim">predict.ldt.estim()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim.projection'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ldt.estim.projection_+3A_x">x</code></td>
<td>
<p>An object of class <code>ldt.estim.projection</code></p>
</td></tr>
<tr><td><code id="print.ldt.estim.projection_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function has no output.
</p>

<hr>
<h2 id='print.ldt.list'>Prints an <code>ldt.list</code> object</h2><span id='topic+print.ldt.list'></span>

<h3>Description</h3>

<p>Prints an <code>ldt.list</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.list'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ldt.list_+3A_x">x</code></td>
<td>
<p>An object of class <code>ldt.list</code></p>
</td></tr>
<tr><td><code id="print.ldt.list_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function has no output.
</p>

<hr>
<h2 id='print.ldt.search'>Prints an <code>ldt.search</code> object</h2><span id='topic+print.ldt.search'></span>

<h3>Description</h3>

<p>Prints the main results in an <code>ldt.search</code> object.
This includes information about the first best models and significant coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.search'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ldt.search_+3A_x">x</code></td>
<td>
<p>An object of class <code>ldt.search</code></p>
</td></tr>
<tr><td><code id="print.ldt.search_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code>ldt.search</code> object is an output from one of the <code>search.?</code> functions (see <code>search.sur</code>, <code>search.varma</code>, or <code>search.bin</code>).
</p>


<h3>Value</h3>

<p>This function has no output.
</p>

<hr>
<h2 id='print.ldt.varma.prediction'>Prints an <code>ldt.varma.prediction</code> object</h2><span id='topic+print.ldt.varma.prediction'></span>

<h3>Description</h3>

<p>An <code>ldt.varma.prediction</code> object is the output of <code><a href="#topic+predict.ldt.estim.varma">predict.ldt.estim.varma()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.varma.prediction'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ldt.varma.prediction_+3A_x">x</code></td>
<td>
<p>An object of class <code>ldt.varma.prediction</code></p>
</td></tr>
<tr><td><code id="print.ldt.varma.prediction_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function has no output.
</p>

<hr>
<h2 id='rand.mnormal'>Generate Random Samples from a Multivariate Normal Distribution</h2><span id='topic+rand.mnormal'></span>

<h3>Description</h3>

<p>Use this function to get random samples from a multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rand.mnormal(n, mu = NULL, sigma = NULL, p = NULL, byRow = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rand.mnormal_+3A_n">n</code></td>
<td>
<p>The number of samples to generate.</p>
</td></tr>
<tr><td><code id="rand.mnormal_+3A_mu">mu</code></td>
<td>
<p>The mean vector of the distribution.
If <code>NULL</code>, it defaults to a zero vector of length <code>p</code>.
If <code>NA</code>, it is set to a random vector.</p>
</td></tr>
<tr><td><code id="rand.mnormal_+3A_sigma">sigma</code></td>
<td>
<p>The covariance matrix of the distribution.
If <code>NULL</code>, it defaults to an identity matrix of size <code>p x p</code>.
If <code>NA</code>, it is set to a random positive definite matrix.</p>
</td></tr>
<tr><td><code id="rand.mnormal_+3A_p">p</code></td>
<td>
<p>The dimension of the distribution, if both <code>mu</code> and <code>sigma</code> are <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="rand.mnormal_+3A_byrow">byRow</code></td>
<td>
<p>If <code>TRUE</code>, generated samples are stored in the rows. Otherwise, they are stored in the columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the generated sample (<code>p x n</code>), <code>mu</code>, and <code>sigma</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s1 &lt;- rand.mnormal(10, mu = c(0, 0), sigma = matrix(c(1, 0.5, 0.5, 1), ncol = 2))
s2 &lt;- rand.mnormal(10, mu = c(1,1), sigma = NA, p = 2)
s3 &lt;- rand.mnormal(10, p = 2, byRow = FALSE) #standard normal

</code></pre>

<hr>
<h2 id='residuals.ldt.estim'>Extract Residuals Data</h2><span id='topic+residuals.ldt.estim'></span>

<h3>Description</h3>

<p>This function returns residuals from or calculates the standardized residuals for an <code>ldt.estim</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.estim'
residuals(object, equations = NULL, standardized = FALSE, pearson = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.ldt.estim_+3A_object">object</code></td>
<td>
<p>An object of class <code>ldt.estim</code>.</p>
</td></tr>
<tr><td><code id="residuals.ldt.estim_+3A_equations">equations</code></td>
<td>
<p>A number, a numeric array or a string array specifying the equations with residual data. If <code>NULL</code>, residuals in all equations are returned.</p>
</td></tr>
<tr><td><code id="residuals.ldt.estim_+3A_standardized">standardized</code></td>
<td>
<p>If <code>TRUE</code>, standardized residuals are returned. See details.</p>
</td></tr>
<tr><td><code id="residuals.ldt.estim_+3A_pearson">pearson</code></td>
<td>
<p>If <code>TRUE</code>, it returns (or uses) Pearson residuals for binary choice regression.</p>
</td></tr>
<tr><td><code id="residuals.ldt.estim_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standardized residuals have identical variance.
In order to calculate the standardized residuals, each residual is divided by <code class="reqn">s\sqrt{w_i(1-h_{ii})}</code> where <code class="reqn">s</code> is the standard error of residuals and <code class="reqn">h_{ii}</code> is the leverage of <code class="reqn">i</code>-th observation. <code class="reqn">w_i</code> is the weight of the <code class="reqn">i</code>-th observation if data is weighted, and 1 otherwise.
Note that while the residuals are estimated in a system, the <code class="reqn">h_{ii}</code> is calculated in a univariate context as the <code class="reqn">i</code>-th diagonal of <code class="reqn">X(X'X)^{-1}X'</code> matrix, where <code class="reqn">X</code> is the exogenous variables in the corresponding equation.
</p>


<h3>Value</h3>

<p>A matrix containing the residuals data.
</p>

<hr>
<h2 id='s.cluster.h'>Hierarchical Clustering</h2><span id='topic+s.cluster.h'></span>

<h3>Description</h3>

<p>This function performs hierarchical clustering on a group of variables, given their distances from each other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.cluster.h(distances, linkage = "single")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.cluster.h_+3A_distances">distances</code></td>
<td>
<p>Lower triangle of a symmetric distance matrix (without the diagonal).
This can be the output of <code><a href="#topic+s.distance">s.distance</a></code> function.</p>
</td></tr>
<tr><td><code id="s.cluster.h_+3A_linkage">linkage</code></td>
<td>
<p>Character string specifying the method for calculating the distance in a left-right node merge.
It can be <code>single</code>, <code>complete</code>, <code>uAverage</code>, <code>wAverage</code>, or <code>ward</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main purpose of exporting this statistics helper method is to show the inner calculations of the package.
</p>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>merge</code></td>
<td>
<p>An integer matrix representing the merge matrix. </p>
</td></tr>
<tr><td><code>height</code></td>
<td>
<p>A numeric vector representing the heights. </p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>An integer vector representing the orders.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10
data &lt;- data.frame(x = rnorm(n), y = rnorm(n), z = rnorm(n))
distances &lt;- s.distance(data)
clusters &lt;- s.cluster.h(distances)

</code></pre>

<hr>
<h2 id='s.cluster.h.group'>Group Variables with Hierarchical Clustering</h2><span id='topic+s.cluster.h.group'></span>

<h3>Description</h3>

<p>This function groups the columns of a numeric matrix based on the hierarchical clustering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.cluster.h.group(
  data,
  nGroups = 2,
  threshold = 0,
  distance = "correlation",
  linkage = "single",
  correlation = "pearson"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.cluster.h.group_+3A_data">data</code></td>
<td>
<p>A numeric matrix with variables in the columns.</p>
</td></tr>
<tr><td><code id="s.cluster.h.group_+3A_ngroups">nGroups</code></td>
<td>
<p>Integer value specifying the number of required groups.</p>
</td></tr>
<tr><td><code id="s.cluster.h.group_+3A_threshold">threshold</code></td>
<td>
<p>Numeric value specifying a threshold for omitting variables.
If the distance between two variables in a group is less than this value, the second one will be omitted.
Note that a change in the order of the columns might change the results.</p>
</td></tr>
<tr><td><code id="s.cluster.h.group_+3A_distance">distance</code></td>
<td>
<p>Character string specifying how distances are calculated.
It can be <code>correlation</code>, <code>absCorrelation</code>, <code>euclidean</code>, <code>manhattan</code>, or <code>maximum</code>.
See <code><a href="#topic+s.distance">s.distance</a></code> function.</p>
</td></tr>
<tr><td><code id="s.cluster.h.group_+3A_linkage">linkage</code></td>
<td>
<p>Character string specifying how distances are calculated in a left-right node merge.
It can be <code>single</code>, <code>complete</code>, <code>uAverage</code>, <code>wAverage</code>, or <code>ward</code>.
See <code><a href="#topic+s.cluster.h">s.cluster.h</a></code> function.</p>
</td></tr>
<tr><td><code id="s.cluster.h.group_+3A_correlation">correlation</code></td>
<td>
<p>Character string specifying the type of correlation if <code>distance</code> is correlation.
It can be <code>pearson</code> or <code>spearman</code>. See <code><a href="#topic+s.distance">s.distance</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The results might be different from R's 'cutree' function.
(I don't know how 'cutree' works) Here this function iterates over the nodes and
whenever a split occurs, it adds a group until the required number of groups is reached.
</p>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>groups</code></td>
<td>
<p>A list of integer vectors representing the indexes of variables in each group. </p>
</td></tr>
<tr><td><code>removed</code></td>
<td>
<p>An integer vector representing the indexes of removed variables.</p>
</td></tr>
</table>

<hr>
<h2 id='s.combine.stats4'>Combine Mean, Variance, Skewness, and Kurtosis
This function combines two sets of mean, variance, skewness, and kurtosis and generates the combined statistics.</h2><span id='topic+s.combine.stats4'></span>

<h3>Description</h3>

<p>Combine Mean, Variance, Skewness, and Kurtosis
This function combines two sets of mean, variance, skewness, and kurtosis and generates the combined statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.combine.stats4(list1, list2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.combine.stats4_+3A_list1">list1</code></td>
<td>
<p>A list representing the first <code>mean</code>, <code>variance</code>, <code>skewness</code>, <code>kurtosis</code>, <code>weight</code>, and <code>count</code>.</p>
</td></tr>
<tr><td><code id="s.combine.stats4_+3A_list2">list2</code></td>
<td>
<p>A list representing the second distribution (similar to <code>list1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume there are two samples with <code class="reqn">mean_i</code>, <code class="reqn">variance_i</code>, <code class="reqn">skewness_i</code>, and <code class="reqn">kurtosis_i</code> for <code class="reqn">i=1,2</code>,
this function calculates the mean, variance, skewness, and kurtosis of the combined sample.
It does not need the data itself.
It is based on population variance, skewness, and kurtosis and calculates the population statistics.
Note that the kurtosis is not excess kurtosis.
</p>


<h3>Value</h3>

<p>A list similar to <code>list1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000 # sample size (increase it for more accurate result)
sample1 &lt;- rchisq(n,3)
sample2 &lt;- rchisq(n,5)

d1 &lt;- list(mean = mean(sample1),
           variance = var(sample1),
           skewness = moments::skewness(sample1),
           kurtosis = moments::kurtosis(sample1),
           count=length(sample1),
           weight = length(sample1))
d2 &lt;- list(mean = mean(sample2),
           variance = var(sample2),
           skewness = moments::skewness(sample2),
           kurtosis = moments::kurtosis(sample2),
           count=length(sample2),
           weight = length(sample2))
c &lt;- s.combine.stats4(d1,d2)

# we can compare the results:
combined &lt;- c(sample1,sample2)
mean_c = mean(combined)
variance_c = var(combined)
skewness_c = moments::skewness(combined)
kurtosis_c = moments::kurtosis(combined)

</code></pre>

<hr>
<h2 id='s.distance'>Get the Distances Between Variables</h2><span id='topic+s.distance'></span>

<h3>Description</h3>

<p>This function calculates the distances between the columns of a numeric matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.distance(
  data,
  distance = "correlation",
  correlation = "pearson",
  checkNan = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.distance_+3A_data">data</code></td>
<td>
<p>A numeric matrix with variables in the columns.</p>
</td></tr>
<tr><td><code id="s.distance_+3A_distance">distance</code></td>
<td>
<p>Character string specifying the type of distance.
It can be <code>correlation</code>, <code>absCorrelation</code>, <code>euclidean</code>, <code>manhattan</code>, or <code>maximum</code>.</p>
</td></tr>
<tr><td><code id="s.distance_+3A_correlation">correlation</code></td>
<td>
<p>Character string specifying the type of correlation if <code>distance</code> is correlation.
It can be <code>pearson</code> or <code>spearman</code>.</p>
</td></tr>
<tr><td><code id="s.distance_+3A_checknan">checkNan</code></td>
<td>
<p>Logical value indicating whether to check for <code>NA</code>s (and omit them if any exist).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main purpose of exporting this statistics helper method is to show the inner calculations of the package.
</p>


<h3>Value</h3>

<p>A symmetric matrix (lower triangle as a vector).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10
data &lt;- data.frame(x = rnorm(n), y = rnorm(n), z = rnorm(n))
distances &lt;- s.distance(data)

</code></pre>

<hr>
<h2 id='s.gld.density.quantile'>GLD Density-Quantile Function</h2><span id='topic+s.gld.density.quantile'></span>

<h3>Description</h3>

<p>This function calculates the densities of a Generalized Lambda Distribution (FKLM) given a vector of probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.gld.density.quantile(probs, p1, p2, p3, p4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.gld.density.quantile_+3A_probs">probs</code></td>
<td>
<p>A numeric vector representing the probabilities.</p>
</td></tr>
<tr><td><code id="s.gld.density.quantile_+3A_p1">p1</code></td>
<td>
<p>Numeric value representing the first parameter (location) of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.density.quantile_+3A_p2">p2</code></td>
<td>
<p>Numeric value representing the second parameter (scale) of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.density.quantile_+3A_p3">p3</code></td>
<td>
<p>Numeric value representing the third parameter (skewness) of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.density.quantile_+3A_p4">p4</code></td>
<td>
<p>Numeric value representing the fourth parameter (kurtosis) of the distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is a helper statistics method in this package and is generally used to plot density function of a GLD distribution.
</p>


<h3>Value</h3>

<p>A numeric vector representing the densities for each probability in <code>probs</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+s.gld.quantile">s.gld.quantile</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># In this example we use this function and plot the density function for
# standard normal distribution:
probs &lt;- seq(0.1,0.9,0.1)
x &lt;- s.gld.quantile(probs, 0,1,0,0)
y &lt;- s.gld.density.quantile(probs, 0,1,0,0)
plot(x,y)
lines(x,y)
</code></pre>

<hr>
<h2 id='s.gld.from.moments'>Get the GLD Parameters from the moments</h2><span id='topic+s.gld.from.moments'></span>

<h3>Description</h3>

<p>Calculates the parameters of the generalized lambda distribution (FKML), given the first four moments of the distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.gld.from.moments(
  mean = 0,
  variance = 1,
  skewness = 0,
  excessKurtosis = 0,
  type = 0,
  start = NULL,
  nelderMeadOptions = get.options.neldermead()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.gld.from.moments_+3A_mean">mean</code></td>
<td>
<p>A number for the mean of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.from.moments_+3A_variance">variance</code></td>
<td>
<p>A number for the variance of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.from.moments_+3A_skewness">skewness</code></td>
<td>
<p>A number for the skewness of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.from.moments_+3A_excesskurtosis">excessKurtosis</code></td>
<td>
<p>A number for the excess kurtosis of the distribution.</p>
</td></tr>
<tr><td><code id="s.gld.from.moments_+3A_type">type</code></td>
<td>
<p>An integer to restrict the shape of the distribution. See details section.</p>
</td></tr>
<tr><td><code id="s.gld.from.moments_+3A_start">start</code></td>
<td>
<p>A numeric vector of size 2 for the starting value.</p>
</td></tr>
<tr><td><code id="s.gld.from.moments_+3A_neldermeadoptions">nelderMeadOptions</code></td>
<td>
<p>A list of options for Nelder-Mead algorithm. Use <a href="#topic+get.options.neldermead">get.options.neldermead</a> for initialization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The type of the distribution is determined by one or two restrictions:
</p>

<ul>
<li> <p><strong>type 0:</strong> general, no restriction
</p>
</li>
<li> <p><strong>type 1:</strong> symmetric 'type 0', p3 == p4
</p>
</li>
<li> <p><strong>type 2:</strong> uni-modal continuous tail, p3 &lt; 1 &amp; p4 &lt; 1
</p>
</li>
<li> <p><strong>type 3:</strong> symmetric 'type 2', p3 == p4
</p>
</li>
<li> <p><strong>type 4:</strong> uni-modal continuous tail finite slope, p3 &lt;= 0.5 &amp; p4 &lt;= 0.5
</p>
</li>
<li> <p><strong>type 5:</strong> symmetric 'type 4', p3 == p4
</p>
</li>
<li> <p><strong>type 6:</strong> uni-modal truncated density curves, p3 &gt;= 2 &amp; p4 &gt;= 2 (includes uniform distribution)
</p>
</li>
<li> <p><strong>type 7:</strong> symmetric 'type 6', p3 == p4
</p>
</li>
<li> <p><strong>type 8:</strong> S shaped, (p3 &gt; 2 &amp; 1 &lt; p4 &lt; 2) or (1 &lt; p3 &lt; 2 &amp; p4 &gt; 2)
</p>
</li>
<li> <p><strong>type 9:</strong> U shaped, (1 &lt; p3 &lt;= 2) and (1 &lt; p4 &lt;= 2)
</p>
</li>
<li> <p><strong>type 10:</strong> symmetric 'type 9', p3 == p4
</p>
</li>
<li> <p><strong>type 11:</strong> monotone, p3 &gt; 1 &amp; p4 &lt;= 1
</p>
</li></ul>



<h3>Value</h3>

<p>A vector of length 5. The first 4 elements are the parameters of the GLD distribution.
The last one is the number of iterations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- s.gld.from.moments(0,1,0,0, start = c(0,0), type = 4)
probs &lt;- seq(0.1,0.9,0.1)
x &lt;- s.gld.quantile(probs, res[1],res[2],res[3],res[4])
y &lt;- s.gld.density.quantile(probs, res[1],res[2],res[3],res[4])
plot(x,y)
lines(x,y)


</code></pre>

<hr>
<h2 id='s.gld.quantile'>GLD Quantile Function</h2><span id='topic+s.gld.quantile'></span>

<h3>Description</h3>

<p>This function calculates the quantiles of a Generalized Lambda Distribution (FKML).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.gld.quantile(probs, p1, p2, p3, p4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.gld.quantile_+3A_probs">probs</code></td>
<td>
<p>A numeric vector of probabilities.</p>
</td></tr>
<tr><td><code id="s.gld.quantile_+3A_p1">p1</code></td>
<td>
<p>Numeric value representing the first parameter of the distribution (location of the distribution).</p>
</td></tr>
<tr><td><code id="s.gld.quantile_+3A_p2">p2</code></td>
<td>
<p>Numeric value representing the second parameter of the distribution (scale of the distribution).</p>
</td></tr>
<tr><td><code id="s.gld.quantile_+3A_p3">p3</code></td>
<td>
<p>Numeric value representing the third parameter of the distribution (skewness of the distribution).</p>
</td></tr>
<tr><td><code id="s.gld.quantile_+3A_p4">p4</code></td>
<td>
<p>Numeric value representing the fourth parameter of the distribution (kurtosis of the distribution).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is a helper statistics method in this package and is generally used to plot density function of a GLD distribution.
See the example of <code><a href="#topic+s.gld.density.quantile">s.gld.density.quantile</a></code> function for more details.
</p>


<h3>Value</h3>

<p>A numeric vector representing the quantiles for each probability in <code>probs</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+s.gld.density.quantile">s.gld.density.quantile</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res = s.gld.quantile(c(0.1,0.5,0.95), 0,1,0,0) # standard normal distribution

</code></pre>

<hr>
<h2 id='s.metric.from.weight'>Convert a Weight to Metric</h2><span id='topic+s.metric.from.weight'></span>

<h3>Description</h3>

<p>This function converts a weight to its metric equivalent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.metric.from.weight(value, metricName, minValue = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.metric.from.weight_+3A_value">value</code></td>
<td>
<p>Numeric value of the weight.</p>
</td></tr>
<tr><td><code id="s.metric.from.weight_+3A_metricname">metricName</code></td>
<td>
<p>Character string specifying the name of the metric.
See <code><a href="#topic+get.search.metrics">get.search.metrics</a></code> function for the list of available options.</p>
</td></tr>
<tr><td><code id="s.metric.from.weight_+3A_minvalue">minValue</code></td>
<td>
<p>A minimum value used in exponential weight formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+s.weight.from.metric">s.weight.from.metric</a> and <a href="#topic+get.search.metrics">get.search.metrics</a> for more details.
</p>
<p>Note that the main purpose of exporting this statistics helper method is to show the inner calculations of the package.
</p>


<h3>Value</h3>

<p>A numeric value representing the converted weight.
</p>


<h3>See Also</h3>

<p><a href="#topic+s.weight.from.metric">s.weight.from.metric</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>weight &lt;- s.weight.from.metric(-3.4, "sic")
metric &lt;- s.metric.from.weight(weight, "sic")

</code></pre>

<hr>
<h2 id='s.pca'>Principal Component Analysis</h2><span id='topic+s.pca'></span>

<h3>Description</h3>

<p>This function performs PCA on the columns of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.pca(x, center = TRUE, scale = TRUE, newX = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.pca_+3A_x">x</code></td>
<td>
<p>A numeric matrix with variables in the columns.</p>
</td></tr>
<tr><td><code id="s.pca_+3A_center">center</code></td>
<td>
<p>Logical value indicating whether to demean the columns of <code>x</code>.</p>
</td></tr>
<tr><td><code id="s.pca_+3A_scale">scale</code></td>
<td>
<p>Logical value indicating whether to scale the columns of <code>x</code> to unit variance.</p>
</td></tr>
<tr><td><code id="s.pca_+3A_newx">newX</code></td>
<td>
<p>A numeric matrix to be used in projection.
Its structure must be similar to <code>x</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main purpose of exporting this statistics helper method is to show the inner calculations of the package.
</p>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>removed0Var</code></td>
<td>
<p>An integer vector showing the zero-based indices of removed columns with zero variances.</p>
</td></tr>
<tr><td><code>directions</code></td>
<td>
<p>Directions matrix.</p>
</td></tr>
<tr><td><code>stds</code></td>
<td>
<p>An integer vector showing the standard deviation of the principal components.</p>
</td></tr>
<tr><td><code>stds2Ratio</code></td>
<td>
<p>Shows <code>stds^2/sum(stds^2)</code>.</p>
</td></tr>
<tr><td><code>projections</code></td>
<td>
<p>Projections matrix if <code>newX</code> is provided.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+get.options.pca">get.options.pca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(340)
data &lt;- matrix(rnorm(500), nrow = 50, ncol = 10)

# using prcomp function
resR = prcomp(data, center = TRUE, scale. = TRUE)

# using s.pca in this package
res = s.pca(data,TRUE,TRUE,data)

# res$projections and resR$x must be equal
# res$directions and t(resR$rotation) must be equal

# ----- ANOTHER EXAMPLE: PCA where there is a constant variable:
data &lt;- data.frame( x = rnorm(100), y = rnorm(100), z = rep(0, 100))

# using s.pca in this package
res &lt;- s.pca(data)

# using prcomp function
res_invalid &lt;- try(prcomp(data, center = TRUE,
                          scale. = TRUE))
# Fails, we should remove 'z' first

</code></pre>

<hr>
<h2 id='s.roc'>Get ROC Curve Data for Binary Classification</h2><span id='topic+s.roc'></span>

<h3>Description</h3>

<p>This function calculates the required points for plotting the ROC curve and the AUC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.roc(y, scores, weights = NULL, options = get.options.roc())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.roc_+3A_y">y</code></td>
<td>
<p>A numeric vector (<code>Nx1</code>) representing the actual values.</p>
</td></tr>
<tr><td><code id="s.roc_+3A_scores">scores</code></td>
<td>
<p>A numeric vector (<code>Nx1</code>) representing the calculated probabilities for the <strong>negative</strong> observations.</p>
</td></tr>
<tr><td><code id="s.roc_+3A_weights">weights</code></td>
<td>
<p>A numeric vector (<code>Nx1</code>) representing the weights of the observations.
Use <code>NULL</code> for equal weights.</p>
</td></tr>
<tr><td><code id="s.roc_+3A_options">options</code></td>
<td>
<p>A list from <code><a href="#topic+get.options.roc">get.options.roc</a></code> function for more options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is generally a statistics helper method in this package and it shows the inner calculations.
See AUC section in <a href="#topic+get.search.metrics">get.search.metrics</a> for a discussion.
</p>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>Number of observations. </p>
</td></tr>
<tr><td><code>auc</code></td>
<td>
<p>Value of AUC. </p>
</td></tr>
<tr><td><code>points</code></td>
<td>
<p>Points for plotting ROC.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- c(1, 0, 1, 0, 1, 1, 0, 0, 1, 0)
scores &lt;- c(0.1, 0.2, 0.3, 0.5, 0.5, 0.5, 0.7, 0.8, 0.9, 1)
res1 &lt;- s.roc(y,scores)
costs &lt;- c(1,2,1,4,1,5,1,1,0.5,1)
costMatrix &lt;- matrix(c(0.02,-1,-3,3),2,2)
opt &lt;- get.options.roc(costs = costs, costMatrix = costMatrix)
res2 &lt;- s.roc(y,scores,NULL,options = opt)
</code></pre>

<hr>
<h2 id='s.weight.from.metric'>Convert a Metric to Weight</h2><span id='topic+s.weight.from.metric'></span>

<h3>Description</h3>

<p>This function converts a metric to its weight equivalent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.weight.from.metric(value, metricName, minValue = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.weight.from.metric_+3A_value">value</code></td>
<td>
<p>Numeric value of the metric.</p>
</td></tr>
<tr><td><code id="s.weight.from.metric_+3A_metricname">metricName</code></td>
<td>
<p>Character string specifying the name of the metric.
See <a href="#topic+get.search.metrics">get.search.metrics</a> function for the list of available options.</p>
</td></tr>
<tr><td><code id="s.weight.from.metric_+3A_minvalue">minValue</code></td>
<td>
<p>A minimum value to be used for metrics with exponential weight formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a collection of models for the data, a metric is not
generally a metric of the relative quality of a model. This function
converts the value of a metric to such a number.
see <a href="#topic+get.search.metrics">get.search.metrics</a> for more details.
</p>
<p>The main purpose of exporting this statistics helper method is to show the inner calculations of the package.
</p>


<h3>Value</h3>

<p>A numeric value representing the converted metric.
</p>


<h3>See Also</h3>

<p><a href="#topic+s.metric.from.weight">s.metric.from.weight</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>weight &lt;- s.weight.from.metric(-3.4, "sic")
metric &lt;- s.metric.from.weight(weight, "sic")

</code></pre>

<hr>
<h2 id='search.bin'>Create a Model Set for Binary Choice Models</h2><span id='topic+search.bin'></span>

<h3>Description</h3>

<p>Use this function to create a binary choice model set and search for the best models (and other information) based on in-sample and out-of-sample evaluation metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.bin(
  data,
  combinations,
  metrics = get.search.metrics(),
  modelChecks = get.search.modelchecks(),
  items = get.search.items(),
  options = get.search.options(),
  costMatrices = NULL,
  searchLogit = TRUE,
  searchProbit = FALSE,
  optimOptions = get.options.newton(),
  aucOptions = get.options.roc()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search.bin_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_combinations">combinations</code></td>
<td>
<p>A list that determines the combinations of the exogenous variables in the search process.
Use <code><a href="#topic+get.combinations">get.combinations()</a></code> function to define it.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_metrics">metrics</code></td>
<td>
<p>A list of options for measuring performance. Use <a href="#topic+get.search.metrics">get.search.metrics</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_modelchecks">modelChecks</code></td>
<td>
<p>A list of options for excluding a subset of the model set. Use <a href="#topic+get.search.modelchecks">get.search.modelchecks</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_items">items</code></td>
<td>
<p>A list of options for specifying the purpose of the search. Use <a href="#topic+get.search.items">get.search.items</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_options">options</code></td>
<td>
<p>A list of extra options for performing the search. Use <a href="#topic+get.search.options">get.search.options</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_costmatrices">costMatrices</code></td>
<td>
<p>A list of numeric matrices where each one determines how to score the calculated probabilities.
Given the number of choices <code>n</code>, a frequency cost matrix is an <code>m x n+1</code> matrix.
The first column determines the thresholds.
Elements in the <code>j</code>-th column determine the costs corresponding to the <code>j-1</code>-th choice in <code>y</code>.
It can be <code>NULL</code> if it is not selected in <code>metrics</code>.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_searchlogit">searchLogit</code></td>
<td>
<p>If <code>TRUE</code>, logit regressions are added to the model set.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_searchprobit">searchProbit</code></td>
<td>
<p>If <code>TRUE</code>, probit regressions are added to the model set.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_optimoptions">optimOptions</code></td>
<td>
<p>A list for Newton optimization options.
Use <a href="#topic+get.options.newton">get.options.newton</a> function to get the options.</p>
</td></tr>
<tr><td><code id="search.bin_+3A_aucoptions">aucOptions</code></td>
<td>
<p>A list for AUC calculation options.
Use <a href="#topic+get.options.roc">get.options.roc</a> function to get the options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A nested list with the following members:
</p>
<table>
<tr><td><code>counts</code></td>
<td>
<p>Information about the expected number of models, number of estimated models, failed estimations, and some details about the failures.</p>
</td></tr>
<tr><td><code>results</code></td>
<td>
<p>A data frame with requested information in <code>items</code> list.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>The arguments and some general information about the search process such as the elapsed time.</p>
</td></tr>
</table>
<p>Note that the output does not contain any estimation results, but minimum required data to estimate the models (Use <code>summary()</code> function to get the estimation).
</p>


<h3>See Also</h3>

<p><a href="#topic+estim.bin">estim.bin</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We simulate some data for this example:
# sample data:
n = 50 # number of observations
num_x_r &lt;- 3L # number of relevant explanatory variables
num_x_ir &lt;- 20 # (relatively large) number of irrelevant explanatory variables
set.seed(340)
sample &lt;- sim.bin(num_x_r, n)
x_ir &lt;- lapply(1:num_x_ir, function(x) rnorm(n))

# prepare data:
data &lt;- data.frame(sample$y, sample$x, x_ir)
colnames(data) &lt;- c("Y", colnames(sample$x), paste0("z", 1:num_x_ir))

# Use glm function to estimate and analyse:
fit &lt;- glm(Y ~ . - Y, data = data, family = binomial())
summary(fit)

# You can also use this package estimation function:
data0 &lt;- get.data(data,
                equations = list(Y ~ . - Y),
                addIntercept = FALSE)
fit &lt;- estim.bin(data = data0)
# format and print coefficients:
print(fit)

# Alternatively, You can define a binary choice model set:
x_sizes = c(1:3) # assuming we know the number of relevant explanatory variables is less than 3
metric_options &lt;- get.search.metrics(typesIn = c("sic")) # We use SIC for searching
search_res &lt;- search.bin(data = data0,
                         combinations = get.combinations(sizes = x_sizes),
                         metrics = metric_options)
print(search_res)

# Use summary function to estimate the best model:
search_sum &lt;- summary(search_res, y = sample$y, x = data[,3:ncol(data)])

# format and print coefficients:
s_fit &lt;- summary(search_res)
print(s_fit$results[[1]]$value)

# Try a step-wise search for creating a larger model set:
search_res &lt;- search.bin(data = data0,
                         combinations = get.combinations(
                           sizes = list(c(1, 2, 3), c(4)),
                           stepsNumVariables = c(NA, 7)),
                         metrics = metric_options)
# combinations argument is different

print(search_res)
# Use summary like before.

</code></pre>

<hr>
<h2 id='search.rfunc'>Create a Model Set for an R Function</h2><span id='topic+search.rfunc'></span>

<h3>Description</h3>

<p>Use this model to create a model set for an R function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.rfunc(
  data = get.data(),
  combinations = get.combinations(),
  metrics = get.search.metrics(),
  modelChecks = get.search.modelchecks(),
  items = get.search.items(),
  options = get.search.options(),
  rFuncName,
  length1,
  isInnerExogenous
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search.rfunc_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_combinations">combinations</code></td>
<td>
<p>A list that determines the combinations of endogenous and exogenous variables in the search process.
Use <code><a href="#topic+get.combinations">get.combinations()</a></code> function to define it.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_metrics">metrics</code></td>
<td>
<p>A list of options for measuring performance.
Use <a href="#topic+get.search.metrics">get.search.metrics</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_modelchecks">modelChecks</code></td>
<td>
<p>A list of options for excluding a subset of the model set.
See and use <a href="#topic+get.search.modelchecks">get.search.modelchecks</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_items">items</code></td>
<td>
<p>A list of options for specifying the purpose of the search.
See and use <a href="#topic+get.search.items">get.search.items</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_options">options</code></td>
<td>
<p>A list of extra options for performing the search.
See and use <a href="#topic+get.search.options">get.search.options</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_rfuncname">rFuncName</code></td>
<td>
<p>Name of a function that uses column indices and number of endogenous variables with respect to <code>data</code>.
It should estimate a model and return a list with required performance statistics. See details.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_length1">length1</code></td>
<td>
<p>An integer for the length of requested information. This can be the number of exogenous variables.</p>
</td></tr>
<tr><td><code id="search.rfunc_+3A_isinnerexogenous">isInnerExogenous</code></td>
<td>
<p>If <code>TRUE</code>, exogenous indices are defined by <code>innerGroups</code> in the <code>combinations</code> argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The central part of calling this function is to write a function with <code>rFuncName</code> name.
This function must have the following arguments:
</p>

<ul>
<li> <p><code>columnIndices</code>: determines the variables to be used in the current iteration. These indices point to the column of <code>data$data</code> matrix. E.g., you can create a matrix of available data by using <code>data$data[,colIndices]</code>. It contains weight column index (at <code>numEndo+1</code>), if <code>data$hasWeight</code> is <code>TRUE</code>.
</p>
</li>
<li> <p><code>numEndo</code>: can be used to divide the <code>columnIndices</code> into endogenous and exogenous indices.
</p>
</li>
<li> <p><code>data, metrics, modelChecks, items</code>: The arguments of current function which are passed to this function.
</p>
</li></ul>

<p>The <code>rFuncName</code> function should use these arguments and estimate or predict by using any available R function.
</p>
<p>This function must return a <code>List</code> with the following items:
</p>

<ul>
<li> <p><code>error</code> (Character string or NULL): It not <code>NULL</code> or empty, it is considered as a failed estimation with the given message.
</p>
</li>
<li> <p><code>metrics</code> (Numeric Matrix): Model performance for each target variable. Available target variables must be in the columns and metrics in the rows.
</p>
</li>
<li> <p><code>extra</code> (Numeric Vector or NULL): Extra information in form of integers, which defines the current model.
</p>
</li>
<li> <p><code>type1means</code> (Numeric Matrix or NULL): Means of <code>type1</code> (coefficients or predictions) for each target variable. Target variables must be in the columns. Make sure to skip the rows which the model does not present any information.
</p>
</li>
<li> <p><code>type1vars</code> (Numeric Matrix or NULL): similar to <code>type1means</code> but for reporting the variances.
</p>
</li></ul>



<h3>Value</h3>

<p>A nested list with the following members:
</p>
<table>
<tr><td><code>counts</code></td>
<td>
<p>Information about the expected number of models, number of estimated models, failed estimations, and some details about the failures.</p>
</td></tr>
<tr><td><code>results</code></td>
<td>
<p>A data frame with requested information in <code>items</code> list.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>The arguments and some general information about the search process such as the elapsed time.</p>
</td></tr>
</table>
<p>Note that the output does not contain any estimation results, but minimum required data to estimate the models (Use <code>summary()</code> function to get the estimation).
</p>

<hr>
<h2 id='search.steps'>Step-wise estimation</h2><span id='topic+search.steps'></span>

<h3>Description</h3>

<p>This function uses the calculated inclusion weights and selects a subset of variables in each step.
Note that it uses the values for the first target variable and first metric and might not be suitable for multi-target or multi-metric searches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.steps(method, isInnerExogenous, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search.steps_+3A_method">method</code></td>
<td>
<p>sur, bin or varma</p>
</td></tr>
<tr><td><code id="search.steps_+3A_isinnerexogenous">isInnerExogenous</code></td>
<td>
<p>Determines if the inner indices are for exogenous variables.</p>
</td></tr>
<tr><td><code id="search.steps_+3A_...">...</code></td>
<td>
<p>Additional arguments for the search function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the result
</p>

<hr>
<h2 id='search.sur'>Create a Model Set for SUR Models</h2><span id='topic+search.sur'></span>

<h3>Description</h3>

<p>Use this function to create a Seemingly Unrelated Regression model set and search for the best models (and other information) based on in-sample and out-of-sample evaluation metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.sur(
  data = get.data(),
  combinations = get.combinations(),
  metrics = get.search.metrics(),
  modelChecks = get.search.modelchecks(),
  items = get.search.items(),
  options = get.search.options(),
  searchSigMaxIter = 0,
  searchSigMaxProb = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search.sur_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_combinations">combinations</code></td>
<td>
<p>A list that determines the combinations of endogenous and exogenous variables in the search process.
Use <code><a href="#topic+get.combinations">get.combinations()</a></code> function to define it.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_metrics">metrics</code></td>
<td>
<p>A list of options for measuring performance. Use <a href="#topic+get.search.metrics">get.search.metrics</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_modelchecks">modelChecks</code></td>
<td>
<p>A list of options for excluding a subset of the model set. Use <a href="#topic+get.search.modelchecks">get.search.modelchecks</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_items">items</code></td>
<td>
<p>A list of options for specifying the purpose of the search. Use <a href="#topic+get.search.items">get.search.items</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_options">options</code></td>
<td>
<p>A list of extra options for performing the search. Use <a href="#topic+get.search.options">get.search.options</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_searchsigmaxiter">searchSigMaxIter</code></td>
<td>
<p>Maximum number of iterations in searching for significant coefficients. Use 0 to disable the search.</p>
</td></tr>
<tr><td><code id="search.sur_+3A_searchsigmaxprob">searchSigMaxProb</code></td>
<td>
<p>Maximum value of type I error to be used in searching for significant coefficients. If p-value is less than this, it is interpreted as significant.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A nested list with the following members:
</p>
<table>
<tr><td><code>counts</code></td>
<td>
<p>Information about the expected number of models, number of estimated models, failed estimations, and some details about the failures.</p>
</td></tr>
<tr><td><code>results</code></td>
<td>
<p>A data frame with requested information in <code>items</code> list.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>The arguments and some general information about the search process such as the elapsed time.</p>
</td></tr>
</table>
<p>Note that the output does not contain any estimation results, but minimum required data to estimate the models (Use <code>summary()</code> function to get the estimation).
</p>


<h3>See Also</h3>

<p><a href="#topic+estim.sur">estim.sur</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_y &lt;- 2L # number of equations
num_x_r &lt;- 3L # number of relevant explanatory variables
num_x_ir &lt;-
  10 # (relatively large) number of irrelevant explanatory variables
num_obs = 100  # number of observations

# create random data
sample &lt;- sim.sur(sigma = num_y, coef = num_x_r, nObs = num_obs)
x_ir &lt;- matrix(rnorm(num_obs * num_x_ir), ncol = num_x_ir) # irrelevant data

# prepare data for estimation
data &lt;- data.frame(sample$y, sample$x, x_ir)
colnames(data) &lt;- c(colnames(sample$y), colnames(sample$x), paste0("z", 1:num_x_ir))

# Use systemfit to estimate and analyse:
exp_names &lt;- paste0(colnames(data)[(num_y + 1):(length(colnames((data))))], collapse = " + ")
fmla &lt;- lapply(1:num_y, function(i) as.formula(paste0("Y", i, " ~ -1 + ", exp_names)))
fit &lt;- systemfit::systemfit(fmla, data = data, method = "SUR")
summary(fit)

# You can also use this package estimation function:
fit &lt;- estim.sur(data = get.data(data, endogenous = num_y, addIntercept = FALSE))
print(fit)

# Alternatively, You can define an SUR model set:
x_sizes = c(1:3) # assuming we know the number of relevant explanatory variables is less than 3
num_targets = 2
metric_options &lt;- get.search.metrics(typesIn = c("sic")) # We use SIC for searching
search_res &lt;- search.sur(data = get.data(data, endogenous = num_y, addIntercept = FALSE),
                         combinations = get.combinations(numTargets = num_targets,
                                                         sizes = x_sizes,
                                                         innerGroups = list(c(1), c(2))),
                         metrics = metric_options)
print(search_res)

# Use summary function to estimate the best models:
search_sum &lt;- summary(search_res)

# Print the best model:
print(search_sum$results[[2]]$value)
#   see 'estim.sur' function

# Using a step-wise search to build a larger model set:
x_sizes_steps = list(c(1, 2, 3), c(4))
counts_steps = c(NA, 7)
search_step_res &lt;- search.sur(data = get.data(data, endogenous = num_y, addIntercept = FALSE),
                              combinations = get.combinations(numTargets = num_targets,
                                                              sizes = x_sizes_steps,
                                                              stepsNumVariables = counts_steps,
                                                              innerGroups = list(c(1,2))),
                              metrics = metric_options)
# combinations argument is different

print(search_step_res)

</code></pre>

<hr>
<h2 id='search.varma'>Create Model Set for VARMA Models</h2><span id='topic+search.varma'></span>

<h3>Description</h3>

<p>Use this function to create a Vector Autoregressive Moving Average model set and search for the best models (and other information) based on in-sample and out-of-sample evaluation metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.varma(
  data = get.data(),
  combinations = get.combinations(),
  metrics = get.search.metrics(),
  modelChecks = get.search.modelchecks(),
  items = get.search.items(),
  options = get.search.options(),
  maxParams = c(1, 0, 0, 0, 0, 0),
  seasonsCount = 0,
  maxHorizon = 1,
  simUsePreviousEstim = FALSE,
  olsStdMultiplier = 2,
  lbfgsOptions = get.options.lbfgs()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search.varma_+3A_data">data</code></td>
<td>
<p>A list that determines data and other required information for the search process.
Use <code><a href="#topic+get.data">get.data()</a></code> function to generate it from a <code>matrix</code> or a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_combinations">combinations</code></td>
<td>
<p>A list that determines the combinations of endogenous and exogenous variables in the search process.
Use <code><a href="#topic+get.combinations">get.combinations()</a></code> function to define it.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_metrics">metrics</code></td>
<td>
<p>A list of options for measuring performance. Use <a href="#topic+get.search.metrics">get.search.metrics</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_modelchecks">modelChecks</code></td>
<td>
<p>A list of options for excluding a subset of the model set. Use <a href="#topic+get.search.modelchecks">get.search.modelchecks</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_items">items</code></td>
<td>
<p>A list of options for specifying the purpose of the search. Use <a href="#topic+get.search.items">get.search.items</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_options">options</code></td>
<td>
<p>A list of extra options for performing the search. Use <a href="#topic+get.search.options">get.search.options</a> function to get them.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_maxparams">maxParams</code></td>
<td>
<p>An integer vector that determines the maximum values for the parameters of the VARMA model: <code>(p,d,q,P,D,Q)</code>. If <code>NULL</code>, <code>c(2,0,0,0,0,0)</code> is used.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_seasonscount">seasonsCount</code></td>
<td>
<p>An integer value representing the number of observations per unit of time.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_maxhorizon">maxHorizon</code></td>
<td>
<p>An integer value representing the maximum value for the prediction horizon if <code>type1</code> is <code>TRUE</code> in the <code>modelChecks</code> argument. Also, it is used as the maximum prediction horizon in checking predictions.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_simusepreviousestim">simUsePreviousEstim</code></td>
<td>
<p>If <code>TRUE</code>, parameters are initialized only in the first step of the simulation. The initial values of the n-th simulation (with one more observation) are the estimations from the previous step.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_olsstdmultiplier">olsStdMultiplier</code></td>
<td>
<p>A number used as a multiplier for the standard deviation of OLS, used for restricting maximum likelihood estimation.</p>
</td></tr>
<tr><td><code id="search.varma_+3A_lbfgsoptions">lbfgsOptions</code></td>
<td>
<p>A list containing L-BFGS optimization options. Use <a href="#topic+get.options.lbfgs">get.options.lbfgs</a> function for initialization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A nested list with the following members:
</p>
<table>
<tr><td><code>counts</code></td>
<td>
<p>Information about the expected number of models, number of estimated models, failed estimations, and some details about the failures.</p>
</td></tr>
<tr><td><code>results</code></td>
<td>
<p>A data frame with requested information in <code>items</code> list.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>The arguments and some general information about the search process such as the elapsed time.</p>
</td></tr>
</table>
<p>Note that the output does not contain any estimation results, but minimum required data to estimate the models (Use <code>summary()</code> function to get the estimation).
</p>


<h3>See Also</h3>

<p><a href="#topic+estim.varma">estim.varma</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We simulate some data for this example:
set.seed(340)
n = 100
num_eq &lt;- 3L
num_ar &lt;- 2L
num_ma &lt;- 1L
num_ma &lt;- 1L
num_exo &lt;- 2L
sample &lt;- sim.varma(num_eq, arList = num_ar, maList = num_ma, exoCoef = num_exo, nObs = n)

# (relatively large) number of irrelevant explanatory variables:
num_y_ir &lt;- 10
y_ir &lt;- lapply(1:num_y_ir, function(x) rnorm(n))

# prepare data:
data &lt;- data.frame(sample$y, y_ir, sample$x)
colnames(data) &lt;- c(colnames(sample$y), paste0("w", 1:num_y_ir), colnames(sample$x))


# Create a VARMA model set:
y_sizes = 3 # assuming we know the number of relevant endogenous variables
metric_options &lt;- get.search.metrics(typesIn = c("aic")) # We use SIC for searching
search_res &lt;- search.varma(data = get.data(data, endogenous = num_eq + num_y_ir),
                           combinations = get.combinations(sizes = y_sizes,
                                                           numTargets = 3),
                           metrics = metric_options,
                           maxHorizon = 0)
print(search_res)


</code></pre>

<hr>
<h2 id='sim.bin'>Generate Random Sample from a DC Model</h2><span id='topic+sim.bin'></span>

<h3>Description</h3>

<p>This function generates a random sample from an discrete choice regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.bin(
  coef = 2L,
  nObs = 100,
  probit = FALSE,
  maxWeight = 1,
  pPos = 0.5,
  sampleFactor = 4,
  toNumeric = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.bin_+3A_coef">coef</code></td>
<td>
<p>Either a single integer specifying the number of variables in the model,
or a numeric vector of coefficients for the regression.</p>
</td></tr>
<tr><td><code id="sim.bin_+3A_nobs">nObs</code></td>
<td>
<p>The number of observations to generate.</p>
</td></tr>
<tr><td><code id="sim.bin_+3A_probit">probit</code></td>
<td>
<p>Logical value indicating whether to generate data from a probit model
(if <code>TRUE</code>) or a logit model (if <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="sim.bin_+3A_maxweight">maxWeight</code></td>
<td>
<p>Integer value indicating the maximum weight of the observations.
If <code>1</code>, observations are not weighted.
If larger than <code>1</code>, a vector of weights is generated and included in the return list. The weights are drawn from a discrete uniform distribution with a maximum value determined by <code>maxWeight</code>.
If weighted, a larger sample is created (<code>nObs * sampleFactor * maxWeight</code>) and a subset of them is randomly selected, where the probability of selection is determined by the weight.</p>
</td></tr>
<tr><td><code id="sim.bin_+3A_ppos">pPos</code></td>
<td>
<p>The percentage of positive observations (<code>y=1</code>) in the endogenous variable y.
Must be between 0 and 1.
In the current implementation, this is independent of the weights, if <code>maxWeight</code> is larger than 1.</p>
</td></tr>
<tr><td><code id="sim.bin_+3A_samplefactor">sampleFactor</code></td>
<td>
<p>The factor used to control the size of the initial sample.
A larger value generates a larger initial sample, which can increase the accuracy
of the generated sample but also takes more time and memory.</p>
</td></tr>
<tr><td><code id="sim.bin_+3A_tonumeric">toNumeric</code></td>
<td>
<p>If <code>TRUE</code>, <code>y</code> and <code>w</code> are transformed to have numeric vector.
Otherwise, they contain an integer vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>The endogenous variable.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The exogenous variables.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>The weights of the observations. It is <code>NULL</code> if <code>weighted</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code>p1</code></td>
<td>
<p>Prob(Y=1)</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>The coefficients of the regression.</p>
</td></tr>
<tr><td><code>probit</code></td>
<td>
<p>Logical value indicating whether data was generated from a probit model.</p>
</td></tr>
<tr><td><code>pPos</code></td>
<td>
<p>The percentage of negative observations in y.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+estim.bin">estim.bin</a>, <a href="#topic+search.bin">search.bin</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate data from a logit model with 3 variables
sample &lt;- sim.bin(3L, 100)

# see the examples in 'estim.bin' or 'search.bin' functions
</code></pre>

<hr>
<h2 id='sim.sur'>Generate Random Sample from an SUR Model</h2><span id='topic+sim.sur'></span>

<h3>Description</h3>

<p>This function generates a random sample from an Seemingly Unrelated Regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.sur(sigma = 1L, coef = 1L, nObs = 100, intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.sur_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix of the errors.
If it is an integer value, it specifies the number of equations in the SUR model and covariance matrix is generated randomly.</p>
</td></tr>
<tr><td><code id="sim.sur_+3A_coef">coef</code></td>
<td>
<p>Coefficients of the model.
If it is an integer value, it specifies the number of exogenous variables in each equation of the SUR model and coefficient matrix is generated randomly.</p>
</td></tr>
<tr><td><code id="sim.sur_+3A_nobs">nObs</code></td>
<td>
<p>Number of observations to generate.</p>
</td></tr>
<tr><td><code id="sim.sur_+3A_intercept">intercept</code></td>
<td>
<p>If <code>TRUE</code>, an intercept is included in the model as the first exogenous variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>matrix, the generated endogenous variable(s).</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>matrix, the generated exogenous variable(s).</p>
</td></tr>
<tr><td><code>e</code></td>
<td>
<p>matrix, the generated errors.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>matrix, the covariance matrix of the disturbances.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>matrix, the coefficients used in the model.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>logical, whether an intercept was included in the model.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+sim.varma">sim.varma</a>,<a href="#topic+estim.sur">estim.sur</a>,<a href="#topic+search.sur">search.sur</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_y &lt;- 2L
num_x &lt;- 3L
n_obs = 100
data &lt;- sim.sur(sigma = num_y, coef = num_x, nObs = n_obs)

# see the examples in 'estim.sur' or 'search.sur' functions
</code></pre>

<hr>
<h2 id='sim.varma'>Generate Random Sample from a VARMA Model</h2><span id='topic+sim.varma'></span>

<h3>Description</h3>

<p>This function generates a multivariate time series using a VARMA process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.varma(
  sigma = 2L,
  arList = 1L,
  maList = 0L,
  exoCoef = 0L,
  nObs = 100,
  nBurn = 10,
  intercept = TRUE,
  d = 0,
  startFrequency = NULL,
  seasonalCoefs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.varma_+3A_sigma">sigma</code></td>
<td>
<p>A positive definite matrix representing the covariance matrix of the white noise series or an integer representing the dimension of a random covariance matrix to generate.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_arlist">arList</code></td>
<td>
<p>A list of matrices representing the AR coefficients of the VARMA model or an integer representing the number of random AR coefficients to generate.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_malist">maList</code></td>
<td>
<p>A list of matrices representing the MA coefficients of the VARMA model or an integer representing the number of random MA coefficients to generate. For identification purposes, it generates diagonal matrices.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_exocoef">exoCoef</code></td>
<td>
<p>A matrix representing the coefficients of the exogenous variables or an integer representing the number of random exogenous coefficients to generate.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_nobs">nObs</code></td>
<td>
<p>An integer representing the number of observations to generate.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_nburn">nBurn</code></td>
<td>
<p>An integer representing the number of burn-in observations to remove from the generated time series.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_intercept">intercept</code></td>
<td>
<p>A numeric vector representing the intercept of the VARMA model or a logical value indicating whether to generate a random intercept.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_d">d</code></td>
<td>
<p>An integer representing the order of integration.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_startfrequency">startFrequency</code></td>
<td>
<p>The frequency of the first observation in the data.</p>
</td></tr>
<tr><td><code id="sim.varma_+3A_seasonalcoefs">seasonalCoefs</code></td>
<td>
<p>An integer vector of size 4: <code>(P,D,Q,s)</code> where
<code>P</code> is the number of random seasonal AR coefficients to generate,
<code>Q</code> is the number of random seasonal MA coefficients to generate,
<code>D</code> is the order of seasonal integration,
and <code>s</code> is the number of seasons.
These are effective if <code>arList</code> and <code>maList</code> are randomly generated within the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>The simulated endogenous data.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The simulated exogenous data.</p>
</td></tr>
<tr><td><code>e</code></td>
<td>
<p>The simulated white noise series.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The covariance matrix of the white noise series.</p>
</td></tr>
<tr><td><code>arList</code></td>
<td>
<p>The list of autoregressive coefficients.</p>
</td></tr>
<tr><td><code>maList</code></td>
<td>
<p>The list of moving average coefficients.</p>
</td></tr>
<tr><td><code>exoCoef</code></td>
<td>
<p>The matrix of exogenous coefficients.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>The intercept vector.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The order of the integration.</p>
</td></tr>
<tr><td><code>seasonalCoefs</code></td>
<td>
<p>The argument <code>seasonalCoefs</code> </p>
</td></tr>
<tr><td><code>nObs</code></td>
<td>
<p>The number of observations generated.</p>
</td></tr>
<tr><td><code>nBurn</code></td>
<td>
<p>The number of burn-in observations removed.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>sample1 &lt;- sim.varma(2L, 3L, 2L)

ar1 &lt;- matrix(c(0.7,0.2,-0.4,0.3),2,2)
ar2 &lt;- matrix(c(-0.4,0.1,0.2,-0.3),2,2)
ma1 &lt;- matrix(c(0.5,-0.1,0.3,0.4),2,2)
Sigma &lt;- matrix(c(1,0.3,0.3,1),2,2)
B &lt;- matrix(c(0.5,-0.3),2)

sample2 &lt;- sim.varma(Sigma, list(ar1, ar2), list(ma1), exoCoef = B ,
                    nObs =100, nBurn =10 , intercept = c(1,-1))

# Plot the y series
matplot(sample2$y,type = "l")

# see the examples in 'estim.varma' or 'search.varma' functions
</code></pre>

<hr>
<h2 id='summary.ldt.search'>Summary for an <code>ldt.search</code> object</h2><span id='topic+summary.ldt.search'></span>

<h3>Description</h3>

<p>Use this function to get the full estimation of the models reported in the output of a search process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.search'
summary(object, test = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ldt.search_+3A_object">object</code></td>
<td>
<p>An <code>ldt.search</code> object.</p>
</td></tr>
<tr><td><code id="summary.ldt.search_+3A_test">test</code></td>
<td>
<p>If <code>TRUE</code> and applicable (e.g., in model estimation), it checks the metrics and throws error for any inconsistencies between the current estimation and the one calculated in the search process (Provided that negative seed is used).</p>
</td></tr>
<tr><td><code id="summary.ldt.search_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code>ldt.search</code> object is an output from one of the <code>search.?</code> functions (see <code>search.sur</code>, <code>search.varma</code>, or <code>search.bin</code>).
</p>


<h3>Value</h3>

<p>The output replaces the value of <code>object$results</code> with the summary from <a href="#topic+summary.ldt.search.item">summary.ldt.search.item</a>.
</p>

<hr>
<h2 id='summary.ldt.search.item'>Summary for an <code>ldt.search.item</code> object</h2><span id='topic+summary.ldt.search.item'></span>

<h3>Description</h3>

<p>While you can get a summary of an item in a search result, this function is mainly designed to be called from <a href="#topic+print.ldt.search">print.ldt.search</a> function.
Its main job is to estimate the full model using the reported indices from the search process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldt.search.item'
summary(object, searchResult = NULL, test = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ldt.search.item_+3A_object">object</code></td>
<td>
<p>An <code>ldt.search.item</code> object.</p>
</td></tr>
<tr><td><code id="summary.ldt.search.item_+3A_searchresult">searchResult</code></td>
<td>
<p>Parent list of <code>object</code>, which is an <code>ldt.search</code> object.</p>
</td></tr>
<tr><td><code id="summary.ldt.search.item_+3A_test">test</code></td>
<td>
<p>If <code>TRUE</code> and applicable (e.g., in model estimation), it checks the metrics and throws error for any inconsistencies between the current estimation and the one calculated in the search process.</p>
</td></tr>
<tr><td><code id="summary.ldt.search.item_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code>ldt.search.item</code> object is a member of <code>ldt.search</code> object.
An <code>ldt.search</code> object is an output from one of the <code>search.?</code> functions (see <code>search.sur</code>, <code>search.varma</code>, or <code>search.bin</code>).
</p>


<h3>Value</h3>

<p>If the object contains the indices of endogenous variables of an estimated model, it returns the estimation output.
Otherwise, it returns object.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
