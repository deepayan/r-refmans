<!DOCTYPE html><html><head><title>Help for package surveysd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {surveysd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calc.stError'><p>Calcualte point estimates and their standard errors using bootstrap</p>
weights.</a></li>
<li><a href='#computeLinear'><p>Numerical weighting functions</p></a></li>
<li><a href='#cpp_mean'><p>Calculate mean by factors</p></a></li>
<li><a href='#demo.eusilc'><p>Generate multiple years of EU-SILC data</p></a></li>
<li><a href='#draw.bootstrap'><p>Draw bootstrap replicates</p></a></li>
<li><a href='#generate.HHID'><p>Generate new houshold ID for survey data with rotating panel design taking</p>
into account split households</a></li>
<li><a href='#ipf'><p>Iterative Proportional Fitting</p></a></li>
<li><a href='#ipf_step'><p>Perform one step of iterative proportional updating</p></a></li>
<li><a href='#kishFactor'><p>Kish Factor</p></a></li>
<li><a href='#plot.surveysd'><p>Plot surveysd-Objects</p></a></li>
<li><a href='#PointEstimates'><p>Weighted Point Estimates</p></a></li>
<li><a href='#print.surveysd'><p>Print function for surveysd objects</p></a></li>
<li><a href='#recalib'><p>Calibrate weights</p></a></li>
<li><a href='#rescaled.bootstrap'><p>Draw bootstrap replicates</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Survey Standard Error Estimation for Cumulated Estimates and
their Differences in Complex Panel Designs</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johannes Gussenbauer &lt;Johannes.Gussenbauer@statistik.gv.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculate point estimates and their standard errors in complex household surveys using bootstrap replicates. Bootstrapping considers survey design with a rotating panel. A comprehensive description of the methodology can be found under <a href="https://statistikat.github.io/surveysd/articles/methodology.html">https://statistikat.github.io/surveysd/articles/methodology.html</a>.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.12),data.table,ggplot2,laeken,methods</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/statistikat/surveysd">https://github.com/statistikat/surveysd</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/statistikat/surveysd/issues">https://github.com/statistikat/surveysd/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-19 08:04:11 UTC; gussen</td>
</tr>
<tr>
<td>Author:</td>
<td>Johannes Gussenbauer [aut, cre],
  Alexander Kowarik <a href="https://orcid.org/0000-0001-8598-4130"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Gregor de Cillia [aut],
  Matthias Till [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-12-19 10:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calc.stError'>Calcualte point estimates and their standard errors using bootstrap
weights.</h2><span id='topic+calc.stError'></span>

<h3>Description</h3>

<p>Calculate point estimates as well as standard errors of variables in surveys.
Standard errors are estimated using bootstrap weights (see <a href="#topic+draw.bootstrap">draw.bootstrap</a>
and <a href="#topic+recalib">recalib</a>). In addition the standard error of an estimate can be
calcualted using the survey data for 3 or more consecutive periods, which
results in a reduction of the standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.stError(
  dat,
  weights = attr(dat, "weights"),
  b.weights = attr(dat, "b.rep"),
  period = attr(dat, "period"),
  var,
  fun = weightedRatio,
  national = FALSE,
  group = NULL,
  fun.adjust.var = NULL,
  adjust.var = NULL,
  period.diff = NULL,
  period.mean = NULL,
  bias = FALSE,
  size.limit = 20,
  cv.limit = 10,
  p = NULL,
  add.arg = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.stError_+3A_dat">dat</code></td>
<td>
<p>either data.frame or data.table containing the survey data.
Surveys can be a panel survey or rotating panel survey, but does not need
to be. For rotating panel survey bootstrap weights can be created using
<a href="#topic+draw.bootstrap">draw.bootstrap</a> and <a href="#topic+recalib">recalib</a>.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_weights">weights</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code>
containing the original sample weights. Used to calculate point estimates.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_b.weights">b.weights</code></td>
<td>
<p>character vector specifying the names of the columns in
<code>dat</code> containing bootstrap weights. Used to calculate standard errors.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_period">period</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code>
containing the sample periods.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_var">var</code></td>
<td>
<p>character vector containing variable names in <code>dat</code> on which <code>fun</code>
shall be applied for each sample period.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_fun">fun</code></td>
<td>
<p>function which will be applied on <code>var</code> for each sample period.
Predefined functions are <a href="#topic+weightedRatio">weightedRatio</a>, <a href="#topic+weightedSum">weightedSum</a>, but can also take
any other function which returns a double or integer and uses weights as
its second argument.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_national">national</code></td>
<td>
<p>boolean, if TRUE point estimates resulting from fun will be
divided by the point estimate at the national level.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_group">group</code></td>
<td>
<p>character vectors or list of character vectors containig
variables in <code>dat</code>. For each list entry <code>dat</code> will be split in subgroups
according to the containing variables as well as <code>period</code>. The
pointestimates are then estimated for each subgroup seperately. If
<code>group=NULL</code> the data will split into sample periods by default.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_fun.adjust.var">fun.adjust.var</code></td>
<td>
<p>can be either <code>NULL</code> or a function. This argument can
be used to apply a function for each <code>period</code> and bootstrap weight to the
data. The resulting estimates will be passed down to <code>fun</code>. See details for
more explanations.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_adjust.var">adjust.var</code></td>
<td>
<p>can be either <code>NULL</code> or a character specifying the first
argument in <code>fun.adjust.var</code>.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_period.diff">period.diff</code></td>
<td>
<p>character vectors, defining periods for which the
differences in the point estimate as well it's standard error is
calculated. Each entry must have the form of <code>"period1 - period2"</code>. Can be
NULL</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_period.mean">period.mean</code></td>
<td>
<p>odd integer, defining the range of periods over which the
sample mean of point estimates is additionally calcualted.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_bias">bias</code></td>
<td>
<p>boolean, if <code>TRUE</code> the sample mean over the point estimates of
the bootstrap weights is returned.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_size.limit">size.limit</code></td>
<td>
<p>integer defining a lower bound on the number of
observations on <code>dat</code> in each group defined by <code>period</code> and the entries in
<code>group</code>. Warnings are returned if the number of observations in a subgroup
falls below <code>size.limit</code>. In addition the concerned groups are available in
the function output.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_cv.limit">cv.limit</code></td>
<td>
<p>non-negativ value defining a upper bound for the standard
error in relation to the point estimate. If this relation exceed
<code>cv.limit</code>, for a point estimate, they are flagged and available in the
function output.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_p">p</code></td>
<td>
<p>numeric vector containing values between 0 and 1. Defines which
quantiles for the distribution of <code>var</code> are additionally estimated.</p>
</td></tr>
<tr><td><code id="calc.stError_+3A_add.arg">add.arg</code></td>
<td>
<p>additional arguments which will be passed to fun. Can be
either a named list or vector. The names of the object correspond to the
function arguments and the values to column names in dat, see also
examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>calc.stError</code> takes survey data (<code>dat</code>) and returns point estimates
as well as their standard Errors defined by <code>fun</code> and <code>var</code> for each sample
period in <code>dat</code>. <code>dat</code> must be household data where household members
correspond to multiple rows with the same household identifier. The data
should at least contain the following columns:
</p>

<ul>
<li><p> Column indicating the sample period;
</p>
</li>
<li><p> Column indicating the household ID;
</p>
</li>
<li><p> Column containing the household sample weights;
</p>
</li>
<li><p> Columns which contain the bootstrap weights (see output of <a href="#topic+recalib">recalib</a>);
</p>
</li>
<li><p> Columns listed in <code>var</code> as well as in <code>group</code>
</p>
</li></ul>

<p>For each variable in <code>var</code> as well as sample period the function <code>fun</code> is
applied using the original as well as the bootstrap sample weights.<br />
The point estimate is then selected as the result of <code>fun</code> when using the
original sample weights and it's standard error is estimated with the result
of <code>fun</code> using the bootstrap sample weights. <br />
<br />
<code>fun</code> can be any function which returns a double or integer and uses sample
weights as it's second argument. The predifined options are <code>weightedRatio</code>
and <code>weightedSum</code>.<br />
<br />
For the option <code>weightedRatio</code> a weighted ratio (in \
calculated for <code>var</code> equal to 1, e.g
<code>sum(weight[var==1])/sum(weight[!is.na(var)])*100</code>.<br />
Additionally using the option <code>national=TRUE</code> the weighted ratio (in \
divided by the weighted ratio at the national level for each <code>period</code>.
<br />
If <code>group</code> is not <code>NULL</code> but a vector of variables from <code>dat</code> then <code>fun</code> is
applied on each subset of <code>dat</code> defined by all combinations of values in
<code>group</code>.<br />
For instance if <code>group = "sex"</code> with &quot;sex&quot; having the values &quot;Male&quot; and
&quot;Female&quot; in <code>dat</code> the point estimate and standard error is calculated on the
subsets of <code>dat</code> with only &quot;Male&quot; or &quot;Female&quot; value for &quot;sex&quot;. This is done
for each value of <code>period</code>. For variables in <code>group</code> which have <code>NA</code>s in
<code>dat</code> the rows containing the missings will be discarded. <br />
When <code>group</code> is a list of character vectors, subsets of <code>dat</code> and the
following estimation of the point estimate, including the estimate for the
standard error, are calculated for each list entry.<br />
<br />
The optional parameters <code>fun.adjust.var</code> and <code>adjust.var</code> can be used if the
values in <code>var</code> are dependent on the <code>weights</code>. As is for instance the case
for the poverty thershhold calculated from EU-SILC.
In such a case an additional function can be supplied using <code>fun.adjust.var</code>
as well as its first argument <code>adjust.var</code>, which needs to be part of the
data set <code>dat</code>. Then, before applying <code>fun</code> on variable <code>var</code>
for all <code>period</code> and groups, the function <code>fun.adjust.var</code> is applied to
<code>adjust.var</code> using each of the bootstrap weights seperately (NOTE: weight is
used as the second argument of <code>fun.adjust.var</code>).
Thus creating i=1,...,<code>length(b.weights)</code> additional variables.
For applying <code>fun</code> on <code>var</code> the estimates for the bootstrap replicate will
now use each of the corresponding new additional variables. So instead of
</p>
<p style="text-align: center;"><code class="reqn">fun(var,weights,...),fun(var,b.weights[1],...),
fun(var,b.weights[2],...),...</code>
</p>

<p>the function <code>fun</code> will be applied in the way
</p>
<p style="text-align: center;"><code class="reqn">fun(var,weights,...),fun(var.1,b.weights[1],...),fun(var.2,
b.weights[2],...),...</code>
</p>

<p>where <code>var.1</code>, <code>var.2</code>, <code>...</code> correspond to the estimates resulting from
<code>fun.adjust.var</code> and <code>adjust.var</code>.
NOTE: This procedure is especially usefull if the <code>var</code> is dependent on
<code>weights</code> and <code>fun</code> is applied on subgroups of the data set. Then it is not
possible to capture this procedure with <code>fun</code> and <code>var</code>, see examples for a
more hands on explanation.
<br />
When defining <code>period.diff</code> the difference of point estimates between periods
as well their standard errors are calculated.<br />
The entries in <code>period.diff</code> must have the form of <code>"period1 - period2"</code>
which means that the results of the point estimates for <code>period2</code> will be
substracted from the results of the point estimates for <code>period1</code>.<br />
<br />
Specifying <code>period.mean</code> leads to an improvement in standard error by
averaging the results for the point estimates, using the bootstrap weights,
over <code>period.mean</code> periods.
Setting, for instance, <code>period.mean = 3</code> the results in averaging these
results over each consecutive set of 3 periods.<br />
Estimating the standard error over these averages gives an improved estimate
of the standard error for the central period, which was used for
averaging.<br />
The averaging of the results is also applied in differences of point
estimates. For instance defining <code>period.diff = "2015-2009"</code> and
<code>period.mean = 3</code>
the differences in point estimates of 2015 and 2009, 2016 and 2010 as well as
2014 and 2008 are calcualated and finally the average over these 3
differences is calculated.
The periods set in <code>period.diff</code> are always used as the middle periods around
which the mean over <code>period.mean</code> years is build.
<br />
Setting <code>bias</code> to <code>TRUE</code> returns the calculation of a mean over the results
from the bootstrap replicates. In  the output the corresponding columns is
labeled <em>_mean</em> at the end.<br />
<br />
If <code>fun</code> needs more arguments they can be supplied in <code>add.arg</code>. This can
either be a named list or vector.<br />
<br />
The parameter <code>size.limit</code> indicates a lower bound of the sample size for
subsets in <code>dat</code> created by <code>group</code>. If the sample size of a subset falls
below <code>size.limit</code> a warning will be displayed.<br />
In addition all subsets for which this is the case can be selected from the
output of <code>calc.stError</code> with <code style="white-space: pre;">&#8288;$smallGroups&#8288;</code>.<br />
With the parameter <code>cv.limit</code> one can set an upper bound on the coefficient
of variantion. Estimates which exceed this bound are flagged with <code>TRUE</code> and
are available in the function output with <code style="white-space: pre;">&#8288;$cvHigh&#8288;</code>.
<code>cv.limit</code> must be a positive integer and is treated internally as \
for <code>cv.limit=1</code> the estimate will be flagged if the coefficient of
variantion exceeds 1\
<br />
When specifying <code>period.mean</code>, the decrease in standard error for choosing
this method is internally calcualted and a rough estimate for an implied
increase in sample size is available in the output with <code style="white-space: pre;">&#8288;$stEDecrease&#8288;</code>.
The rough estimate for the increase in sample size uses the fact that for a
sample of size <code class="reqn">n</code> the sample estimate for the standard error of most
point estimates converges with a factor <code class="reqn">1/\sqrt{n}</code> against the true
standard error <code class="reqn">\sigma</code>.
</p>


<h3>Value</h3>

<p>Returns a list containing:
</p>

<ul>
<li> <p><code>Estimates</code>: data.table containing period differences and/or k period
averages for estimates of
<code>fun</code> applied to <code>var</code> as well as the corresponding standard errors, which
are calculated using the bootstrap weights. In addition the sample size,
<code>n</code>, and poplutaion size for each group is added to the output.
</p>
</li>
<li> <p><code>smallGroups</code>: data.table containing groups for which the number of
observation falls below <code>size.limit</code>.
</p>
</li>
<li> <p><code>cvHigh</code>: data.table containing a boolean variable which indicates for each
estimate if the estimated standard error exceeds <code>cv.limit</code>.
</p>
</li>
<li> <p><code>stEDecrease</code>: data.table indicating for each estimate the theoretical
increase in sample size which is gained when averaging over k periods. Only
returned if <code>period.mean</code> is not <code>NULL</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Johannes Gussenbauer, Alexander Kowarik, Statistics Austria
</p>


<h3>See Also</h3>

<p><a href="#topic+draw.bootstrap">draw.bootstrap</a> <br />
<a href="#topic+recalib">recalib</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import data and calibrate

set.seed(1234)
eusilc &lt;- demo.eusilc(n = 4,prettyNames = TRUE)
dat_boot &lt;- draw.bootstrap(eusilc, REP = 3, hid = "hid", weights = "pWeight",
                           strata = "region", period = "year")
dat_boot_calib &lt;- recalib(dat_boot, conP.var = "gender", conH.var = "region")

# estimate weightedRatio for povertyRisk per period

err.est &lt;- calc.stError(dat_boot_calib, var = "povertyRisk",
                        fun = weightedRatio)
err.est$Estimates

# calculate weightedRatio for povertyRisk and fraction of one-person
# households per period

dat_boot_calib[, onePerson := .N == 1, by = .(year, hid)]
err.est &lt;- calc.stError(dat_boot_calib, var = c("povertyRisk", "onePerson"),
                        fun = weightedRatio)
err.est$Estimates

## Not run: 
# estimate weightedRatio for povertyRisk per period and gender and
# period x region x gender 

group &lt;- list("gender", c("gender", "region"))
err.est &lt;- calc.stError(dat_boot_calib, var = "povertyRisk",
                        fun = weightedRatio, group = group)
err.est$Estimates

# use average over 3 periods for standard error estimation
# and calculate estimate for difference of
# period 2011 and 2012 inclulding standard errors
period.diff &lt;- c("2012-2011")
err.est &lt;- calc.stError(
  dat_boot_calib, var = "povertyRisk", fun = weightedRatio,
  period.diff = period.diff,  # &lt;- take difference of periods 2012 and 2011
  period.mean = 3)  # &lt;- average over 3 periods
err.est$Estimates

## End(Not run)
# for more examples see https://statistikat.github.io/surveysd/articles/error_estimation.html

</code></pre>

<hr>
<h2 id='computeLinear'>Numerical weighting functions</h2><span id='topic+computeLinear'></span><span id='topic+computeLinearG1'></span><span id='topic+computeFrac'></span><span id='topic+numericalWeighting'></span>

<h3>Description</h3>

<p>Customize weight-updating within factor levels in case of numerical
calibration. The functions described here serve as inputs for <a href="#topic+ipf">ipf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeLinear(curValue, target, x, w, boundLinear = 10)

computeLinearG1(curValue, target, x, w, boundLinear = 10)

computeFrac(curValue, target, x, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeLinear_+3A_curvalue">curValue</code></td>
<td>
<p>Current summed up value. Same as <code>sum(x*w)</code></p>
</td></tr>
<tr><td><code id="computeLinear_+3A_target">target</code></td>
<td>
<p>Target value. An element of <code>conP</code> in <a href="#topic+ipf">ipf</a></p>
</td></tr>
<tr><td><code id="computeLinear_+3A_x">x</code></td>
<td>
<p>Vector of numeric values to be calibrated against</p>
</td></tr>
<tr><td><code id="computeLinear_+3A_w">w</code></td>
<td>
<p>Vector of weights</p>
</td></tr>
<tr><td><code id="computeLinear_+3A_boundlinear">boundLinear</code></td>
<td>
<p>The output <code>f</code> will satisfy
<code style="white-space: pre;">&#8288;1/boundLinear &lt;= f &lt;= boundLinear&#8288;</code>. See <code>bound</code> in <a href="#topic+ipf">ipf</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>computeFrac</code> provides the &quot;standard&quot; IPU updating scheme given as
</p>
<p style="text-align: center;"><code class="reqn">f = target/curValue</code>
</p>

<p>which means that each weight inside the level will be multtiplied by the same
factor when doing the actual update step (<code>w := f*w</code>). <code>computeLinear</code> on the
other hand calculates <code>f</code> as
</p>

<div style="text-align: center;"> f<sub>i</sub> = a  &middot; x<sub>i</sub> + b </div>

<p>where <code>a</code> and <code>b</code> are chosen, so f satisfies the following two equations.
</p>

<div style="text-align: center;">&sum; f<sub>i</sub> w<sub>i</sub>
       x<sub>i</sub> = target</div>


<div style="text-align: center;">&sum; f<sub>i</sub>
       w<sub>i</sub> = &sum; w<sub>i</sub></div>

<p><code>computeLinearG1</code> calculates <code>f</code> in the same way as <code>computeLinear</code>, but if
<code>f_i*w_i&lt;1</code> <code>f_i</code> will be set to <code>1/w_i</code>.
</p>


<h3>Value</h3>

<p>A weight multiplier <code>f</code>
</p>

<hr>
<h2 id='cpp_mean'>Calculate mean by factors</h2><span id='topic+cpp_mean'></span><span id='topic+geometric_mean_reference'></span>

<h3>Description</h3>

<p>These functions calculate the arithmetic and geometric mean of the weight for each class. <code>geometric_mean</code> and
<code>arithmetic_mean</code> return a <code>numeric</code> vector of the same length as <code>w</code> which stores the averaged weight for each
observation. <code>geometric_mean_reference</code> returns the same value by reference, i.e. the input value <code>w</code> gets
overwritten by the updated weights. See examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geometric_mean_reference(w, classes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cpp_mean_+3A_w">w</code></td>
<td>
<p>An numeric vector. All entries should be positive.</p>
</td></tr>
<tr><td><code id="cpp_mean_+3A_classes">classes</code></td>
<td>
<p>A factor variable. Must have the same length as <code>w</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

## create random data
nobs &lt;- 10
classLabels &lt;- letters[1:3]
dat = data.frame(
  weight = exp(rnorm(nobs)),
  household = factor(sample(classLabels, nobs, replace = TRUE))
)
dat

## calculate weights with geometric_mean
geom_weight &lt;- geometric_mean(dat$weight, dat$household)
cbind(dat, geom_weight)

## calculate weights with arithmetic_mean
arith_weight &lt;- arithmetic_mean(dat$weight, dat$household)
cbind(dat, arith_weight)

## calculate weights "by reference"
geometric_mean_reference(dat$weight, dat$household)
dat

## End(Not run)
</code></pre>

<hr>
<h2 id='demo.eusilc'>Generate multiple years of EU-SILC data</h2><span id='topic+demo.eusilc'></span>

<h3>Description</h3>

<p>Create a dummy dataset to be used for demonstrating the functionalities of
the <code>surveysd</code> package based on <a href="laeken.html#topic+eusilc">laeken::eusilc</a>. Please refer to the
documentation page of the original data for details about the variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demo.eusilc(n = 8, prettyNames = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="demo.eusilc_+3A_n">n</code></td>
<td>
<p>Number of years to generate. Should be at least 1</p>
</td></tr>
<tr><td><code id="demo.eusilc_+3A_prettynames">prettyNames</code></td>
<td>
<p>Create easy-to-read names for certain variables.
Recommended for demonstration purposes. Otherwise, use the original codes
documented in <a href="laeken.html#topic+eusilc">laeken::eusilc</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>prettyNames</code> is <code>TRUE</code>, the following variables will be available in an
easy-to-read manner.
</p>

<ul>
<li> <p><code>hid</code> Household id. Consistent with respect to the reference period
(<code>year</code>)
</p>
</li>
<li> <p><code>hsize</code> Size of the household. derived from <code>hid</code> and <code>period</code>
</p>
</li>
<li> <p><code>region</code> Federal state of austria where the household is located
</p>
</li>
<li> <p><code>pid</code> Personal id. Consistent with respect to the reference period (<code>year</code>)
</p>
</li>
<li> <p><code>age</code> Age-class of the respondent
</p>
</li>
<li> <p><code>gender</code> A persons gender (<code>"male"</code>, <code>"Female"</code>)
</p>
</li>
<li> <p><code>ecoStat</code> Ecnomic status
(<code>"part time"</code>, <code>"full time"</code>, <code>"unemployed"</code>, ...)
</p>
</li>
<li> <p><code>citizenship</code> Citizenship (<code>"AT"</code>, <code>"EU"</code>, <code>"other"</code>)
</p>
</li>
<li> <p><code>pWeight</code> Personal sample weight inside the reference period
</p>
</li>
<li> <p><code>year</code>. Simulated reference period
</p>
</li>
<li> <p><code>povertyRisk</code>. Logical variable determining whether a respondent is at risk
of poverty
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>demo.eusilc(n = 1, prettyNames = TRUE)[, c(1:8, 26, 28:30)]
</code></pre>

<hr>
<h2 id='draw.bootstrap'>Draw bootstrap replicates</h2><span id='topic+draw.bootstrap'></span>

<h3>Description</h3>

<p>Draw bootstrap replicates from survey data with rotating panel
design. Survey information, like ID, sample weights, strata and population
totals per strata, should be specified to ensure meaningfull survey
bootstraping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw.bootstrap(
  dat,
  REP = 1000,
  hid = NULL,
  weights,
  period = NULL,
  strata = NULL,
  cluster = NULL,
  totals = NULL,
  single.PSU = c("merge", "mean"),
  boot.names = NULL,
  split = FALSE,
  pid = NULL,
  new.method = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw.bootstrap_+3A_dat">dat</code></td>
<td>
<p>either data.frame or data.table containing the survey data with
rotating panel design.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_rep">REP</code></td>
<td>
<p>integer indicating the number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_hid">hid</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code> containing
the household id. If <code>NULL</code> (the default), the household structure is not
regarded.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_weights">weights</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code>
containing the sample weights.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_period">period</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code> containing
the sample periods. If <code>NULL</code> (the default), it is assumed that all
observations belong to the same period.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_strata">strata</code></td>
<td>
<p>character vector specifying the name(s) of the column in <code>dat</code>
by which the population was stratified. If <code>strata</code> is a vector
stratification will be assumed as the combination of column names contained
in <code>strata</code>. Setting in addition <code>cluster</code> not NULL stratification will be
assumed on multiple stages, where each additional entry in <code>strata</code>
specifies the stratification variable for the next lower stage. see Details
for more information.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_cluster">cluster</code></td>
<td>
<p>character vector specifying cluster in the data. If not
already specified in <code>cluster</code> household ID is taken es the lowest level
cluster.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_totals">totals</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code> containing
the the totals per strata and/or cluster. Is ONLY optional if <code>cluster</code> is
<code>NULL</code> or equal <code>hid</code> and <code>strata</code> contains one columnname! Then the
households per strata will be calcualted using the <code>weights</code> argument. If
clusters and strata for multiple stages are specified <code>totals</code> needs to be
a vector of <code>length(strata)</code> specifying the column on <code>dat</code> that contain
the total number of PSUs at each stage. <code>totals</code> is interpreted from left
the right, meaning that the first argument corresponds to the number of
PSUs at the first and the last argument to the number of PSUs at the last
stage.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_single.psu">single.PSU</code></td>
<td>
<p>either &quot;merge&quot; or &quot;mean&quot; defining how single PSUs need to
be dealt with. For <code>single.PSU="merge"</code> single PSUs at each stage are
merged with the strata or cluster with the next least number of PSUs. If
multiple of those exist one will be select via random draw. For
<code>single.PSU="mean"</code> single PSUs will get the mean over all bootstrap
replicates at the stage which did not contain single PSUs.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_boot.names">boot.names</code></td>
<td>
<p>character indicating the leading string of the column names
for each bootstrap replica. If NULL defaults to &quot;w&quot;.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_split">split</code></td>
<td>
<p>logical, if TRUE split households are considered using <code>pid</code>,
for more information see Details.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_pid">pid</code></td>
<td>
<p>column in <code>dat</code> specifying the personal identifier. This
identifier needs to be unique for each person throught the whole data set.</p>
</td></tr>
<tr><td><code id="draw.bootstrap_+3A_new.method">new.method</code></td>
<td>
<p>logical, if TRUE bootstrap replicates will never be
negative even if in some strata the whole population is in the sample.
WARNING: This is still experimental and resulting standard errors might be
underestimated! Use this if for some strata the whole population is in the
sample!</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>draw.bootstrap</code> takes <code>dat</code> and draws <code>REP</code> bootstrap replicates
from it.
<code>dat</code> must be household data where household members correspond to multiple
rows with the same household
identifier. For most practical applications, the following columns should be
available in the dataset
and passed via the corresponding parameters:
</p>

<ul>
<li><p> Column indicating the sample period (parameter <code>period</code>).
</p>
</li>
<li><p> Column indicating the household ID (parameter <code>hid</code>)
</p>
</li>
<li><p> Column containing the household sample weights (parameter <code>weights</code>);
</p>
</li>
<li><p> Columns by which population was stratified during the sampling process
(parameter: <code>strata</code>).
</p>
</li></ul>

<p>For single stage sampling design a column the argument <code>totals</code> is optional,
meaning that a column of the number of PSUs at the first stage does not need
to be supplied.
For this case the number of PSUs is calculated and added to <code>dat</code> using
<code>strata</code> and <code>weights</code>. By setting <code>cluster</code> to NULL single stage sampling
design is always assumed and
if <code>strata</code> contains of multiple column names the combination of all those
column names will be used for stratification.
</p>
<p>In the case of multi stage sampling design the argument <code>totals</code> needs to be
specified and needs to have the same number of arguments as <code>strata</code>.
</p>
<p>If <code>cluster</code> is <code>NULL</code> or does not contain <code>hid</code> at the last stage, <code>hid</code>
will automatically be used as the final cluster. If, besides <code>hid</code>,
clustering in additional stages is specified the number of column names in
<code>strata</code> and <code>cluster</code> (including <code>hid</code>) must be the same. If for any stage
there was no clustering or stratification one can set &quot;1&quot; or &quot;I&quot; for this
stage.
</p>
<p>For example <code style="white-space: pre;">&#8288;strata=c("REGION","I"),cluster=c("MUNICIPALITY","HID")&#8288;</code> would
speficy a 2 stage sampling design where at the first stage the municipalities
where drawn stratified by regions
and at the 2nd stage housholds are drawn in each municipality without
stratification.
</p>
<p>Bootstrap replicates are drawn for each survey period (<code>period</code>) using the
function <a href="#topic+rescaled.bootstrap">rescaled.bootstrap</a>.
Afterwards the bootstrap replicates for each household are carried forward
from the first period the household enters the survey to all the censecutive
periods it stays in the survey.
</p>
<p>This ensures that the bootstrap replicates follow the same logic as the
sampled households, making the bootstrap replicates more comparable to the
actual sample units.
</p>
<p>If <code>split</code> ist set to <code>TRUE</code> and <code>pid</code> is specified, the bootstrap replicates
are carried forward using the personal identifiers instead of the houshold
identifier.
This takes into account the issue of a houshold splitting up.
Any person in this new split household will get the same bootstrap replicate
as the person that has come from an other household in the survey.
People who enter already existing households will also get the same bootstrap
replicate as the other households members had in the previous periods.
</p>


<h3>Value</h3>

<p>the survey data with the number of REP bootstrap replicates added as
columns.
</p>
<p>Returns a data.table containing the original data as well as the
number of <code>REP</code> columns containing the bootstrap replicates for each
repetition.<br />
The columns of the bootstrap replicates are by default labeled &quot;w<em>Number</em>&quot;
where <em>Number</em> goes from 1 to <code>REP</code>. If the column names of the bootstrap
replicates should start with a different character or string the parameter
<code>boot.names</code> can be used.
</p>


<h3>Author(s)</h3>

<p>Johannes Gussenbauer, Alexander Kowarik, Statistics Austria
</p>


<h3>See Also</h3>

<p><code><a href="data.table.html#topic+data.table">data.table</a></code> for more information on
data.table objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
eusilc &lt;- demo.eusilc(prettyNames = TRUE)

## draw sample without stratification or clustering
dat_boot &lt;- draw.bootstrap(eusilc, REP = 10, weights = "pWeight",
                           period = "year")

## use stratification w.r.t. region and clustering w.r.t. households
dat_boot &lt;- draw.bootstrap(
  eusilc, REP = 10, hid = "hid", weights = "pWeight",
  strata = "region", period = "year")

## use multi-level clustering
dat_boot &lt;- draw.bootstrap(
  eusilc, REP = 10, hid = "hid", weights = "pWeight",
  strata = c("region", "age"), period = "year")


# create spit households
eusilc[, pidsplit := pid]
year &lt;- eusilc[, unique(year)]
year &lt;- year[-1]
leaf_out &lt;- c()
for(y in year) {
  split.person &lt;- eusilc[
    year == (y-1) &amp; !duplicated(hid) &amp; !(hid %in% leaf_out),
    sample(pid, 20)
  ]
  overwrite.person &lt;- eusilc[
    (year == (y)) &amp; !duplicated(hid) &amp; !(hid %in% leaf_out),
    .(pid = sample(pid, 20))
  ]
  overwrite.person[, c("pidsplit", "year_curr") := .(split.person, y)]

  eusilc[overwrite.person, pidsplit := i.pidsplit,
         on = .(pid, year &gt;= year_curr)]
  leaf_out &lt;- c(leaf_out,
                eusilc[pid %in% c(overwrite.person$pid,
                                  overwrite.person$pidsplit),
                unique(hid)])
}

dat_boot &lt;- draw.bootstrap(
  eusilc, REP = 10, hid = "hid", weights = "pWeight",
  strata = c("region", "age"), period = "year", split = TRUE,
  pid = "pidsplit")
# split households were considered e.g. household and
# split household were both selected or not selected
dat_boot[, data.table::uniqueN(w1), by = pidsplit][V1 &gt; 1]

## End(Not run)

</code></pre>

<hr>
<h2 id='generate.HHID'>Generate new houshold ID for survey data with rotating panel design taking
into account split households</h2><span id='topic+generate.HHID'></span>

<h3>Description</h3>

<p>Generating a new houshold ID for survey data using a houshold ID and a
personal ID.
For surveys with rotating panel design containing housholds, houshold members
can move from an existing household to a new one, that was not originally in
the sample. This leads to the creation of so called split households. Using a
peronal ID (that stays fixed over the whole survey), an indicator for
different time steps and a houshold ID, a new houshold ID is assigned to the
original and the split household.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.HHID(dat, period = "RB010", pid = "RB030", hid = "DB030")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate.HHID_+3A_dat">dat</code></td>
<td>
<p>data table of data frame containing the survey data</p>
</td></tr>
<tr><td><code id="generate.HHID_+3A_period">period</code></td>
<td>
<p>column name of <code>dat</code> containing an indicator for the
rotations, e.g years, quarters, months, ect...</p>
</td></tr>
<tr><td><code id="generate.HHID_+3A_pid">pid</code></td>
<td>
<p>column name of <code>dat</code> containing the personal identifier. This
needs to be fixed for an indiviual throught the whole survey</p>
</td></tr>
<tr><td><code id="generate.HHID_+3A_hid">hid</code></td>
<td>
<p>column name of <code>dat</code> containing the household id. This needs
to for a household throught the whole survey</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the survey data <code>dat</code> as data.table object containing a new and
an old household ID. The new household ID which considers the split
households is now named <code>hid</code> and the original household ID has a
trailing &quot;_orig&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(surveysd)
library(laeken)
library(data.table)

eusilc &lt;- surveysd:::demo.eusilc(n=4)

# create spit households
eusilc[,rb030split:=rb030]
year &lt;- eusilc[,unique(year)]
year &lt;- year[-1]
leaf_out &lt;- c()
for(y in year) {
  split.person &lt;- eusilc[year==(y-1)&amp;!duplicated(db030)&amp;!db030%in%leaf_out,
                         sample(rb030,20)]
  overwrite.person &lt;- eusilc[year==(y)&amp;!duplicated(db030)&amp;!db030%in%leaf_out,
                             .(rb030=sample(rb030,20))]
  overwrite.person[,c("rb030split","year_curr"):=.(split.person,y)]

  eusilc[overwrite.person,
         rb030split:=i.rb030split,on=.(rb030,year&gt;=year_curr)]
  leaf_out &lt;- c(
    leaf_out,
    eusilc[rb030%in%c(overwrite.person$rb030,overwrite.person$rb030split),
    unique(db030)])
}

# pid which are in split households
eusilc[,.(uniqueN(db030)),by=list(rb030split)][V1&gt;1]

eusilc.new &lt;- generate.HHID(eusilc, period = "year", pid = "rb030split",
                            hid = "db030")

# no longer any split households in the data
eusilc.new[,.(uniqueN(db030)),by=list(rb030split)][V1&gt;1]

## End(Not run)

</code></pre>

<hr>
<h2 id='ipf'>Iterative Proportional Fitting</h2><span id='topic+ipf'></span>

<h3>Description</h3>

<p>Adjust sampling weights to given totals based on household-level and/or
individual level constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipf(
  dat,
  hid = NULL,
  conP = NULL,
  conH = NULL,
  epsP = 1e-06,
  epsH = 0.01,
  verbose = FALSE,
  w = NULL,
  bound = 4,
  maxIter = 200,
  meanHH = TRUE,
  allPthenH = TRUE,
  returnNA = TRUE,
  looseH = FALSE,
  numericalWeighting = computeLinear,
  check_hh_vars = TRUE,
  conversion_messages = FALSE,
  nameCalibWeight = "calibWeight",
  minMaxTrim = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ipf_+3A_dat">dat</code></td>
<td>
<p>a <code>data.table</code> containing household ids (optionally), base
weights (optionally), household and/or personal level variables (numerical
or categorical) that should be fitted.</p>
</td></tr>
<tr><td><code id="ipf_+3A_hid">hid</code></td>
<td>
<p>name of the column containing the household-ids within <code>dat</code> or
NULL if such a variable does not exist.</p>
</td></tr>
<tr><td><code id="ipf_+3A_conp">conP</code></td>
<td>
<p>list or (partly) named list defining the constraints on person
level.  The list elements are contingency tables in array representation
with dimnames corresponding to the names of the relevant calibration
variables in <code>dat</code>. If a numerical variable is to be calibrated, the
respective list element has to be named with the name of that numerical
variable. Otherwise the list element shoud NOT be named.</p>
</td></tr>
<tr><td><code id="ipf_+3A_conh">conH</code></td>
<td>
<p>list or (partly) named list defining the constraints on
household level.  The list elements are contingency tables in array
representation with dimnames corresponding to the names of the relevant
calibration variables in <code>dat</code>. If a numerical variable is to be
calibrated, the respective list element has to be named with the name of
that numerical variable. Otherwise the list element shoud NOT be named.</p>
</td></tr>
<tr><td><code id="ipf_+3A_epsp">epsP</code></td>
<td>
<p>numeric value or list (of numeric values and/or arrays)
specifying the convergence limit(s) for <code>conP</code>. The list can contain
numeric values and/or arrays which must appear in the same order as the
corresponding constraints in <code>conP</code>. Also, an array must have the same
dimensions and dimnames as the corresponding constraint in <code>conP</code>.</p>
</td></tr>
<tr><td><code id="ipf_+3A_epsh">epsH</code></td>
<td>
<p>numeric value or list (of numeric values and/or arrays)
specifying the convergence limit(s) for <code>conH</code>. The list can contain
numeric values and/or arrays which must appear in the same order as the
corresponding constraints in <code>conH</code>. Also, an array must have the same
dimensions and dimnames as the corresponding constraint in <code>conH</code>.</p>
</td></tr>
<tr><td><code id="ipf_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, some progress information will be printed.</p>
</td></tr>
<tr><td><code id="ipf_+3A_w">w</code></td>
<td>
<p>name if the column containing the base weights within <code>dat</code> or NULL
if such a variable does not exist. In the latter case, every observation
in <code>dat</code> is assigned a starting weight of 1.</p>
</td></tr>
<tr><td><code id="ipf_+3A_bound">bound</code></td>
<td>
<p>numeric value specifying the multiplier for determining the
weight trimming boundary if the change of the base weights should be
restricted, i.e. if the weights should stay between 1/<code>bound</code>*<code>w</code>
and <code>bound</code>*<code>w</code>.</p>
</td></tr>
<tr><td><code id="ipf_+3A_maxiter">maxIter</code></td>
<td>
<p>numeric value specifying the maximum number of iterations
that should be performed.</p>
</td></tr>
<tr><td><code id="ipf_+3A_meanhh">meanHH</code></td>
<td>
<p>if TRUE, every person in a household is assigned the mean of
the person weights corresponding to the household. If <code>"geometric"</code>, the
geometric mean is used rather than the arithmetic mean.</p>
</td></tr>
<tr><td><code id="ipf_+3A_allpthenh">allPthenH</code></td>
<td>
<p>if TRUE, all the person level calibration steps are
performed before the houshold level calibration steps (and <code>meanHH</code>, if
specified). If FALSE, the houshold level calibration steps (and <code>meanHH</code>,
if specified) are performed after everey person level calibration step.
This can lead to better convergence properties in certain cases but also
means that the total number of calibration steps is increased.</p>
</td></tr>
<tr><td><code id="ipf_+3A_returnna">returnNA</code></td>
<td>
<p>if TRUE, the calibrated weight will be set to NA in case of
no convergence.</p>
</td></tr>
<tr><td><code id="ipf_+3A_looseh">looseH</code></td>
<td>
<p>if FALSE, the actual constraints <code>conH</code> are used for
calibrating all the hh weights. If TRUE, only the weights for which the
lower and upper thresholds defined by <code>conH</code> and <code>epsH</code> are exceeded are
calibrated. They are however not calibrated against the actual constraints
<code>conH</code> but against these lower and upper thresholds, i.e.
<code>conH</code>-<code>conH</code>*<code>epsH</code> and <code>conH</code>+<code>conH</code>*<code>epsH</code>.</p>
</td></tr>
<tr><td><code id="ipf_+3A_numericalweighting">numericalWeighting</code></td>
<td>
<p>See <a href="#topic+numericalWeighting">numericalWeighting</a></p>
</td></tr>
<tr><td><code id="ipf_+3A_check_hh_vars">check_hh_vars</code></td>
<td>
<p>If <code>TRUE</code> check for non-unique values inside of a
household for variables in household constraints</p>
</td></tr>
<tr><td><code id="ipf_+3A_conversion_messages">conversion_messages</code></td>
<td>
<p>show a message, if inputs need to be reformatted.
This can be useful for speed optimizations if ipf is called several times
with similar inputs (for example bootstrapping)</p>
</td></tr>
<tr><td><code id="ipf_+3A_namecalibweight">nameCalibWeight</code></td>
<td>
<p>character defining the name of the variable for the
newly generated calibrated weight.</p>
</td></tr>
<tr><td><code id="ipf_+3A_minmaxtrim">minMaxTrim</code></td>
<td>
<p>numeric vector of length2, first element a minimum value
for weights to be trimmed to, second element a maximum value for weights to
be trimmed to.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the weighting procedure described
here: <a href="https://doi.org/10.17713/ajs.v45i3.120">doi:10.17713/ajs.v45i3.120</a>.
Usage examples can be found in the corresponding vignette
(<code>vignette("ipf")</code>).
</p>
<p><code>conP</code> and <code>conH</code> are contingency tables, which can be created with <code>xtabs</code>.
The <code>dimnames</code> of those tables should match the names and levels of the
corresponding columns in <code>dat</code>.
</p>
<p><code>maxIter</code>, <code>epsP</code> and <code>epsH</code> are the stopping criteria. <code>epsP</code> and <code>epsH</code>
describe relative tolerances in the sense that
</p>
<p style="text-align: center;"><code class="reqn">1-epsP &lt; \frac{w_{i+1}}{w_i} &lt; 1+epsP</code>
</p>

<p>will be used as convergence criterium. Here i is the iteration step and wi is
the weight of a specific person at step i.
</p>
<p>The algorithm
performs best if all varables occuring in the constraints (<code>conP</code> and <code>conH</code>)
as well as the household variable are coded as <code>factor</code>-columns in <code>dat</code>.
Otherwise, conversions will be necessary which can be monitored with the
<code>conversion_messages</code> argument. Setting <code>check_hh_vars</code> to <code>FALSE</code> can also
incease the performance of the scheme.
</p>


<h3>Value</h3>

<p>The function will return the input data <code>dat</code> with the calibrated
weights <code>calibWeight</code> as an additional column as well as attributes. If no
convergence has been reached in <code>maxIter</code> steps, and <code>returnNA</code> is <code>TRUE</code>
(the default), the column <code>calibWeights</code> will only consist of <code>NA</code>s. The
attributes of the table are attributes derived from the <code>data.table</code> class
as well as the following.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>converged</code> </td><td style="text-align: left;"> Did the algorithm converge in <code>maxIter</code> steps? </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>iterations</code> </td><td style="text-align: left;"> The number of iterations performed. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>conP</code>, <code>conH</code>, <code>epsP</code>, <code>epsH</code> </td><td style="text-align: left;"> See Arguments. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>conP_adj</code>, <code>conH_adj</code> </td><td style="text-align: left;"> Adjusted versions of <code>conP</code> and <code>conH</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>formP</code>, <code>formH</code> </td><td style="text-align: left;"> Formulas that were used to calculate <code>conP_adj</code> and
<code>conH_adj</code> based on the output table.
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Alexander Kowarik, Gregor de Cillia
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# load data
eusilc &lt;- demo.eusilc(n = 1, prettyNames = TRUE)

# personal constraints
conP1 &lt;- xtabs(pWeight ~ age, data = eusilc)
conP2 &lt;- xtabs(pWeight ~ gender + region, data = eusilc)
conP3 &lt;- xtabs(pWeight*eqIncome ~ gender, data = eusilc)

# household constraints
conH1 &lt;- xtabs(pWeight ~ hsize + region, data = eusilc)

# simple usage ------------------------------------------

calibweights1 &lt;- ipf(
  eusilc,
  conP = list(conP1, conP2, eqIncome = conP3),
  bound = NULL,
  verbose = TRUE
)

# compare personal weight with the calibweigth
calibweights1[, .(hid, pWeight, calibWeight)]

# advanced usage ----------------------------------------

# use an array of tolerances
epsH1 &lt;- conH1
epsH1[1:4, ] &lt;- 0.005
epsH1[5, ] &lt;- 0.2

# create an initial weight for the calibration
eusilc[, regSamp := .N, by = region]
eusilc[, regPop := sum(pWeight), by = region]
eusilc[, baseWeight := regPop/regSamp]

calibweights2 &lt;- ipf(
  eusilc,
  conP = list(conP1, conP2),
  conH = list(conH1),
  epsP = 1e-6,
  epsH = list(epsH1),
  bound = 4,
  w = "baseWeight",
  verbose = TRUE
)

# show an adjusted version of conP and the original
attr(calibweights2, "conP_adj")
attr(calibweights2, "conP")

## End(Not run)
</code></pre>

<hr>
<h2 id='ipf_step'>Perform one step of iterative proportional updating</h2><span id='topic+ipf_step'></span><span id='topic+ipf_step_ref'></span><span id='topic+ipf_step_f'></span><span id='topic+combine_factors'></span>

<h3>Description</h3>

<p>C++ routines to invoke a single iteration of the Iterative proportional updating (IPU) scheme. Targets and classes
are assumed to be one dimensional in the <code>ipf_step</code> functions. <code>combine_factors</code> aggregates several vectors of
type factor into a single one to allow multidimensional ipu-steps. See examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipf_step_ref(w, classes, targets)

ipf_step(w, classes, targets)

ipf_step_f(w, classes, targets)

combine_factors(dat, targets)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ipf_step_+3A_w">w</code></td>
<td>
<p>a numeric vector of weights. All entries should be positive.</p>
</td></tr>
<tr><td><code id="ipf_step_+3A_classes">classes</code></td>
<td>
<p>a factor variable. Must have the same length as <code>w</code>.</p>
</td></tr>
<tr><td><code id="ipf_step_+3A_targets">targets</code></td>
<td>
<p>key figure to target with the ipu scheme. A numeric verctor of the same length as <code>levels(classes)</code>.
This can also be a <code>table</code> produced by <code>xtabs</code>. See examples.</p>
</td></tr>
<tr><td><code id="ipf_step_+3A_dat">dat</code></td>
<td>
<p>a <code>data.frame</code> containing the factor variables to be combined.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ipf_step</code> returns the adjusted weights. <code>ipf_step_ref</code> does the same, but updates <code>w</code> by reference rather than
returning. <code>ipf_step_f</code> returns a multiplicator: adjusted weights divided by unadjusted weights. <code>combine_factors</code> is
designed to make <code>ipf_step</code> work with contingency tables produced by <a href="stats.html#topic+xtabs">xtabs</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
############# one-dimensional ipu ##############

## create random data
nobs &lt;- 10
classLabels &lt;- letters[1:3]
dat = data.frame(
  weight = exp(rnorm(nobs)),
  household = factor(sample(classLabels, nobs, replace = TRUE))
)
dat

## create targets (same lenght as classLabels!)
targets &lt;- 3:5

## calculate weights
new_weight &lt;- ipf_step(dat$weight, dat$household, targets)
cbind(dat, new_weight)

## check solution
xtabs(new_weight ~ dat$household)

## calculate weights "by reference"
ipf_step_ref(dat$weight, dat$household, targets)
dat

############# multidimensional ipu ##############

## load data
factors &lt;- c("time", "sex", "smoker", "day")
tips &lt;- data.frame(sex=c("Female","Male","Male"), day=c("Sun","Mon","Tue"),
time=c("Dinner","Lunch","Lunch"), smoker=c("No","Yes","No"))
tips &lt;- tips[factors]

## combine factors
con &lt;- xtabs(~., tips)
cf &lt;- combine_factors(tips, con)
cbind(tips, cf)[sample(nrow(tips), 10, replace = TRUE),]

## adjust weights
weight &lt;- rnorm(nrow(tips)) + 5
adjusted_weight &lt;- ipf_step(weight, cf, con)

## check outputs
con2 &lt;- xtabs(adjusted_weight ~ ., data = tips)
sum((con - con2)^2)

</code></pre>

<hr>
<h2 id='kishFactor'>Kish Factor</h2><span id='topic+kishFactor'></span>

<h3>Description</h3>

<p>Compute the design effect due to unequal weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kishFactor(w, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kishFactor_+3A_w">w</code></td>
<td>
<p>a numeric vector with weights</p>
</td></tr>
<tr><td><code id="kishFactor_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether NA values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The factor is computed acording to 'Weighting for Unequal P_i', Leslie Kish, Journal of Official Statistics, Vol. 8. No. 2, 1992
</p>
<p style="text-align: center;"><code class="reqn"> deff = \sqrt n \sum_j w_j^2 / (\sum_j w_j)^2</code>
</p>



<h3>Value</h3>

<p>The function will return the the kish factor
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kishFactor(rep(1,10))
kishFactor(rlnorm(10))
</code></pre>

<hr>
<h2 id='plot.surveysd'>Plot surveysd-Objects</h2><span id='topic+plot.surveysd'></span>

<h3>Description</h3>

<p>Plot results of <code>calc.stError()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'surveysd'
plot(
  x,
  variable = x$param$var[1],
  type = c("summary", "grouping"),
  groups = NULL,
  sd.type = c("dot", "ribbon"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.surveysd_+3A_x">x</code></td>
<td>
<p>object of class 'surveysd' output of function <a href="#topic+calc.stError">calc.stError</a></p>
</td></tr>
<tr><td><code id="plot.surveysd_+3A_variable">variable</code></td>
<td>
<p>Name of the variable for which standard errors have been
calcualated in <code>dat</code></p>
</td></tr>
<tr><td><code id="plot.surveysd_+3A_type">type</code></td>
<td>
<p>can bei either <code>"summary"</code> or <code>"grouping"</code>, default value is
<code>"summary"</code>. For <code>"summary"</code> a barplot is created giving an overview of the
number of estimates having the flag <code>smallGroup</code>, <code>cvHigh</code>, both or none
of them. For 'grouping' results for point estimate and standard error are
plotted for pre defined groups.</p>
</td></tr>
<tr><td><code id="plot.surveysd_+3A_groups">groups</code></td>
<td>
<p>If <code>type='grouping'</code> variables must be defined by which the
data is grouped. Only 2 levels are supported as of right now. If only one
group is defined the higher group will be the estimate over the whole
period. Results are plotted for the first argument in <code>groups</code> as well as
for the combination of <code>groups[1]</code> and <code>groups[2]</code>.</p>
</td></tr>
<tr><td><code id="plot.surveysd_+3A_sd.type">sd.type</code></td>
<td>
<p>can bei either <code>'ribbon'</code> or <code>'dot'</code> and is only used if
<code>type='grouping'</code>. Default is <code>"dot"</code>
For <code>sd.type='dot'</code> point estimates are plotted and flagged if the
corresponding standard error and/or the standard error using the mean over
k-periods exceeded the value <code>cv.limit</code> (see <a href="#topic+calc.stError">calc.stError</a>).
For <code>sd.type='ribbon'</code> the point estimates including ribbons, defined by
point estimate +- estimated standard error are plotted.
The calculated standard errors using the mean over k periods are plotted
using less transparency. Results for the higher level (~<code>groups[1]</code>) are
coloured grey.</p>
</td></tr>
<tr><td><code id="plot.surveysd_+3A_...">...</code></td>
<td>
<p>additional arguments supplied to plot.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(surveysd)

set.seed(1234)
eusilc &lt;- demo.eusilc(n = 3, prettyNames = TRUE)

dat_boot &lt;- draw.bootstrap(eusilc, REP = 3, hid = "hid", weights = "pWeight",
                           strata = "region", period = "year")

# calibrate weight for bootstrap replicates
dat_boot_calib &lt;- recalib(dat_boot, conP.var = "gender", conH.var = "region")

# estimate weightedRatio for povmd60 per period
group &lt;- list("gender", "region", c("gender", "region"))
err.est &lt;- calc.stError(dat_boot_calib, var = "povertyRisk",
                        fun = weightedRatio,
                        group = group , period.mean = NULL)


plot(err.est)

# plot results for gender
# dotted line is the result on the national level
plot(err.est, type = "grouping", groups = "gender")


# plot results for rb090 in each db040
# with standard errors as ribbons
plot(err.est, type = "grouping", groups = c("gender", "region"), sd.type = "ribbon")


</code></pre>

<hr>
<h2 id='PointEstimates'>Weighted Point Estimates</h2><span id='topic+PointEstimates'></span><span id='topic+weightedRatio'></span><span id='topic+weightedSum'></span>

<h3>Description</h3>

<p>Predefined functions for weighted point estimates in package <code>surveysd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedRatio(x, w)

weightedSum(x, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PointEstimates_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="PointEstimates_+3A_w">w</code></td>
<td>
<p>weight vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predefined functions are weighted ratio and weighted sum.
</p>


<h3>Value</h3>

<p>Each of the functions return a single numeric value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:10
w &lt;- 10:1
weightedRatio(x,w)
x &lt;- 1:10
w &lt;- 10:1
weightedSum(x,w)
</code></pre>

<hr>
<h2 id='print.surveysd'>Print function for surveysd objects</h2><span id='topic+print.surveysd'></span>

<h3>Description</h3>

<p>Prints the results of a call to <a href="#topic+calc.stError">calc.stError</a>. Shows used variables and
function, number of point estiamtes
as well as properties of the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'surveysd'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.surveysd_+3A_x">x</code></td>
<td>
<p>an object of class <code>'surveysd'</code></p>
</td></tr>
<tr><td><code id="print.surveysd_+3A_...">...</code></td>
<td>
<p>additonal parameters</p>
</td></tr>
</table>

<hr>
<h2 id='recalib'>Calibrate weights</h2><span id='topic+recalib'></span>

<h3>Description</h3>

<p>Calibrate weights for bootstrap replicates by using iterative proportional
updating to match population totals on various household and personal levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recalib(
  dat,
  hid = attr(dat, "hid"),
  weights = attr(dat, "weights"),
  b.rep = attr(dat, "b.rep"),
  period = attr(dat, "period"),
  conP.var = NULL,
  conH.var = NULL,
  conP = NULL,
  conH = NULL,
  epsP = 0.01,
  epsH = 0.02,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recalib_+3A_dat">dat</code></td>
<td>
<p>either data.frame or data.table containing the sample survey for
various periods.</p>
</td></tr>
<tr><td><code id="recalib_+3A_hid">hid</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code> containing
the household ID.</p>
</td></tr>
<tr><td><code id="recalib_+3A_weights">weights</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code>
containing the sample weights.</p>
</td></tr>
<tr><td><code id="recalib_+3A_b.rep">b.rep</code></td>
<td>
<p>character specifying the names of the columns in <code>dat</code>
containing bootstrap weights which should be recalibratet</p>
</td></tr>
<tr><td><code id="recalib_+3A_period">period</code></td>
<td>
<p>character specifying the name of the column in <code>dat</code> containing
the sample period.</p>
</td></tr>
<tr><td><code id="recalib_+3A_conp.var">conP.var</code></td>
<td>
<p>character vector containig person-specific variables to which
weights should be calibrated or a list of such character vectors.
Contingency tables for the population are calculated per <code>period</code> using
<code>weights</code>.</p>
</td></tr>
<tr><td><code id="recalib_+3A_conh.var">conH.var</code></td>
<td>
<p>character vector containig household-specific variables to
which weights should be calibrated or a list of such character vectors.
Contingency tables for the population are calculated per <code>period</code> using
<code>weights</code>.</p>
</td></tr>
<tr><td><code id="recalib_+3A_conp">conP</code></td>
<td>
<p>list or (partly) named list defining the constraints on person
level.  The list elements are contingency tables in array representation
with dimnames corresponding to the names of the relevant calibration
variables in <code>dat</code>. If a numerical variable is to be calibrated, the
respective list element has to be named with the name of that numerical
variable. Otherwise the list element shoud NOT be named.</p>
</td></tr>
<tr><td><code id="recalib_+3A_conh">conH</code></td>
<td>
<p>list or (partly) named list defining the constraints on
household level.  The list elements are contingency tables in array
representation with dimnames corresponding to the names of the relevant
calibration variables in <code>dat</code>. If a numerical variable is to be
calibrated, the respective list element has to be named with the name of
that numerical variable. Otherwise the list element shoud NOT be named.</p>
</td></tr>
<tr><td><code id="recalib_+3A_epsp">epsP</code></td>
<td>
<p>numeric value specifying the convergence limit for <code>conP.var</code>
or <code>conP</code>, see <code><a href="#topic+ipf">ipf()</a></code>.</p>
</td></tr>
<tr><td><code id="recalib_+3A_epsh">epsH</code></td>
<td>
<p>numeric value specifying the convergence limit for <code>conH.var</code>
or <code>conH</code>, see <code><a href="#topic+ipf">ipf()</a></code>.</p>
</td></tr>
<tr><td><code id="recalib_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to function <code><a href="#topic+ipf">ipf()</a></code> from this
package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>recalib</code> takes survey data (<code>dat</code>) containing the bootstrap replicates
generated by <a href="#topic+draw.bootstrap">draw.bootstrap</a> and calibrates weights for each bootstrap
replication according to population totals for person- or household-specific
variables. <br />
<code>dat</code> must be household data where household members correspond to multiple
rows with the same household identifier. The data should at least containt
the following columns:
</p>

<ul>
<li><p> Column indicating the sample period;
</p>
</li>
<li><p> Column indicating the household ID;
</p>
</li>
<li><p> Column containing the household sample weights;
</p>
</li>
<li><p> Columns which contain the bootstrap replicates (see output of
<a href="#topic+draw.bootstrap">draw.bootstrap</a>);
</p>
</li>
<li><p> Columns indicating person- or household-specific variables for which sample
weight should be adjusted.
</p>
</li></ul>

<p>For each period and each variable in <code>conP.var</code> and/or <code>conH.var</code> contingency
tables are estimated to get margin totals on personal- and/or
household-specific variables in the population.<br />
Afterwards the bootstrap replicates are multiplied with the original sample
weight and the resulting product ist then adjusted using <code><a href="#topic+ipf">ipf()</a></code> to match the
previously calcualted contingency tables. In this process the columns of the
bootstrap replicates are overwritten by the calibrated weights.<br />
</p>


<h3>Value</h3>

<p>Returns a data.table containing the survey data as well as the
calibrated weights for the bootstrap replicates. The original bootstrap
replicates are overwritten by the calibrated weights. If calibration of a
bootstrap replicate does not converge the bootsrap weight is not returned
and numeration of the returned bootstrap weights is reduced by one.
</p>


<h3>Author(s)</h3>

<p>Johannes Gussenbauer, Alexander Kowarik, Statistics Austria
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ipf">ipf()</a></code> for more information on iterative
proportional fitting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

eusilc &lt;- demo.eusilc(prettyNames = TRUE)

dat_boot &lt;- draw.bootstrap(eusilc, REP = 10, hid = "hid",
                           weights = "pWeight",
                           strata = "region", period = "year")

# calibrate weight for bootstrap replicates
dat_boot_calib &lt;- recalib(dat_boot, conP.var = "gender", conH.var = "region",
                          verbose = TRUE)


# calibrate on other variables
dat_boot_calib &lt;- recalib(dat_boot, conP.var = c("gender", "age"),
                          conH.var = c("region", "hsize"), verbose = TRUE)

# supply contingency tables directly
conP &lt;- xtabs(pWeight ~ age + gender + year, data = eusilc)
conH &lt;- xtabs(pWeight ~ hsize + region + year,
              data = eusilc[!duplicated(paste(db030,year))])
dat_boot_calib &lt;- recalib(dat_boot, conP.var = NULL,
                          conH.var = NULL, conP = list(conP),
                          conH = list(conH), verbose = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='rescaled.bootstrap'>Draw bootstrap replicates</h2><span id='topic+rescaled.bootstrap'></span>

<h3>Description</h3>

<p>Draw bootstrap replicates from survey data using the rescaled
bootstrap for stratified multistage sampling, presented by Preston, J.
(2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rescaled.bootstrap(
  dat,
  REP = 1000,
  strata = "DB050&gt;1",
  cluster = "DB060&gt;DB030",
  fpc = "N.cluster&gt;N.households",
  single.PSU = c("merge", "mean"),
  return.value = c("data", "replicates"),
  check.input = TRUE,
  new.method = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rescaled.bootstrap_+3A_dat">dat</code></td>
<td>
<p>either data frame or data table containing the survey sample</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_rep">REP</code></td>
<td>
<p>integer indicating the number of bootstraps to be drawn</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_strata">strata</code></td>
<td>
<p>string specifying the column name in <code>dat</code> that is used for
stratification. For multistage sampling multiple column names can be
specified by <code>strata=c("strata1&gt;strata2&gt;strata3")</code>. See Details for more
information.</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_cluster">cluster</code></td>
<td>
<p>string specifying the column name in <code>dat</code> that is used for
clustering. For instance given a household sample the column containing
the household ID should be supplied.
For multistage sampling multiple column names can be specified
by <code>cluster=c("cluster1&gt;cluster2&gt;cluster3")</code>.
See Details for more information.</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_fpc">fpc</code></td>
<td>
<p>string specifying the column name in <code>dat</code> that contains the
number of PSUs at the first stage. For multistage sampling the number of
PSUs at each stage must be specified by <code>strata=c("fpc1&gt;fpc2&gt;fpc3")</code>.</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_single.psu">single.PSU</code></td>
<td>
<p>either &quot;merge&quot; or &quot;mean&quot; defining how single PSUs need to
be dealt with. For <code>single.PSU="merge"</code> single PSUs at each stage are
merged with the strata or cluster with the next least number of PSUs. If
multiple of those exist one will be select via random draw. For
<code>single.PSU="mean"</code> single PSUs will get the mean over all bootstrap
replicates at the stage which did not contain single PSUs.</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_return.value">return.value</code></td>
<td>
<p>either &quot;data&quot; or &quot;replicates&quot; specifying the return value
of the function. For &quot;data&quot; the survey data is returned as class
<code>data.table</code>, for &quot;replicates&quot; only the bootstrap replicates are returned
as <code>data.table</code>.</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_check.input">check.input</code></td>
<td>
<p>logical, if TRUE the input will be checked before applying
the bootstrap procedure</p>
</td></tr>
<tr><td><code id="rescaled.bootstrap_+3A_new.method">new.method</code></td>
<td>
<p>logical, if TRUE bootstrap replicates will never be
negative even if in some strata the whole population is in the sample.
WARNING: This is still experimental and resulting standard errors might be
underestimated! Use this if for some strata the whole population is in the
sample!</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For specifying multistage sampling designs the column names in
<code>strata</code>,<code>cluster</code> and <code>fpc</code> need to seperated by &quot;&gt;&quot;.<br />
For multistage sampling the strings are read from left to right meaning that
the column name before the first &quot;&gt;&quot; is taken as the column for
stratification/clustering/number of PSUs at the first and the column after
the last &quot;&gt;&quot; is taken as the column for stratification/clustering/number of
PSUs at the last stage.
If for some stages the sample was not stratified or clustered one must
specify this by &quot;1&quot; or &quot;I&quot;, e.g. <code>strata=c("strata1&gt;I&gt;strata3")</code> if there was
no stratification at the second stage or <code>cluster=c("cluster1&gt;cluster2&gt;I")</code>
if there were no clusters at the last stage.<br />
The number of PSUs at each stage is not calculated internally and must be
specified for any sampling design.
For single stage sampling using stratification this can usually be done by
adding over all sample weights of each PSU by each strata-code.<br />
Spaces in each of the strings will be removed, so if column names contain
spaces they should be renamed before calling this procedure!
</p>


<h3>Value</h3>

<p>returns the complete data set including the bootstrap replicates or
just the bootstrap replicates, depending on <code>return.value="data"</code> or
<code>return.value="replicates"</code> respectively.
</p>


<h3>Author(s)</h3>

<p>Johannes Gussenbauer, Statistics Austria
</p>


<h3>References</h3>

<p>Preston, J. (2009). Rescaled bootstrap for stratified multistage
sampling. Survey Methodology. 35. 227-234.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(surveysd)
library(data.table)
set.seed(1234)
eusilc &lt;- demo.eusilc(n = 1,prettyNames = TRUE)

eusilc[,N.households:=uniqueN(hid),by=region]
eusilc.bootstrap &lt;- rescaled.bootstrap(eusilc,REP=10,strata="region",
                                       cluster="hid",fpc="N.households")

eusilc[,new_strata:=paste(region,hsize,sep="_")]
eusilc[,N.housholds:=uniqueN(hid),by=new_strata]
eusilc.bootstrap &lt;- rescaled.bootstrap(eusilc,REP=10,strata=c("new_strata"),
                                       cluster="hid",fpc="N.households")


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
