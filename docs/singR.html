<!DOCTYPE html><html><head><title>Help for package singR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {singR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%^%'><p>Calculate the power of a square matrix</p></a></li>
<li><a href='#angleMatchICA'><p>Match the colums of Mx and My</p></a></li>
<li><a href='#aveM'><p>Average Mj for Mx and My</p>
Here subjects are by rows, columns correspond to components</a></li>
<li><a href='#calculateJB'><p>Calculates the sum of the JB scores across all components, useful for determining rho.</p></a></li>
<li><a href='#covwhitener'><p>Returns square root of the precision matrix for whitening</p></a></li>
<li><a href='#create.graph.long'><p>create graph dataset with netmat and mmp_order</p>
a data.frame called with vectorization of reordered netmat by mmp_order.</a></li>
<li><a href='#curvilinear'><p>Curvilinear algorithm with r0 joint components</p></a></li>
<li><a href='#curvilinear_c'><p>Curvilinear algorithm based on C code with r0 joint components</p></a></li>
<li><a href='#est.M.ols'><p>Estimate mixing matrix from estimates of components</p></a></li>
<li><a href='#exampledata'><p>Data for simulation example 1</p></a></li>
<li><a href='#gen.inits'><p>Generate initialization from specific space</p></a></li>
<li><a href='#greedymatch'><p>Greedy Match</p></a></li>
<li><a href='#lngca'><p>Decompose the original data through LNGCA method.</p></a></li>
<li><a href='#matchICA'><p>match ICA</p></a></li>
<li><a href='#NG_number'><p>find the number of non-Gaussian components in the data.</p></a></li>
<li><a href='#orthogonalize'><p>Orthogonalization of matrix</p></a></li>
<li><a href='#permmatRank_joint'><p>Permutation test to get joint components ranks</p></a></li>
<li><a href='#permTestJointRank'><p>Permutation test with Greedymatch</p></a></li>
<li><a href='#pmse'><p>Permutation invariant mean squared error</p></a></li>
<li><a href='#signchange'><p>Sign change for S matrix to image</p></a></li>
<li><a href='#singR'><p>SImultaneous Non-Gaussian Component analysis for data integration.</p></a></li>
<li><a href='#standard'><p>Standardization with double centered and column scaling</p></a></li>
<li><a href='#theta2W'><p>Convert angle vector into orthodox matrix</p></a></li>
<li><a href='#tiltedgaussian'><p>tiltedgaussian</p></a></li>
<li><a href='#vec2net'><p>Create network matrices from vectorized lower diagonals</p>
<code>vec2net</code> transfer the matrix vectorized lower diagonals into net to show the component image.</a></li>
<li><a href='#whitener'><p>Whitening Function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simultaneous Non-Gaussian Component Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-07</td>
</tr>
<tr>
<td>Author:</td>
<td>Liangkang Wang <a href="https://orcid.org/0000-0003-3393-243X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Irina Gaynanova <a href="https://orcid.org/0000-0002-4116-0268"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Benjamin Risk <a href="https://orcid.org/0000-0003-1090-0777"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Liangkang Wang &lt;liangkang_wang@brown.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of SING algorithm to extract joint and individual non-Gaussian components from two datasets. SING uses an objective function that maximizes the skewness and kurtosis of latent components with a penalty to enhance the similarity between subject scores. Unlike other existing methods, SING does not use PCA for dimension reduction, but rather uses non-Gaussianity, which can improve feature extraction. Benjamin B.Risk, Irina Gaynanova (2021) &lt;<a href="https://doi.org/10.1214%2F21-AOAS1466">doi:10.1214/21-AOAS1466</a>&gt;.  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS (&ge; 7.3-57), Rcpp (&ge; 1.0.8.3), clue (&ge; 0.3-61), gam (&ge;
1.20.1), ICtest (&ge; 0.3-5)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, covr, testthat (&ge; 3.0.0), rmarkdown</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-08 00:30:17 UTC; lwang151</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-09 00:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+5E+25'>Calculate the power of a square matrix</h2><span id='topic++25+5E+25'></span>

<h3>Description</h3>

<p>returns a matrix composed of eigenvector x diag(eigenvalue ^ power) x eigenvector'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>S %^% power
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B5E+2B25_+3A_s">S</code></td>
<td>
<p>a square matrix</p>
</td></tr>
<tr><td><code id="+2B25+2B5E+2B25_+3A_power">power</code></td>
<td>
<p>the times of power</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix after power calculation that eigenvector x diag(eigenvalue ^ power) x eigenvector'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix(1:9,3,3)
a %^% 2

</code></pre>

<hr>
<h2 id='angleMatchICA'>Match the colums of Mx and My</h2><span id='topic+angleMatchICA'></span>

<h3>Description</h3>

<p><code>angleMatchICA</code> match the colums of Mx and My, using the n x p parameterization of the JIN decomposition assumes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angleMatchICA(Mx, My, Sx = NULL, Sy = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="angleMatchICA_+3A_mx">Mx</code></td>
<td>
<p>Subject score for X   matrix of n x n.comp</p>
</td></tr>
<tr><td><code id="angleMatchICA_+3A_my">My</code></td>
<td>
<p>Subject score for Y   matrix of n x n.comp</p>
</td></tr>
<tr><td><code id="angleMatchICA_+3A_sx">Sx</code></td>
<td>
<p>Variable loadings for X  matrix of n.comp x px</p>
</td></tr>
<tr><td><code id="angleMatchICA_+3A_sy">Sy</code></td>
<td>
<p>Variable loadings for Y  matrix of n.comp x py</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrixes:
## Mx:
## My:
## matchedangles:
## allangles:
## perm:
## omangles:
</p>

<hr>
<h2 id='aveM'>Average Mj for Mx and My
Here subjects are by rows, columns correspond to components</h2><span id='topic+aveM'></span>

<h3>Description</h3>

<p>Average Mj for Mx and My
Here subjects are by rows, columns correspond to components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aveM(mjX, mjY)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aveM_+3A_mjx">mjX</code></td>
<td>
<p>n x rj</p>
</td></tr>
<tr><td><code id="aveM_+3A_mjy">mjY</code></td>
<td>
<p>n x rj</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new Mj
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#get simulation data
data(exampledata)
data=exampledata

# To get n.comp value, we can use NG_number function.

# use JB statistic as the measure of nongaussianity to run lngca with df=0
output_JB=singR(dX=exampledata$dX,dY=exampledata$dY,
df=0,rho_extent="small",distribution="JB",individual=TRUE)

est.Mj = aveM(output_JB$est.Mjx,output_JB$est.Mjy)


</code></pre>

<hr>
<h2 id='calculateJB'>Calculates the sum of the JB scores across all components, useful for determining rho.</h2><span id='topic+calculateJB'></span>

<h3>Description</h3>

<p>We measure non-Gaussianity using Jarque-Bera (JB) statistic, which is a weighted combination of squared skewness and kurtosis, <a href="https://www.jstor.org/stable/1403192?origin=crossref">JB paper</a>.
The data has to be standardized and mean 0 and sd to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateJB(S = NULL, U = NULL, X = NULL, alpha = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculateJB_+3A_s">S</code></td>
<td>
<p>the variable loadings r x px.</p>
</td></tr>
<tr><td><code id="calculateJB_+3A_u">U</code></td>
<td>
<p>U matrix for matched columns rj x n</p>
</td></tr>
<tr><td><code id="calculateJB_+3A_x">X</code></td>
<td>
<p>whitened data matrix n x px, data = whitenerXA %*% dXcentered</p>
</td></tr>
<tr><td><code id="calculateJB_+3A_alpha">alpha</code></td>
<td>
<p>JB weighting of skewness and kurtosis. default = 0.8</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the sum of JB score across all components.
</p>

<hr>
<h2 id='covwhitener'>Returns square root of the precision matrix for whitening</h2><span id='topic+covwhitener'></span>

<h3>Description</h3>

<p>Returns square root of the precision matrix for whitening
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covwhitener(X, n.comp = ncol(X), center.row = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covwhitener_+3A_x">X</code></td>
<td>
<p>Matrix</p>
</td></tr>
<tr><td><code id="covwhitener_+3A_n.comp">n.comp</code></td>
<td>
<p>the number of components</p>
</td></tr>
<tr><td><code id="covwhitener_+3A_center.row">center.row</code></td>
<td>
<p>whether to center</p>
</td></tr>
</table>


<h3>Value</h3>

<p>square root of the precision matrix for whitening
</p>

<hr>
<h2 id='create.graph.long'>create graph dataset with netmat and mmp_order
a data.frame called with vectorization of reordered netmat by mmp_order.</h2><span id='topic+create.graph.long'></span>

<h3>Description</h3>

<p>create graph dataset with netmat and mmp_order
a data.frame called with vectorization of reordered netmat by mmp_order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.graph.long(gmatrix, sort_indices = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.graph.long_+3A_gmatrix">gmatrix</code></td>
<td>
<p>netmat</p>
</td></tr>
<tr><td><code id="create.graph.long_+3A_sort_indices">sort_indices</code></td>
<td>
<p>mmp_order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with vectors:
## X1: vector of numerics.
## X2: vector of numerics.
## value: vectorization of reordered netmat by mmp_order.
</p>

<hr>
<h2 id='curvilinear'>Curvilinear algorithm with r0 joint components</h2><span id='topic+curvilinear'></span>

<h3>Description</h3>

<p>The curvilinear algorithm is modified from <a href="https://www.semanticscholar.org/paper/A-feasible-method-for-optimization-with-constraints-Wen-Yin/d419879cdb80a87c3b7ab88e9f7478c1e70780ca">Wen and Yin paper</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>curvilinear(
  Ux,
  Uy,
  xData,
  yData,
  invLx,
  invLy,
  rho,
  tau = 0.01,
  alpha = 0.8,
  maxiter = 1000,
  tol = 1e-06,
  rj
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="curvilinear_+3A_ux">Ux</code></td>
<td>
<p>Matrix with n.comp x n, initial value of Ux, comes from greedyMatch.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_uy">Uy</code></td>
<td>
<p>Matrix with n.comp x n, initial value of Uy, comes from greedyMatch.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_xdata">xData</code></td>
<td>
<p>matrix with n x px, Xw = Lx %*% Xc.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_ydata">yData</code></td>
<td>
<p>matrix with n x py, Yw = Ly %*% Yc.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_invlx">invLx</code></td>
<td>
<p>Inverse matrix of Lx, matrix n x n.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_invly">invLy</code></td>
<td>
<p>Inverse matrix of Ly, matrix n x n.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_rho">rho</code></td>
<td>
<p>the weight parameter of matching relative to non-gaussianity.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_tau">tau</code></td>
<td>
<p>initial step size, default value is 0.01</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_alpha">alpha</code></td>
<td>
<p>controls weighting of skewness and kurtosis. Default value is 0.8, which corresponds to the Jarque-Bera test statistic with 0.8 weighting on squared skewness and 0.2 on squared kurtosis.</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_maxiter">maxiter</code></td>
<td>
<p>default value is 1000</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_tol">tol</code></td>
<td>
<p>the threshold of change in Ux and Uy to stop the curvlinear function</p>
</td></tr>
<tr><td><code id="curvilinear_+3A_rj">rj</code></td>
<td>
<p>the joint rank, comes from greedyMatch.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrices:
</p>

<dl>
<dt><code>Ux</code></dt><dd><p>Optimized Ux with matrix n.comp x n.</p>
</dd>
<dt><code>Uy</code></dt><dd><p>Optimized Uy with matrix n.comp x n.</p>
</dd>
<dt><code>tau</code></dt><dd><p>step size</p>
</dd>
<dt><code>iter</code></dt><dd><p>number of iterations.</p>
</dd>
<dt><code>error</code></dt><dd><p>PMSE(Ux,Uxnew)+PMSE(Uy,Uynew)</p>
</dd>
<dt><code>obj</code></dt><dd><p>Objective Function value</p>
</dd>
</dl>


<hr>
<h2 id='curvilinear_c'>Curvilinear algorithm based on C code with r0 joint components</h2><span id='topic+curvilinear_c'></span>

<h3>Description</h3>

<p>#' The curvilinear algorithm is modified from <a href="https://www.semanticscholar.org/paper/A-feasible-method-for-optimization-with-constraints-Wen-Yin/d419879cdb80a87c3b7ab88e9f7478c1e70780ca">Wen and Yin paper</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>curvilinear_c(
  Ux,
  Uy,
  xData,
  yData,
  invLx,
  invLy,
  rho,
  tau = 0.01,
  alpha = 0.8,
  maxiter = 1000,
  tol = 1e-06,
  rj
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="curvilinear_c_+3A_ux">Ux</code></td>
<td>
<p>Matrix with n.comp x n, initial value of Ux, comes from greedyMatch.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_uy">Uy</code></td>
<td>
<p>Matrix with n.comp x n, initial value of Uy, comes from greedyMatch.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_xdata">xData</code></td>
<td>
<p>matrix with n x px, Xw = Lx %*% Xc.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_ydata">yData</code></td>
<td>
<p>matrix with n x py, Yw = Ly %*% Yc.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_invlx">invLx</code></td>
<td>
<p>Inverse matrix of Lx, matrix n x n.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_invly">invLy</code></td>
<td>
<p>Inverse matrix of Ly, matrix n x n.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_rho">rho</code></td>
<td>
<p>the weight parameter of matching relative to non-gaussianity.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_tau">tau</code></td>
<td>
<p>initial step size, default value is 0.01</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_alpha">alpha</code></td>
<td>
<p>controls weighting of skewness and kurtosis. Default value is 0.8, which corresponds to the Jarque-Bera test statistic with 0.8 weighting on squared skewness and 0.2 on squared kurtosis.</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_maxiter">maxiter</code></td>
<td>
<p>default value is 1000</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_tol">tol</code></td>
<td>
<p>the threshold of change in Ux and Uy to stop the curvilinear function</p>
</td></tr>
<tr><td><code id="curvilinear_c_+3A_rj">rj</code></td>
<td>
<p>the joint rank, comes from greedyMatch.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrices:
</p>

<dl>
<dt><code>Ux</code></dt><dd><p>Optimized Ux with matrix n.comp x n.</p>
</dd>
<dt><code>Uy</code></dt><dd><p>Optimized Uy with matrix n.comp x n.</p>
</dd>
<dt><code>tau</code></dt><dd><p>step size</p>
</dd>
<dt><code>iter</code></dt><dd><p>number of iterations.</p>
</dd>
<dt><code>error</code></dt><dd><p>PMSE(Ux,Uxnew)+PMSE(Uy,Uynew)</p>
</dd>
<dt><code>obj</code></dt><dd><p>Objective Function value</p>
</dd>
</dl>


<hr>
<h2 id='est.M.ols'>Estimate mixing matrix from estimates of components</h2><span id='topic+est.M.ols'></span>

<h3>Description</h3>

<p>Estimate mixing matrix from estimates of components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est.M.ols(sData, xData, intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est.M.ols_+3A_sdata">sData</code></td>
<td>
<p>S rx x px</p>
</td></tr>
<tr><td><code id="est.M.ols_+3A_xdata">xData</code></td>
<td>
<p>dX n x px</p>
</td></tr>
<tr><td><code id="est.M.ols_+3A_intercept">intercept</code></td>
<td>
<p>default = TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix Mx, dimension n x rx.
</p>

<hr>
<h2 id='exampledata'>Data for simulation example 1</h2><span id='topic+exampledata'></span>

<h3>Description</h3>

<p>Data for simulation example 1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exampledata
</code></pre>


<h3>Format</h3>

<p>A data list with 10 subsets:
</p>

<dl>
<dt>dX</dt><dd><p>original data matrix for X with n x px, 48x3602</p>
</dd>
<dt>dY</dt><dd><p>original data matrix for Y with n x py, 48x4950</p>
</dd>
<dt>mj</dt><dd><p>true mj matrix, n x rj, 48x2</p>
</dd>
<dt>sIx</dt><dd><p>true S matrix of independent non-Gaussian components in X, ri_x x px, 2x3602</p>
</dd>
<dt>sIy</dt><dd><p>true S matrix of independent non-Gaussian components in Y, ri_y x py, 2x4950</p>
</dd>
<dt>sjx</dt><dd><p>true S matrix of joint non-Gaussian components in X, rj x px, 2x3602</p>
</dd>
<dt>sjy</dt><dd><p>true S matrix of joint non-Gaussian components in Y, rj x py, 2x4950</p>
</dd>
<dt>snr</dt><dd><p>signal to noise ratio</p>
</dd>
<dt>R2x</dt><dd><p>R2 for x data</p>
</dd>
<dt>R2y</dt><dd><p>R2 for y data</p>
</dd>
</dl>


<hr>
<h2 id='gen.inits'>Generate initialization from specific space</h2><span id='topic+gen.inits'></span>

<h3>Description</h3>

<p>Generate initialization from specific space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.inits(p, d, runs, orth.method = c("svd", "givens"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.inits_+3A_p">p</code></td>
<td>
<p>p*p orthodox matrix</p>
</td></tr>
<tr><td><code id="gen.inits_+3A_d">d</code></td>
<td>
<p>p*d orthodox matrix</p>
</td></tr>
<tr><td><code id="gen.inits_+3A_runs">runs</code></td>
<td>
<p>the number of orthodox matrix</p>
</td></tr>
<tr><td><code id="gen.inits_+3A_orth.method">orth.method</code></td>
<td>
<p>orthodox method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of initialization of mixing matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gen.inits(2,3,3,'svd')
</code></pre>

<hr>
<h2 id='greedymatch'>Greedy Match</h2><span id='topic+greedymatch'></span>

<h3>Description</h3>

<p><code>Greedy Match</code> matches a column of Mx and My by minimizing chordal distance between vectors,
removes the matched columns and then finds the next pair.
This equivalent to maximizing absolute correlation for data in which each column has mean equal to zero.
Returns permuted columns of Mx and My. This function does not do any scaling or sign flipping.
For this matching to coincide with angle matching, the columns must have zero mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greedymatch(Mx, My, Ux, Uy)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="greedymatch_+3A_mx">Mx</code></td>
<td>
<p>Subject Score for X with n x n.comp.X matrix</p>
</td></tr>
<tr><td><code id="greedymatch_+3A_my">My</code></td>
<td>
<p>Subject Score for Y with n x n.comp.Y matrix</p>
</td></tr>
<tr><td><code id="greedymatch_+3A_ux">Ux</code></td>
<td>
<p>Matrix with n.comp x n, Mx = Lx^-1 %*% t Ux, Lx is the whitener matrix of dX.</p>
</td></tr>
<tr><td><code id="greedymatch_+3A_uy">Uy</code></td>
<td>
<p>Matrix with n.comp x n, My = Ly^-1 %*% t Uy, Ly is the whitener matrix of dY.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrices:
</p>

<dl>
<dt><code>Mx</code></dt><dd><p>Columns of original Mx reordered from highest to lowest correlation with matched component in My</p>
</dd>
<dt><code>My</code></dt><dd><p>Columns of original My reordered from highest to lowest correlation with matched component in Mx</p>
</dd>
<dt><code>Ux</code></dt><dd><p>Permuted rows of original Ux corresponds to MapX</p>
</dd>
<dt><code>Uy</code></dt><dd><p>Permuted rows of original Uy corresponds to MapY</p>
</dd>
<dt><code>correlations</code></dt><dd><p>a vector of correlations for each pair of columns in permuted Mx and M</p>
</dd>
<dt><code>mapX</code></dt><dd><p>the sequence of the columns in original Mx.</p>
</dd>
<dt><code>mapY</code></dt><dd><p>the sequence of the columns in original MY.</p>
</dd>
</dl>


<hr>
<h2 id='lngca'>Decompose the original data through LNGCA method.</h2><span id='topic+lngca'></span>

<h3>Description</h3>

<p>Implements the methods of linear non-Gaussian component analysis (LNGCA) and likelihood component analysis (when using a density, e.g., tilted Gaussian) from the <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1407772">LNGCA paper</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lngca(
  xData,
  n.comp = NULL,
  Ux.list = NULL,
  whiten = c("sqrtprec", "eigenvec", "none"),
  maxit = 1000,
  eps = 1e-06,
  verbose = FALSE,
  restarts.pbyd = 0,
  restarts.dbyd = 0,
  distribution = c("JB", "tiltedgaussian", "logistic"),
  density = FALSE,
  out.all = FALSE,
  orth.method = c("svd", "givens"),
  df = 0,
  stand = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lngca_+3A_xdata">xData</code></td>
<td>
<p>the original dataset for decomposition, matrix of n x px.</p>
</td></tr>
<tr><td><code id="lngca_+3A_n.comp">n.comp</code></td>
<td>
<p>the number of components to be estimated.</p>
</td></tr>
<tr><td><code id="lngca_+3A_ux.list">Ux.list</code></td>
<td>
<p>list of user specified initial values for Ux. If null, will generate random orthogonal matrices. See restarts.pbyd and restarts.dbyd</p>
</td></tr>
<tr><td><code id="lngca_+3A_whiten">whiten</code></td>
<td>
<p>whitening method. Defaults to &quot;svd&quot; which uses the n left eigenvectors divided by sqrt(px-1) by 'eigenvec'. Optionally uses the square root of the n x n &quot;precision&quot; matrix by 'sqrtprec'.</p>
</td></tr>
<tr><td><code id="lngca_+3A_maxit">maxit</code></td>
<td>
<p>max iteration, defalut = 1000</p>
</td></tr>
<tr><td><code id="lngca_+3A_eps">eps</code></td>
<td>
<p>default = 1e-06</p>
</td></tr>
<tr><td><code id="lngca_+3A_verbose">verbose</code></td>
<td>
<p>default = FALSE</p>
</td></tr>
<tr><td><code id="lngca_+3A_restarts.pbyd">restarts.pbyd</code></td>
<td>
<p>default = 0. Generates p x d random orthogonal matrices. Use a large number for large datasets. Note: it is recommended that you run lngca twice with different seeds and compare the results, which should be similar when a sufficient number of restarts is used. In practice, stability with large datasets and a large number of components can be challenging.</p>
</td></tr>
<tr><td><code id="lngca_+3A_restarts.dbyd">restarts.dbyd</code></td>
<td>
<p>default = 0. These are d x d initial matrices padded with zeros, which results in initializations from the principal subspace. Can speed up convergence but may miss low variance non-Gaussian components.</p>
</td></tr>
<tr><td><code id="lngca_+3A_distribution">distribution</code></td>
<td>
<p>distribution methods with default to tilted Gaussian. &quot;logistic&quot; is similar to infomax ICA, JB is capable of capture super and sub Gaussian distribution while being faster than tilted Gaussian. (tilted Gaussian tends to be most accurate, but computationally much slower.)</p>
</td></tr>
<tr><td><code id="lngca_+3A_density">density</code></td>
<td>
<p>return the estimated tilted Gaussian density? default = FALSE</p>
</td></tr>
<tr><td><code id="lngca_+3A_out.all">out.all</code></td>
<td>
<p>default = FALSE</p>
</td></tr>
<tr><td><code id="lngca_+3A_orth.method">orth.method</code></td>
<td>
<p>default = 'svd'. Method to generate random initial matrices. See [gen.inits()]</p>
</td></tr>
<tr><td><code id="lngca_+3A_df">df</code></td>
<td>
<p>default = 0, df of the spline used in fitting the non-parametric density. use df=8 or so for tilted gaussian. set df=0 for JB and logistic.</p>
</td></tr>
<tr><td><code id="lngca_+3A_stand">stand</code></td>
<td>
<p>whether to standardize the data to have row and column means equal to 0 and the row standard deviation equal to 1 (i.e., all variables on same scale). Often used when combined with singR for data integration.</p>
</td></tr>
<tr><td><code id="lngca_+3A_...">...</code></td>
<td>
<p>other arguments to tiltedgaussian estimation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function outputs a list including the following:
</p>

<dl>
<dt><code>U</code></dt><dd><p>matrix rx x n, part of the expression that Ax = Ux x Lx and Ax x Xc = Sx, where Lx is the whitener matrix.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>the value of log-likelihood in the lngca method.</p>
</dd>
<dt><code>S</code></dt><dd><p>the variable loading matrix r x px, each row is a component, which can be used to measure nongaussianity</p>
</dd>
<dt><code>df</code></dt><dd><p>egree of freedom.</p>
</dd>
<dt><code>distribution</code></dt><dd><p>the method used for data decomposition.</p>
</dd>
<dt><code>whitener</code></dt><dd><p>A symmetric whitening matrix n x n from dX, the same with  whitenerXA = est.sigmaXA %^% -0.5</p>
</dd>
<dt><code>M</code></dt><dd><p>Mx Mtrix with n x rx.</p>
</dd>
<dt><code>nongaussianity</code></dt><dd><p>the nongaussianity score for each component saved in S matrix.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
#get simulation data
data(exampledata)
data=exampledata

# To get n.comp value, we can use NG_number function.

# use JB statistic as the measure of nongaussianity to run lngca with df=0
estX_JB = lngca(xData = data$dX, n.comp = 4,
 whiten = 'sqrtprec', restarts.pbyd = 20, distribution='JB',df=0)

# use the tiltedgaussian distribution to run lngca with df=8. This takes a long time:
estX_tilt = lngca(xData = data$dX, n.comp = 4,
 whiten = 'sqrtprec', restarts.pbyd = 20, distribution='tiltedgaussian',df=8)

# true non-gaussian component of Sx, include individual and joint components
trueSx = rbind(data$sjX,data$siX)

# use pmse to compare the difference of the two methods
pmse(S1 = t(trueSx),S2=t(estX_JB$S),standardize = TRUE)
pmse(S1 = t(trueSx),S2=t(estX_tilt$S),standardize = TRUE)

# the lngca using tiltedgaussian tends to be more accurate
# with smaller pmse value, but takes longer to run.


</code></pre>

<hr>
<h2 id='matchICA'>match ICA</h2><span id='topic+matchICA'></span>

<h3>Description</h3>

<p>match ICA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchICA(S, template, M = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matchICA_+3A_s">S</code></td>
<td>
<p>loading variable matrix</p>
</td></tr>
<tr><td><code id="matchICA_+3A_template">template</code></td>
<td>
<p>template for match</p>
</td></tr>
<tr><td><code id="matchICA_+3A_m">M</code></td>
<td>
<p>subject score matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the match result
</p>

<hr>
<h2 id='NG_number'>find the number of non-Gaussian components in the data.</h2><span id='topic+NG_number'></span>

<h3>Description</h3>

<p>find the number of non-Gaussian components in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NG_number(data, type = "S3")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NG_number_+3A_data">data</code></td>
<td>
<p>original matrix with n x p.</p>
</td></tr>
<tr><td><code id="NG_number_+3A_type">type</code></td>
<td>
<p>'S1', 'S2' or 'S3'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the number of non-Gaussian components in the data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(singR)
data("exampledata")
data=exampledata
NG_number(data$dX)

</code></pre>

<hr>
<h2 id='orthogonalize'>Orthogonalization of matrix</h2><span id='topic+orthogonalize'></span>

<h3>Description</h3>

<p>Orthogonalization of matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orthogonalize(W)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orthogonalize_+3A_w">W</code></td>
<td>
<p>arbitrary matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>orthogonalized matrix
</p>

<hr>
<h2 id='permmatRank_joint'>Permutation test to get joint components ranks</h2><span id='topic+permmatRank_joint'></span>

<h3>Description</h3>

<p>Permutation test to get joint components ranks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permmatRank_joint(matchedResults, nperms = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permmatRank_joint_+3A_matchedresults">matchedResults</code></td>
<td>
<p>results generated by angleMatchICA</p>
</td></tr>
<tr><td><code id="permmatRank_joint_+3A_nperms">nperms</code></td>
<td>
<p>the number of permutation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrixes
## pvalues: pvalues for the matched colunmns don't have correlation.
## corrperm: correlation value for original Mx with each random permutation of My.
## corrmatched: the correlation for each pair of matched columns.
</p>

<hr>
<h2 id='permTestJointRank'>Permutation test with Greedymatch</h2><span id='topic+permTestJointRank'></span>

<h3>Description</h3>

<p>Permutation test with Greedymatch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permTestJointRank(
  MatchedMx,
  MatchedMy,
  nperm = 1000,
  alpha = 0.01,
  multicore = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permTestJointRank_+3A_matchedmx">MatchedMx</code></td>
<td>
<p>matrix with nsubject x n.comp.X, comes from greedymatch</p>
</td></tr>
<tr><td><code id="permTestJointRank_+3A_matchedmy">MatchedMy</code></td>
<td>
<p>matrix with nsubject2 x n.comp.Y, comes from greedymatch</p>
</td></tr>
<tr><td><code id="permTestJointRank_+3A_nperm">nperm</code></td>
<td>
<p>default value = 1000</p>
</td></tr>
<tr><td><code id="permTestJointRank_+3A_alpha">alpha</code></td>
<td>
<p>default value = 0.01</p>
</td></tr>
<tr><td><code id="permTestJointRank_+3A_multicore">multicore</code></td>
<td>
<p>default value = 0</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrixes
## rj: joint component rank
## pvalues: pvalue for the components(columns) not matched
## fwer_alpha: quantile of corr permutation with 1- alpha
</p>

<hr>
<h2 id='pmse'>Permutation invariant mean squared error</h2><span id='topic+pmse'></span>

<h3>Description</h3>

<p>Permutation invariant mean squared error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmse(M1 = NULL, M2 = NULL, S1 = NULL, S2 = NULL, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmse_+3A_m1">M1</code></td>
<td>
<p>Subject score 1 matrix r x n.</p>
</td></tr>
<tr><td><code id="pmse_+3A_m2">M2</code></td>
<td>
<p>Subject score 2 matrix r x n.</p>
</td></tr>
<tr><td><code id="pmse_+3A_s1">S1</code></td>
<td>
<p>Loading 1 with matrix p x r.</p>
</td></tr>
<tr><td><code id="pmse_+3A_s2">S2</code></td>
<td>
<p>Loading 2 with matrix p x r.</p>
</td></tr>
<tr><td><code id="pmse_+3A_standardize">standardize</code></td>
<td>
<p>whether to standardize</p>
</td></tr>
</table>


<h3>Value</h3>

<p>permutation invariant mean squared error
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#get simulation data
data(exampledata)

# use JB stat to compute with singR
output_JB=singR(dX=exampledata$dX,dY=exampledata$dY,
df=0,rho_extent="small",distribution="JB",individual=TRUE)

# use pmse to measure difference from the truth
pmse(M1 = t(output_JB$est.Mj),M2 = t(exampledata$mj),standardize = TRUE)


</code></pre>

<hr>
<h2 id='signchange'>Sign change for S matrix to image</h2><span id='topic+signchange'></span>

<h3>Description</h3>

<p>Sign change for S matrix to image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signchange(S, M = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="signchange_+3A_s">S</code></td>
<td>
<p>S, r x px.</p>
</td></tr>
<tr><td><code id="signchange_+3A_m">M</code></td>
<td>
<p>Mx, n x r.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of positive S and positive Mx.
</p>

<hr>
<h2 id='singR'>SImultaneous Non-Gaussian Component analysis for data integration.</h2><span id='topic+singR'></span>

<h3>Description</h3>

<p>This function combines all steps from the <a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-15/issue-3/Simultaneous-non-Gaussian-component-analysis-SING-for-data-integration-in/10.1214/21-AOAS1466.full">SING paper</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singR(
  dX,
  dY,
  n.comp.X = NULL,
  n.comp.Y = NULL,
  df = 0,
  rho_extent = c("small", "medium", "large"),
  Cplus = TRUE,
  tol = 1e-10,
  stand = FALSE,
  distribution = "JB",
  maxiter = 1500,
  individual = FALSE,
  whiten = c("sqrtprec", "eigenvec", "none"),
  restarts.dbyd = 0,
  restarts.pbyd = 20
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="singR_+3A_dx">dX</code></td>
<td>
<p>original dataset for decomposition, matrix of n x px.</p>
</td></tr>
<tr><td><code id="singR_+3A_dy">dY</code></td>
<td>
<p>original dataset for decomposition, matrix of n x py.</p>
</td></tr>
<tr><td><code id="singR_+3A_n.comp.x">n.comp.X</code></td>
<td>
<p>the number of non-Gaussian components in dataset X. If null, will estimate the number using ICtest::FOBIasymp.</p>
</td></tr>
<tr><td><code id="singR_+3A_n.comp.y">n.comp.Y</code></td>
<td>
<p>the number of non-Gaussian components in dataset Y. If null, will estimate the number using ICtest::FOBIasymp.</p>
</td></tr>
<tr><td><code id="singR_+3A_df">df</code></td>
<td>
<p>default value=0 when use JB, if df&gt;0, estimates a density for the loadings using a tilted Gaussian (non-parametric density estimate).</p>
</td></tr>
<tr><td><code id="singR_+3A_rho_extent">rho_extent</code></td>
<td>
<p>Controls similarity of the scores in the two datasets. Numerical value and three options in character are acceptable. small, medium or large is defined from the JB statistic. Try &quot;small&quot; and see if the loadings are equal, then try others if needed. If numeric input, it will multiply the input by JBall to get the rho.</p>
</td></tr>
<tr><td><code id="singR_+3A_cplus">Cplus</code></td>
<td>
<p>whether to use C code (faster) in curvilinear search.</p>
</td></tr>
<tr><td><code id="singR_+3A_tol">tol</code></td>
<td>
<p>difference tolerance in curvilinear search.</p>
</td></tr>
<tr><td><code id="singR_+3A_stand">stand</code></td>
<td>
<p>whether to use standardization, if true, it will make the column and row means to 0 and columns sd to 1. If false, it will only make the row means to 0.</p>
</td></tr>
<tr><td><code id="singR_+3A_distribution">distribution</code></td>
<td>
<p>&quot;JB&quot; or &quot;tiltedgaussian&quot;; &quot;JB&quot; is much faster. In SING, this refers to the &quot;density&quot; formed from the vector of loadings. &quot;tiltedgaussian&quot; with large df can potentially model more complicated patterns.</p>
</td></tr>
<tr><td><code id="singR_+3A_maxiter">maxiter</code></td>
<td>
<p>the max iteration number for the curvilinear search.</p>
</td></tr>
<tr><td><code id="singR_+3A_individual">individual</code></td>
<td>
<p>whether to return the individual non-Gaussian components, default value = F.</p>
</td></tr>
<tr><td><code id="singR_+3A_whiten">whiten</code></td>
<td>
<p>whitening method used in lngca. Defaults to &quot;svd&quot; which uses the n left eigenvectors divided by sqrt(px-1) by 'eigenvec'. Optionally uses the square root of the n x n &quot;precision&quot; matrix by 'sqrtprec'.</p>
</td></tr>
<tr><td><code id="singR_+3A_restarts.dbyd">restarts.dbyd</code></td>
<td>
<p>default = 0. These are d x d initial matrices padded with zeros, which results in initializations from the principal subspace. Can speed up convergence but may miss low variance non-Gaussian components.</p>
</td></tr>
<tr><td><code id="singR_+3A_restarts.pbyd">restarts.pbyd</code></td>
<td>
<p>default = 20. Generates p x d random orthogonal matrices. Use a large number for large datasets. Note: it is recommended that you run lngca twice with different seeds and compare the results, which should be similar when a sufficient number of restarts is used. In practice, stability with large datasets and a large number of components can be challenging.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function outputs a list including the following:
</p>

<dl>
<dt><code>Sjx</code></dt><dd><p>variable loadings for joint NG components in dataset X with matrix rj x px.</p>
</dd>
<dt><code>Sjy</code></dt><dd><p>variable loadings for joint NG components in dataset Y with matrix rj x py.</p>
</dd>
<dt><code>Six</code></dt><dd><p>variable loadings for individual NG components in dataset X with matrix riX x px.</p>
</dd>
<dt><code>Siy</code></dt><dd><p>variable loadings for individual NG components in dataset Y with matrix riX x py.</p>
</dd>
<dt><code>Mix</code></dt><dd><p>scores of individual NG components in X with matrix n x riX.</p>
</dd>
<dt><code>Miy</code></dt><dd><p>scores of individual NG components in Y with matrix n x riY.</p>
</dd>
<dt><code>est.Mjx</code></dt><dd><p>Estimated subject scores for joint components in dataset X with matrix n x rj.</p>
</dd>
<dt><code>est.Mjy</code></dt><dd><p>Estimated subject scores for joint components in dataset Y with matrix n x rj.</p>
</dd>
<dt><code>est.Mj</code></dt><dd><p>Average of est.Mjx and est.Mjy as the subject scores for joint components in both datasets with matrix n x rj.</p>
</dd>
<dt><code>C_plus</code></dt><dd><p>whether to use C version of curvilinear search.</p>
</dd>
<dt><code>rho_extent</code></dt><dd><p>the weight of rho in search</p>
</dd>
<dt><code>df</code></dt><dd><p>degree of freedom, = 0 when use JB, &gt;0 when use tiltedgaussian.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
#get simulation data
data(exampledata)

# use JB stat to compute with singR
output_JB=singR(dX=exampledata$dX,dY=exampledata$dY,
df=0,rho_extent="small",distribution="JB",individual=TRUE)

# use tiltedgaussian distribution to compute with singR.
# tiltedgaussian may be more accurate but is considerably slower,
# and is not recommended for large datasets.
output_tilted=singR(dX=exampledata$dX,dY=exampledata$dY,
df=5,rho_extent="small",distribution="tiltedgaussian",individual=TRUE)

# use pmse to measure difference from the truth
pmse(M1 = t(output_JB$est.Mj),M2 = t(exampledata$mj),standardize = TRUE)

pmse(M1 = t(output_tilted$est.Mj),M2 = t(exampledata$mj),standardize = TRUE)


</code></pre>

<hr>
<h2 id='standard'>Standardization with double centered and column scaling</h2><span id='topic+standard'></span>

<h3>Description</h3>

<p>Standardization with double centered and column scaling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standard(data, dif.tol = 0.001, max.iter = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standard_+3A_data">data</code></td>
<td>
<p>input matrix with n x px.</p>
</td></tr>
<tr><td><code id="standard_+3A_dif.tol">dif.tol</code></td>
<td>
<p>the value for the threshold of scaling</p>
</td></tr>
<tr><td><code id="standard_+3A_max.iter">max.iter</code></td>
<td>
<p>default value = 10</p>
</td></tr>
</table>


<h3>Value</h3>

<p>standardized matrix with n x px.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>spmwm = 3*matrix(rnorm(100000),nrow=100)+1
dim(spmwm)
apply(spmwm,1,mean) # we want these to be 0
apply(spmwm,2,mean) # we want these to be 0
apply(spmwm,2,sd) # we want each of these variances to be 1

spmwm_cp=standard(spmwm)
max(abs(apply(spmwm_cp,1,mean)))
max(abs(apply(spmwm_cp,2,mean)))
max(abs(apply(spmwm_cp,2,sd)-1))
</code></pre>

<hr>
<h2 id='theta2W'>Convert angle vector into orthodox matrix</h2><span id='topic+theta2W'></span>

<h3>Description</h3>

<p>Convert angle vector into orthodox matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theta2W(theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theta2W_+3A_theta">theta</code></td>
<td>
<p>vector of angles theta</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an orthodox matrix
</p>

<hr>
<h2 id='tiltedgaussian'>tiltedgaussian</h2><span id='topic+tiltedgaussian'></span>

<h3>Description</h3>

<p>tiltedgaussian
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tiltedgaussian(xData, df = 8, B = 100, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tiltedgaussian_+3A_xdata">xData</code></td>
<td>
<p>input data</p>
</td></tr>
<tr><td><code id="tiltedgaussian_+3A_df">df</code></td>
<td>
<p>degree freedom</p>
</td></tr>
<tr><td><code id="tiltedgaussian_+3A_b">B</code></td>
<td>
<p>default value=100</p>
</td></tr>
<tr><td><code id="tiltedgaussian_+3A_...">...</code></td>
<td>
<p>ellipsis</p>
</td></tr>
</table>

<hr>
<h2 id='vec2net'>Create network matrices from vectorized lower diagonals
<code>vec2net</code> transfer the matrix vectorized lower diagonals into net to show the component image.</h2><span id='topic+vec2net'></span>

<h3>Description</h3>

<p>Create network matrices from vectorized lower diagonals
<code>vec2net</code> transfer the matrix vectorized lower diagonals into net to show the component image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2net(invector, make.diag = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2net_+3A_invector">invector</code></td>
<td>
<p>vectorized lower diagonals.</p>
</td></tr>
<tr><td><code id="vec2net_+3A_make.diag">make.diag</code></td>
<td>
<p>default value = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a net matrx
</p>


<h3>Examples</h3>

<pre><code class='language-R'>net = vec2net(1:10)
</code></pre>

<hr>
<h2 id='whitener'>Whitening Function</h2><span id='topic+whitener'></span>

<h3>Description</h3>

<p>Whitening Function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whitener(X, n.comp = ncol(X), center.row = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="whitener_+3A_x">X</code></td>
<td>
<p>dataset p x n.</p>
</td></tr>
<tr><td><code id="whitener_+3A_n.comp">n.comp</code></td>
<td>
<p>the number of components</p>
</td></tr>
<tr><td><code id="whitener_+3A_center.row">center.row</code></td>
<td>
<p>whether center the row of data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a whitener matrix
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
