<!DOCTYPE html><html><head><title>Help for package HTSCluster</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HTSCluster}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HTSCluster-package'>
<p>Clustering high throughput sequencing (HTS) data</p></a></li>
<li><a href='#highDimensionARI'>
<p>Calculate ARI for high-dimensional data via data splits</p></a></li>
<li><a href='#HTSClusterUsersGuide'><p>View HTSCluster User's Guide</p></a></li>
<li><a href='#Init'>
<p>Parameter initialization for a Poisson mixture model.</p></a></li>
<li><a href='#logLikePoisMix'>
<p>Log likelihood calculation for a Poisson mixture model</p></a></li>
<li><a href='#plot.HTSCluster'><p>Visualize results from clustering using a Poisson mixture model</p></a></li>
<li><a href='#PoisMixClus'>
<p>Poisson mixture model estimation and model selection</p></a></li>
<li><a href='#PoisMixMean'>
<p>Calculate the conditional per-cluster mean of each observation</p></a></li>
<li><a href='#PoisMixSim'>
<p>Simulate data from a Poisson mixture model</p></a></li>
<li><a href='#probaPost'>
<p>Calculate the conditional probability of belonging to each cluster in a Poisson mixture model</p></a></li>
<li><a href='#summary.HTSCluster'><p>Summarize results from clustering using a Poisson mixture model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Clustering High-Throughput Transcriptome Sequencing (HTS) Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.11</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrea Rau, Gilles Celeux, Marie-Laure Martin-Magniette, Cathy Maugis-
    Rabusseau</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrea Rau &lt;andrea.rau@jouy.inra.fr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>edgeR, plotrix, capushe, grDevices, graphics, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>HTSFilter, Biobase</td>
</tr>
<tr>
<td>Description:</td>
<td>A Poisson mixture model is implemented to cluster genes from high-
    throughput transcriptome sequencing (RNA-seq) data. Parameter estimation is
    performed using either the EM or CEM algorithm, and the slope heuristics are
    used for model selection (i.e., to choose the number of clusters).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-04 15:08:30 UTC; araul</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-05 08:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='HTSCluster-package'>
Clustering high throughput sequencing (HTS) data
</h2><span id='topic+HTSCluster-package'></span><span id='topic+HTSCluster'></span>

<h3>Description</h3>

<p>A Poisson mixture model is implemented to cluster genes from high-throughput 
transcriptome sequencing (RNA-seq) data. Parameter estimation is performed using 
either the EM or CEM algorithm, and the slope heuristics are used for model 
selection (i.e., to choose the number of clusters).
</p>


<h3>Author(s)</h3>

<p>Andrea Rau, Gilles Celeux, Marie-Laure Martin-Magniette, Cathy Maugis-Rabusseau
</p>
<p>Maintainer: Andrea Rau
</p>


<h3>References</h3>

<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011) Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 2000 observations

simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions

## Run the PMM model for g = 3
## "TC" library size estimate, EM algorithm

run &lt;- PoisMixClus(y, g=3, conds=conds, norm="TC") 

## Estimates of pi and lambda for the selected model

pi.est &lt;- run$pi
lambda.est &lt;- run$lambda


## Not run: PMM for 4 total clusters, with one fixed class
## "TC" library size estimate, EM algorithm
##
## run &lt;- PoisMixClus(y, g = 3, norm = "TC", conds = conds, 
##    fixed.lambda = list(c(1,1,1))) 
##
##
## Not run: PMM model for 4 clusters, with equal proportions
## "TC" library size estimate, EM algorithm
##
## run &lt;- PoisMixClus(y, g = 4, norm = "TC", conds = conds, 
##     equal.proportions = TRUE) 
##
##
## Not run: PMM model for g = 1, ..., 10 clusters, Split Small-EM init
##
## run1.10 &lt;- PoisMixClusWrapper(y, gmin = 1, gmax = 10, conds = conds, 
##	norm = "TC")
##
##
## Not run: PMM model for g = 1, ..., 10 clusters, Small-EM init
##
## run1.10bis &lt;-  &lt;- PoisMixClusWrapper(y, gmin = 1, gmax = 10, conds = conds, 
##	norm = "TC", split.init = FALSE)
##
##
## Not run: previous model equivalent to the following
##
## for(K in 1:10) {
##	run &lt;- PoisMixClus(y, g = K, conds = conds, norm = "TC")
## }


</code></pre>

<hr>
<h2 id='highDimensionARI'>
Calculate ARI for high-dimensional data via data splits
</h2><span id='topic+highDimensionARI'></span>

<h3>Description</h3>

<p>This function is used to calculate Adjusted Rand Index (ARI) values for high-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>highDimensionARI(x, y, splits = 2, verbose = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="highDimensionARI_+3A_x">x</code></td>
<td>

<p>Vector of classification labels
</p>
</td></tr>
<tr><td><code id="highDimensionARI_+3A_y">y</code></td>
<td>

<p>Vector of classification labels
</p>
</td></tr>
<tr><td><code id="highDimensionARI_+3A_splits">splits</code></td>
<td>

<p>Number of subsets data should be split into
</p>
</td></tr>
<tr><td><code id="highDimensionARI_+3A_verbose">verbose</code></td>
<td>

<p><code>TRUE</code> if verbose output is desired
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of Adjusted Rand Index for samples <code>x</code> and <code>y</code>
</p>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>

<hr>
<h2 id='HTSClusterUsersGuide'>View HTSCluster User's Guide</h2><span id='topic+HTSClusterUsersGuide'></span>

<h3>Description</h3>

<p>Finds the location of the HTSCluster User's Guide and optionally opens it.</p>


<h3>Usage</h3>

<pre><code class='language-R'>HTSClusterUsersGuide(view=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HTSClusterUsersGuide_+3A_view">view</code></td>
<td>
<p>logical, should the document be opened using the default PDF document reader?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>vignette("HTSCluster")</code> will find the short HTSCluster Vignette which describes how to obtain the HTSCluster User's Guide.
The User's Guide is not itself a true vignette because it is not automatically generated using <code><a href="utils.html#topic+Sweave">Sweave</a></code> during the package build process.
This means that it cannot be found using <code>vignette</code>, hence the need for this special function.
</p>
<p>If the operating system is other than Windows, then the PDF viewer used is that given by <code>Sys.getenv("R_PDFVIEWER")</code>.
The PDF viewer can be changed using <code>Sys.putenv(R_PDFVIEWER=)</code>.
</p>
<p>Note that this function was adapted from that defined by Gordon Smyth in the edgeR package.
</p>


<h3>Value</h3>

<p>Character string giving the file location.
If <code>view=TRUE</code>, the PDF document reader is started and the User's Guide is opened, as a side effect.</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+system">system</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To get the location:
HTSClusterUsersGuide(view=FALSE)
# To open in pdf viewer:
## Not run: HTSClusterUsersGuide()
</code></pre>

<hr>
<h2 id='Init'>
Parameter initialization for a Poisson mixture model.
</h2><span id='topic+emInit'></span><span id='topic+kmeanInit'></span><span id='topic+splitEMInit'></span><span id='topic+probaPostInit'></span>

<h3>Description</h3>

<p>These functions implement a variety of initialization methods for the parameters of a Poisson mixture model: the Small EM initialization strategy (<code>emInit</code>) described in Rau et al. (2011), a K-means initialization strategy (<code>kmeanInit</code>) that is itself used to initialize the small EM strategy, the splitting small-EM initialization strategy (<code>splitEMInit</code>) based on that described in Papastamoulis et al. (2014), and a function to initialize a small-EM strategy using the posterior probabilities (<code>probaPostInit</code>) obtained from a previous run with one fewer cluster following the splitting strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
emInit(y, g, conds, norm, alg.type = "EM", 
    init.runs, init.iter, fixed.lambda, equal.proportions, verbose)

kmeanInit(y, g, conds, norm, fixed.lambda,
    equal.proportions)

splitEMInit(y, g, conds, norm, alg.type, fixed.lambda,
    equal.proportions, prev.labels, prev.probaPost, init.runs, 
    init.iter, verbose)

probaPostInit(y, g, conds, norm, alg.type = "EM", 
    fixed.lambda, equal.proportions, probaPost.init, init.iter,
    verbose)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Init_+3A_y">y</code></td>
<td>

<p>(<em>n</em> x <em>q</em>) matrix of observed counts for <em>n</em> observations and <em>q</em> variables
</p>
</td></tr>
<tr><td><code id="Init_+3A_g">g</code></td>
<td>

<p>Number of clusters. If <code>fixed.lambda</code> contains a list of lambda values to be fixed, <em>g</em> corresponds to the number of clusters in addition to those fixed.
</p>
</td></tr>
<tr><td><code id="Init_+3A_conds">conds</code></td>
<td>

<p>Vector of length <em>q</em> defining the condition (treatment group) for each variable (column) in <code>y</code>
</p>
</td></tr>
<tr><td><code id="Init_+3A_norm">norm</code></td>
<td>

<p>The type of estimator to be used to normalize for differences in library size: (&ldquo;<code>TC</code>&rdquo; for total count, &ldquo;<code>UQ</code>&rdquo; for upper quantile, &ldquo;<code>Med</code>&rdquo; for median, 
&ldquo;<code>DESeq</code>&rdquo; for the normalization method in the DESeq package, and &ldquo;<code>TMM</code>&rdquo; for the TMM normalization method (Robinson and Oshlack, 2010). Can also
be a vector (of length <em>q</em>) containing pre-estimated library size estimates for each sample.
</p>
</td></tr>
<tr><td><code id="Init_+3A_alg.type">alg.type</code></td>
<td>

<p>Algorithm to be used for parameter estimation (&ldquo;<code>EM</code>&rdquo; or &ldquo;<code>CEM</code>&rdquo; for the EM or CEM algorithms, respectively)
</p>
</td></tr>
<tr><td><code id="Init_+3A_init.runs">init.runs</code></td>
<td>

<p>In the case of the Small-EM algorithm, the number of independent runs to be performed.
In the case of the splitting Small-EM algorithm, the number of cluster splits to be performed in the splitting small-EM initialization. 
</p>
</td></tr>
<tr><td><code id="Init_+3A_init.iter">init.iter</code></td>
<td>

<p>The number of iterations to run within each Small-EM algorithm
</p>
</td></tr>
<tr><td><code id="Init_+3A_fixed.lambda">fixed.lambda</code></td>
<td>

<p>If one (or more) clusters with fixed values of lambda is desires, a list containing vectors of length <em>d</em> (the number of conditions). Note that the values of lambda chosen must satisfy the constraint noted in the technical report.
</p>
</td></tr>
<tr><td><code id="Init_+3A_equal.proportions">equal.proportions</code></td>
<td>

<p>If <code>TRUE</code>, the cluster proportions are set to be equal for all clusters. Default is <code>FALSE</code> (unequal cluster proportions)
</p>
</td></tr>
<tr><td><code id="Init_+3A_prev.labels">prev.labels</code></td>
<td>

<p>A vector of length <em>n</em> of cluster labels obtained from the previous run (g-1 clusters)
</p>
</td></tr>
<tr><td><code id="Init_+3A_prev.probapost">prev.probaPost</code></td>
<td>

<p>An <em>n</em> x (<em>g</em>-1) matrix of the conditional probabilities of each observation belonging to each of the 
<em>g</em>-1 clusters from the previous run
</p>
</td></tr>
<tr><td><code id="Init_+3A_probapost.init">probaPost.init</code></td>
<td>

<p>An <em>n</em> x (<em>g</em>) matrix of the conditional probabilities of each observation belonging to each of the 
<em>g</em> clusters following the splitting strategy in the <code>splitEMInit</code> function
</p>
</td></tr>
<tr><td><code id="Init_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, include verbose output
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In practice, the user will not directly call the initialization functions described here; they are indirectly called
for a single number of clusters through the <code>PoisMixClus</code> function (via <code>init.type</code>) or via the 
<code>PoisMixClusWrapper</code> function for a sequence of cluster numbers (via <code>gmin.init.type</code> and <code>split.init</code>). 
</p>
<p>To initialize parameter values for the EM and CEM algorithms, for the Small-EM strategy (Biernacki et al., 2003) we use the <code>emInit</code> function as follows. For a given number of independent runs (given by <code>init.runs</code>), the following procedure is used to obtain parameter values: first, a K-means algorithm (MacQueen, 1967) is run to partition the data into <code>g</code> clusters (<code class="reqn">\hat{\boldsymbol{z}}^{(0)}</code>). Second, initial parameter values <code class="reqn">\boldsymbol{\pi}^{(0)}</code> and <code class="reqn">\boldsymbol{\lambda}^{(0)}</code> are calculated (see Rau et al. (2011) for details). Third, a given number of iterations of an EM algorithm are run (defined by <code>init.iter</code>), using <code class="reqn">\boldsymbol{\pi}^{(0)}</code> and <code class="reqn">\boldsymbol{\lambda}^{(0)}</code> as initial values. Finally, among the <code>init.runs</code> sets of parameter values, we use <code class="reqn">\hat{\boldsymbol{\lambda}}</code> and <code class="reqn">\hat{\boldsymbol{\pi}}</code> corresponding to the highest log likelihood or completed log likelihood to initialize the subsequent full EM or CEM algorithms, respectively.
</p>
<p>For the splitting small EM initialization strategy, we implement an approach similar to that described in Papastamoulis et al. (2014),
where the cluster from the previous run (with <em>g</em>-1 clusters) with the largest entropy is chosen to be split into two new clusters,
followed by a small EM run as described above.
</p>


<h3>Value</h3>

<table>
<tr><td><code>pi.init</code></td>
<td>
<p>Vector of length <code>g</code> containing the estimate for <code class="reqn">\hat{\boldsymbol{\pi}}</code> corresponding to the highest log likelihood (or completed log likelihood) from the chosen inialization strategy. </p>
</td></tr>
<tr><td><code>lambda.init</code></td>
<td>
<p>(<em>d</em> x <code>g</code>) matrix containing the estimate of <code class="reqn">\hat{\boldsymbol{\lambda}}</code> corresponding to the highest log likelihood (or completed log likelihood) from the chosen initialization strategy, where <em>d</em> is the number of conditions and <code>g</code> is the number of clusters. </p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>(<em>d</em> x <code>g</code>) matrix containing the estimate of <code class="reqn">\hat{\boldsymbol{\lambda}}</code> arising from the splitting initialization and small EM run for a single split, 
where <em>d</em> is the number of conditions and <code>g</code> is the number of clusters. </p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>Vector of length <code>g</code> containing the estimate for <code class="reqn">\hat{\boldsymbol{\pi}}</code> arising from the splitting initialization and small EM run for a single split, where <code>g</code> is the 
number of clusters.  </p>
</td></tr>
<tr><td><code>log.like</code></td>
<td>
<p>Log likelihood arising from the splitting initialization and small EM run for a single split. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Anders, S. and Huber, W. (2010) Differential expression analysis for sequence count data. <em>Genome Biology</em>, <b>11</b>(R106), 1-28.
</p>
<p>Biernacki, C., Celeux, G., Govaert, G. (2003) Choosing starting values for the EM algorithm for getting the highest likelhiood in multivariate Gaussian mixture models. <em>Computational Statistics and Data Analysis</em>, <b>41</b>(1), 561-575.
</p>
<p>MacQueen, J. B. (1967) Some methods for classification and analysis of multivariate observations. In <em>Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability</em>, number 1, pages 281-297. Berkeley, University of California Press.
</p>
<p>Papastamoulis, P., Martin-Magniette, M.-L., and Maugis-Rabusseau, C. (2014). On the estimation of mixtures of Poisson regression models with large number of components. <em>Computational Statistics and Data Analysis</em>: 3rd special Issue on Advances in Mixture Models, DOI: 10.1016/j.csda.2014.07.005.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>
<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Robinson, M. D. and Oshlack, A. (2010) A scaling normalization method for differential expression analysis of RNA-seq data. <em>Genome Biology</em>, <b>11</b>(R25).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoisMixClus">PoisMixClus</a></code> for Poisson mixture model estimation for a given number of clusters,
<code><a href="#topic+PoisMixClusWrapper">PoisMixClusWrapper</a></code> for Poisson mixture model estimation and model selection for a sequence of cluster numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 500 observations

simulate &lt;- PoisMixSim(n = 500, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions

## Calculate initial values for lambda and pi using the Small-EM
## initialization (4 classes, PMM-II model with "TC" library size)
##
## init.values &lt;- emInit(y, g = 4, conds, 
##    norm = "TC", alg.type = "EM", 
##    init.runs = 50, init.iter = 10, fixed.lambda = NA,
##    equal.proportions = FALSE, verbose = FALSE)
## pi.init &lt;- init.values$pi.init
## lambda.init &lt;- init.values$lambda.init


</code></pre>

<hr>
<h2 id='logLikePoisMix'>
Log likelihood calculation for a Poisson mixture model
</h2><span id='topic+logLikePoisMix'></span><span id='topic+logLikePoisMixDiff'></span><span id='topic+mylogLikePoisMixObs'></span>

<h3>Description</h3>

<p>Functions to calculate the log likelihood for a Poisson mixture model, the difference in log likelihoods for two different sets of parameters of a Poisson mixture model or the log-likelihood for each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLikePoisMix(y, mean, pi)
logLikePoisMixDiff(y, mean.new, pi.new, mean.old, pi.old)
mylogLikePoisMixObs(y, conds, s, lambda, pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLikePoisMix_+3A_y">y</code></td>
<td>

<p>(<em>n</em> x <em>q</em>) matrix of observed counts for <em>n</em> observations and <em>q</em> variables
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_mean">mean</code></td>
<td>

<p>List of length <em>g</em> containing the (<em>n</em> x <em>q</em>) matrices of conditional mean expression for all observations, as calculated by the <code><a href="#topic+PoisMixMean">PoisMixMean</a></code> function, where <em>g</em> represents the number of clusters
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_mean.new">mean.new</code></td>
<td>

<p>List of length <em>g</em> containing the (<em>n</em> x <em>q</em>) matrices of conditional mean expression for all observations for one set of parameters, as calculated by the <code><a href="#topic+PoisMixMean">PoisMixMean</a></code> function, where <em>g</em> represents the number of clusters
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_mean.old">mean.old</code></td>
<td>

<p>List of length <em>g</em> containing the (<em>n</em> x <em>q</em>) matrices of conditional mean expression for all observations for another set of parameters, as calculated by the <code><a href="#topic+PoisMixMean">PoisMixMean</a></code> function, where <em>g</em> represents the number of clusters
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_pi.new">pi.new</code></td>
<td>

<p>Vector of length <em>g</em> containing one estimate for <code class="reqn">\hat{\boldsymbol{\pi}}</code>
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_pi.old">pi.old</code></td>
<td>

<p>Vector of length <em>g</em> containing another estimate for <code class="reqn">\hat{\boldsymbol{\pi}}</code>
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_pi">pi</code></td>
<td>

<p>Vector of length <em>g</em> containing estimate for <code class="reqn">\hat{\boldsymbol{\pi}}</code>
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_conds">conds</code></td>
<td>

<p>Vector of length <em>q</em> defining the condition (treatment group) for each variable (column) in <code>y</code>
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_s">s</code></td>
<td>

<p>Estimate of normalized per-variable library size
</p>
</td></tr>
<tr><td><code id="logLikePoisMix_+3A_lambda">lambda</code></td>
<td>

<p>(<em>d</em> x <code>g</code>) matrix containing the current estimate of lambda, where <em>d</em> is the number of conditions (treatment groups) and <code>g</code> is the number of clusters
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>logLikePoisMixDiff</code> function is used to calculate the difference in log likelihood for two different sets of parameters in a Poisson mixture model; it is used to determine convergence in the EM algorithm run by the <code><a href="#topic+PoisMixClus">PoisMixClus</a></code> function.
The <code>logLikePoisMix</code> function (taken largely from the <code>mylogLikePoisMix</code> function from the <code>poisson.glm.mix</code> R package) calculates the log likelihood for a given set of parameters in a Poisson mixture model and is used in the <code><a href="#topic+PoisMixClus">PoisMixClus</a></code> function for the calculation of the BIC and ICL. 
The <code>mylogLikePoisMixObs</code> function calculates the log likelihood per observation for a given set of parameters in a Poisson mixture model. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>ll</code></td>
<td>
<p>(Depending on the context), the log likelihood, difference in log likelihoods for two different sets of parameters, or per-observation log-likelihood</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In the <code>logLikePoisMixDiff</code> function, we make use of the alternative mass function for a Poisson density proposed by Loader (2000) to avoid computational difficulties. The <code>logLikePoisMixDiff</code> function returns a default value of 100 if one or both of the log likelihoods associated with the two parameter sets takes on a value of <code class="reqn">-\infty</code>.
</p>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Loader, C. (2000) Fast and accurate computation of binomial probabilities. Available at <a href="https://lists.gnu.org/archive/html/octave-maintainers/2011-09/pdfK0uKOST642.pdf">https://lists.gnu.org/archive/html/octave-maintainers/2011-09/pdfK0uKOST642.pdf</a>.
</p>
<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011) Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoisMixClus">PoisMixClus</a></code> for Poisson mixture model estimation and model selection; 
<code><a href="#topic+PoisMixMean">PoisMixMean</a></code> to calculate the per-cluster conditional mean of each observation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", low cluster separation
## n = 200 observations

simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "low")
y &lt;- simulate$y
conds &lt;- simulate$conditions
w &lt;- rowSums(y)               ## Estimate of w
r &lt;- table(conds)             ## Number of replicates per condition
d &lt;- length(unique(conds))    ## Number of conditions
s &lt;- colSums(y) / sum(y)      ## TC estimate of lib size
s.dot &lt;- rep(NA, d)           ## Summing lib size within conditions
for(j in 1:d) s.dot[j] &lt;- sum(s[which(conds == unique(conds)[j])]);

## Initial guess for pi and lambda
g.true &lt;- 4
pi.guess &lt;- simulate$pi
## Recalibrate so that (s.dot * lambda.guess) = 1
lambda.sim &lt;- simulate$lambda
lambda.guess &lt;- matrix(NA, nrow = d, ncol = g.true)
for(k in 1:g.true) {
    tmp &lt;- lambda.sim[,k]/sum(lambda.sim[,k])
    lambda.guess[,k] &lt;- tmp/s.dot
}

## Run the PMM-II model for g = 4
## with EM algorithm and "TC" library size parameter
run &lt;- PoisMixClus(y, g = 4, norm = "TC", conds = conds) 
pi.est &lt;- run$pi
lambda.est &lt;- run$lambda

## Mean values for each of the parameter sets
mean.guess &lt;- PoisMixMean(y, 4, conds, s, lambda.guess)
mean.est &lt;- PoisMixMean(y, 4, conds, s, lambda.est)

## Difference in log likelihoods       
LL.diff &lt;- logLikePoisMixDiff(y, mean.guess, pi.guess, mean.est, pi.est)
LL.diff             ## -12841.11

</code></pre>

<hr>
<h2 id='plot.HTSCluster'>Visualize results from clustering using a Poisson mixture model</h2><span id='topic+plot.HTSCluster'></span><span id='topic+plot.HTSClusterWrapper'></span>

<h3>Description</h3>

<p>A function to visualize the clustering results obtained from a Poisson mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HTSCluster'
plot(x, file.name = FALSE, 
    graphs = c("map", "map.bycluster", "lambda"), data=NA, ...)
## S3 method for class 'HTSClusterWrapper'
plot(x, file.name = FALSE,
    graphs = c("capushe", "ICL", "BIC"), capushe.validation=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.HTSCluster_+3A_x">x</code></td>
<td>
<p> An object of class <code>"HTSCluster"</code> or <code>"HTSClusterWrapper"</code></p>
</td></tr>
<tr><td><code id="plot.HTSCluster_+3A_file.name">file.name</code></td>
<td>
<p> Optional file name if plots are to be saved in a PDF file.</p>
</td></tr>
<tr><td><code id="plot.HTSCluster_+3A_graphs">graphs</code></td>
<td>
<p> Type of graph to be included in plots. May be equal to
<code>"map"</code>, <code>"may.bycluster"</code>, <code>"weighted.histograms"</code>, and/or <code>"lambda"</code> for objects
of class <code>"HTSCluster"</code> and <code>c("ICL", "BIC")</code> for objects of class
<code>"HTSClusterWrapper"</code></p>
</td></tr>
<tr><td><code id="plot.HTSCluster_+3A_capushe.validation">capushe.validation</code></td>
<td>
<p> Optional number of clusters to use for capushe validation (should be less than the maximum number of clusters
specificed in the <code>"HTSClusterWrapper"</code> object).</p>
</td></tr>
<tr><td><code id="plot.HTSCluster_+3A_data">data</code></td>
<td>

<p>(<em>n</em> x <em>q</em>) matrix of observed counts for <em>n</em> observations and <em>q</em> variables (only required for the plotting of weighted histograms)
</p>
</td></tr>
<tr><td><code id="plot.HTSCluster_+3A_...">...</code></td>
<td>
<p>Additional arguments (mainly useful for plotting)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects of class <code>"HTSCluster"</code>, the plotting function provides the possibility for the following visualizations:
</p>
<p>1) A histogram of maximum conditional probabilities across all clusters.
</p>
<p>2) Per-cluster boxplots of maximum conditional probabilities.
</p>
<p>3) Weighted histograms of observation profiles (with weights equal to the 
corresponding conditional probability for each observation in each cluster),
plotted independently for each variable. Fitted densities after fitting the
Poisson mixture model are overlaid in red.
</p>
<p>4) A global view of <code class="reqn">\boldsymbol{\lambda}</code> and <code class="reqn">\boldsymbol{\pi}</code> values for the selected model. When the
number of conditions &lt;= 2, bar heights represent the value of <code class="reqn">\boldsymbol{\lambda}_k</code> for each
cluster, and bar width corresponds to the value of <code class="reqn">\boldsymbol{\pi_k}</code>. 
</p>
<p>For objects of class <code>"HTSClusterWrapper"</code>, the plotting function provides the possibility for one or all of the following visualizations:
</p>
<p>1) ICL plot for all fitted models.
</p>
<p>2) BIC plot for all fitted models.
</p>
<p>5) Capushe diagnostic plots.
</p>


<h3>Author(s)</h3>

<p>Andrea Rau</p>


<h3>References</h3>

<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Andrea Rau, Gilles Celeux, Marie-Laure Martin-Magniette, and Cathy Maugis-Rabusseau (2011). 
Clustering high-throughput sequencing data with Poisson mixture models. <em>Technical report</em>
RR-7786, Inria Saclay &ndash; Ile-de-France.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoisMixClus">PoisMixClus</a></code>, <code><a href="#topic+PoisMixClusWrapper">PoisMixClusWrapper</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 2000 observations
simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions

## Run the PMM-II model for g = 3
## "TC" library size estimate, EM algorithm
run &lt;- PoisMixClus(y, g = 3, 
    norm = "TC", conds = conds, init.type = "small-em")

## Visualization of results (not run):
## plot(run)


</code></pre>

<hr>
<h2 id='PoisMixClus'>
Poisson mixture model estimation and model selection
</h2><span id='topic+PoisMixClus'></span><span id='topic+PoisMixClusWrapper'></span>

<h3>Description</h3>

<p>These functions implement the EM and CEM algorithms for parameter estimation in a Poisson mixture model for clustering high throughput sequencing observations (e.g., genes) for a single number of clusters (<code>PoisMixClus</code>) or a sequence of cluster numbers (<code>PoisMixClusWrapper</code>). Parameters are initialized using a Small-EM strategy as described in Rau et al. (2011) or the splitting small-EM strategy described in Papastamoulis et al. (2014), and model selection is performed using the ICL criteria. Note that these functions implement the PMM-I and PMM-II models described in Rau et al. (2011). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoisMixClus(y, g, conds, norm = "TMM", 
    init.type = "small-em", init.runs = 1, init.iter = 10,
    alg.type = "EM", cutoff = 10e-6, iter = 1000, fixed.lambda = NA,
    equal.proportions = FALSE, prev.labels = NA, 
    prev.probaPost = NA, verbose = FALSE, interpretation = "sum",
	EM.verbose = FALSE, wrapper = FALSE, subset.index = NA)

PoisMixClusWrapper(y, gmin = 1, gmax, conds, 
    norm = "TMM", gmin.init.type = "small-em",
    init.runs = 1, init.iter = 10, split.init = TRUE, alg.type = "EM", 
    cutoff = 10e-6, iter = 1000, fixed.lambda = NA, 
    equal.proportions = FALSE, verbose = FALSE, interpretation = "sum",
	EM.verbose = FALSE, subset.index = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoisMixClus_+3A_y">y</code></td>
<td>

<p>(<em>n</em> x <em>q</em>) matrix of observed counts for <em>n</em> observations and <em>q</em> variables
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_g">g</code></td>
<td>

<p>Number of clusters (a single value). If <code>fixed.lambda</code> contains a list of lambda values to be fixed, 
<code>g</code> corresponds to the number of clusters in addition to those fixed.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_gmin">gmin</code></td>
<td>

<p>The minimum number of clusters in a sequence to be tested. In cases where clusters are included with a fixed value 
of lambda, <code>gmin</code> corresponds to the minimum number of clusters in addition to those that are fixed.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_gmax">gmax</code></td>
<td>

<p>The maximum number of clusters in a sequence to be tested. In cases where clusters are included with a fixed value 
of lambda, <code>gmax</code> corresponds to the maximum number of clusters in addition to those that are fixed.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_conds">conds</code></td>
<td>

<p>Vector of length <em>q</em> defining the condition (treatment group) for each variable (column) in <code>y</code>
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_norm">norm</code></td>
<td>

<p>The type of estimator to be used to normalize for differences in library size: (&ldquo;<code>TC</code>&rdquo; for total count, &ldquo;<code>UQ</code>&rdquo; for upper quantile, &ldquo;<code>Med</code>&rdquo; for median, 
&ldquo;<code>DESeq</code>&rdquo; for the normalization method in the DESeq package, and &ldquo;<code>TMM</code>&rdquo; for the TMM normalization method (Robinson and Oshlack, 2010). Can also
be a vector (of length <em>q</em>) containing pre-estimated library size estimates for each sample. Note that if the user provides
pre-calculated normalization factors, the package will make use of <code>norm/sum(norm)</code> as normalization factors.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_init.type">init.type</code></td>
<td>

<p>Type of initialization strategy to be used (&ldquo;<code>small-em</code>&rdquo; for the Small-EM strategy described in Rau et al. (2011), and &ldquo;<code>kmeans</code>&rdquo; for a simple <em>K</em>-means initialization)
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_gmin.init.type">gmin.init.type</code></td>
<td>

<p>Type of initialization strategy to be used for the minimum number of clusters in a sequence (<code>gmin</code>): 
(&ldquo;<code>small-em</code>&rdquo; for the Small-EM strategy described in Rau et al. (2011), and &ldquo;<code>kmeans</code>&rdquo; for a simple <em>K</em>-means initialization)
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_init.runs">init.runs</code></td>
<td>

<p>Number of runs to be used for the Small-EM strategy described in Rau et al. (2011), with a default value of 1
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_init.iter">init.iter</code></td>
<td>

<p>Number of iterations to be used within each run for the Small-EM strategry, with a default value of 10
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_split.init">split.init</code></td>
<td>

<p>If <code>TRUE</code>, the splitting initialization strategy of Papastamoulis et al. (2014) will be used for cluster sizes
(<code>gmin</code>+1, ..., <code>gmax</code>). If <code>FALSE</code>, the initialization strategy specified in <code>gmin.init.type</code>
is used for all cluster sizes in the sequence.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_alg.type">alg.type</code></td>
<td>

<p>Algorithm to be used for parameter estimation (&ldquo;<code>EM</code>&rdquo; or &ldquo;<code>CEM</code>&rdquo;)
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_cutoff">cutoff</code></td>
<td>

<p>Cutoff to declare algorithm convergence (in terms of differences in log likelihoods from one iteration to the next)
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_iter">iter</code></td>
<td>

<p>Maximum number of iterations to be run for the chosen algorithm
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_fixed.lambda">fixed.lambda</code></td>
<td>

<p>If one (or more) clusters with fixed values of lambda is desired, a list containing vectors of length <em>d</em> (the number of conditions). 
specifying the fixed values of lambda for each fixed cluster.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_equal.proportions">equal.proportions</code></td>
<td>

<p>If <code>TRUE</code>, the cluster proportions are set to be equal for all clusters. Default is <code>FALSE</code> (unequal cluster proportions).
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_prev.labels">prev.labels</code></td>
<td>

<p>A vector of length <em>n</em> of cluster labels obtained from the previous run (g-1 clusters) to be used with the splitting
small-EM strategy described in described in Papastamoulis et al. (2014). For other initialization strategies, this 
parameter takes the value NA
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_prev.probapost">prev.probaPost</code></td>
<td>

<p>An <em>n</em> x (<em>g</em>-1) matrix of the conditional probabilities of each observation belonging to each of the 
<em>g</em>-1 clusters from the previous run, to be used with the splitting small-EM strategy of described in Papastamoulis 
et al. (2012). For other initialization strategies, this parameter takes the value NA
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, include verbose output
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_interpretation">interpretation</code></td>
<td>

<p>If <code>"sum"</code>, cluster behavior is interpreted with respect to overall gene expression level (sums per gene), 
otherwise for <code>"mean"</code>, cluster behavior is interpreted with respect to mean gene expression (means per gene).
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_em.verbose">EM.verbose</code></td>
<td>

<p>If <code>TRUE</code>, more informative output is printed about the EM algorithm, including the number of iterations run and
the difference between log-likelihoods at the last and penultimate iterations.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_subset.index">subset.index</code></td>
<td>

<p>Optional vector providing the indices of a subset of genes that should be used for the co-expression analysis (i.e., row indices
of the data matrix <code>y</code>.
</p>
</td></tr>
<tr><td><code id="PoisMixClus_+3A_wrapper">wrapper</code></td>
<td>

<p><code>TRUE</code> if the <code>PoisMixClus</code> function is run from within the <code>PoisMixClusWrapper</code> main function, and <code>FALSE</code>
otherwise. This mainly helps to avoid recalculating parameters several times that are used throughout the algorithm (e.g., library
sizes, etc.)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Output of <code>PoisMixClus</code> is an S3 object of class <code>HTSCluster</code>, and output of <code>PoisMixClusWrapper</code> is an S3 object
of class <code>HTSClusterWrapper</code>.
</p>
<p>In a Poisson mixture model, the data <code class="reqn">\mathbf{y}</code> are assumed to come from <em>g</em> distinct subpopulations (clusters), each of which is modeled separately; the overall population is thus a mixture of these subpopulations. In the case of a Poisson mixture model with <em>g</em> components, the model may be written as
</p>
<p style="text-align: center;"><code class="reqn">f(\mathbf{y};g,\boldsymbol{\Psi}_g) = \prod_{i=1}^n \sum_{k=1}^g \pi_k \prod_{j=1}^{d}\prod_{l=1}^{r_j} P(y_{ijl} ; \boldsymbol{\theta}_k)</code>
</p>

<p>for <code class="reqn">i = 1, \ldots, n</code> observations in <code class="reqn">l = 1, \ldots, r_j</code> replicates of <code class="reqn">j = 1, \ldots, d</code> conditions (treatment groups), where <code class="reqn">P(\cdot)</code> is the standard Poisson density, <code class="reqn">\boldsymbol{\Psi}_g = (\pi_1,\ldots,\pi_{g-1}, \boldsymbol{\theta}^\prime)</code>, <code class="reqn">\boldsymbol{\theta}^\prime</code> contains all of the parameters in <code class="reqn">\boldsymbol{\theta}_1,\ldots,\boldsymbol{\theta}_g</code> assumed to be distinct, and <code class="reqn">\boldsymbol{\pi} = (\pi_1,\ldots,\pi_g)^\prime</code> are the mixing proportions such that <code class="reqn">\pi_k</code> is in (0,1) for all <em>k</em> and <code class="reqn">\sum_k \pi_k = 1</code>.
</p>
<p>We consider the following parameterization for the mean <code class="reqn">\boldsymbol{\theta}_k = (\mu_{ijlk})</code>. We consider
</p>
<p style="text-align: center;"><code class="reqn">\mu_{ijlk} = w_i s_{jl} \lambda_{jk}</code>
</p>

<p>where <code class="reqn">w_i</code> corresponds to the expression level of observation <em>i</em>, <code class="reqn">\boldsymbol{\lambda}_k = (\lambda_{1k},\ldots,\lambda_{dk})</code> 
corresponds to the clustering parameters that define the profiles of the genes in cluster <em>k</em> across all variables, and  
<code class="reqn">s_{jl}</code> is the normalized library size (a fixed constant) for replicate <em>l</em> of condition <em>j</em>.
</p>
<p>There are two approaches to estimating the parameters of a finite mixture model and obtaining a clustering of the data: the estimation approach (via the EM algorithm) and the clustering approach (via the CEM algorithm). Parameter initialization is done using a Small-EM strategy as described in Rau et al. (2011) via the <code><a href="#topic+emInit">emInit</a></code> function. Model selection may be performed using the BIC or ICL criteria, or the slope heuristics.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lambda</code></td>
<td>
<p>(<em>d</em> x <em>g</em>) matrix containing the estimate of <code class="reqn">\hat{\boldsymbol{\lambda}}</code></p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>Vector of length <em>g</em> containing the estimate of <code class="reqn">\hat{\boldsymbol{\pi}}</code></p>
</td></tr>
<tr><td><code>labels</code></td>
<td>
<p>Vector of length <em>n</em> containing the cluster assignments of the <em>n</em> observations</p>
</td></tr>
<tr><td><code>probaPost</code></td>
<td>
<p>Matrix containing the conditional probabilities of belonging to each cluster for all observations</p>
</td></tr>
<tr><td><code>log.like</code></td>
<td>
<p>Value of log likelihood</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Value of BIC criterion</p>
</td></tr>
<tr><td><code>ICL</code></td>
<td>
<p>Value of ICL criterion</p>
</td></tr>
<tr><td><code>alg.type</code></td>
<td>
<p>Estimation algorithm used; matches the argument <code>alg.type</code> above)</p>
</td></tr>
<tr><td><code>norm</code></td>
<td>
<p>Library size normalization factors used</p>
</td></tr>
<tr><td><code>conds</code></td>
<td>
<p>Conditions specified by user</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>Number of iterations run</p>
</td></tr>
<tr><td><code>logLikeDiff</code></td>
<td>
<p>Difference in log-likelihood between the last and penultimate iterations of the algorithm</p>
</td></tr>
<tr><td><code>subset.index</code></td>
<td>
<p>If provided by the user, the indices of subset of genes used for co-expression analyses</p>
</td></tr>
<tr><td><code>loglike.all</code></td>
<td>
<p>Log likelihoods calculated for each of the fitted models for cluster sizes <code>gmin</code>, ..., <code>gmax</code></p>
</td></tr>
<tr><td><code>capushe</code></td>
<td>
<p>Results of capushe model selection, an object of class <code>"Capushe"</code></p>
</td></tr>
<tr><td><code>ICL.all</code></td>
<td>
<p>ICL values calculated for each of the fitted models for cluster sizes <code>gmin</code>, ..., <code>gmax</code></p>
</td></tr>
<tr><td><code>ICL.results</code></td>
<td>
<p>Object of class <code>HTSCluster</code> giving the results from the model chosen via the ICL criterion</p>
</td></tr>
<tr><td><code>BIC.results</code></td>
<td>
<p>Object of class <code>HTSCluster</code> giving the results from the model chosen via the BIC</p>
</td></tr>
<tr><td><code>DDSE.results</code></td>
<td>
<p>Object of class <code>HTSCluster</code> giving the results from the model chosen via the DDSE slope heuristics criterion</p>
</td></tr>
<tr><td><code>Djump.results</code></td>
<td>
<p>Object of class <code>HTSCluster</code> giving the results from the model chosen via the Djump slope heuristics criterion</p>
</td></tr>
<tr><td><code>all.results</code></td>
<td>
<p>List of objects of class <code>HTSCluster</code> giving the results for all models for cluster sizes <code>gmin</code>, ..., <code>gmax</code></p>
</td></tr>
<tr><td><code>model.selection</code></td>
<td>
<p>Type of criteria used for model selection, equal to <code>NA</code> for direct calls to <code>PoisMixClus</code> or
<code>"DDSE"</code>, <code>"Djump"</code>, <code>"BIC"</code>, or <code>"ICL"</code> for the respective selected models for calls to <code>PoisMixClusWrapper</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that the <code>fixed.lambda</code> argument is primarily intended to be used in the case when a single cluster is fixed to 
have equal clustering parameters lambda across all conditions (i.e., <code class="reqn">\lambda_{j1}=\lambda_{1}=1</code>); this is particularly useful
when identifying genes with non-differential expression across all conditions (see the <code>HTSDiff</code> R package for more details).
Alternatively, this argument could be used to specify a cluster for which genes are only expressed in a single condition 
(e.g., <code class="reqn">\lambda_{11} = 1</code> and <code class="reqn">\lambda_{j1} = 0</code> for all <code class="reqn">j &gt; 1</code>). Other possibilities could be considered,
but note that the fixed values of lambda must satisfy the constraint <code class="reqn">\sum_j \lambda_{jk}s_{j.} = 1</code> for all <code class="reqn">k</code> 
imposed in the model; if this is not the case, a warning message will be printed.
</p>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Anders, S. and Huber, W. (2010) Differential expression analysis for sequence count data. <em>Genome Biology</em>, <b>11</b>(R106), 1-28.
</p>
<p>Papastamoulis, P., Martin-Magniette, M.-L., and Maugis-Rabusseau, C. (2014). On the estimation of mixtures of Poisson regression models with large number of components. <em>Computational Statistics and Data Analysis</em>: 3rd special Issue on Advances in Mixture Models, DOI: 10.1016/j.csda.2014.07.005.
</p>
<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+probaPost">probaPost</a></code> for the calculation of the conditional probability of belonging to a cluster;
<code><a href="#topic+PoisMixMean">PoisMixMean</a></code> for the calculation of the per-cluster conditional mean of each observation;
<code><a href="#topic+logLikePoisMixDiff">logLikePoisMixDiff</a></code> for the calculation of the log likelihood of a Poisson mixture model;
<code><a href="#topic+emInit">emInit</a></code> and <code><a href="#topic+kmeanInit">kmeanInit</a></code> for the Small-EM parameter initialization strategy
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 200 observations

simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions

## Run the PMM model for g = 3
## "TC" library size estimate, EM algorithm

run &lt;- PoisMixClus(y, g = 3, conds = conds, norm = "TC") 

## Estimates of pi and lambda for the selected model

pi.est &lt;- run$pi
lambda.est &lt;- run$lambda


## Not run: PMM for 4 total clusters, with one fixed class
## "TC" library size estimate, EM algorithm
##
## run &lt;- PoisMixClus(y, g = 3, norm = "TC", conds = conds, 
##    fixed.lambda = list(c(1,1,1))) 
##
##
## Not run: PMM model for 4 clusters, with equal proportions
## "TC" library size estimate, EM algorithm
##
## run &lt;- PoisMixClus(y, g = 4, norm = "TC", conds = conds, 
##     equal.proportions = TRUE) 
##
##
## Not run: PMM model for g = 1, ..., 10 clusters, Split Small-EM init
##
## run1.10 &lt;- PoisMixClusWrapper(y, gmin = 1, gmax = 10, conds = conds, 
##	norm = "TC")
##
##
## Not run: PMM model for g = 1, ..., 10 clusters, Small-EM init
##
## run1.10bis &lt;-  &lt;- PoisMixClusWrapper(y, gmin = 1, gmax = 10, conds = conds, 
##	norm = "TC", split.init = FALSE)
##
##
## Not run: previous model equivalent to the following
##
## for(K in 1:10) {
##	run &lt;- PoisMixClus(y, g = K, conds = conds, norm = "TC")
## } 

</code></pre>

<hr>
<h2 id='PoisMixMean'>
Calculate the conditional per-cluster mean of each observation
</h2><span id='topic+PoisMixMean'></span>

<h3>Description</h3>

<p>This function is used to calculate the conditional per-cluster mean expression for all observations. This value corresponds to
<code class="reqn">\boldsymbol{\mu} = (\mu_{ijlk}) = (\hat{w}_i \hat{\lambda}_{jk})</code>
for the PMM-I model and
<code class="reqn">\boldsymbol{\mu} = (\mu_{ijlk}) = (\hat{w}_i s_{jl} \hat{\lambda}_{jk})</code>
for the PMM-II model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoisMixMean(y, g, conds, s, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoisMixMean_+3A_y">y</code></td>
<td>

<p>(<em>n</em> x <em>q</em>) matrix of observed counts for <em>n</em> observations and <em>q</em> variables
</p>
</td></tr>
<tr><td><code id="PoisMixMean_+3A_g">g</code></td>
<td>

<p>Number of clusters
</p>
</td></tr>
<tr><td><code id="PoisMixMean_+3A_conds">conds</code></td>
<td>

<p>Vector of length <em>q</em> defining the condition (treatment group) for each variable (column) in <code>y</code>
</p>
</td></tr>
<tr><td><code id="PoisMixMean_+3A_s">s</code></td>
<td>

<p>Estimate of normalized per-variable library size
</p>
</td></tr>
<tr><td><code id="PoisMixMean_+3A_lambda">lambda</code></td>
<td>

<p>(<em>d</em> x <code>g</code>) matrix containing the current estimate of lambda, where <em>d</em> is the number of conditions (treatment groups) and <code>g</code> is the number of clusters
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length <code>g</code> containing the (<em>n</em> x <em>q</em>) matrices of mean expression for all observations, conditioned on each of the <code>g</code> clusters
</p>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoisMixClus">PoisMixClus</a></code> for Poisson mixture model estimation and model selection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 200 observations

simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions
s &lt;- colSums(y) / sum(y) 	## TC estimate of lib size

## Run the PMM-II model for g = 3
## "TC" library size estimate, EM algorithm

run &lt;- PoisMixClus(y, g = 3, norm = "TC", conds = conds) 
pi.est &lt;- run$pi
lambda.est &lt;- run$lambda

## Calculate the per-cluster mean for each observation
means &lt;- PoisMixMean(y, g = 3, conds, s, lambda.est) 

</code></pre>

<hr>
<h2 id='PoisMixSim'>
Simulate data from a Poisson mixture model
</h2><span id='topic+PoisMixSim'></span>

<h3>Description</h3>

<p>This function simulates data from a Poisson mixture model, as described by Rau et al. (2011). Data are simulated with varying expression level (<code class="reqn">w_i</code>) for 4 clusters. Clusters may be simulated with &ldquo;high&rdquo; or &ldquo;low&rdquo; separation, and three different options are available for the library size setting: &ldquo;equal&rdquo;, &ldquo;A&rdquo;, and &ldquo;B&rdquo;, as described by Rau et al. (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoisMixSim(n = 2000, libsize, separation)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoisMixSim_+3A_n">n</code></td>
<td>

<p>Number of observations
</p>
</td></tr>
<tr><td><code id="PoisMixSim_+3A_libsize">libsize</code></td>
<td>

<p>The type of library size difference to be simulated (&ldquo;<code>equal</code>&rdquo;, &ldquo;<code>A</code>&rdquo;, or &ldquo;<code>B</code>&rdquo;, as described by Rau et al. (2011))
</p>
</td></tr>
<tr><td><code id="PoisMixSim_+3A_separation">separation</code></td>
<td>

<p>Cluster separation (&ldquo;<code>high</code>&rdquo; or &ldquo;<code>low</code>&rdquo;, as described by Rau et al. (2011))
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>y</code></td>
<td>
<p>(<em>n</em> x <em>q</em>) matrix of simulated counts for <em>n</em> observations and <em>q</em> variables</p>
</td></tr>
<tr><td><code>labels</code></td>
<td>
<p>Vector of length <em>n</em> defining the true cluster labels of the simulated data</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>Vector of length 4 (the number of clusters) containing the true value of <code class="reqn">\boldsymbol{\pi}</code></p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>(<em>d</em> x <em>4</em>) matrix of <code class="reqn">\boldsymbol{\lambda}</code> values for <em>d</em> conditions (3 in the case of <code>libsize =</code> &ldquo;<code>equal</code>&rdquo; or &ldquo;<code>A</code>&rdquo;, and 2 otherwise) in 4 clusters (see note below)</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>Row sums of <code>y</code> (estimate of <code class="reqn">\hat{w}</code>)</p>
</td></tr>
<tr><td><code>conditions</code></td>
<td>
<p>Vector of length <em>q</em> defining the condition (treatment group) for each variable (column) in <code>y</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>If one or more observations are simulated such that all variables have a value of 0, those rows are removed from the data matrix; as such, in some cases the simulated data <code>y</code> may have less than <code>n</code> rows.
</p>
<p>The PMM-I model includes the parameter constraint <code class="reqn">\sum_k \lambda_{jk} r_j = 1</code>, where <code class="reqn">r_j</code> is the number of replicates in condition (treatment group) <code class="reqn">j</code>. Similarly, the parameter constraint in the PMM-II model is <code class="reqn">\sum_j \sum_l \lambda_{jk}s_{jl} = 1</code>, where <code class="reqn">s_{jl}</code> is the library size for replicate <em>l</em> of condition <em>j</em>. The value of <code>lambda</code> corresponds to that used to generate the simulated data, where the library sizes were set as described in Table 2 of Rau et al. (2011). However, due to variability in the simulation process, the actually library sizes of the data <code>y</code> are not exactly equal to these values; this means that the value of <code>lambda</code> may not be directly compared to an estimated value of <code class="reqn">\hat{\boldsymbol{\lambda}}</code> as obtained from the <code><a href="#topic+PoisMixClus">PoisMixClus</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 200 observations

simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions

</code></pre>

<hr>
<h2 id='probaPost'>
Calculate the conditional probability of belonging to each cluster in a Poisson mixture model
</h2><span id='topic+probaPost'></span>

<h3>Description</h3>

<p>This function computes the conditional probabilities <code class="reqn">t_{ik}</code> that an observation <em>i</em> arises from the <code class="reqn">k^{\mathrm{th}}</code> component for the current value of the mixture parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probaPost(y, g, conds, pi, s, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probaPost_+3A_y">y</code></td>
<td>

<p>(<em>n</em> x <em>q</em>) matrix of observed counts for <em>n</em> observations and <em>q</em> variables
</p>
</td></tr>
<tr><td><code id="probaPost_+3A_g">g</code></td>
<td>

<p>Number of clusters
</p>
</td></tr>
<tr><td><code id="probaPost_+3A_conds">conds</code></td>
<td>

<p>Vector of length <em>q</em> defining the condition (treatment group) for each variable (column) in <code>y</code>
</p>
</td></tr>
<tr><td><code id="probaPost_+3A_pi">pi</code></td>
<td>

<p>Vector of length <code>g</code> containing the current estimate of <code class="reqn">\hat{\boldsymbol{\pi}}</code>
</p>
</td></tr>
<tr><td><code id="probaPost_+3A_s">s</code></td>
<td>

<p>Vector of length <em>q</em> containing the estimates for the normalized library size parameters for each of the <em>q</em> variables in <code>y</code>
</p>
</td></tr>
<tr><td><code id="probaPost_+3A_lambda">lambda</code></td>
<td>

<p>(<em>d</em> x <code>g</code>) matrix containing the current estimate <code class="reqn">\boldsymbol{\lambda}</code>, where <em>d</em> is the number of conditions (treatment groups)
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>t</code></td>
<td>
<p>(<em>n</em> x <code>g</code>) matrix made up of the conditional probability of each observation belonging to each of the <code>g</code> clusters</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If all values of <code class="reqn">t_{ik}</code> are 0 (or nearly zero), the observation is assigned with probability one to belong to the cluster with the closest mean (in terms of the Euclidean distance from the observation). To avoid calculation difficulties, extreme values of <code class="reqn">t_{ik}</code> are smoothed, such that those smaller than 1e-10 or larger than 1-1e-10 are set equal to 1e-10 and 1-1e-10, respectively.
</p>


<h3>Author(s)</h3>

<p>Andrea Rau
</p>


<h3>References</h3>

<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoisMixClus">PoisMixClus</a></code> for Poisson mixture model estimation and model selection;
<code><a href="#topic+PoisMixMean">PoisMixMean</a></code> to calculate the conditional per-cluster mean of each observation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 200 observations

simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions
s &lt;- colSums(y) / sum(y)     ## TC estimate of lib size

## Run the PMM-II model for g = 3
## "TC" library size estimate, EM algorithm

run &lt;- PoisMixClus(y, g = 3, norm = "TC",
 	conds = conds) 
pi.est &lt;- run$pi
lambda.est &lt;- run$lambda

## Calculate the conditional probability of belonging to each cluster
proba &lt;- probaPost(y, g = 3, conds = conds, pi = pi.est, s = s, 
	lambda = lambda.est)

## head(round(proba,2))

</code></pre>

<hr>
<h2 id='summary.HTSCluster'>Summarize results from clustering using a Poisson mixture model</h2><span id='topic+summary.HTSCluster'></span><span id='topic+summary.HTSClusterWrapper'></span>

<h3>Description</h3>

<p>A function to summarize the clustering results obtained from a Poisson mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HTSCluster'
summary(object, ...)
## S3 method for class 'HTSClusterWrapper'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.HTSCluster_+3A_object">object</code></td>
<td>
<p> An object of class <code>"HTSCluster"</code> or <code>"HTSClusterWrapper"</code></p>
</td></tr>
<tr><td><code id="summary.HTSCluster_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary function for an object of class <code>"HTSCluster"</code> provides the following summary of results:
</p>
<p>1) Number of clusters and model selection criterion used, if applicable.
</p>
<p>2) Number of observations across all clusters with a maximum conditional probability
greater than 90
model.
</p>
<p>3) Number of observations per cluster with a maximum conditional probability
greater than 90
selected model.
</p>
<p>4) <code class="reqn">\boldsymbol{\lambda}</code> values for the selected model.
</p>
<p>5) <code class="reqn">\boldsymbol{\pi}</code> values for the selected model.
</p>
<p>The summary function for an object of class <code>"HTSClusterWrapper"</code> provides the number of clusters selected for
the BIC, ICL, DDSE, and Djump model selection approaches.
</p>


<h3>Author(s)</h3>

<p>Andrea Rau</p>


<h3>References</h3>

<p>Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux G. (2015). Co-expression analysis of high-throughput transcriptome sequencing data with Poisson mixture models. Bioinformatics, 31(9):1420-1427.
</p>
<p>Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011). Clustering high-throughput sequencing data with Poisson mixture models. Inria Research Report 7786. Available at <a href="https://inria.hal.science/inria-00638082">https://inria.hal.science/inria-00638082</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoisMixClus">PoisMixClus</a></code>, <code><a href="#topic+PoisMixClusWrapper">PoisMixClusWrapper</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(12345)

## Simulate data as shown in Rau et al. (2011)
## Library size setting "A", high cluster separation
## n = 2000 observations
simulate &lt;- PoisMixSim(n = 200, libsize = "A", separation = "high")
y &lt;- simulate$y
conds &lt;- simulate$conditions

## Run the PMM-II model for g = 3
## "TC" library size estimate, EM algorithm
run &lt;- PoisMixClus(y, g = 3, 
    norm = "TC", conds = conds, init.type = "small-em")

## Summary of results:
summary(run)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
