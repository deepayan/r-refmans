<!DOCTYPE html><html><head><title>Help for package memochange</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {memochange}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BP_estim'><p>Breakpoint estimators for a change in persistence</p></a></li>
<li><a href='#BT'><p>function to calculate sequence of test statistics by Busetti and Taylor (2004). For internal use only.</p></a></li>
<li><a href='#cusum'><p>function to calculate sequence of cusum test statistics by Leybourne, Taylor, and Kim (2006). For internal use only</p></a></li>
<li><a href='#CUSUM_simple'><p>Simple test for change-in-mean under long memory</p></a></li>
<li><a href='#cusum_test'><p>Cusum-type test against a change in persistence</p></a></li>
<li><a href='#CUSUMfixed'><p>Self-normalized CUSUM tests for structural change under long memory.</p></a></li>
<li><a href='#CUSUMLM'><p>CUSUM long memory test for a single change in the mean of a long-memory time series.</p></a></li>
<li><a href='#CV'><p>function to generate critical values. For internal use only.</p></a></li>
<li><a href='#d_vec'><p>function to extract critical values. For internal use only.</p></a></li>
<li><a href='#ers_test'><p>Unit root test by Elliot et al. (1996). For internal use only</p></a></li>
<li><a href='#fb_longrun'><p>function to estimate the fixed-b long-run variance. For internal use only.</p></a></li>
<li><a href='#fixbsupw'><p>Fixed-b sup Wald test for a single change in the mean of a long-memory time series.</p></a></li>
<li><a href='#getCV'><p>function to extract critical values. For internal use only.</p></a></li>
<li><a href='#HLT'><p>function to calculate unit root test to adjust test statistic as suggested by Harvey, Leybourne, and Taylor (2006).</p></a></li>
<li><a href='#HLTmin'><p>function to calculate sequence of minimum test statistics by Harvey, Leybourne, and Taylor (2006). For internal use only</p></a></li>
<li><a href='#LBI'><p>function to calculate sequence of LBI test statistics by Busetti and Taylor (2004). For internal use only.</p></a></li>
<li><a href='#LBI_test'><p>Locally best invariant test against a change in persistence</p></a></li>
<li><a href='#LKSN'><p>function to calculate sequence of LKSN test statistics. For internal use only</p></a></li>
<li><a href='#LKSN_test'><p>DF-type test against a change in persistence</p></a></li>
<li><a href='#LT'><p>function to calculate sequence of test statistics by Leybourne and Taylor (2004). For internal use only.</p></a></li>
<li><a href='#memochange'><p>memochange: Testing for Structural Breaks under Long Memory and Testing for Changes in Persistence</p></a></li>
<li><a href='#MR'><p>function to calculate sequence of test statistics by Martins and Rodrigues (2014). For internal use only</p></a></li>
<li><a href='#MR_test'><p>LM test against a change in persistence</p></a></li>
<li><a href='#pb_sim'><p>Simulates persistence-break process</p></a></li>
<li><a href='#ratio_test'><p>Ratio-based test against a change in persistence</p></a></li>
<li><a href='#snsupwald'><p>Self-normalized sup Wald test for a single change in the mean of a long-memory time series.</p></a></li>
<li><a href='#snwilcoxon'><p>Self-normalized Wilcoxon test for a single change in the mean of a long-memory time series.</p></a></li>
<li><a href='#wald_test'><p>function to calculate wald_test. For internal use only</p></a></li>
<li><a href='#wilcoxonLM'><p>Wilcoxon long memory test for a single change in the mean of a long-memory time series.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Testing for Structural Breaks under Long Memory and Testing for
Changes in Persistence</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-07-25</td>
</tr>
<tr>
<td>Description:</td>
<td>Test procedures and break point estimators for persistent processes that exhibit structural breaks in mean or in persistence.
    On the one hand the package contains the most popular approaches for testing whether a time series exhibits a break in persistence from I(0) to I(1) or vice versa, such as those of Busetti and Taylor (2004) and Leybourne, Kim, and Taylor (2007).
    The approach by Martins and Rodrigues (2014), which allows to detect changes from I(d1) to I(d2) with d1 and d2 being non-integers, is included as well.
    In case the tests reject the null of constant persistence, various breakpoint estimators are available to detect the point of the break as well as the order of integration in the two regimes.
    On the other hand the package contains the most popular approaches to test for a change-in-mean of a long-memory time series, which were recently reviewed by Wenger, Leschinski, and Sibbertsen (2018). 
    These include memory robust versions of the CUSUM, sup-Wald, and Wilcoxon type tests. The tests either utilize consistent estimates of the long-run variance or a self normalization approach in their test statistics.
    Betken (2016) &lt;<a href="https://doi.org/10.1111%2Fjtsa.12187">doi:10.1111/jtsa.12187</a>&gt;
    Busetti and Taylor (2004) &lt;<a href="https://doi.org/10.1016%2Fj.jeconom.2003.10.028">doi:10.1016/j.jeconom.2003.10.028</a>&gt;
    Dehling, Rooch and Taqqu (2012) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9469.2012.00799.x">doi:10.1111/j.1467-9469.2012.00799.x</a>&gt;
    Harvey, Leybourne and Taylor (2006) &lt;<a href="https://doi.org/10.1016%2Fj.jeconom.2005.07.002">doi:10.1016/j.jeconom.2005.07.002</a>&gt;
    Horvath and Kokoszka (1997) &lt;<a href="https://doi.org/10.1016%2FS0378-3758%2896%2900208-X">doi:10.1016/S0378-3758(96)00208-X</a>&gt;
    Hualde and Iacone (2017) &lt;<a href="https://doi.org/10.1016%2Fj.econlet.2016.10.014">doi:10.1016/j.econlet.2016.10.014</a>&gt;
    Iacone, Leybourne and Taylor (2014) &lt;<a href="https://doi.org/10.1111%2Fjtsa.12049">doi:10.1111/jtsa.12049</a>&gt;
    Leybourne, Kim, Smith, and Newbold (2003) &lt;<a href="https://doi.org/10.1111%2F1368-423X.t01-1-00110">doi:10.1111/1368-423X.t01-1-00110</a>&gt;
    Leybourne and Taylor (2004) &lt;<a href="https://doi.org/10.1016%2Fj.econlet.2003.12.015">doi:10.1016/j.econlet.2003.12.015</a>&gt;
    Leybourne, Kim, and Taylor (2007): &lt;<a href="https://doi.org/10.1111%2Fj.1467-9892.2006.00517.x">doi:10.1111/j.1467-9892.2006.00517.x</a>&gt;
    Martins and Rodrigues (2014) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2012.07.021">doi:10.1016/j.csda.2012.07.021</a>&gt;
    Shao (2011) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9892.2010.00717.x">doi:10.1111/j.1467-9892.2010.00717.x</a>&gt;
    Sibbertsen and Kruse (2009) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9892.2009.00611.x">doi:10.1111/j.1467-9892.2009.00611.x</a>&gt;
    Wang (2008) &lt;<a href="https://doi.org/10.1080%2F00949650701216604">doi:10.1080/00949650701216604</a>&gt;
    Wenger, Leschinski and Sibbertsen (2018) &lt;<a href="https://doi.org/10.1016%2Fj.econlet.2017.12.007">doi:10.1016/j.econlet.2017.12.007</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>urca (&ge; 1.3.0), forecast (&ge; 8.6), fracdiff (&ge; 1.4.2),
LongMemoryTS (&ge; 0.1.0), sandwich (&ge; 2.5.1), strucchange (&ge;
1.5.1), longmemo (&ge; 1.1.1), stats (&ge; 3.4.1)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, xts, zoo, data.table, utils,
graphics</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-07-26 13:57:49 UTC; Kai</td>
</tr>
<tr>
<td>Author:</td>
<td>Janis Becker [aut],
  Kai Wenger [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kai Wenger &lt;kai.wenger@gmx.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-07-26 23:10:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='BP_estim'>Breakpoint estimators for a change in persistence</h2><span id='topic+BP_estim'></span>

<h3>Description</h3>

<p>This function estimates the location where the investigated time series exhibits a break in persistence. It requires
knowledge of the direction of the break, i.e. an increase or decrease in persistence. This
needs to be determined beforehand using one of the various persistence change tests provided in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BP_estim(x, trend = c("none", "linear"), tau = 0.2, type = c("BT",
  "LKT", "LKSN", "MR"), direction = c("01", "10"), d_estim = c("ELW",
  "GPH"), d_bw = 0.7, m = 0, serial = c(FALSE, TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BP_estim_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_tau">tau</code></td>
<td>
<p>the function searches in the interval <code>[T*tau,T*(1-tau)]</code> for a break in persistence with T being the length of the time series. It must hold that <code>0&lt;tau&lt;0.5</code>, default is <code>tau=0.2</code> as commonly used in the literature. Note that if <code>type="BT"</code> and <code>T*tau&lt;=2+ as.numeric(trend=="linear")</code>, <code>type="LT"</code> and <code>T*tau&lt;=2+ as.numeric(trend=="linear") + (m&gt;3)*(m-3)</code>, <code>type="LKSN"</code> and <code>T*tau&lt;=10</code>, or <code>type="MR"</code> and <code>T*tau&lt;=2+(p&gt;1)*p</code>the break point cannot be found.</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_type">type</code></td>
<td>
<p>which type of break point estimator should be used, <code>"LKSN"</code> for the estimator by Leybourne, Kim, Smith, and Newbold (2003), <code>"BT"</code> for the estimator by Busetti and Taylor (2004), <code>"LKT"</code> for the estimator by Leybourne, Kim, and Taylor (2006),
and <code>MR</code> for the estimator by Martins and Rodrigues (2014). See details.</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_direction">direction</code></td>
<td>
<p>direction of the change in persistence, <code>"01"</code> implies an increase in persistence over time and <code>"10"</code> a decrease. See details.</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_d_estim">d_estim</code></td>
<td>
<p>which estimator should be used to determine the order of integration in the two regimes, <code>"GPH"</code> corresponds to the estimator by Geweke and Porter-Hudak (1983) and <code>"ELW"</code> corresponds to the exact local Whittle estimator by Shimotsu and Phillips (2005).</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_d_bw">d_bw</code></td>
<td>
<p>bandwidth used for estimating the order of integration d. Default is <code>d_bw=0.7</code>. Note that the estimation of the memory parameter can only be performed for 0&lt;d_bw&lt;=1 and it is even recommended to choose 0.5&lt;=d_bw&lt;=0.8 as otherwise the estimators might be inconsistent.&quot;)</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_m">m</code></td>
<td>
<p>Number of covariances used for the estimation of the long run variance when considering the LKT estimator. Default is <code>m=0</code>.</p>
</td></tr>
<tr><td><code id="BP_estim_+3A_serial">serial</code></td>
<td>
<p>boolean, indicating whether to account for serial correlation of the errors when considering the MR estimator. Default is <code>serial=FALSE</code> implying no correction for serial correlation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimators BT and LKSN are only consistent for changes from I(0) to I(1) or vice versa, the LKT estimator is consistent for changes from stationary to nonstationary memory or vice versa (cf. also Sibbertsen and Kruse (2009)), and the MR estimator is consistent for changes in d in general.
</p>


<h3>Value</h3>

<p>Returns a list that contains break point, estimate of the order of integration in the two regimes (the memory parameter d) and standard deviation of this estimate.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>References</h3>

<p>Leybourne, S., Kim, T., Smith, V., and Newbold, P. (2003): Tests for a change in persistence against the null of difference-stationarity. Econometrics Journal, 6, pp. 291-311.
</p>
<p>Busetti, F. and Taylor, R. (2004): Tests of stationarity against a change in persistence. Journal of Econometrics, 123, pp. 33-66.
</p>
<p>Leybourne, S., Kim, T., and Taylor, R. (2007): Cusum of squares-based tests for a change in persistence. Journal of Time Series Analysis, 28, pp. 408-433.
</p>
<p>Martins, L.. and Rodrigues, P. (2014): Testing for persistence change in fractionally integrated models: An application to world inflation rates Cusum of squares-based tests for a change in persistence. Computational Statistics and Data Analysis, 76, pp. 502-522.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cusum_test">cusum_test</a></code>, <code><a href="#topic+LKSN_test">LKSN_test</a></code>, <code><a href="#topic+MR_test">MR_test</a></code>, <code><a href="#topic+ratio_test">ratio_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate dummy-data
series &lt;- c(rnorm(200), cumsum(rnorm(200)))

# estimate the break point
BP_estim(series, trend="none", type="BT", direction="01", d_estim="ELW")
</code></pre>

<hr>
<h2 id='BT'>function to calculate sequence of test statistics by Busetti and Taylor (2004). For internal use only.</h2><span id='topic+BT'></span>

<h3>Description</h3>

<p>function to calculate sequence of test statistics by Busetti and Taylor (2004). For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BT(x, trend, tau)
</code></pre>

<hr>
<h2 id='cusum'>function to calculate sequence of cusum test statistics by Leybourne, Taylor, and Kim (2006). For internal use only</h2><span id='topic+cusum'></span>

<h3>Description</h3>

<p>function to calculate sequence of cusum test statistics by Leybourne, Taylor, and Kim (2006). For internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cusum(x, trend, m = 0, tau)
</code></pre>

<hr>
<h2 id='CUSUM_simple'>Simple test for change-in-mean under long memory</h2><span id='topic+CUSUM_simple'></span>

<h3>Description</h3>

<p>This function performs a CUSUM test on a change-in-mean that is robust under long memory. It is based on the fractionally differenced series where
the long-memory parameter is estimated by a consistent estimator.
The function returns the test statistic as well as the p-value of the test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CUSUM_simple(x, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CUSUM_simple_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="CUSUM_simple_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the p-value of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): A simple test on structural change in long-memory time series. Economics Letters, 136, pp. 90-94.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CUSUMLM">CUSUMLM</a></code>, <code><a href="#topic+CUSUMfixed">CUSUMfixed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series without a change in mean
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series 
# with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local 
# Whittle approach. The bandwidth to estimate d is chosen 
# as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the test on both time series
CUSUM_simple(tseries, d_est)
CUSUM_simple(tseries2, d_est2)
# For the series with no change in mean the test does not 
# reject the null hypothesis of a constant mean across time 
# at any reasonable significance level.
# For the series with a change in mean the test rejects the 
# null hypothesis at a 5% significance level.
</code></pre>

<hr>
<h2 id='cusum_test'>Cusum-type test against a change in persistence</h2><span id='topic+cusum_test'></span>

<h3>Description</h3>

<p>This function performs a cusum-type test for a change in persistence as suggested by Leybourne, Taylor, and Kim (2006) and extended by Sibbertsen and Kruse (2009).
Under the null hypothesis the time series is nonstationary throughout and under the alternative a change from nonstationary to stationary or vice versa has occured.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cusum_test(x, trend = c("none", "linear"), tau = 0.2, type = c("LKT",
  "SK"), m = 0, simu = 0, M = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cusum_test_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="cusum_test_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="cusum_test_+3A_tau">tau</code></td>
<td>
<p>the function tests in the interval <code>[T*tau,T*(1-tau)]</code> for a break in persistence with T being the length of the time series. It must hold that <code>0&lt;tau&lt;0.5</code>, default is <code>tau=0.2</code> as commonly used in the literature. Note that if <code>T*tau&lt;=1+as.numeric(trend=="linear") + (m&gt;3)*(m-3)</code> the test statistic cannot be calculated.</p>
</td></tr>
<tr><td><code id="cusum_test_+3A_type">type</code></td>
<td>
<p>which type of cusum test should be performed, <code>"LKT"</code> for the cusum test by Leybourne, Taylor, and Kim (2006) and <code>"SK"</code> for the extension by Sibbertsen and Kruse (2009). See details.</p>
</td></tr>
<tr><td><code id="cusum_test_+3A_m">m</code></td>
<td>
<p>Number of covariances used for the estimation of the long run variance. Default is <code>m=0</code>.</p>
</td></tr>
<tr><td><code id="cusum_test_+3A_simu">simu</code></td>
<td>
<p>whether critical values should be simulated or interpolated, <code>simu=1</code> means simulation, <code>simu=0</code> means interpolation based on critical values for <code>tau=0.2</code>. See details. Default is <code>simu=0</code>.</p>
</td></tr>
<tr><td><code id="cusum_test_+3A_m">M</code></td>
<td>
<p>number of replications in case critical values should be simulated. Default is <code>M=10000</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Leybourne, Taylor, and Kim (2006) introduced a cusum-type test that is able to identify when time series
exhibit changes in persistence. Under the null
hypothesis, the series is throughout I(1), i.e. nonstationary. Under the alternative the series exhibits a
break either from I(0) to I(1) or vice versa. Sibbertsen and Kruse (2009) extended the test such that under the null hypothesis
the time series is I(d) throughout, with d&gt;1/2 and under the alternative a change from I(d1) to I(d2), where d1&lt;1/2 and 1/2&lt;d2&lt;3/2, or vice versa has occured.
While the test statistic remains the same, the critical values of the extended test change as they depend on the order of integration.
Furthermore, the procedure by SK integrates the series if d is estimated to be smaller than 1/2. This allows to overcome the problem of the approach by LKT which is that is has a degenerated limiting distribution when the series is stationary.
To determine the order of integration (the memory parameter d) the semiparametric estimator by Geweke and Porter-Hudak (1983) is used.
</p>
<p>The critical values of the tests vary with sample size and d. If <code>simu=0</code>, the critical values provided
are based on linear interpolation of the critical values simulated by Leybourne, Taylor, and Kim (2006) respectively the response curves by Sibbertsen and Kruse (2009).
These are, however, only valid for <code>tau=0.2</code> and <code>m=0</code>. 
In case that non-default values are chosen for <code>tau</code> or <code>m</code>, it is recommended to set <code>simu=1</code> which means that critical values are simulated based on the given data using M replications. 
Caution, for a time series of length <code>T=100</code> and <code>M=10,000</code> replications this takes approximately thirty minutes with increasing duration for higher T or M.  
It should be noted, however, that M smaller than 10,000 make the results unreliable.
</p>


<h3>Value</h3>

<p>Returns a matrix that consists of test statistic and critical values for testing against a change from nonstationary to stationary, stationary to nonstationary, and against a change in an unknown direction.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>References</h3>

<p>Leybourne, S., Kim, T., and Taylor, R. (2007): Cusum of squares-based tests for a change in persistence. Journal of Time Series Analysis, 28, pp. 408-433.
</p>
<p>Sibbertsen, P. and Kruse, R. (2009): Testing for a break in persistence under long-range dependencies. Journal of Time Series Analysis, 30, pp. 263-285.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate dummy-data
series &lt;- c(rnorm(200), cumsum(rnorm(200)))

# test for a break in persistence
cusum_test(series, trend="none", type="SK")
</code></pre>

<hr>
<h2 id='CUSUMfixed'>Self-normalized CUSUM tests for structural change under long memory.</h2><span id='topic+CUSUMfixed'></span>

<h3>Description</h3>

<p>This function performs a family of CUSUM tests for a change-in-mean that are robust under long memory. They apply non-parametric kernel-based
fixed-b and fixed-m long-run variance estimators in the denominator of the test statistics.
The function returns the test statistic as well as critical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CUSUMfixed(x, d, procedure, bandw, tau = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CUSUMfixed_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="CUSUMfixed_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
<tr><td><code id="CUSUMfixed_+3A_procedure">procedure</code></td>
<td>
<p>string that specifies whether the CUSUM fixed-b or fixed-m type A or type B tests are used. It can be chosen between
<code>"CUSUMfixedb_typeA"</code>, <code>"CUSUMfixedb_typeB"</code>, <code>"CUSUMfixedm_typeA"</code>, and <code>"CUSUMfixedm_typeB"</code> (see Wenger, Leschinski (2019) for details).</p>
</td></tr>
<tr><td><code id="CUSUMfixed_+3A_bandw">bandw</code></td>
<td>
<p>integer that determines the bandwidth used for estimation of the long-run variance. For the fixed-b tests <code>b=[0.05,0.1,0.2,0.3,...,0.9,1]</code>, for the
fixed-m tests <code>m=[1,2,3,4,10,25,50,100,150,200]</code>. Recommended bandwidth by Wenger, Leschinski (2019) are <code>b=0.1</code> and <code>m=10</code>.</p>
</td></tr>
<tr><td><code id="CUSUMfixed_+3A_tau">tau</code></td>
<td>
<p>integer that defines the search area, which is <code>[tau,1-tau]</code>. Default is <code>tau=0.15</code> as suggested by Andrews (1993).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the critical values are generated for <code>tau=0.15</code> using the Bartlett kernel for the fixed-b tests or averaging the first m periodogram
ordinates (which corresponds to the Daniell kernel) for the fixed-m tests.
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the corresponding critical values of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Wenger, K. and Leschinski, C. (2019): Change-in-mean tests in long-memory time series: a review of recent developments. AStA Advances in Statistical Analysis, 103:2, pp. 237-256.
</p>
<p>Hualde, J. and Iacone, F. (2017): Fixed bandwidth asymptotics for the studentized mean of fractionally integrated processes. Economics Letters, 150, pp. 39-43.
</p>
<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CUSUMLM">CUSUMLM</a></code>, <code><a href="#topic+CUSUM_simple">CUSUM_simple</a></code>, <code><a href="#topic+fixbsupw">fixbsupw</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series 
# with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local 
# Whittle approach. The bandwidth to estimate d is chosen 
# as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the different types of the test on both time series
CUSUMfixed(tseries, d=d_est, procedure="CUSUMfixedb_typeA", bandw=0.1)
CUSUMfixed(tseries, d=d_est, procedure="CUSUMfixedb_typeB", bandw=0.1)
CUSUMfixed(tseries, d=d_est, procedure="CUSUMfixedm_typeA", bandw=10)
CUSUMfixed(tseries, d=d_est, procedure="CUSUMfixedm_typeB", bandw=10)

CUSUMfixed(tseries2, d=d_est2, procedure="CUSUMfixedb_typeA", bandw=0.1)
CUSUMfixed(tseries2, d=d_est2, procedure="CUSUMfixedb_typeB", bandw=0.1)
CUSUMfixed(tseries2, d=d_est2, procedure="CUSUMfixedm_typeA", bandw=10)
CUSUMfixed(tseries2, d=d_est2, procedure="CUSUMfixedm_typeB", bandw=10)
# For the series with no change in mean all tests do not reject 
# the null hypothesis of a constant mean across time at 
# any reasonable significance level.
# For the series with a change in mean all tests reject the 
# null hypothesis at a 1% significance level.
</code></pre>

<hr>
<h2 id='CUSUMLM'>CUSUM long memory test for a single change in the mean of a long-memory time series.</h2><span id='topic+CUSUMLM'></span>

<h3>Description</h3>

<p>This function performs a modified CUSUM test for a change-in-mean that is robust under long memory. It replaces the standardization
as well as the long-run variance estimator compared to the standard CUSUM test.
The function returns the test statistic as well as critical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CUSUMLM(x, d, delta, tau = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CUSUMLM_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="CUSUMLM_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
<tr><td><code id="CUSUMLM_+3A_delta">delta</code></td>
<td>
<p>integer that determines the bandwidth that is used to estimate the constant <code>G</code> that approximates the short run dynamics of the time series at the origin.
The same bandwidth should be used that is applied to estimate <code>d</code> before. See Wenger, Leschinski, Sibbertsen (2018) for details.</p>
</td></tr>
<tr><td><code id="CUSUMLM_+3A_tau">tau</code></td>
<td>
<p>integer that defines the search area, which is <code>[tau,1-tau]</code>. Default is <code>tau=0.15</code> as suggested by Andrews (1993).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the critical values are generated for <code>tau=0.15</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the corresponding critical values of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): Change-in-mean tests in long-memory time series: a review of recent developments. AStA Advances in Statistical Analysis, 103:2, pp. 237-256.
</p>
<p>Wang, L. (2008): Change-in-mean problem for long memory time series models with applications. Journal of Statistical Computation and Simulation, 78:7, pp. 653-668.
</p>
<p>Horvath, L. and Kokoszka, P. (1997): The effect of long-range dependence on change-point estimators. Journal of Statistical Planung and Inference, 64, pp. 57-81.
</p>
<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CUSUMfixed">CUSUMfixed</a></code>, <code><a href="#topic+CUSUM_simple">CUSUM_simple</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series 
# with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local 
# Whittle approach. The bandwidth to estimate d is chosen 
# as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the test on both time series
CUSUMLM(tseries, delta=0.65, d=d_est)
CUSUMLM(tseries2, delta=0.65, d=d_est2)
# For the series with no change in mean the test does not 
# reject the null hypothesis of a constant mean across time 
# at any reasonable significance level.
# For the series with a change in mean the test rejects the 
# null hypothesis at a 1% significance level.
</code></pre>

<hr>
<h2 id='CV'>function to generate critical values. For internal use only.</h2><span id='topic+CV'></span>

<h3>Description</h3>

<p>function to generate critical values. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV(x, statistic, trend, type, m = 0, M, d = 0, tau, serial = FALSE,
  lmax = 0)
</code></pre>

<hr>
<h2 id='d_vec'>function to extract critical values. For internal use only.</h2><span id='topic+d_vec'></span>

<h3>Description</h3>

<p>function to extract critical values. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d_vec
</code></pre>


<h3>Format</h3>

<p>An object of class <code>numeric</code> of length 11.</p>

<hr>
<h2 id='ers_test'>Unit root test by Elliot et al. (1996). For internal use only</h2><span id='topic+ers_test'></span>

<h3>Description</h3>

<p>Unit root test by Elliot et al. (1996). For internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ers_test(y, trend, lag.max, T)
</code></pre>

<hr>
<h2 id='fb_longrun'>function to estimate the fixed-b long-run variance. For internal use only.</h2><span id='topic+fb_longrun'></span>

<h3>Description</h3>

<p>function to estimate the fixed-b long-run variance. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fb_longrun(tseries, m, type = "Bartlett")
</code></pre>

<hr>
<h2 id='fixbsupw'>Fixed-b sup Wald test for a single change in the mean of a long-memory time series.</h2><span id='topic+fixbsupw'></span>

<h3>Description</h3>

<p>This function performs a sup-Wald test on a change-in-mean, which is standardized by a non-parametric kernel-based long-run variance estimator.
Therefore, the test is robust under long-memory.
The function returns the test statistic as well as critical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixbsupw(x, d, bandw = 0.1, tau = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixbsupw_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="fixbsupw_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
<tr><td><code id="fixbsupw_+3A_bandw">bandw</code></td>
<td>
<p>integer that determines the bandwidth parameter for the long-run variance estimator. It can take values in the range <code>bandw=[0.05,0.1,0.2]</code>. Default is
<code>bandw=0.1</code>, which is suggested by Iacone, Leybourne and Taylor (2014).</p>
</td></tr>
<tr><td><code id="fixbsupw_+3A_tau">tau</code></td>
<td>
<p>integer that defines the search area, which is <code>[tau,1-tau]</code>. Default is <code>tau=0.15</code> as suggested by Andrews (1993).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the critical values are generated for <code>tau=0.15</code> using the Bartlett kernel.
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the corresponding critical values of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Iacone, F. and Leybourne, S. J. and Taylor, R. A. M. (2014): A fixed-b Test for a Break in Level at an unknown Time under Fractional Integration. Journal of Time Series Analysis, 35, pp. 40-54.
</p>
<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CUSUMfixed">CUSUMfixed</a></code>, <code><a href="#topic+snsupwald">snsupwald</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series
#  with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local 
# Whittle approach. The bandwidth to estimate d is chosen 
# as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the test on both time series
fixbsupw(tseries, d=d_est)
fixbsupw(tseries2, d=d_est2)
# For the series with no change in mean the test does not reject 
# the null hypothesis of a constant mean across time at any 
# reasonable significance level.
# For the series with a change in mean the test rejects the 
# null hypothesis at a 1% significance level.
</code></pre>

<hr>
<h2 id='getCV'>function to extract critical values. For internal use only.</h2><span id='topic+getCV'></span>

<h3>Description</h3>

<p>function to extract critical values. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCV()
</code></pre>

<hr>
<h2 id='HLT'>function to calculate unit root test to adjust test statistic as suggested by Harvey, Leybourne, and Taylor (2006).</h2><span id='topic+HLT'></span>

<h3>Description</h3>

<p>function to calculate unit root test to adjust test statistic as suggested by Harvey, Leybourne, and Taylor (2006).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLT(x, trend, z)
</code></pre>

<hr>
<h2 id='HLTmin'>function to calculate sequence of minimum test statistics by Harvey, Leybourne, and Taylor (2006). For internal use only</h2><span id='topic+HLTmin'></span>

<h3>Description</h3>

<p>function to calculate sequence of minimum test statistics by Harvey, Leybourne, and Taylor (2006). For internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLTmin(x, trend, z, tau)
</code></pre>

<hr>
<h2 id='LBI'>function to calculate sequence of LBI test statistics by Busetti and Taylor (2004). For internal use only.</h2><span id='topic+LBI'></span>

<h3>Description</h3>

<p>function to calculate sequence of LBI test statistics by Busetti and Taylor (2004). For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LBI(x, trend, tau)
</code></pre>

<hr>
<h2 id='LBI_test'>Locally best invariant test against a change in persistence</h2><span id='topic+LBI_test'></span>

<h3>Description</h3>

<p>This function performs the locally best invariant test against a change in persistence as suggested by Busetti and Taylor (2004). Under the null hypothesis the time series is I(0) throughout and
under the alternative a change from either I(1) to I(0) or I(0) to I(1) has occured.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LBI_test(x, trend = c("none", "linear"), tau = 0.2,
  statistic = c("mean", "max", "exp"), simu = 0, M = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LBI_test_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="LBI_test_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="LBI_test_+3A_tau">tau</code></td>
<td>
<p>the function tests in the interval <code>[T*tau,T*(1-tau)]</code> for a break in persistence with T being the length of the time series. It must hold that <code>0&lt;tau&lt;0.5</code>, default is <code>tau=0.2</code> as commonly used in the literature. Note that if <code>T*tau&lt;=1+as.numeric(trend=="linear")</code> the test statistic cannot be calculated.</p>
</td></tr>
<tr><td><code id="LBI_test_+3A_statistic">statistic</code></td>
<td>
<p>which type of test statistic should be used, <code>"mean"</code> corresponds to Hansen's (1991) mean score, <code>"max"</code> to Andrews' (1993) maximum statistic, and <code>"exp"</code> to Andrews and Ploberger's (1994) mean-exponential statistic.</p>
</td></tr>
<tr><td><code id="LBI_test_+3A_simu">simu</code></td>
<td>
<p>whether critical values should be simulated or interpolated, <code>simu=1</code> means simulation, <code>simu=0</code> means interpolation. See details. Default is <code>simu=0</code>.</p>
</td></tr>
<tr><td><code id="LBI_test_+3A_m">M</code></td>
<td>
<p>number of replications in case critical values should be simulated. Default is <code>M=10000</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The critical values of the tests vary with the sample size. If <code>simu=0</code>, the critical values provided
are based on linear interpolation of the critical values simulated by Busetti and Taylor (2004). These are, however, only valid for <code>tau=0.2</code>. 
In case that another value is chosen for <code>tau</code>, it is recommended to set <code>simu=1</code> which means that critical values are simulated based on the given data using M replications.
For a time series of length <code>T=100</code> and <code>M=10,000</code> replications this takes approximately five minutes with increasing duration for higher T or M.  
It should be noted, however, that M smaller than 10,000 make the results unreliable.
</p>


<h3>Value</h3>

<p>Returns a matrix that consists of test statistic and critical values (corresponding to <code>alpha=0.1,0.05,0.01</code>) for testing against a change from I(1) to I(0), I(0) to I(1), and against a change in an unknown direction.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>References</h3>

<p>Busetti, F. and Taylor, R. (2004): Tests of stationarity against a change in persistence. Journal of Econometrics, 123, pp. 33-66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cusum_test">cusum_test</a></code>, <code><a href="#topic+LKSN_test">LKSN_test</a></code>, <code><a href="#topic+MR_test">MR_test</a></code>, <code><a href="#topic+ratio_test">ratio_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate dummy-data
series &lt;- c(rnorm(100), cumsum(rnorm(100)))

# test for a break in persistence
LBI_test(series, trend="none", statistic="mean")
</code></pre>

<hr>
<h2 id='LKSN'>function to calculate sequence of LKSN test statistics. For internal use only</h2><span id='topic+LKSN'></span>

<h3>Description</h3>

<p>function to calculate sequence of LKSN test statistics. For internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LKSN(x, trend, tau, lmax)
</code></pre>

<hr>
<h2 id='LKSN_test'>DF-type test against a change in persistence</h2><span id='topic+LKSN_test'></span>

<h3>Description</h3>

<p>This function performs the DF-type test against a change in persistence as suggested by Leybourne, Kim, Smith, and Newbold (2003). Under the null hypothesis the time series is I(1) throughout and
under the alternative a change from either I(1) to I(0) or I(0) to I(1) has occured.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LKSN_test(x, trend = c("none", "linear"), tau = 0.2, lmax = 0,
  simu = 0, M = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LKSN_test_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="LKSN_test_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="LKSN_test_+3A_tau">tau</code></td>
<td>
<p>the function tests in the interval <code>[T*tau,T*(1-tau)]</code> for a break in persistence with T being the length of the time series. It must hold that <code>0&lt;tau&lt;0.5</code>, default is <code>tau=0.2</code> as commonly used in the literature. Note that if <code>T*tau&lt;11</code> the test statistic cannot be calculated.</p>
</td></tr>
<tr><td><code id="LKSN_test_+3A_lmax">lmax</code></td>
<td>
<p>Maximum number of lagged differences to be included in the test regression. Default is <code>lmax=0</code>. Note that small sample critical values might differ for <code>lmax&gt;0</code> so that simulation is recommended in this case.</p>
</td></tr>
<tr><td><code id="LKSN_test_+3A_simu">simu</code></td>
<td>
<p>whether critical values should be simulated or interpolated, <code>simu=1</code> means simulation, <code>simu=0</code> means interpolation. See details. Default is <code>simu=0</code>.</p>
</td></tr>
<tr><td><code id="LKSN_test_+3A_m">M</code></td>
<td>
<p>number of replications in case critical values are simulated. Default is <code>M=10000</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The critical values of the tests vary with the sample size. If <code>simu=0</code>, the critical values provided
are based on linear interpolation of the critical values simulated by Leybourne, Kim, Smith, and Newbold (2003). These are, however, only valid for <code>tau=0.2</code> and <code>lmax=0</code>. 
In case that non-default values are chosen for <code>tau</code> or <code>lmax</code>, it is recommended to set <code>simu=1</code> which means that critical values are simulated based on the given data using M replications. 
Caution, for a time series of length <code>T=100</code> and <code>M=10,000</code> replications this takes approximately thirty minutes with increasing duration for higher T or M.  
It should be noted, however, that M smaller than 10,000 make the results unreliable.
</p>


<h3>Value</h3>

<p>Returns a matrix that consists of test statistic and critical values (corresponding to <code>alpha=0.1,0.05</code>) for testing against a change from I(1) to I(0), I(0) to I(1), and against a change in an unknown direction.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>References</h3>

<p>Leybourne, S., Kim, T., Smith, V., and Newbold, P. (2003): Tests for a change in persistence against the null of difference-stationarity. Econometrics Journal, 6, pp. 291-311.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cusum_test">cusum_test</a></code>, <code><a href="#topic+LBI_test">LBI_test</a></code>, <code><a href="#topic+MR_test">MR_test</a></code>, <code><a href="#topic+ratio_test">ratio_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate dummy-data
series &lt;- c(rnorm(200), cumsum(rnorm(200)))

# test for a break in persistence
LKSN_test(series, trend="none")
</code></pre>

<hr>
<h2 id='LT'>function to calculate sequence of test statistics by Leybourne and Taylor (2004). For internal use only.</h2><span id='topic+LT'></span>

<h3>Description</h3>

<p>function to calculate sequence of test statistics by Leybourne and Taylor (2004). For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LT(x, trend, m, tau)
</code></pre>

<hr>
<h2 id='memochange'>memochange: Testing for Structural Breaks under Long Memory and Testing for Changes in Persistence</h2><span id='topic+memochange'></span><span id='topic+memochange-package'></span>

<h3>Description</h3>

<p>Test procedures and break point estimators for persistent processes that exhibit structural breaks in mean or in persistence.<br /> <br /> 
On the one hand, the package contains the most popular approaches for testing whether a time series exhibits a break in persistence from I(0) to I(1) or vice versa, such as those of Busetti and Taylor (2004) and Leybourne, Kim, and Taylor (2007).
The approach by Martins and Rodrigues (2014), which allows to detect changes from I(d1) to I(d2) with d1 and d2 being non-integers, is included as well.<br />
In case the tests reject the null of constant persistence, various breakpoint estimators are available to detect the point of the break as well as the order of integration in the two regimes.<br /> <br />
On the other hand, the package contains the most popular approaches to test for a change in mean in a long-memory time series, which were recently reviewed by Wenger, Leschinski, and Sibbertsen (2018). 
These include memory robust versions of the CUSUM, sup-Wald, and Wilcoxon type tests. The tests either utilize consistent estimates of the long-run variance or a self normalization approach in their test statistics.
</p>


<h3>Details</h3>

<p>For details see the readme and vignettes in the corresponding GitHub repository (https://github.com/KaiWenger/memochange).
</p>


<h3>Author(s)</h3>

<p>Kai Wenger &lt;Kai.Wenger@gmx.de&gt;, Janis Becker
</p>


<h3>References</h3>

<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>
<p>Betken, A. (2016): Testing for change-points in long-range dependent time series by means of a self-normalized wilcoxon test. Journal of Time Series Analysis, 37, pp. 785-908.
</p>
<p>Busetti, F. and Taylor, R. (2004): Tests of stationarity against a change in persistence. Journal of Econometrics, 123, pp. 33-66.
</p>
<p>Dehling, H. and Rooch, A. and Taqqu, M. S. (2012): Non-Parametric Change-Point Tests for Long-Range Dependent Data. Scandinavian Journal of Statistics, 40, pp. 153-173.
</p>
<p>Harvey, D., Leybourne, S. and Taylor, R. (2006): Modified tests for a change in persistence. Journal of Econometrics, 134, pp. 441-469.
</p>
<p>Horvath, L. and Kokoszka, P. (1997): The effect of long-range dependence on change-point estimators. Journal of Statistical Planung and Inference, 64, pp. 57-81.
</p>
<p>Hualde, J. and Iacone, F. (2017): Fixed bandwidth asymptotics for the studentized mean of fractionally integrated processes. Economics Letters, 150, pp. 39-43.
</p>
<p>Iacone, F. and Leybourne, S. J. and Taylor, R. A. M. (2014): A fixed-b Test for a Break in Level at an unknown Time under Fractional Integration. Journal of Time Series Analysis, 35, pp. 40-54.
</p>
<p>Leybourne, S., Kim, T., Smith, V., and Newbold, P. (2003): Tests for a change in persistence against the null of difference-stationarity. Econometrics Journal, 6, pp. 291-311.
</p>
<p>Leybourne, S. and Taylor, R. (2004): On tests for changes in persistence. Economics letters, 84, pp. 107-115.
</p>
<p>Leybourne, S., Kim, T., and Taylor, R. (2007): Cusum of squares-based tests for a change in persistence. Journal of Time Series Analysis, 28, pp. 408-433.
</p>
<p>Martins, L.. and Rodrigues, P. (2014): Testing for persistence change in fractionally integrated models: An application to world inflation rates Cusum of squares-based tests for a change in persistence. Computational Statistics and Data Analysis, 76, pp. 502-522.
</p>
<p>Shao, X. (2011): A simple test of changes in mean in the possible presence of long-range dependence. Journal of Time Series Analysis, 32, pp. 598-606.
</p>
<p>Sibbertsen, P. and Kruse, R. (2009): Testing for a break in persistence under long-range dependencies. Journal of Time Series Analysis, 30, pp. 263-285.
</p>
<p>Wang, L. (2008): Change-in-mean problem for long memory time series models with applications. Journal of Statistical Computation and Simulation, 78:7, pp. 653-668.
</p>
<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): Change-in-mean tests in long-memory time series: a review of recent developments. AStA Advances in Statistical Analysis, 103:2, pp. 237-256.
</p>
<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): A simple test on structural change in long-memory time series. Economics Letters, 136, pp. 90-94.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BP_estim">BP_estim</a></code>, <code><a href="#topic+CUSUM_simple">CUSUM_simple</a></code>,
<code><a href="#topic+cusum_test">cusum_test</a></code>, <code><a href="#topic+CUSUMfixed">CUSUMfixed</a></code>, <code><a href="#topic+CUSUMLM">CUSUMLM</a></code>,
<code><a href="#topic+fixbsupw">fixbsupw</a></code>, <code><a href="#topic+LBI_test">LBI_test</a></code>, <code><a href="#topic+LKSN_test">LKSN_test</a></code>, <code><a href="#topic+MR_test">MR_test</a></code>,
<code><a href="#topic+pb_sim">pb_sim</a></code>, <code><a href="#topic+ratio_test">ratio_test</a></code>, <code><a href="#topic+snsupwald">snsupwald</a></code>,
<code><a href="#topic+snwilcoxon">snwilcoxon</a></code>, <code><a href="#topic+wilcoxonLM">wilcoxonLM</a></code>
</p>

<hr>
<h2 id='MR'>function to calculate sequence of test statistics by Martins and Rodrigues (2014). For internal use only</h2><span id='topic+MR'></span>

<h3>Description</h3>

<p>function to calculate sequence of test statistics by Martins and Rodrigues (2014). For internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MR(x, trend, serial, tau)
</code></pre>

<hr>
<h2 id='MR_test'>LM test against a change in persistence</h2><span id='topic+MR_test'></span>

<h3>Description</h3>

<p>This function performs a LM-type test for a change in persistence as suggested by Martins and Rodrigues (2014).
Under the null hypothesis the memory parameter d is constant over the sample. Under the alternative
an increase or a decrease of the memory parameter has occured over time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MR_test(x, trend = c("none", "linear"), tau = 0.2,
  statistic = c("squared", "standard"), simu = 0, M = 10000,
  serial = c(FALSE, TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MR_test_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="MR_test_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="MR_test_+3A_tau">tau</code></td>
<td>
<p>the function tests in the interval <code>[T*tau,T*(1-tau)]</code> for a break in persistence with T being the length of the time series. It must hold that <code>0&lt;tau&lt;0.5</code>, default is <code>tau=0.2</code> as commonly used in the literature. Note that if <code>T*tau&lt;=2</code> the test statistic cannot be calculated.</p>
</td></tr>
<tr><td><code id="MR_test_+3A_statistic">statistic</code></td>
<td>
<p>which type of test statistic should be used, <code>"squared"</code> for the squared t-statistic and <code>"standard"</code> for the standard t-test. Default is <code>statistic="squared"</code>.</p>
</td></tr>
<tr><td><code id="MR_test_+3A_simu">simu</code></td>
<td>
<p>whether critical values should be simulated or interpolated, <code>simu=1</code> means simulation, <code>simu=0</code> means interpolation. See details. Default is <code>simu=0</code>.</p>
</td></tr>
<tr><td><code id="MR_test_+3A_m">M</code></td>
<td>
<p>number of replications in case critical values should be simulated. Default is <code>M=10000</code>.</p>
</td></tr>
<tr><td><code id="MR_test_+3A_serial">serial</code></td>
<td>
<p>boolean, indicating whether to account for serial correlation of the errors. Default is <code>serial=FALSE</code> implying no correction for serial correlation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The critical values of the tests vary with sample size and memory parameter d. If <code>simu=0</code>, the critical values provided
are based on linear interpolation of the critical values simulated by Martins and Rodrigues (2014). These are, however, only valid for <code>tau=0.2</code> and <code>serial=FALSE</code>. 
In case that non-default values are chosen for <code>tau</code> or <code>serial</code>, it is recommended to set <code>simu=1</code> which means that critical values are simulated based on the given data using M replications. 
Caution, for a time series of length <code>T=750</code> and <code>M=10,000</code> replications this takes approximately twelve hours with increasing duration for higher T or M.  
It should be noted, however, that M smaller than 10,000 make the results unreliable.
</p>


<h3>Value</h3>

<p>Returns a matrix that consists of test statistic and critical values (corresponding to <code>alpha=0.1,0.05,0.01</code>) for testing against an increase in memory, against a decrease in memory, and against a change in an unknown direction.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>References</h3>

<p>Martins, L.. and Rodrigues, P. (2014): Testing for persistence change in fractionally integrated models: An application to world inflation rates. Computational Statistics and Data Analysis, 76, pp. 502-522.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cusum_test">cusum_test</a></code>, <code><a href="#topic+LBI_test">LBI_test</a></code>, <code><a href="#topic+LKSN_test">LKSN_test</a></code>, <code><a href="#topic+ratio_test">ratio_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate dummy-data
series &lt;- c(rnorm(200), cumsum(rnorm(200)))

# test for a break in persistence
MR_test(series, trend="none", statistic="squared")
</code></pre>

<hr>
<h2 id='pb_sim'>Simulates persistence-break process</h2><span id='topic+pb_sim'></span>

<h3>Description</h3>

<p>This function simulates a fractional white noise process that exhibits a break in persistence using <code>FI.sim</code> from the <code>LongMemoryTS</code> package. In the first part of the series the noise is integrated with order <code>d_1</code> and in the second part with order <code>d_2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pb_sim(T, tau, trend = c("none", "linear"), tp = 0, d1, d2, mean = 0,
  var = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pb_sim_+3A_t">T</code></td>
<td>
<p>length of the time series.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_tau">tau</code></td>
<td>
<p>break fraction, <code>T*tau</code> yields the break point. It needs to hold that <code>0&lt;tau&lt;1</code>.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_tp">tp</code></td>
<td>
<p>trend parameter, <code>t*tp</code> yields the contribution of the trend component if <code>trend="linear"</code>.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_d1">d1</code></td>
<td>
<p>order of integration of the first part of the series.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_d2">d2</code></td>
<td>
<p>order of integration of the second part of the series.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_mean">mean</code></td>
<td>
<p>mean of the series. Default is <code>mean=0</code>.</p>
</td></tr>
<tr><td><code id="pb_sim_+3A_var">var</code></td>
<td>
<p>variance of the innovations. Default is <code>var=1</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector containing the simulated time series.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate persistence-break time series
series &lt;- pb_sim(500, 0.5, "none", d1=0.2, d2=0.8, mean=0, var=1)

# plot generated series
stats::ts.plot(series)
</code></pre>

<hr>
<h2 id='ratio_test'>Ratio-based test against a change in persistence</h2><span id='topic+ratio_test'></span>

<h3>Description</h3>

<p>This function performs a ratio-based test against a change in persistence. Under the null hypothesis the time series is I(0) throughout and
under the alternative a change from either I(1) to I(0) or I(0) to I(1) has occured.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratio_test(x, trend = c("none", "linear"), tau = 0.2,
  statistic = c("mean", "max", "exp"), type = c("BT", "LT", "HLT",
  "HLTmin"), m = 0, z = 9, simu = 0, M = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ratio_test_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_trend">trend</code></td>
<td>
<p>whether the time series exhibits a trend, <code>"none"</code> implies no trend and <code>"linear"</code> implies a linear trend.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_tau">tau</code></td>
<td>
<p>the function tests in the interval <code>[T*tau,T*(1-tau)]</code> for a break in persistence with T being the length of the time series. It must hold that <code>0&lt;tau&lt;0.5</code>, default is <code>tau=0.2</code> as commonly used in the literature. Note that if <code>type="BT"</code> or <code>type="HLT"</code> and <code>T*tau&lt;= 1 + as.numeric(trend=="linear")</code>, <code>type="LT"</code> and <code>T*tau&lt;=1+ as.numeric(trend=="linear") + (m&gt;3)*(m-3)</code>, or <code>type="HLT"</code> and <code>T*tau&lt;=(z+1)</code> the test statistic cannot be calculated.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_statistic">statistic</code></td>
<td>
<p>which type of test statistic should be used, <code>"mean"</code> corresponds to Hansen's (1991) mean score, <code>"max"</code> to Andrews' (1993) maximum statistic, and <code>"exp"</code> to Andrews and Ploberger's (1994) mean-exponential statistic</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_type">type</code></td>
<td>
<p>which type of ratio test should be performed, <code>"BT"</code> for the standard ratio test by Busetti and Taylor (2004), <code>"LT"</code> for the modified ratio test by Leybourne and Taylor (2004), and <code>"HLT"</code>&quot; respectively <code>"HLTmin"</code> are the modified tests by Harvey, Leybourne, and Taylor (2006). See details.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_m">m</code></td>
<td>
<p>Number of covariances used for the estimation of the long run variance if <code>statistic=LT</code> is used. Default is <code>m=0</code>.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_z">z</code></td>
<td>
<p>Number of polynomials used if <code>"HLT"</code> or <code>"HLTmin"</code> are considered. Default is <code>z=9</code>.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_simu">simu</code></td>
<td>
<p>whether critical values should be simulated or interpolated, <code>simu=1</code> means simulation, <code>simu=0</code> means interpolation based on critical values for <code>tau=0.2</code>. See details. Default is <code>simu=0</code>.</p>
</td></tr>
<tr><td><code id="ratio_test_+3A_m">M</code></td>
<td>
<p>number of replications in case critical values should be simulated. Default is <code>M=10000</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Busetti and Taylor (2004) (BT) introduced a test that is able to identify when time series
exhibit changes in persistence. Under the null
hypothesis, the series is constant I(0), i.e. stationary. Under the alternative the series exhibits a
break either from I(0) to I(1) or I(1) to I(0). As the test is oversized for weakly dependent time series,
Leybourne and Taylor (2004) (LT) standardized the test statistic by an estimate of the long run variance using m lags.
Another problem is that constant I(1) processes are neither covered under the null nor the alternative.
Here, the test often rejects the null although no change in persistence occured.
Harvey, Leybourne, and Taylor (2006) (HLT) introduced a modification where they multiply the test statistic by
a unit root test. This allows the test statistic to have the same critical values under both constant I(0) and constant I(1).
It should be noted, however, that only the critical values are identical, the distribution is highly irregular.
</p>
<p>The critical values of the tests vary with the sample size. If <code>simu=0</code>, the critical values provided
are based on linear interpolation of the critical values simulated by Harvey, Leybourne, and Taylor (2006). These are, however, only valid for <code>tau=0.2</code>, <code>m=0</code>, and <code>z=9</code>. 
In case that non-default values are chosen for <code>tau</code>, <code>m</code>, or <code>z</code>, it is recommended to set <code>simu=1</code> which means that critical values are simulated based on the given data using M replications. 
Caution, for a time series of length <code>T=100</code> and <code>M=10,000</code> replications this takes approximately fifteen minutes with increasing duration for higher T or M.  
It should be noted, however, that M smaller than 10,000 make the results unreliable.
</p>


<h3>Value</h3>

<p>Returns a matrix that consists of test statistic and critical values (corresponding to <code>alpha=0.1,0.05,0.01</code>) for testing against a change from I(1) to I(0), I(0) to I(1), and against a change in an unknown direction.
</p>


<h3>Author(s)</h3>

<p>Janis Becker
</p>


<h3>References</h3>

<p>Busetti, F. and Taylor, R. (2004): Tests of stationarity against a change in persistence. Journal of Econometrics, 123, pp. 33-66.
</p>
<p>Leybourne, S. and Taylor, R. (2004): On tests for changes in persistence. Economics letters, 84, pp. 107-115.
</p>
<p>Harvey, D., Leybourne, S. and Taylor, R. (2006): Modified tests for a change in persistence. Journal of Econometrics, 134, pp. 441-469.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cusum_test">cusum_test</a></code>, <code><a href="#topic+LBI_test">LBI_test</a></code>, <code><a href="#topic+LKSN_test">LKSN_test</a></code>, <code><a href="#topic+MR_test">MR_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(410)

# generate dummy-data
series &lt;- c(rnorm(100), cumsum(rnorm(100))) 

# test for a break in persistence
ratio_test(series)
</code></pre>

<hr>
<h2 id='snsupwald'>Self-normalized sup Wald test for a single change in the mean of a long-memory time series.</h2><span id='topic+snsupwald'></span>

<h3>Description</h3>

<p>This function performs a sup Wald test for a change-in-mean that is robust under long memory. In contrast to a standard sup Wald test
it applies a self-normalization approach to estimate the long-run variance.
The function returns the test statistic as well as critical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snsupwald(x, d, tau = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snsupwald_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="snsupwald_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
<tr><td><code id="snsupwald_+3A_tau">tau</code></td>
<td>
<p>integer that defines the search area, which is <code>[tau,1-tau]</code>. Default is <code>tau=0.15</code> as suggested by Andrews (1993).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the critical values are generated for <code>tau=0.15</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the corresponding critical values of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): Change-in-mean tests in long-memory time series: a review of recent developments. AStA Advances in Statistical Analysis, 103:2, pp. 237-256.
</p>
<p>Shao, X. (2011): A simple test of changes in mean in the possible presence of long-range dependence. Journal of Time Series Analysis, 32, pp. 598-606.
</p>
<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fixbsupw">fixbsupw</a></code>, <code><a href="#topic+snwilcoxon">snwilcoxon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series 
# with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local 
# Whittle approach. The bandwidth to estimate d is chosen 
# as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the test on both time series
snsupwald(tseries, d=d_est)
snsupwald(tseries2, d=d_est2)
# For the series with no change in mean the test does not reject the 
# null hypothesis of a constant mean across time at any reasonable 
# significance level.
# For the series with a change in mean the test rejects the null hypothesis 
# at a 1% significance level.
</code></pre>

<hr>
<h2 id='snwilcoxon'>Self-normalized Wilcoxon test for a single change in the mean of a long-memory time series.</h2><span id='topic+snwilcoxon'></span>

<h3>Description</h3>

<p>This function performs a Wilcoxon test for a change-in-mean that is robust under long memory. In contrast to a standard Wilcoxon test
it applies a self-normalization approach to estimate the long-run variance.
The function returns the test statistic as well as critical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snwilcoxon(x, d, tau = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snwilcoxon_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="snwilcoxon_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
<tr><td><code id="snwilcoxon_+3A_tau">tau</code></td>
<td>
<p>integer that defines the search area, which is <code>[tau,1-tau]</code>. Default is <code>tau=0.15</code> as suggested by Andrews (1993).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the critical values are generated for <code>tau=0.15</code>. Furthermore, it is assumed that we have a 1st-order Hermite process. For details see Betken (2016).
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the corresponding critical values of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): Change-in-mean tests in long-memory time series: a review of recent developments. AStA Advances in Statistical Analysis, 103:2, pp. 237-256.
</p>
<p>Betken, A. (2016): Testing for change-points in long-range dependent time series by means of a self-normalized wilcoxon test. Journal of Time Series Analysis, 37, pp. 785-908.
</p>
<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wilcoxonLM">wilcoxonLM</a></code>, <code><a href="#topic+snsupwald">snsupwald</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series 
# with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local Whittle approach.
# The bandwidth to estimate d is chosen as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the test on both time series
snwilcoxon(tseries, d=d_est)
snwilcoxon(tseries2, d=d_est2)
# For the series with no change in mean the test does not reject the null hypothesis 
# of a constant mean across time at any reasonable significance level.
# For the series with a change in mean the test rejects the null hypothesis 
# at a 1% significance level.
</code></pre>

<hr>
<h2 id='wald_test'>function to calculate wald_test. For internal use only</h2><span id='topic+wald_test'></span>

<h3>Description</h3>

<p>function to calculate wald_test. For internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wald_test(Sigma, b, Terms)
</code></pre>

<hr>
<h2 id='wilcoxonLM'>Wilcoxon long memory test for a single change in the mean of a long-memory time series.</h2><span id='topic+wilcoxonLM'></span>

<h3>Description</h3>

<p>This function performs a Wilcoxon type test for a change-in-mean that is robust under long memory. It applies a consistent estimator of the
long-run variance under long memory and uses a different normalization compared to a standard Wilcoxon test.
The function returns the test statistic as well as critical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wilcoxonLM(x, d, tau = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wilcoxonLM_+3A_x">x</code></td>
<td>
<p>the univariate numeric vector to be investigated. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="wilcoxonLM_+3A_d">d</code></td>
<td>
<p>integer that specifies the long-memory parameter.</p>
</td></tr>
<tr><td><code id="wilcoxonLM_+3A_tau">tau</code></td>
<td>
<p>integer that defines the search area, which is <code>[tau,1-tau]</code>. Default is <code>tau=0.15</code> as suggested by Andrews (1993).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the critical values are generated for <code>tau=0.15</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing the test statistic and the corresponding critical values of the test.
</p>


<h3>Author(s)</h3>

<p>Kai Wenger
</p>


<h3>References</h3>

<p>Wenger, K. and Leschinski, C. and Sibbertsen, P. (2018): Change-in-mean tests in long-memory time series: a review of recent developments. AStA Advances in Statistical Analysis, 103:2, pp. 237-256.
</p>
<p>Dehling, H. and Rooch, A. and Taqqu, M. S. (2012): Non-Parametric Change-Point Tests for Long-Range Dependent Data. Scandinavian Journal of Statistics, 40, pp. 153-173.
</p>
<p>Andrews, D. W. K. (1993): Tests for Parameter Instability and Structural Change With Unknown Change Point. Econometrica, 61, pp. 821-856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+snwilcoxon">snwilcoxon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set model parameters
T        &lt;- 500
d        &lt;- 0.2

set.seed(410)

# generate a fractionally integrated (long-memory) time series
tseries  &lt;- fracdiff::fracdiff.sim(n=T, d=d)$series

# generate a fractionally integrated (long-memory) time series 
# with a change in mean in the middle of the series
changep  &lt;- c(rep(0,T/2), rep(1,T/2))
tseries2 &lt;- tseries+changep

# estimate the long-memory parameter of both series via local Whittle approach.
# The bandwidth to estimate d is chosen as T^0.65, which is usual in literature
d_est    &lt;- LongMemoryTS::local.W(tseries, m=floor(1+T^0.65))$d
d_est2   &lt;- LongMemoryTS::local.W(tseries2, m=floor(1+T^0.65))$d

# perform the test on both time series
wilcoxonLM(tseries, d=d_est)
wilcoxonLM(tseries2, d=d_est2)
# For the series with no change in mean the test does not reject the null hypothesis
# of a constant mean across time at any reasonable significance level.
# For the series with a change in mean the test rejects the null hypothesis 
# at a 5% significance level.
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
