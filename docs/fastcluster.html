<!DOCTYPE html><html><head><title>Help for package fastcluster</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fastcluster}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fastcluster'><p>Fast hierarchical, agglomerative clustering routines for R and Python</p></a></li>
<li><a href='#hclust'><p>Fast hierarchical, agglomerative clustering of dissimilarity data</p></a></li>
<li><a href='#hclust.vector'><p>Fast hierarchical, agglomerative clustering of vector data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-22</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Hierarchical Clustering Routines for R and 'Python'</td>
</tr>
<tr>
<td>Copyright:</td>
<td>Until package version 1.1.23: © 2011 Daniel Müllner
&lt;https://danifold.net&gt;. All changes from version 1.1.24 on: ©
Google Inc. &lt;https://www.google.com&gt;.</td>
</tr>
<tr>
<td>Enhances:</td>
<td>stats, flashClust</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>This is a two-in-one package which provides interfaces to
        both R and 'Python'. It implements fast hierarchical, agglomerative
        clustering routines. Part of the functionality is designed as drop-in
        replacement for existing routines: linkage() in the 'SciPy' package
        'scipy.cluster.hierarchy', hclust() in R's 'stats' package, and the
        'flashClust' package. It provides the same functionality with the
        benefit of a much faster implementation. Moreover, there are
        memory-saving routines for clustering of vector data, which go beyond
        what the existing packages provide. For information on how to install
        the 'Python' files, see the file INSTALL in the source distribution.
        Based on the present package, Christoph Dalitz also wrote a pure 'C++'
        interface to 'fastcluster':
        <a href="https://lionel.kr.hs-niederrhein.de/~dalitz/data/hclust/">https://lionel.kr.hs-niederrhein.de/~dalitz/data/hclust/</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.freebsd.org/copyright/freebsd-license.html">FreeBSD</a> | <a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://danifold.net/fastcluster.html">https://danifold.net/fastcluster.html</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-22 20:04:59 UTC; muellner</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Müllner [aut, cph, cre],
  Google Inc. [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Müllner &lt;daniel@danifold.net&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-12 22:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='fastcluster'>Fast hierarchical, agglomerative clustering routines for R and Python</h2><span id='topic+fastcluster'></span><span id='topic+fastcluster-package'></span>

<h3>Description</h3>

<p>The <span class="pkg">fastcluster</span> package provides efficient algorithms for hierarchical,
agglomerative clustering. In addition to the R interface, there is also
a Python interface to the underlying C++ library, to be found in the
source distribution.
</p>


<h3>Details</h3>

<p>The function <code><a href="#topic+hclust">hclust</a></code> provides clustering when the
input is a dissimilarity matrix. A dissimilarity matrix can be
computed from vector data by <code><a href="stats.html#topic+dist">dist</a></code>. The
<code><a href="#topic+hclust">hclust</a></code> function can be used as a drop-in replacement for
existing routines: <code><a href="stats.html#topic+hclust">stats::hclust</a></code> and
<code><a href="flashClust.html#topic+hclust">flashClust::hclust</a></code> alias
<code><a href="flashClust.html#topic+flashClust">flashClust::flashClust</a></code>. Once the
fastcluster library is loaded at the beginning of the code, every
program that uses hierarchical clustering can benefit immediately and
effortlessly from the performance gain
</p>
<p>When the package is loaded, it overwrites the function
<code><a href="#topic+hclust">hclust</a></code> with the new code.
</p>
<p>The function <code><a href="#topic+hclust.vector">hclust.vector</a></code> provides memory-saving routines
when the input is vector data.
</p>
<p>Further information:
</p>

<ul>
<li><p> R documentation pages: <code><a href="#topic+hclust">hclust</a></code>,
<code><a href="#topic+hclust.vector">hclust.vector</a></code>
</p>
</li>
<li><p> A comprehensive User's manual:
<a href="https://CRAN.R-project.org/package=fastcluster/vignettes/fastcluster.pdf">fastcluster.pdf</a>. Get this from the R
command line with <code>vignette('fastcluster')</code>.
</p>
</li>
<li><p> JSS paper: <a href="https://doi.org/10.18637/jss.v053.i09">doi:10.18637/jss.v053.i09</a>.
</p>
</li>
<li><p> See the author's home page for a performance comparison:
<a href="https://danifold.net/fastcluster.html">https://danifold.net/fastcluster.html</a>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Daniel Müllner</p>


<h3>References</h3>

<p><a href="https://danifold.net/fastcluster.html">https://danifold.net/fastcluster.html</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+hclust">hclust</a></code>, <code><a href="#topic+hclust.vector">hclust.vector</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Taken and modified from stats::hclust
#
# hclust(...)        # new method
# hclust.vector(...) # new method
# stats::hclust(...) # old method

require(fastcluster)
require(graphics)

hc &lt;- hclust(dist(USArrests), "ave")
plot(hc)
plot(hc, hang = -1)

## Do the same with centroid clustering and squared Euclidean distance,
## cut the tree into ten clusters and reconstruct the upper part of the
## tree from the cluster centers.
hc &lt;- hclust.vector(USArrests, "cen")
# squared Euclidean distances
hc$height &lt;- hc$height^2
memb &lt;- cutree(hc, k = 10)
cent &lt;- NULL
for(k in 1:10){
  cent &lt;- rbind(cent, colMeans(USArrests[memb == k, , drop = FALSE]))
}
hc1 &lt;- hclust.vector(cent, method = "cen", members = table(memb))
# squared Euclidean distances
hc1$height &lt;- hc1$height^2
opar &lt;- par(mfrow = c(1, 2))
plot(hc,  labels = FALSE, hang = -1, main = "Original Tree")
plot(hc1, labels = FALSE, hang = -1, main = "Re-start from 10 clusters")
par(opar)
</code></pre>

<hr>
<h2 id='hclust'>Fast hierarchical, agglomerative clustering of dissimilarity data</h2><span id='topic+hclust'></span>

<h3>Description</h3>

<p>This function implements hierarchical clustering with the same interface as <code><a href="stats.html#topic+hclust">hclust</a></code> from the <span class="pkg"><a href="stats.html#topic+stats">stats</a></span> package but with much faster algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hclust(d, method="complete", members=NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hclust_+3A_d">d</code></td>
<td>
<p>a dissimilarity structure as produced by <code>dist</code>.</p>
</td></tr>
<tr><td><code id="hclust_+3A_method">method</code></td>
<td>
<p>the agglomeration method to be used. This must be (an
unambiguous abbreviation of) one of <code>"single"</code>,
<code>"complete"</code>, <code>"average"</code>, <code>"mcquitty"</code>,
<code>"ward.D"</code>, <code>"ward.D2"</code>, <code>"centroid"</code> or <code>"median"</code>.</p>
</td></tr>
<tr><td><code id="hclust_+3A_members">members</code></td>
<td>
<p><code>NULL</code> or a vector with length the number of
observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the documentation of the original function
<code><a href="stats.html#topic+hclust">hclust</a></code> in the <span class="pkg"><a href="stats.html#topic+stats">stats</a></span> package.
</p>
<p>A comprehensive User's manual
<a href="https://CRAN.R-project.org/package=fastcluster/vignettes/fastcluster.pdf">fastcluster.pdf</a> is available as a vignette. Get this from the R command line with <code>vignette('fastcluster')</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>'hclust'</code>. It encodes a stepwise dendrogram.</p>


<h3>Author(s)</h3>

<p>Daniel Müllner</p>


<h3>References</h3>

<p><a href="https://danifold.net/fastcluster.html">https://danifold.net/fastcluster.html</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+fastcluster">fastcluster</a></code>, <code><a href="#topic+hclust.vector">hclust.vector</a></code>, <code><a href="stats.html#topic+hclust">stats::hclust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Taken and modified from stats::hclust
#
# hclust(...)        # new method
# stats::hclust(...) # old method

require(fastcluster)
require(graphics)

hc &lt;- hclust(dist(USArrests), "ave")
plot(hc)
plot(hc, hang = -1)

## Do the same with centroid clustering and squared Euclidean distance,
## cut the tree into ten clusters and reconstruct the upper part of the
## tree from the cluster centers.
hc &lt;- hclust(dist(USArrests)^2, "cen")
memb &lt;- cutree(hc, k = 10)
cent &lt;- NULL
for(k in 1:10){
  cent &lt;- rbind(cent, colMeans(USArrests[memb == k, , drop = FALSE]))
}
hc1 &lt;- hclust(dist(cent)^2, method = "cen", members = table(memb))
opar &lt;- par(mfrow = c(1, 2))
plot(hc,  labels = FALSE, hang = -1, main = "Original Tree")
plot(hc1, labels = FALSE, hang = -1, main = "Re-start from 10 clusters")
par(opar)
</code></pre>

<hr>
<h2 id='hclust.vector'>Fast hierarchical, agglomerative clustering of vector data</h2><span id='topic+hclust.vector'></span>

<h3>Description</h3>

<p>This function implements hierarchical, agglomerative clustering with memory-saving algorithms.</p>


<h3>Usage</h3>

<pre><code class='language-R'>hclust.vector(X, method="single", members=NULL, metric='euclidean', p=NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hclust.vector_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(N\times D)</code> matrix of '<a href="base.html#topic+double">double</a>' values:
<code class="reqn">N</code> observations in <code class="reqn">D</code> variables.</p>
</td></tr>
<tr><td><code id="hclust.vector_+3A_method">method</code></td>
<td>
<p>the agglomeration method to be used. This must be (an
unambiguous abbreviation of) one of <code>"single"</code>,
<code>"ward"</code>, <code>"centroid"</code> or <code>"median"</code>.</p>
</td></tr>
<tr><td><code id="hclust.vector_+3A_members">members</code></td>
<td>
<p><code>NULL</code> or a vector with length the number of observations.</p>
</td></tr>
<tr><td><code id="hclust.vector_+3A_metric">metric</code></td>
<td>
<p>the distance measure to be used. This must be one of
<code>"euclidean"</code>, <code>"maximum"</code>, <code>"manhattan"</code>,
<code>"canberra"</code>, <code>"binary"</code> or <code>"minkowski"</code>. Any
unambiguous substring can be given.</p>
</td></tr>
<tr><td><code id="hclust.vector_+3A_p">p</code></td>
<td>
<p>parameter for the Minkowski metric.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code><a href="#topic+hclust.vector">hclust.vector</a></code> provides clustering when the
input is vector data. It uses memory-saving algorithms which allow
processing of larger data sets than <code><a href="#topic+hclust">hclust</a></code> does.
</p>
<p>The <code>"ward"</code>, <code>"centroid"</code> and <code>"median"</code> methods
require <code>metric="euclidean"</code> and cluster the data set with
respect to Euclidean distances.
</p>
<p>For <code>"single"</code> linkage clustering, any dissimilarity
measure may be chosen. Currently, the same metrics are implemented as the
<code><a href="stats.html#topic+dist">dist</a></code> function provides.
</p>
<p>The call</p>
<pre>  hclust.vector(X, method='single', metric=[...])</pre>
<p>gives the same result as</p>
<pre>  hclust(dist(X, metric=[...]), method='single')</pre>
<p>but uses less memory and is equally fast.
</p>
<p>For the Euclidean methods, care must be taken since
<code><a href="#topic+hclust">hclust</a></code> expects <b>squared</b> Euclidean
distances. Hence, the call</p>
<pre>  hclust.vector(X, method='centroid')</pre>
<p>is, aside from the lesser memory requirements, equivalent to</p>
<pre>  d = dist(X)
  hc = hclust(d^2, method='centroid')
  hc$height = sqrt(hc$height)</pre>
<p>The same applies to the <code>"median"</code> method. The <code>"ward"</code> method in
<code><a href="#topic+hclust.vector">hclust.vector</a></code> is equivalent to <code><a href="#topic+hclust">hclust</a></code> with method <code>"ward.D2"</code>,
but to method <code>"ward.D"</code> only after squaring as above.
</p>
<p>More details are in the User's manual
<a href="https://CRAN.R-project.org/package=fastcluster/vignettes/fastcluster.pdf">fastcluster.pdf</a>, which is available as
a vignette. Get this from the R command line with
<code>vignette('fastcluster')</code>.
</p>


<h3>Author(s)</h3>

<p>Daniel Müllner</p>


<h3>References</h3>

<p><a href="https://danifold.net/fastcluster.html">https://danifold.net/fastcluster.html</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+fastcluster">fastcluster</a></code>, <code><a href="#topic+hclust">hclust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Taken and modified from stats::hclust
## Perform centroid clustering with squared Euclidean distances,
## cut the tree into ten clusters and reconstruct the upper part of the
## tree from the cluster centers.
hc &lt;- hclust.vector(USArrests, "cen")
# squared Euclidean distances
hc$height &lt;- hc$height^2
memb &lt;- cutree(hc, k = 10)
cent &lt;- NULL
for(k in 1:10){
  cent &lt;- rbind(cent, colMeans(USArrests[memb == k, , drop = FALSE]))
}
hc1 &lt;- hclust.vector(cent, method = "cen", members = table(memb))
# squared Euclidean distances
hc1$height &lt;- hc1$height^2
opar &lt;- par(mfrow = c(1, 2))
plot(hc,  labels = FALSE, hang = -1, main = "Original Tree")
plot(hc1, labels = FALSE, hang = -1, main = "Re-start from 10 clusters")
par(opar)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
