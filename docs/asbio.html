<!DOCTYPE html><html lang="en"><head><title>Help for package asbio</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {asbio}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#agrostis'>
<p>Agrostis variabilis cover measurements</p></a></li>
<li><a href='#aids'><p>Aids and veterans dataset</p>
</p></a></li>
<li><a href='#alfalfa.split.plot'><p>An agricultural split plot design</p></a></li>
<li><a href='#alpha.div'><p>Functions for calculating alpha diversity.</p></a></li>
<li><a href='#anm.ci'>
<p>Animation demonstrations of confidence intervals.</p></a></li>
<li><a href='#anm.coin'>
<p>Animated demonstration of frequentist binomial convergence of probability using a coin flip.</p></a></li>
<li><a href='#anm.cont.pdf'><p>Animated demonstration of density for a continuous pdf</p></a></li>
<li><a href='#anm.die'>
<p>Animated depiction of six-sided die throws.</p></a></li>
<li><a href='#anm.ExpDesign'><p>Animated depiction of experimental designs</p></a></li>
<li><a href='#anm.geo.growth'><p>Animated depictions of population growth</p></a></li>
<li><a href='#anm.loglik'><p>Animated plots of log-likelihood functions</p></a></li>
<li><a href='#anm.ls'>
<p>Animated plot of least squares function.</p></a></li>
<li><a href='#anm.ls.reg'>
<p>Animated plot of the least squares function.</p></a></li>
<li><a href='#anm.LV'><p>Animated depictions of Lotka-Volterra competition and exploitation models</p></a></li>
<li><a href='#anm.mc.bvn'>
<p>Animation of Markov Chain Monte Carlo walks in bivariate normal space</p></a></li>
<li><a href='#anm.samp.design'><p>Animated demonstration of randomized sampling designs</p></a></li>
<li><a href='#anolis'>
<p>Anolis lizard contingency table data</p></a></li>
<li><a href='#anscombe'>
<p>Anscombe's quartet</p></a></li>
<li><a href='#ant.dew'>
<p>Ant honeydew data</p></a></li>
<li><a href='#AP.test'><p>Agresti-Pendergrast test</p></a></li>
<li><a href='#asthma'><p>Asthma repeated measures dataset from Littell et al. (2002)</p></a></li>
<li><a href='#auc'>
<p>Area under a receiver operating characteristic (ROC) curve</p></a></li>
<li><a href='#baby.walk'>
<p>Baby walking times experimental data</p></a></li>
<li><a href='#bats'><p>Bat forearm length as a function of bat age</p></a></li>
<li><a href='#Bayes.disc'>
<p>Bayesian graphical summaries for discrete or categorical data.</p></a></li>
<li><a href='#bayes.lm'>
<p>Bayesian linear models with uniform priors</p></a></li>
<li><a href='#BCI.count'><p>Barro Colorado Island Tree Counts</p></a></li>
<li><a href='#BCI.plant'>
<p>Tree presence/absence data from Barro Colorado island</p></a></li>
<li><a href='#BDM.test'><p>Brunner-Dette-Munk test</p></a></li>
<li><a href='#bear'><p>Grizzly bear litter sizes</p>
</p></a></li>
<li><a href='#beetle'>
<p>Wood boring beetle data</p></a></li>
<li><a href='#best.agreement'>
<p>Determine agreement of two classifications</p></a></li>
<li><a href='#bin2dec'>
<p>Conversion between binary digits and decimal numbers</p></a></li>
<li><a href='#bombus'><p>Bombus pollen data.</p></a></li>
<li><a href='#bone'>
<p>Bone development data</p></a></li>
<li><a href='#book.menu'><p>Pulldown menus for 'asbio' interactive graphical functions</p></a></li>
<li><a href='#boot.ci.M'><p>Bootstrap CI of M-estimators differences of two samples</p></a></li>
<li><a href='#bootstrap'><p>A simple function for bootstrapping</p></a></li>
<li><a href='#bound.angle'>
<p>Angle of azimuth to a boundary.</p></a></li>
<li><a href='#bplot'>
<p>Barplots with error bars (including interval plots)</p></a></li>
<li><a href='#bromus'><p>Bromus tectorum dataset</p></a></li>
<li><a href='#bv.boxplot'><p>Bivariate boxplots</p></a></li>
<li><a href='#bvn.plot'>
<p>Make plots of bivariate normal distributions</p></a></li>
<li><a href='#C.isotope'>
<p>Atmospheric carbon and D14C measurements</p></a></li>
<li><a href='#caribou'>
<p>Caribou count data</p></a></li>
<li><a href='#case0902'>
<p>Dataset of mammal traits from Ramsey and Schaefer (1997)</p></a></li>
<li><a href='#case1202'>
<p>Dataset of salary attributes for male and female workers from Ramsey and Schafer (1997)</p></a></li>
<li><a href='#chi.plot'><p>Chi plots for diagnosing multivariate independence.</p></a></li>
<li><a href='#chronic'><p>Chronic ailment counts for urban and rural women in Australia</p>
</p></a></li>
<li><a href='#ci.boot'>
<p>Bootstrap confidence intervals</p></a></li>
<li><a href='#ci.impt'><p>Confidence interval for the product of two proportions</p></a></li>
<li><a href='#ci.median'><p>Confidence interval for the median</p></a></li>
<li><a href='#ci.mu.oneside'>
<p>One sided confidence interval for mu.</p></a></li>
<li><a href='#ci.mu.z'><p>Z and t confidence intervals for mu.</p></a></li>
<li><a href='#ci.p'>
<p>Confidence interval estimation for the binomial parameter pi using five popular methods.</p></a></li>
<li><a href='#ci.prat'>
<p>Confidence intervals for the ratio of binomial and multinomial proportions</p></a></li>
<li><a href='#ci.prat.ak'>
<p>Confidence intervals for ratios of proportions when the denominator is known</p></a></li>
<li><a href='#ci.sigma'>
<p>Confidence interval for sigma squared.</p></a></li>
<li><a href='#ci.strat'><p>Confidence intervals for stratified random samples.</p></a></li>
<li><a href='#cliff.env'><p>Environmental data for the community dataset cliff.sp</p></a></li>
<li><a href='#cliff.sp'><p>Yellowstone NP cliff community data</p></a></li>
<li><a href='#concrete'><p>Concrete strength dataset for data mining</p></a></li>
<li><a href='#ConDis.matrix'><p>Calculation and display of concordant and discordant pairs</p></a></li>
<li><a href='#corn'>
<p>Corn yield data</p></a></li>
<li><a href='#crab.weight'>
<p>crab gill and body weight data</p></a></li>
<li><a href='#crabs'>
<p>Agresti crabs dataset</p></a></li>
<li><a href='#cuckoo'>
<p>Tippett cuckoo egg data</p></a></li>
<li><a href='#D.sq'><p>Mahalanobis distance for two sites using a pooled covariance matrix</p></a></li>
<li><a href='#death.penalty'>
<p>Florida state death penalty data</p></a></li>
<li><a href='#deer'><p>Maternal deer data</p></a></li>
<li><a href='#deer.296'>
<p>Mule deer telemetry data</p></a></li>
<li><a href='#depression'>
<p>Hamilton depression scores before and after drug treatment</p></a></li>
<li><a href='#DH.test'><p>Doornik-Hansen test for multivariate normality.</p></a></li>
<li><a href='#dO2'>
<p>Dissolved levels in locations above and below a town</p></a></li>
<li><a href='#drugs'>
<p>Contingency data for high school marijuana, alcohol, and cigarette use</p></a></li>
<li><a href='#e.cancer'><p>Esophageal cancer data modified slightly to create a balanced three-way</p>
factorial design</a></li>
<li><a href='#eff.rbd'>
<p>Efficiency of a randomized block design compared to a CRD</p></a></li>
<li><a href='#enzyme'>
<p>Enzymatic rate data for the phospholipase protein ExoU</p></a></li>
<li><a href='#ES.May'><p>May's effective specialization index</p></a></li>
<li><a href='#exercise.repeated'><p>Repeated measures data for an exercise experiment.</p></a></li>
<li><a href='#facebook'>
<p>Facebook performance metrics for data mining and machine learning</p></a></li>
<li><a href='#Fbird'><p>Frigatebird drumming frequency data</p></a></li>
<li><a href='#fire'>
<p>Fire data from Yellowstone National Park</p></a></li>
<li><a href='#fly.sex'>
<p>Fly sex and longevity</p></a></li>
<li><a href='#frog'><p>Australian frog calls following fire</p></a></li>
<li><a href='#fruit'>
<p>Fruit weight data from Littell et al. (2002)</p></a></li>
<li><a href='#G.mean'><p>Geometric mean</p></a></li>
<li><a href='#g.test'>
<p>Likelihood ratio test for tabular data</p></a></li>
<li><a href='#garments'>
<p>Garment Latin square data from Littell et al. (2002)</p></a></li>
<li><a href='#Glucose2'><p>Glucose Levels Following Alcohol Ingestion</p></a></li>
<li><a href='#goats'><p>Mountain goat data from Yellowstone National Park</p></a></li>
<li><a href='#grass'><p>Agricultural factorial design</p></a></li>
<li><a href='#H.mean'><p>Harmonic mean</p></a></li>
<li><a href='#heart'>
<p>Heart rate data from Milliken and Johnson (2009)</p></a></li>
<li><a href='#HL.mean'><p>Hodges-Lehman estimator of location</p></a></li>
<li><a href='#huber.mu'><p>Huber M-estimator of location</p></a></li>
<li><a href='#huber.NR'><p>Huber M-estimator iterative least squares algorithm</p></a></li>
<li><a href='#huber.one.step'><p>Huber one step M-estimator</p></a></li>
<li><a href='#illusions'>
<p>Visual illusions illustrating human perception errors.</p></a></li>
<li><a href='#ipomopsis'>
<p>Ipomopsis fruit yield data</p></a></li>
<li><a href='#joint.ci.bonf'><p>Calculates joint confidence intervals for parameters in linear models using a Bonferroni procedure.</p></a></li>
<li><a href='#K'>
<p>Soil potassium analyses from 8 laboratories</p></a></li>
<li><a href='#Kappa'><p>Calculates kappa statistic and other classification error statistics</p></a></li>
<li><a href='#km'><p>Kaplan-Meier survivorship.</p></a></li>
<li><a href='#Kullback'><p>Kullback test for equal covariance matrices.</p></a></li>
<li><a href='#larrea'>
<p>Creosote bush counts</p></a></li>
<li><a href='#life.exp'>
<p>Mouse life expectancy data</p></a></li>
<li><a href='#lm.select'>
<p>AIC, AICc, BIC, Mallow's Cp, and PRESS evaluation of linear models</p></a></li>
<li><a href='#magnets'><p>Magnet pain relief data</p></a></li>
<li><a href='#MC'>
<p>Simple functions for MCMC demonstrations</p></a></li>
<li><a href='#MC.test'>
<p>Monte Carlo hypothesis testing for two samples.</p></a></li>
<li><a href='#mcmc.norm.hier'>
<p>Gibbs sampling of normal hierarchical models</p></a></li>
<li><a href='#ML.k'>
<p>Maximum likelihood algorithm for determining the binomial dispersal coefficient</p></a></li>
<li><a href='#Mode'><p>Sample mode</p></a></li>
<li><a href='#modlevene.test'><p>Modified Levene's test</p></a></li>
<li><a href='#montane.island'>
<p>Mountain island biogeographic data</p></a></li>
<li><a href='#moose.sel'>
<p>Datasets for resource use and availability</p></a></li>
<li><a href='#mosquito'>
<p>Mosquito wing length data</p></a></li>
<li><a href='#MS.test'><p>Mack-Skillings test</p></a></li>
<li><a href='#myeloma'>
<p>Patient responses to myeloma drug treatments</p></a></li>
<li><a href='#near.bound'><p>Nearest neighbor boundary coordinates</p></a></li>
<li><a href='#one.sample.t'><p>One sample t-test</p></a></li>
<li><a href='#one.sample.z'><p>One sample z-test</p></a></li>
<li><a href='#paik'>
<p>Paik diagrams</p></a></li>
<li><a href='#pairw.anova'><p>Conducts pairwise post hoc and planned comparisons associated with an ANOVA</p></a></li>
<li><a href='#pairw.fried'><p>Multiple pairwise comparison procedure to accompany a Friedman test.</p></a></li>
<li><a href='#pairw.kw'><p>Multiple pairwise comparison procedure to accompany a Kruskal-Wallis test</p></a></li>
<li><a href='#pairw.oneway'>
<p>Welch tests controlled for simultaneous inference</p></a></li>
<li><a href='#panel.cor.res'><p>Functions for customizing correlation matrices</p></a></li>
<li><a href='#partial.R2'><p>Partial correlations of determination in multiple regression</p></a></li>
<li><a href='#partial.resid.plot'><p>Partial residual plots for interpretation of multiple regression.</p></a></li>
<li><a href='#PCB'>
<p>PCBs and herring egg thickness</p></a></li>
<li><a href='#perm.fact.test'><p>Permutation test for two and three way factorial designs</p></a></li>
<li><a href='#pika'>
<p>Nitrogen content of soils under pika haypiles</p></a></li>
<li><a href='#plantTraits'><p>Plant traits for 136 species</p></a></li>
<li><a href='#plot.pairw'>
<p>Plots confidence intervals and/or bars with letters indicating significant differences for objects from class pairw</p></a></li>
<li><a href='#plotAncova'>
<p>Creates plots for one way ANCOVAs</p></a></li>
<li><a href='#plotCI.reg'><p>Plots a simple linear regression along with confidence and prediction intervals.</p>
</p></a></li>
<li><a href='#PM2.5'>
<p>PM 2.5 pollutant data from Pocatello Idaho</p></a></li>
<li><a href='#polyamine'>
<p>Polyamine data from Hollander and  Wolfe (1999)</p></a></li>
<li><a href='#portneuf'>
<p>Portneuf River longitudinal N and P data</p></a></li>
<li><a href='#potash'>
<p>Potash/cotton strength data</p></a></li>
<li><a href='#potato'><p>Fisher's Rothamsted potato data</p>
</p></a></li>
<li><a href='#power.z.test'><p>Power analysis for a one sample z-test</p></a></li>
<li><a href='#press'>
<p>prediction sum of squares</p></a></li>
<li><a href='#Preston.dist'>
<p>Preston diversity analysis</p></a></li>
<li><a href='#prostate'>
<p>Prostate cancer data</p></a></li>
<li><a href='#prp'>
<p>Perpendicularity</p></a></li>
<li><a href='#pseudo.v'><p>Jacknife pseudo-values</p></a></li>
<li><a href='#qq.Plot'>
<p>Normal quantile plots for single or multiple factor levels</p></a></li>
<li><a href='#r.bw'><p>Biweight midvariance, and biweight midcorrelation.</p></a></li>
<li><a href='#r.dist'>
<p>Visualize the sampling distribution of Pearson's product moment correlation</p></a></li>
<li><a href='#R.hat'>
<p>R hat MCMC convergence statistic</p></a></li>
<li><a href='#r.pb'><p>Percentage bend correlation</p></a></li>
<li><a href='#Rabino_CO2'>
<p>CSIRO d13C-CO2 data from Rubino et al., A revised 1000 year atmospheric  13C-CO2 record from Law Dome and South Pole, Antarctica</p></a></li>
<li><a href='#rat'>
<p>Rat glycogen data from Sokal and Rohlf (2012)</p></a></li>
<li><a href='#refinery'><p>Refinery CO dataset</p></a></li>
<li><a href='#rinvchisq'>
<p>Random draws from a scaled inverse chi-square distribution</p></a></li>
<li><a href='#rmvm'>
<p>A multivariate normal dataset for data mining</p></a></li>
<li><a href='#samp.dist'><p>Animated and/or snapshot representations of a statistic's sampling distribution</p></a></li>
<li><a href='#samp.dist.mech'>
<p>Animated representation of sampling distribution basics</p></a></li>
<li><a href='#savage'>
<p>Mammalian BMR and biomass data from Savage et al. (2004)</p></a></li>
<li><a href='#sc.twin'><p>Matched pairs schizophrenia data</p></a></li>
<li><a href='#se.jack'>
<p>Jackknife standard error from a set of pseudovalues</p></a></li>
<li><a href='#sedum.ts'>
<p>CO2 exchange time series data</p></a></li>
<li><a href='#see.accPrec.tck'>
<p>Interactive depiction of precision and accuracy</p></a></li>
<li><a href='#see.ancova.tck'>
<p>Visualize ANCOVA mechanics</p></a></li>
<li><a href='#see.anova.tck'>
<p>Interactive depiction of the ANOVA mechanism</p></a></li>
<li><a href='#see.cor.range.tck'>
<p>Depict the effect of range on correlation</p></a></li>
<li><a href='#see.exppower.tck'>
<p>Visualize exponential power functions</p></a></li>
<li><a href='#see.HW'>
<p>Visualize the Hardy Weinberg equilibrium</p></a></li>
<li><a href='#see.lma.tck'>
<p>ANOVA linear models</p></a></li>
<li><a href='#see.lmr.tck'>
<p>Regression linear model derivation from linear algebra</p></a></li>
<li><a href='#see.lmu.tck'>
<p>Unbalanced and balanced linear models</p></a></li>
<li><a href='#see.logic'>
<p>Interactive worksheet for logical and fallacious arguments</p></a></li>
<li><a href='#see.M'><p>Visualization of the M-estimation function</p></a></li>
<li><a href='#see.mixedII'>
<p>Depiction of the effect of random level selection on inferences concerning fixed effects</p></a></li>
<li><a href='#see.mnom.tck'>
<p>Interactive depiction of the multinomial distribution</p></a></li>
<li><a href='#see.move'>
<p>Interactive visualization of least squares regression.</p></a></li>
<li><a href='#see.nlm'>
<p>Visualize important non-linear functions</p></a></li>
<li><a href='#see.norm.tck'><p>Visualize pdfs</p></a></li>
<li><a href='#see.power'>
<p>Interactive depiction of type I and type II error and power</p></a></li>
<li><a href='#see.rEffect.tck'>
<p>Visualize random effects model</p></a></li>
<li><a href='#see.regression.tck'>
<p>Demonstration of regression mechanics</p></a></li>
<li><a href='#see.roc.tck'>
<p>Interactive depiction of ROC curves</p></a></li>
<li><a href='#see.smooth.tck'>
<p>Interactive smoother demonstrations</p></a></li>
<li><a href='#see.ttest.tck'>
<p>Visualize t-tests</p></a></li>
<li><a href='#see.typeI_II'>
<p>Interactive depiction of type I and II error</p></a></li>
<li><a href='#selftest.se.tck1'>
<p>Interactive self-testing questions</p></a></li>
<li><a href='#Semiconductor'><p>Split plot computer chip data from Littell et al. (2006)</p></a></li>
<li><a href='#SexDeterm'>
<p>Fern environmental sex determination data</p></a></li>
<li><a href='#shad'>
<p>American gizzard shad data</p></a></li>
<li><a href='#shade.norm'><p>Shading functions for interpretation of pdf probabilities.</p></a></li>
<li><a href='#shade.norm.tck'><p>GUI display of probability</p></a></li>
<li><a href='#simberloff'>
<p>Compilations of genus and species counts from Simberloff (1970)</p></a></li>
<li><a href='#skew'><p>Sample skewness and kurtosis</p></a></li>
<li><a href='#SM.temp.moist'>
<p>Alpine soil temperature and moisture time series</p></a></li>
<li><a href='#snore'>
<p>Snoring and heart disease contingency data</p></a></li>
<li><a href='#so2.us.cities'><p>SO2 data for 32 US cities with respect to 6 explanatory variables</p></a></li>
<li><a href='#stan.error'><p>Variance and standard error estimators for the sampling distribution of the sample mean</p></a></li>
<li><a href='#starkey'><p>DEM data from the Starkey experimental forest in NE Oregon</p></a></li>
<li><a href='#suess'>
<p>del14C in the atmosphere from 1700-1950</p></a></li>
<li><a href='#trag'>
<p>Salsify height dataset</p></a></li>
<li><a href='#transM'><p>Transition matrix analysis</p></a></li>
<li><a href='#trim.me'><p>Trim data</p></a></li>
<li><a href='#trim.ranef.test'><p>Robust test for random factors using trimmed means.</p></a></li>
<li><a href='#trim.test'><p>Robust one way trimmed means test.</p></a></li>
<li><a href='#tukey.add.test'><p>Tukey's test of additivity.</p></a></li>
<li><a href='#veneer'>
<p>Veneer data from Littell et al. (2002)</p></a></li>
<li><a href='#Venn'><p>Venn probability diagrams for an event with two outcomes</p></a></li>
<li><a href='#vs'>
<p>Scandinavian site by species community matrix</p></a></li>
<li><a href='#wash.rich'>
<p>Species richness and environmental variables from Mt Washburn</p></a></li>
<li><a href='#webs'><p>Spider web length data</p></a></li>
<li><a href='#wheat'><p>Agricultural randomized block design</p></a></li>
<li><a href='#whickham'>
<p>Whickham contingency table data for smokers and survivorship</p></a></li>
<li><a href='#wildebeest'>
<p>Wildebeest carcass categorical data</p></a></li>
<li><a href='#win'><p>Winsorize data</p></a></li>
<li><a href='#wine'>
<p>White wine quality data for data mining</p></a></li>
<li><a href='#world.co2'><p>World CO2 levels, by country, from 1980 to 2006</p></a></li>
<li><a href='#world.emissions'>
<p>Greenhouse gas emissions from Our World in Data</p></a></li>
<li><a href='#world.pop'><p>Population levels in various countries from 1980-2006</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of Statistical Tools for Biologists</td>
</tr>
<tr>
<td>Version:</td>
<td>1.11</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), tcltk</td>
</tr>
<tr>
<td>Imports:</td>
<td>scatterplot3d, pixmap, plotrix, mvtnorm, deSolve, lattice,
multcompView, grDevices, graphics, stats, utils, gWidgets2,
gWidgets2tcltk</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, tkrplot, R.rsp</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-1-24</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>BWidget</td>
</tr>
<tr>
<td>Author:</td>
<td>Ken Aho [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ken Aho &lt;kenaho1@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions from: Aho, K. (2014) Foundational and Applied Statistics for Biologists using R.  CRC/Taylor and Francis, Boca Raton, FL, ISBN: 978-1-4398-7338-0.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-14 23:02:22 UTC; ahoken</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-14 23:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='agrostis'>
Agrostis variabilis cover measurements
</h2><span id='topic+agrostis'></span>

<h3>Description</h3>

<p>Percent cover of the grass <em>Agrostis variablis</em> at 25 alpine snowbank sites in the Absaroka-Beartooth Mountains.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(agrostis)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 2 variables.
</p>

<dl>
<dt>site</dt><dd><p>Site number</p>
</dd>
<dt>cover</dt><dd><p>Percent cover</p>
</dd>
</dl>



<h3>Source</h3>

<p>Aho, K.  (2006)  <em>Alpine and Cliff Ecosystems in the North-Central Rocky Mountains</em>.  PhD dissertation, Montana State University, Bozeman, MT.
</p>

<hr>
<h2 id='aids'>Aids and veterans dataset
</h2><span id='topic+aids'></span>

<h3>Description</h3>

<p>The veterans administration studied the effect of AZT on AIDS symptoms for 338 HIV-positive military veterans who were just beginning to express AIDS.  AZT treatment was withheld on a random component until helper T cells showed even greater depletion while the other group received the drug immediately.  The subjects were also classified by race.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(aids)</code></pre>


<h3>Format</h3>

<p>A data frame with 338 observations on the following 3 variables.
</p>

<dl>
<dt><code>race</code></dt><dd><p>A factor with levels <code>black</code>, <code>white</code>.</p>
</dd>
<dt><code>AZT</code></dt><dd><p>A factor with levels <code>N</code>, <code>Y</code>.</p>
</dd>
<dt><code>symptoms</code></dt><dd><p>Presence/absence of AIDS symptoms.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Agresti, A. (2012)  <em>Categorical Data Analysis, 3rd edition</em>.  New York.  Wiley.
</p>

<hr>
<h2 id='alfalfa.split.plot'>An agricultural split plot design</h2><span id='topic+alfalfa.split.plot'></span>

<h3>Description</h3>

<p>An experiment was conducted in Iowa in 1944 to see how different varieties of alfalfa responded 
to the last cutting day of the previous year (Snedecor and Cochran 1967). We know that in the 
fall alfalfa can either continue to grow, or stop growing and store resources belowground in roots 
for growth during the following year. Thus, we might expect that later cutting dates inhibits 
growth for the following year. On the other hand, if plants are cut after they have gone into 
senescence, there should be little effect on productivity during the following year. There are 
two factors: 1) variety of alfalfa (three varieties were planted in each of three randomly chosen whole plots), 
and 2) the date of last cutting (Sept 1, Sept. 20, or Oct. 7).  The dates were randomly 
chosen split plots within the whole plots. Replication was accomplished using six blocks of fields. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alfalfa.split.plot)</code></pre>


<h3>Format</h3>

<p>The dataframe contains four variables: 
</p>

<dl>
<dt><code>yield</code></dt><dd>
<p>Alfalfa yield (tons per acre). 
</p>
</dd>
<dt><code>variety</code></dt><dd>
<p>Alfalfa variety.  A factor with three levels &quot;L&quot;= Ladak, &quot;C&quot; = Cosack, and &quot;R&quot; = Ranger describing the variety of alfalfa seed used.
</p>
</dd>
<dt><code>cut.time</code></dt><dd><p>Time of last cutting. A factor with three levels: &quot;None&quot; = field not cut, &quot;S1&quot; = Sept 1, &quot;S20&quot; = Sept. 20, or &quot;O7&quot; = Oct. 7.
</p>
</dd>
<dt><code>block</code></dt><dd><p>The block (whole plot replicate).  A factor with six levels: &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, and &quot;6&quot;.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Snedecor, G. W. and Cochran, G. C.  (1967)  <em>Statistical Methods, 6th edition</em>.  Iowa State University Press.</p>

<hr>
<h2 id='alpha.div'>Functions for calculating alpha diversity.
</h2><span id='topic+alpha.div'></span><span id='topic+Simp.index'></span><span id='topic+SW.index'></span>

<h3>Description</h3>

<p>Alpha diversity quantifies richness and evenness within a sampling unit (replicate).
</p>
<p>The function <code>alpha.div</code> runs <code>Simp.index</code> or <code>SW.index</code> to calculate Simpson's, Inverse Simpson's or Shannon-Weiner diversities. 
</p>
<p>Simpson's index has a straightforward interpretation. It is the probability of reaching into a plot and simultaneously pulling out two different species.  
Inverse Simpson's diversity is equivalent to one over the probability that two randomly chosen individuals will be the same species. 
These measures have been attributed to Simpson (1949).  While it does not allow straightforward interpretation of results, the Shannon-Weiner diversity (<em>H</em>') 
is another commonly used alpha-diversity measure based on the Kullback-Leibler information criterion (Macarthur and Macarthur 1961). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alpha.div(x,index)
Simp.index(x,inv)
SW.index(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="alpha.div_+3A_x">x</code></td>
<td>

<p>A vector or matrix of species abundances (e.g. counts).  The functions assume that species are in columns and sites are in rows.</p>
</td></tr>
<tr><td><code id="alpha.div_+3A_index">index</code></td>
<td>

<p>The type of alpha diversity to be computed.  The function currently has three choices. <code>simp</code> = Simpson's diversity, <code>inv.simp</code>=inverse Simpson's, <code>shan</code> = Shannon-Weiner diversity.</p>
</td></tr>  
<tr><td><code id="alpha.div_+3A_inv">inv</code></td>
<td>
<p>Logical, indicating whether or not Simpson's inverse diversity should be computed.</p>
</td></tr> 	
</table>


<h3>Value</h3>

<p>A single diversity value is returned if <code>x</code> is a vector.  A vector of diversities (one for each site) are returned if <code>x</code> is a matrix. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Simpson, E. H.  (1949)  Measurement of diversity.  <em>Nature</em>.  163: 688.
</p>
<p>MacArthur, R. H., and MacArthur J. W.  (1961)  On bird species diversity.  <em>Ecology</em>.  42: 594-598.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cliff.sp)
alpha.div(cliff.sp,"simp")
</code></pre>

<hr>
<h2 id='anm.ci'>
Animation demonstrations of confidence intervals.
</h2><span id='topic+anm.ci'></span><span id='topic+anm.ci.tck'></span>

<h3>Description</h3>

<p>Provides animated depictions of confidence intervals for <code class="reqn">\mu</code>, <code class="reqn">\sigma^{2}</code>, the population median, and the binomial parameter <code class="reqn">\pi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.ci(parent=expression(rnorm(n)), par.val, conf = 0.95, sigma = NULL,
  par.type = c("mu", "median", "sigma.sq", "p"), n.est = 100,
  n = 50, err.col = 2, par.col = 4, interval = 0.1, ...)

anm.ci.tck()

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.ci_+3A_parent">parent</code></td>
<td>
<p>A parental distribution; ideally a distribution with known parameters.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_par.val">par.val</code></td>
<td>
<p>True parameter value which is being estimated.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_conf">conf</code></td>
<td>
<p>Confidence level: 1-<em>P</em>(type I error).</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_sigma">sigma</code></td>
<td>
<p><code class="reqn">\sigma</code> from the normal pdf, if known.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_par.type">par.type</code></td>
<td>
<p>The parameter whose confidence intervals to be estimated.  There are
currently four choices <code>c("mu", "median", "sigma.sq", "p")</code>.  These are the normal pdf
parameters <code class="reqn">\mu</code> and <code class="reqn">\sigma^{2}</code>, the population median, and the binomial
parameter, <code class="reqn">\pi</code>.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_n.est">n.est</code></td>
<td>
<p>The number of confidence intervals to be created.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_n">n</code></td>
<td>
<p>The sample size used for each confidence interval.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_err.col">err.col</code></td>
<td>
<p>The line color of the intervals which do not include the true value.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_par.col">par.col</code></td>
<td>
<p>The line color denoting the parameter value.</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_interval">interval</code></td>
<td>
<p>The time interval for animation (in seconds).  Smaller intervals speed up animation</p>
</td></tr>
<tr><td><code id="anm.ci_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides an animated plot showing confidence intervals with respect to a known parameter.  Intervals which do not contain the parameter are emphasized with different colors. The function can be run with a <span class="pkg">tcltk</span> GUI function, <code>anm.ci.tck()</code>.
</p>


<h3>Value</h3>

<p>Returns an animated plot.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p>Additional documentation for methods provided in: <code><a href="#topic+ci.mu.t">ci.mu.t</a></code>, <code><a href="#topic+ci.mu.z">ci.mu.z</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>, <code><a href="#topic+ci.sigma">ci.sigma</a></code>, and <code><a href="#topic+ci.p">ci.p</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
parent&lt;-rnorm(100000)
anm.ci(parent, par.val=0, conf =.95, sigma =1, par.type="mu")
anm.ci(parent, par.val=1, conf =.95, par.type="sigma.sq")
anm.ci(parent, par.val=0, conf =.95, par.type="median")
parent&lt;-rbinom(100000,1,p=.65)
anm.ci(parent, par.val=0.65, conf =.95, par.type="p")
##Interactive GUI, requires package 'tcltk'
anm.ci.tck()

## End(Not run)
</code></pre>

<hr>
<h2 id='anm.coin'>
Animated demonstration of frequentist binomial convergence of probability using a coin flip.
</h2><span id='topic+anm.coin'></span><span id='topic+anm.coin.tck'></span>

<h3>Description</h3>

<p>Creates an animated plot showing the results from coin flips, and the resulting convergence in <em>P</em>(Head) as the number of flips grows large.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anm.coin(flips = 1000, p.head = 0.5, interval = 0.01, show.coin = TRUE, ...)
anm.coin.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.coin_+3A_flips">flips</code></td>
<td>
<p>The number of desired coin flips.</p>
</td></tr>
<tr><td><code id="anm.coin_+3A_p.head">p.head</code></td>
<td>
<p>User defined probability of a head; e.g., for a fair coin <code>p.head = 0.5</code>.</p>
</td></tr>
<tr><td><code id="anm.coin_+3A_interval">interval</code></td>
<td>
<p>The time between animation frames, in seconds.</p>
</td></tr>
<tr><td><code id="anm.coin_+3A_show.coin">show.coin</code></td>
<td>
<p>Logical if <code>show.coin=TRUE</code> shows a second plot with coin flip results (head or tail).</p>
</td></tr>
<tr><td><code id="anm.coin_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>show.coin=TRUE</code>, returns two plots configured as a single graphical object.  The first plot shows convergence in estimated <em>P</em>(Head), i.e., number of heads/number of trials, as the number of trials grows large.  The second plot shows individual outcomes of coin flips.  The second (smaller) plot is not returned if <code>show.coin=TRUE</code> is specified. The function <code>anm.coin()</code> can be run with the <span class="pkg">tcltk</span> GUI function, <code>anm.coin.tck()</code>.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rbinom">rbinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: anm.coin()
</code></pre>

<hr>
<h2 id='anm.cont.pdf'>Animated demonstration of density for a continuous pdf
</h2><span id='topic+anm.cont.pdf'></span><span id='topic+see.pdf.conc.tck'></span>

<h3>Description</h3>

<p>A continuous pdf is conceptually a histogram whose bin area sums to one.  Infinite, infinitely small bins, however, are required to allow depiction of an infinite number of distinct continuous outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.cont.pdf(part = "norm", interval = 0.3)

see.pdf.conc.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.cont.pdf_+3A_part">part</code></td>
<td>

<p>Parent distribution, options are <code>"norm"</code> = <em>N</em>(0, 1), <code>"t"</code> = <em>t</em>(10),
<code>"exp"</code> = EXP(1), and <code>"unif"</code> = UNIF(0,1)
</p>
</td></tr>
<tr><td><code id="anm.cont.pdf_+3A_interval">interval</code></td>
<td>

<p>Animation interval
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>May not work every time, because random values may exceed histogram range.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>

<hr>
<h2 id='anm.die'>
Animated depiction of six-sided die throws.
</h2><span id='topic+anm.die'></span><span id='topic+anm.die.tck'></span>

<h3>Description</h3>

<p>Convergence in probability for fair (or loaded) six-sided die.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.die(reps = 300, interval = 0.1, show.die = TRUE, p = c(1/6, 1/6, 1/6, 
1/6, 1/6, 1/6), cl = TRUE)

anm.die.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.die_+3A_reps">reps</code></td>
<td>
<p>Number of die throws.
</p>
</td></tr>
<tr><td><code id="anm.die_+3A_interval">interval</code></td>
<td>

<p>Animation interval in frames per second.
</p>
</td></tr>
<tr><td><code id="anm.die_+3A_show.die">show.die</code></td>
<td>

<p>Logical, indicating whether die outcomes should be shown.
</p>
</td></tr>
<tr><td><code id="anm.die_+3A_p">p</code></td>
<td>

<p>A vector of length six which sums to one indicating the probability of die outcomes.
</p>
</td></tr>
<tr><td><code id="anm.die_+3A_cl">cl</code></td>
<td>

<p>Logical,  Indicating whether or not color should be used.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anm.coin">anm.coin</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
anm.die()

## End(Not run)
</code></pre>

<hr>
<h2 id='anm.ExpDesign'>Animated depiction of experimental designs</h2><span id='topic+anm.ExpDesign'></span><span id='topic+anm.ExpDesign.tck'></span><span id='topic+ExpDesign'></span>

<h3>Description</h3>

<p>Describes random treatment allocation for fifteen experimental designs.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.ExpDesign(method="all", titles =  TRUE, cex.text = 1, mp.col = NULL, lwda = 1, 
n = 10, EUcol = hcl.colors(n, palette = "Dark 3"), interval = 0.5, iter = 30)


ExpDesign(method="all", titles = TRUE, cex.text = 1, mp.col = NULL, lwda = 1, n = 10, 
EUcol = hcl.colors(n, palette = "Dark 3"),...)

anm.ExpDesign.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.ExpDesign_+3A_method">method</code></td>
<td>
<p>A character vector listing the experimental methods to be demonstrated (see <b>Details</b> below).</p>
</td></tr>  
<tr><td><code id="anm.ExpDesign_+3A_titles">titles</code></td>
<td>
<p>A logical argument specifying whether or not plots should have <code>main</code> titles.</p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_interval">interval</code></td>
<td>
<p>Time length spent on each frame in animation (in seconds).</p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_iter">iter</code></td>
<td>
<p>Number of random iterations in animation.</p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_cex.text">cex.text</code></td>
<td>
<p>Text character expansion plots.</p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_mp.col">mp.col</code></td>
<td>
<p>Arrow colors in <code>"matched"</code> plot.  Either a vector of length 3 or a single color.</p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_lwda">lwda</code></td>
<td>
<p>Arrow line widths.</p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_n">n</code></td>
<td>
<p>Sample size (number of experimental units).  Currently only implemented for <code>method = "CRD"</code></p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_eucol">EUcol</code></td>
<td>
<p>Color of text identifying experimental units (or in some designs, treatments).  Currently only implemented for <code>method = "CRD"</code>,  <code>method = "factorial2by2"</code>, <code>method = "RCBD"</code>,  and <code>method = "nested"</code></p>
</td></tr>
<tr><td><code id="anm.ExpDesign_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a plot or series of plots illustrating the workings of experimental designs. Random apportionment of treatments of experimental units (EUs) is illustrated for each of twelve experimental designs.  A character string can be specified in the <code>method</code> argument using a subset of any of the following: <br />
<code>"CRD"</code>: a one-way completely randomized design,<br />
<code>"factorial2by2"</code>: a 2 x 2 design with four EUs,<br />
<code>"factorial2by2by2"</code>: a 2 x 2 x 2 factorial designs with 8 EUs,<br /> 
<code>"nested"</code>: a nested design with two levels of nesting,<br />
<code>"RCBD"</code> a randomized complete block design with two blocks, two treatments and four EUs,<br />
<code>"RIBD"</code>: a randomized incomplete block design with three blocks, three treatments, and six EUs,<br />
<code>"split"</code>: a split plot design with a whole plot (factor A) and a split plot (factor B),<br />
<code>"split.split"</code>: a split split-split plot design, <br />
<code>"SPRB"</code>: split plots in randomized blocks,<br />
<code>"strip.split"</code>: strip-split plot design,<br />
<code>"latin"</code>: a Latin squares design with <em>r</em> = 3, and <br /> 
<code>"pairs"</code>: a matched pairs design.<br />  
The function <code>anm.ExpDesign.tck</code> provides an interactive GUI. Details on these designs are given below. 
</p>


<h3>Completely randomized design (CRD)</h3>

<p>In a <b>completely randomized design</b> experimental units are each randomly assigned to factor levels without constraints like blocking.  This approach can (and should) be implemented in one way ANOVAs, and in more complex formats like factorial and hierarchical designs.  
</p>


<h3>Factorial design</h3>

<p>Treatments can be derived by combining factor levels from the multiple factors.  This is called a <b>factorial design</b>.  In a fully crossed factorial design with two factors, A and B, every level in factor A is contained in every level of factor B.
</p>


<h3>Randomized block design (RBD)</h3>

<p>In a <b>randomized block design</b> a researcher randomly assigns experimental units to treatments separately within units called blocks.  If all treatments are assigned exactly once within each block this is known as a <b>randomized complete block design (RCBD)</b> 
</p>


<h3>Latin squares</h3>

<p><b>Latin squares designs</b> are useful when there are two potential blocking variables.  These can figuratively or literally be represented by rows and columns.  All treatments are assigned to each row and to each column, and for each row and column treatment assignments differ.  Of course this stipulation limits the number of ways one can allocate treatments.  
</p>


<h3>Nested design</h3>

<p>In a <b>nested design</b> factor levels from one factor will be contained entirely in one factor level from another factor.  Consider a design with two factors A and B.  When every level of factor A appears with every level of factor B, and vice versa, then we have a fully crossed factorial design (see above).  Conversely, when levels of B only occur within a single level of A, then B is nested in A.
</p>


<h3>Split plot design</h3>

<p>A <b>split plot</b> design contains two nested levels of randomization.  At the highest level are whole plots which are randomly assigned factor levels from one factor.  At a second nested level whole plots are split to form split plots.  The split plots are randomly assigned factor levels from a second factor.  Split plot designs are replicated in units called blocks. <b>Split-split plot</b> design will have two levels of split plot nesting: C (split-split plots) are split plots within B (split plots), and B are split plots within A (whole plots).  We can see obvious and confusing similarities here to nested designs. A <b>split plot randomized block</b> (<b>SPRB</b>) design will have whole plots randomly assigned within blocks, and split plots randomly assigned within the whole plots.  Thus, levels of A (whole plot) are assigned randomly to a block, and split plots containing levels of B (split plot) are assigned within a level of A. 
</p>


<h3>Strip plot design</h3>

<p>Closely related to split plot designs are strip plots. <b>Strip plots</b> can be used address situations when relatively large experimental units are required for each of two factors in an experiment. A strip plot will have a row and column structure.  Let the number of columns equal to the number of levels in factor A, and let the number of rows be equal to the number of levels in factor B.  Levels in A are randomly assigned to columns only (across all rows) in a RBD format, and levels in B are assigned to rows only (across all columns). Interestingly, the levels in A serve as split plots in B and vice versa.  However, unlike a split plot design assignment of treatments at this level is not entirely random since rows are assigned single levels in A, while columns are assigned single levels in B.  Compared to a factorial design strip plots allow for greater precision in the measurement of interaction effects while sacrificing precision in the measurement of main effects.  Split-block design discussed by Littell et al. (2006), are indistinguishable from strip plots, described earlier, except that they are placed in the context of blocks.  They are also indistinguishable from SPRBs except that the design has an explicit row/column structure (one level of A for each column, one level of B for each row), resulting in larger experimental units for A and B. Conversely, in a SPRB, different levels of A and B can be assigned within columns and rows respectively.  A final type of split/strip plot design is known as a <b>strip-split plot</b>.  Strip-split plots are three way designs (cf. Hoshmand 2006, Milliken and Johnson 2009).  In these models a conventional two factor strip plot is created (factors A and B) and split plots are placed in the resulting cells (levels in factor C). The design is indistinguishable from a split-split plot design except for the fact that &quot;columns&quot; always constitute the same levels in A, while &quot;rows&quot; always constitute the same levels in B, allowing larger experimental units for A and B, and reflecting the strip plot relationship of A and B.  Other, even more complex variants of split and strip plots are possible are possible.  For instance, Littell et al. (2006) discuss a case study they describe as strip-split-split plot design!  
</p>


<h3>Matched pairs</h3>

<p>In a <b>matched pairs</b> design treatments are compared by using the same (or highly similar) experimental units.  If treatments are assigned at particular time segments it is assumed that outcomes within an experimental unit are independent, i.e., there is no &quot;carryover&quot; effect from the previous treatment.  Violation of this assumption may result in ashpericity and prevent conventional approaches.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Hoshmand, A. R. (2006) <em>Design of Experiments for Agriculture and the Natural Sciences 2nd Edition</em>. CRC Press. 
</p>
<p>Littell, R. C., Stroup, W. W., and R. J. Fruend  (2002)  <em>SAS for linear models</em>. Wiley, New York.  
</p>
<p>Milliken, G. A., and D. E. Johnson  (2009) <em>Analysis of messy data: Vol. I. Designed 	experiments, 2nd edition</em>. CRC. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+samp.design">samp.design</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExpDesign()
## Not run: anm.ExpDesign()
</code></pre>

<hr>
<h2 id='anm.geo.growth'>Animated depictions of population growth
</h2><span id='topic+anm.geo.growth'></span><span id='topic+anm.exp.growth'></span><span id='topic+anm.log.growth'></span><span id='topic+anm.geo.growth.tck'></span><span id='topic+anm.exp.growth.tck'></span><span id='topic+anm.log.growth.tck'></span>

<h3>Description</h3>

<p>Animated depictions of geometric, exponential, and logistic growth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.geo.growth(n0, lambda, time = seq(0, 20), ylab = "Abundance",
xlab = "Time", interval = 0.1, ...)

anm.exp.growth(n, rmax, time = seq(0, 20), ylab = "Abundance",
xlab = "Time", interval = 0.1, ...)

anm.log.growth(n, rmax, K, time = seq(0, 60), ylab = "Abundance",
xlab = "Time", interval = 0.1, ...)

anm.geo.growth.tck()

anm.exp.growth.tck()

anm.log.growth.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.geo.growth_+3A_n0">n0</code></td>
<td>

<p>Population size at time zero for geometric population growth.
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_lambda">lambda</code></td>
<td>

<p>Geometric growth rate.
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_time">time</code></td>
<td>

<p>A time sequence, i.e. a vector of integers which must include 0.
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_ylab">ylab</code></td>
<td>

<p><em>Y</em>-axis label.
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_xlab">xlab</code></td>
<td>

<p><em>X</em>-axis label
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_interval">interval</code></td>
<td>

<p>Animation interval in seconds per frame.
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_n">n</code></td>
<td>
<p>Initial population numbers for exponential and logistic growth
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_rmax">rmax</code></td>
<td>

<p>The maximum intrinsic rate of increase
</p>
</td></tr>
<tr><td><code id="anm.geo.growth_+3A_k">K</code></td>
<td>

<p>The carrying capacity
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Presented here are three famous population growth models from ecology.  Geometric, exponential and logistic growth.  The first two model growth in the presence of unlimited resources.  Geometric growth is exponential growth assuming non-overlapping generations, and is computed as:
</p>
<p style="text-align: center;"><code class="reqn">N_t = N_{0}\lambda^t,</code>
</p>

<p>where <code class="reqn">N_t</code> is the number of individuals at time <em>y</em>, <code class="reqn">\lambda</code> is the geometric growth rate, and <em>t</em> is time.
</p>
<p>Exponential growth allows simultaneous existence of multiple generations, and is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\frac{dN}{dt}=r_{max}N,</code>
</p>

<p>where <code class="reqn">r_{max}</code> is the maximum intrinsic rate of increase, i.e. max(birth rate - death rate), and <em>N</em> is the population size.  With logistic growth, exponential growth is slowed as <em>N</em> approaches the carrying capacity.  It is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\frac{dN}{dt}=r_{max}N\frac{K-N}{K},</code>
</p>

<p>where <code class="reqn">r_{max}</code> is the maximum rate of intrinsic increase, <code class="reqn">N</code> is the population size, and <code class="reqn">K</code> is the carrying capacity
</p>
<p>All three functions can be run from <span class="pkg">tcltk</span> GUIs.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anm.LVexp">anm.LVexp</a></code>, <code><a href="#topic+anm.LVcomp">anm.LVcomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
anm.geo.growth(10,2.4)

## End(Not run)
</code></pre>

<hr>
<h2 id='anm.loglik'>Animated plots of log-likelihood functions</h2><span id='topic+anm.loglik'></span><span id='topic+loglik.plot'></span><span id='topic+loglik.norm.plot'></span><span id='topic+loglik.pois.plot'></span><span id='topic+loglik.binom.plot'></span><span id='topic+loglik.exp.plot'></span><span id='topic+loglik.custom.plot'></span><span id='topic+anm.loglik.tck'></span>

<h3>Description</h3>

<p>Plots the normal, exponential, Poisson, binomial, and &quot;custom&quot; log-likelihood functions.  By definition, likelihoods for parameter estimates are calculated by holding data constant and varying estimates.  For the normal distribution a fixed value for the parameter which is not being estimated (<code class="reqn">\mu</code> or <code class="reqn">\sigma^2</code>) is established using MLEs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anm.loglik(X, dist = c("norm", "poi", "bin", "exp", "custom"),
plot.likfunc = TRUE, parameter = NULL, func = NULL, poss = NULL,
plot.density = TRUE, plot.calc = FALSE, xlab = NULL, ylab = NULL,
conv = diff(range(X))/70, anim = TRUE, est.col = 2, density.leg = TRUE,
cex.leg = 0.9, interval = 0.01, ...)

loglik.norm.plot(X, parameter = c("mu", "sigma.sq"), poss = NULL,
plot.likfunc = TRUE, plot.density = TRUE, plot.calc = FALSE,
xlab = NULL, ylab = NULL, conv = 0.01, anim = TRUE, est.col = 2,
density.leg = TRUE, cex.leg = 0.9, interval = 0.01, ...)

loglik.pois.plot(X, poss = NULL, plot.likfunc = TRUE,
plot.density = TRUE, plot.calc = FALSE, xlab = NULL, ylab = NULL,
conv = 0.01, anim = TRUE, interval = 0.01, ...)

loglik.binom.plot(X, poss = NULL, xlab = NULL, ylab = NULL,
plot.likfunc = TRUE, plot.density = TRUE, conv = 0.01, anim = TRUE,
interval = 0.01, ...)

loglik.exp.plot(X, poss = NULL, plot.likfunc = TRUE,
plot.density = TRUE, plot.calc = FALSE, xlab = NULL, ylab = NULL,
conv = 0.01, anim = TRUE, est.col = 2, density.leg = TRUE,
cex.leg = 0.9, interval = 0.01, ...)

loglik.custom.plot(X, func, poss, anim = TRUE, interval = 0.01,
xlab, ylab, ...)

anm.loglik.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.loglik_+3A_x">X</code></td>
<td>
<p>A vector of quantitative data.  The function does not currently handle extremely large datasets, <em>n</em> &gt; 500. Data should be integers (counts) for the Poisson
log-likelihood function, and binary responses (0,1) for the binomial log likelihood function.  Data elements for the exponential log likelihood function must be greater than zero.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_parameter">parameter</code></td>
<td>
<p>The parameter for which ML estimation is desired in <code>loglik.norm.plot</code>.  Specification of either <code>"mu"</code> or <code>"sigma.sq"</code> is required for the normal log-likelihood function.  No specification is required for exponential, Poisson, and binomial log-likelihood functions since these distributions are generally specified with a single parameter, i.e., <code class="reqn">\theta</code> for the exponential, <code class="reqn">\lambda</code> for the Poisson distribution, and <em>p</em> (the probability of a success) for the binomial distribution.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_poss">poss</code></td>
<td>
<p>An optional vector containing a sequence of possible parameter estimates.  Elements in the vector must be distinct.  If <code>poss</code> is not specified a vector of appropriate possibilities is provided by the function.  This argument can be used to set <code>xlim</code> in the likelihood function and density plots.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_dist">dist</code></td>
<td>
<p>The type of assumed distribution there are currently five possibilities: <code>"norm"</code>, <code>"poi"</code>, <code>"binom"</code>, <code>"exp"</code>, and <code>"custom"</code>.  Use of custom distributions requires specification of a custom likelihood function in the argument <code>func</code>.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_plot.likfunc">plot.likfunc</code></td>
<td>
<p>A logical command for indicating whether a graph of the log-likelihood function should be created.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_plot.density">plot.density</code></td>
<td>
<p>A logical command for indicating whether a second graph, in which densities are plotted on the pdf, should be created.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_plot.calc">plot.calc</code></td>
<td>
<p>A logical command for indicating whether a third graph, in which log-densities are added to one another, should be created.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_xlab">xlab</code></td>
<td>
<p>Optional <em>X</em>-axis label.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_ylab">ylab</code></td>
<td>
<p>Optional <em>Y</em>-axis label.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_conv">conv</code></td>
<td>
<p>Precision of likelihood function.  Decreasing <code>conv</code> increases the smoothness and precision of the ML function.  Decreasing <code>conv</code> will also slow the animation.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_anim">anim</code></td>
<td>
<p>A logical command indicating whether animation should be used in plots.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_est.col">est.col</code></td>
<td>
<p>Color used in depicting estimation.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_density.leg">density.leg</code></td>
<td>
<p>Logical.  Should the legend for density be shown?</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_cex.leg">cex.leg</code></td>
<td>
<p>Character expansion for legend.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_interval">interval</code></td>
<td>
<p>Speed of animation, in seconds per frame.  May not work in all systems; see <code><a href="base.html#topic+Sys.sleep">Sys.sleep</a></code>.</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_func">func</code></td>
<td>
<p>Custom likelihood function to be specified when using <code>loglik.custom.plot</code>.  The function should have two arguments.  An optional call to data, and the likelihood function parameter (see example below).</p>
</td></tr>
<tr><td><code id="anm.loglik_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code> can be specified for likelihood function plots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These plots are helpful in explaining the workings of ML estimation for parameters.  Animation is included as an option to further clarify processes.
When specifying <code>poss</code> be sure to include the estimate that you &quot;want&quot; the log-likelihood function to maximize in the vector of possibilities, e.g. <code>mean(X)</code> for estimation of <code class="reqn">\mu</code>.
</p>


<h3>Value</h3>

<p>Three animated plots can be created simultaneously.  The first plot shows the normal, Poisson, exponential, binomial, or custom log-likelihood functions.  The second plot shows the pdf with ML estimates for parameters.
On this graph densities of observations are plotted as pdf parameters are varied.  By default these two graphs will be created simultaneously on a single graphics device.
By specifying <code>plot.calc = TRUE</code> a third plot can also be created which shows that log-likelihood is the sum of the log-densities.
Animation in this third plot will be automatically sped up, using a primitive routine, for large datasets, and slowed for small datasets.
The third plot will not be created for the binomial pdf because there will only be a single outcome from the perspective of likelihood (e.g. 10 successes out of 22 trials).
The second and third plots will not be created for custom likelihood functions.
The function <code>anm.loglik.tck()</code> runs <code>anm.loglik()</code> from a <span class="pkg">tcltk</span> GUI.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dnorm">dnorm</a></code>, <code><a href="stats.html#topic+dpois">dpois</a></code>, <code><a href="stats.html#topic+dexp">dexp</a></code>, <code><a href="stats.html#topic+dbinom">dbinom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
##Normal log likelihood estimation of mu.
X&lt;-c(11.2,10.8,9.0,12.4,12.1,10.3,10.4,10.6,9.3,11.8)
anm.loglik(X,dist="norm",parameter="mu")

##Add a plot describing log-likelihood calculation.
anm.loglik(X,dist="norm",parameter="mu",plot.calc=TRUE)

##Normal log likelihood estimation of sigma squared.
X&lt;-c(11.2,10.8,9.0,12.4,12.1,10.3,10.4,10.6,9.3,11.8)
anm.loglik(X,dist="norm",parameter="sigma.sq")

##Exponential log likelihood estimation of theta
X&lt;-c(0.82,0.32,0.14,0.41,0.09,0.32,0.74,4.17,0.36,1.80,0.74,0.07,0.45,2.33,0.21,
0.79,0.29,0.75,3.45)
anm.loglik(X,dist="exp")

##Poisson log likelihood estimation of lambda.
X&lt;-c(1,3,4,0,2,3,4,3,5)
anm.loglik(X,dist="poi")

##Binomial log likelihood estimation of p.
X&lt;-c(1,1,0,0,0,1,0,0,0,0)#where 1 = a success
anm.loglik(X,dist="bin",interval=.2)

##Custom log-likelihood function
func&lt;-function(X=NULL,theta)theta^5*(1-theta)^10
anm.loglik(X=NULL,func=func,dist="custom",poss=seq(0,1,0.01),
xlab="Possibilities",ylab="Log-likelihood")

##Interactive GUI, requires package 'tcltk'
anm.loglik.tck()

## End(Not run)
</code></pre>

<hr>
<h2 id='anm.ls'>
Animated plot of least squares function.
</h2><span id='topic+anm.ls'></span><span id='topic+anm.ls.tck'></span>

<h3>Description</h3>

<p>Depicts the process of least squares estimation by plotting the least squares function with respect to a vector of estimate possibilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.ls(X, poss=NULL, parameter = "mu", est.lty = 2, est.col = 2,
conv=diff(range(X))/50, anim=TRUE, plot.lsfunc = TRUE, plot.res = TRUE, 
interval=0.01, xlab=expression(paste("Estimates for ", italic(E),
"(",italic(X),")", sep = "")),...)

anm.ls.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.ls_+3A_x">X</code></td>
<td>

<p>A numeric vector containing sample data.
</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_poss">poss</code></td>
<td>

<p>An ordered numeric sequence of possible parameter estimates.  Inclusion of the least squares estimate in the vector (e.g. <code class="reqn">\bar{X}</code> for <code class="reqn">\mu</code> will cause the least squares function be minimized at this value.
</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_parameter">parameter</code></td>
<td>

<p>Parameter to be estimated.  Only estimation for <em>E</em>(<em>X</em>) is currently implemented.  Note that if  <em>X</em> ~ <em>N</em>(<code class="reqn">\mu</code>,<code class="reqn">\sigma^2</code>) then <em>E</em>(<em>X</em>) =  <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_est.lty">est.lty</code></td>
<td>

<p>Line type to be used to indicate the least squares estimate.
</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_est.col">est.col</code></td>
<td>

<p>Line color to be used to indicate the least squares estimate.
</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_conv">conv</code></td>
<td>
<p>Precision of LS function.  Decreasing <code>conv</code> increases the smoothness and precision of the function.</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_anim">anim</code></td>
<td>
<p>A logical command indicating whether animation should be used in plots.</p>
</td></tr>  
<tr><td><code id="anm.ls_+3A_plot.lsfunc">plot.lsfunc</code></td>
<td>
<p>A logical command indicating whether the least-squares function should be plotted.</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_plot.res">plot.res</code></td>
<td>
<p>A logical command indicating whether a plot of residuals should be created.</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_interval">interval</code></td>
<td>
<p>Speed of animation (in frames per second).  A smaller interval decreases speed.  May not work in all systems; see <code><a href="base.html#topic+Sys.sleep">Sys.sleep</a></code>.</p>
</td></tr> 
<tr><td><code id="anm.ls_+3A_xlab">xlab</code></td>
<td>
<p><em>X</em>-axis label.</p>
</td></tr>
<tr><td><code id="anm.ls_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the least squares function is returned along with the least squares estimate for E(<em>X</em>) given a set of possibilities.  The function <code>anm.ls.tck</code> provides a GUI to run the function.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+loglik.plot">loglik.plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: X&lt;-c(11.2,10.8,9.0,12.4,12.1,10.3,10.4,10.6,9.3,11.8)
anm.ls(X)
## End(Not run)
</code></pre>

<hr>
<h2 id='anm.ls.reg'>
Animated plot of the least squares function.
</h2><span id='topic+anm.ls.reg'></span><span id='topic+anm.ls.reg.tck'></span>

<h3>Description</h3>

<p>Depicts the process of least squares estimation of simple linear regression parameters by plotting the least squares function with respect to estimate possibilities for the intercept or slope.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
anm.ls.reg(X, Y, parameter="slope", nmax=50, interval = 0.1, col = "red",...)

anm.ls.reg.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.ls.reg_+3A_x">X</code></td>
<td>

<p>A numeric vector containing explanatory data.
</p>
</td></tr>
<tr><td><code id="anm.ls.reg_+3A_y">Y</code></td>
<td>

<p>A numeric vector containing response data.
</p>
</td></tr>
<tr><td><code id="anm.ls.reg_+3A_parameter">parameter</code></td>
<td>

<p>Parameter to be estimated.  Either <code>"slope"</code> or <code>"intercept"</code>.</p>
</td></tr>
<tr><td><code id="anm.ls.reg_+3A_nmax">nmax</code></td>
<td>
<p>The number of parameter estimates to be depicted.  The true LS estimate will always be in the center of this sequence.</p>
</td></tr>
<tr><td><code id="anm.ls.reg_+3A_interval">interval</code></td>
<td>
<p>Speed of animation (in frames per second).  A smaller interval decreases speed.  May not work in all systems; see <code><a href="base.html#topic+Sys.sleep">Sys.sleep</a></code>.</p>
</td></tr> 
<tr><td><code id="anm.ls.reg_+3A_col">col</code></td>
<td>
<p>Line color.</p>
</td></tr>
<tr><td><code id="anm.ls.reg_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An animated plot of the plot possible regression lines is created along with an animated plot of the residual sum of squares. The function <code>anm.ls.reg.tck</code> provides a GUI to run the function.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+loglik.plot">loglik.plot</a></code>, <code><a href="#topic+anm.ls">anm.ls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
X&lt;-c(11.2,10.8,9.0,12.4,12.1,10.3,10.4,10.6,9.3,11.8)
Y&lt;-log(X)
anm.ls.reg(X, Y, parameter = "slope")
## End(Not run)
</code></pre>

<hr>
<h2 id='anm.LV'>Animated depictions of Lotka-Volterra competition and exploitation models
</h2><span id='topic+anm.LVcomp'></span><span id='topic+anm.LVexp'></span><span id='topic+anm.LVc.tck'></span><span id='topic+anm.LVe.tck'></span>

<h3>Description</h3>

<p>Creates animated plots of two famous abundance models from ecology; the Lotka-Volterra competition and exploitation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anm.LVcomp(n1, n2, r1, r2, K1, K2, a2.1, a1.2, time = seq(0, 200), ylab =
"Abundance", xlab = "Time", interval = 0.1, ...)

anm.LVexp(nh, np, rh, con, p, d.p, time = seq(0, 200), ylab = "Abundance",
xlab = "Time", interval = 0.1, circle = FALSE, ...)

anm.LVc.tck()

anm.LVe.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.LV_+3A_n1">n1</code></td>
<td>
<p>Initial abundance values for species one.  To be used in the competition function <code>anm.LVcomp</code>, i.e., <code class="reqn">N_1</code> in the competition equations below.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_n2">n2</code></td>
<td>
<p>Initial abundance values for species two in the competition function, i.e., <code class="reqn">N_2</code> in the competition equations below.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_r1">r1</code></td>
<td>
<p>Maximum intrinsic rate of increase for species one, i.e., <code class="reqn">r_{max1}</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_r2">r2</code></td>
<td>
<p>Maximum intrinsic rate of increase for species two in the competition model <code>anm.LVcomp</code>, i.e., <code class="reqn">r_{max2}</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_k1">K1</code></td>
<td>
<p>Carrying capacity for species one, i.e., <code class="reqn">K_1</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_k2">K2</code></td>
<td>
<p>Carrying capacity for species two, i.e., <code class="reqn">K_2</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_a2.1">a2.1</code></td>
<td>
<p>The interspecific effect of species one on species two, i.e., the term <code class="reqn">\alpha_{21}</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_a1.2">a1.2</code></td>
<td>
<p>The interspecific effect of species two on species one, i.e., the term <code class="reqn">\alpha_{12}</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_nh">nh</code></td>
<td>
<p>Initial abundance values for the host (prey) species.  To be used in the the exploitation model <code>anm.LVexp</code>, i.e., the term <code class="reqn">N_h</code> at <code class="reqn">t = 1</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_np">np</code></td>
<td>
<p>Initial abundance values for the predator species in the the exploitation model, i.e., the term <code class="reqn">N_p</code> at <code class="reqn">t = 1</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_rh">rh</code></td>
<td>
<p>The intrinsic rate of increase for the host (prey) species, i.e., the term <code class="reqn">r_h</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_con">con</code></td>
<td>
<p>The conversion rate of prey to predator, i.e., the term <code class="reqn">c</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_p">p</code></td>
<td>
<p>The predation rate, i.e., the term <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_d.p">d.p</code></td>
<td>
<p>The death rate of predators, i.e., the term <code class="reqn">d_p</code>.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_time">time</code></td>
<td>
<p>A time sequence for which competition or exploitation is to be evaluated.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_ylab">ylab</code></td>
<td>
<p><em>Y</em>-axis label.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_xlab">xlab</code></td>
<td>
<p><em>X</em>-axis label.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_interval">interval</code></td>
<td>
<p>Animation speed per frame (in seconds).</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_circle">circle</code></td>
<td>
<p>Logical, if <code>TRUE</code> a circular representation of the relation of prey and predator numbers is drawn.</p>
</td></tr>
<tr><td><code id="anm.LV_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lotka-Volterra competition and exploitation models require simultaneous solutions for two differential equations.  These are solved using the function <code>rk4</code> from <code>odesolve</code>.
</p>
<p>The interspecific competition model is based on:
</p>
<p style="text-align: center;"><code class="reqn">\frac{dN_1}{dt}=r_{max1}N_1\frac{K_1-N_1-\alpha_{12}}{K_1},</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{dN_2}{dt}=r_{max2}N_2\frac{K_2-N_2-\alpha_{21}}{K_2},</code>
</p>

<p>where <code class="reqn">N_1</code> is the number of individuals from species one, <code class="reqn">K_1</code> is the carrying capacity for species one, <code class="reqn">r_{max1}</code> is the maximum intrinsic rate of increase of species one, and <code class="reqn">\alpha_{12}</code> is the interspecific competitive effect of species two on species one.
</p>
<p>The exploitation model is based on:
</p>
<p style="text-align: center;"><code class="reqn">\frac{dN_h}{dt} = r_hN_h-pN_hN_p,</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{dN_p}{dt} = cpN_hN_p-d_pN_p,</code>
</p>

<p>where <code class="reqn">N_h</code> is the number of individuals from the host (prey) species, <code class="reqn">N_p</code> is the number of individuals from the predator species, <code class="reqn">r_h</code> is the intrinsic rate of increase for the host (prey) species, <code class="reqn">p</code> is the rate of predation, <code class="reqn">c</code> is a conversion factor which describes the rate at which prey are converted to new predators, and <code class="reqn">d_p</code> is the death rate of the predators.
</p>
<p>The term <code class="reqn">r_hN_h</code> describes exponential growth for the host (prey) species.  This will be opposed by deaths due to predation, i.e. the term <code class="reqn">pN_hN_p</code>.  The term <code class="reqn">cpN_hN_p</code> is the rate at which predators destroy prey. This in turn will be opposed by <code class="reqn">d_pN_p</code>, i.e. predator deaths.  . The functions <code>anm.LVe.tck()</code> and <code>anm.LVc.tck()</code> allow one to run <code>anm.LVe()</code> and <code>anm.LVc()</code>  with <span class="pkg">tcltk</span> GUIs.
</p>


<h3>Value</h3>

<p>The functions return descriptive animated plots</p>


<h3>Author(s)</h3>

<p>Ken Aho, based on a concept elucidated by M. Crawley</p>


<h3>References</h3>

<p>Molles, M. C. (2010) <em>Ecology, Concepts and Applications, 5th edition</em>.  McGraw Hill.
</p>
<p>Crawley, M. J.  (2007) <em>The R Book</em>.  Wiley
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#---------------------- Competition ---------------------#
##Species 2 drives species 1 to extinction
anm.LVcomp(n1=150,n2=50,r1=.7,r2=.8,K1=200,K2=1000,a2.1=.5,a1.2=.7,time=seq(0,200))
##Species coexist with numbers below carrying capacities
anm.LVcomp(n1=150,n2=50,r1=.7,r2=.8,K1=750,K2=1000,a2.1=.5,a1.2=.7,time=seq(0,200))

#----------------------Exploitation----------------------#
#Fast cycles
anm.LVexp(nh=300,np=50,rh=.7,con=.4,p=.006,d.p=.2,time=seq(0,200))
## End(Not run)
</code></pre>

<hr>
<h2 id='anm.mc.bvn'>
Animation of Markov Chain Monte Carlo walks in bivariate normal space
</h2><span id='topic+anm.mc.bvn'></span><span id='topic+anm.mc.norm'></span><span id='topic+anm.mc.bvn.tck'></span>

<h3>Description</h3>

<p>The algorithm can use three different variants on MCMC random walks: Gibbs sampling, the Metropolis algorithm, and the Metropolis-Hastings algorithms to move through univariate <code>anm.mc.norm</code> and bivariate normal probability space.  The jumping distribution is also bivariate normal with a mean vector at the current bivariate coordinates.  The jumping kernel modifies the jumping distribution through multiplying the variance covariance of this distribution by the specified constant. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anm.mc.bvn(start = c(-4, -4), mu = c(0, 0), sigma = matrix(2, 2, data = c(1, 0,
 0, 1)), length = 1000, sim = "M", jump.kernel = 0.2, xlim = c(-4, 4),
 ylim = c(-4, 4), interval = 0.01, show.leg = TRUE, cex.leg = 1, ...)

anm.mc.norm(start = -4, mu = 0, sigma = 1, length = 2000, sim = "M",
 jump.kernel = 0.2, xlim = c(-4, 4), ylim = c(0, 0.4), interval = 0.01,
 show.leg = TRUE,...)

anm.mc.bvn.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.mc.bvn_+3A_start">start</code></td>
<td>

<p>A two element vector specifying the bivariate starting coordinates.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_mu">mu</code></td>
<td>

<p>A two element vector specifying the mean vector for the proposal distribution.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_sigma">sigma</code></td>
<td>

<p>A 2 x 2 matrix specifying the variance covariance matrix for the proposal distribution.    
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_length">length</code></td>
<td>

<p>The length of the MCMC chain.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_sim">sim</code></td>
<td>

<p>Simulation method used.  Must be one of <code>"G"</code> indicating Gibbs sampling, <code>"M"</code> indicating the Metropolis algorithm, or <code>"MH"</code> indicating the Metropolis-Hastings algorithm (Gibbs sampling is not implemented for <code>anm.mc.norm</code>).
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_jump.kernel">jump.kernel</code></td>
<td>

<p>A number &gt; 0 that will serve as a (squared) multiplier for the proposal variance covariance.  The result of this multiplication will be used as the variance covariance matrix for the jumping distribution.   
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_xlim">xlim</code></td>
<td>

<p>A two element vector describing the upper and lower limits of the <em>x</em>-axis.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_ylim">ylim</code></td>
<td>

<p>A two element vector describing the upper and lower limits of the <em>y</em>-axis.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_interval">interval</code></td>
<td>

<p>Animation interval
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_show.leg">show.leg</code></td>
<td>

<p>Logical.  Indicating whether or not the chain length should be shown.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_cex.leg">cex.leg</code></td>
<td>

<p>Character expansion for legend.
</p>
</td></tr>
<tr><td><code id="anm.mc.bvn_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns two plots.  These are: 1) the proposal bivariate normal distribution in which darker shading indicates higher density, and 2) an animated plot showing the MCMC algorithm walking through the probability space.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Gelman, A., Carlin, J. B., Stern, H. S., and D. B. Rubin (2003)  <em>Bayesian Data Analysis, 2nd edition</em>.  Chapman and Hall/CRC. 
</p>

<hr>
<h2 id='anm.samp.design'>Animated demonstration of randomized sampling designs</h2><span id='topic+anm.samp.design'></span><span id='topic+samp.design'></span><span id='topic+anm.samp.design.tck'></span>

<h3>Description</h3>

<p>Animated Comparisons of outcomes from simple random sampling, stratified random sampling and cluster sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anm.samp.design(n=20, interval = 0.5 ,iter = 30, main = "", lwd = 2, lcol = 2)

samp.design(n = 20, main = "", lwd = 2, lcol = 2)

anm.samp.design.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anm.samp.design_+3A_n">n</code></td>
<td>
<p>The number of samples to be randomly selected from a population of 400.</p>
</td></tr>
<tr><td><code id="anm.samp.design_+3A_interval">interval</code></td>
<td>
<p>Time length spent on each frame in animation (in seconds).</p>
</td></tr>
<tr><td><code id="anm.samp.design_+3A_iter">iter</code></td>
<td>
<p>Number of random iterations in animation.</p>
</td></tr>
<tr><td><code id="anm.samp.design_+3A_main">main</code></td>
<td>
<p>Main heading.</p>
</td></tr>
<tr><td><code id="anm.samp.design_+3A_lwd">lwd</code></td>
<td>
<p>Line width to distinguish strata in stratified and cluster designs.</p>
</td></tr>
<tr><td><code id="anm.samp.design_+3A_lcol">lcol</code></td>
<td>
<p>Line width to distinguish strata in stratified and cluster designs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a plot comparing outcomes of random sampling, stratified random sampling and cluster sampling from a population
of size 400.  For stratified random sampling the population is subdivided into four equally strata of size 100.
and <code>n</code>/4 samples are taken within each strata.  For cluster sampling the population is subdivided into four
equally sized clusters and a census is taken from two clusters (regardless of specification of <code>n</code>).   The function <code>anm.samp.design</code> depicts random sampling using animation</p>


<h3>Value</h3>

<p>A plot is returned with four subplots.  (a) shows the population before sampling, (b) shows simple random sampling, (c) shows stratified random sampling, (d) shows cluster sampling.  The function <code>anm.samp.design.tck</code> provides interactivity with a <span class="pkg">tcltk</span> GUI.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>Examples</h3>

<pre><code class='language-R'>samp.design(20)

#Animated demonstration
## Not run: anm.samp.design(20)
</code></pre>

<hr>
<h2 id='anolis'>
Anolis lizard contingency table data
</h2><span id='topic+anolis'></span>

<h3>Description</h3>

<p>Schoener (1968) examined the resource partitioning of anolis lizards on the Caribbean island of South Bimini.  
He cross-classified lizard counts in habitats (branches in trees) with respect to three variables: 
lizard species <em>A. sargei</em> and <em>A. distichus</em>, branch height (high and low), and branch size (small and large).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(anolis)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 4 variables.
</p>

<dl>
<dt><code>height</code></dt><dd><p>Brach height.  A factor with levels <code>H</code>, <code>L</code>.</p>
</dd>
<dt><code>size</code></dt><dd><p>Brach size.  A factor with levels <code>L</code>, <code>S</code>.</p>
</dd>
<dt><code>species</code></dt><dd><p>Anolis species. A factor with levels <code>distichus</code>, <code>sagrei</code>.</p>
</dd>
<dt><code>count</code></dt><dd><p>Count at the cross classification.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Schoener, T. W.  (1968)  The Anolis lizards of Bimini: resource partitioning in a complex fauna.  
<em>Ecology</em> 49(4): 704-726.
</p>

<hr>
<h2 id='anscombe'>
Anscombe's quartet
</h2><span id='topic+anscombe'></span>

<h3>Description</h3>

<p>A set of four bivariate datasets with the same conditional means, conditional variances, linear regressions, and correlations, but with dramatically different forms of association. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(anscombe)</code></pre>


<h3>Format</h3>

<p>A data frame with 11 observations on the following 8 variables.
</p>

<dl>
<dt><code>x1</code></dt><dd><p>The first conditional variable in the first bivariate dataset.</p>
</dd>
<dt><code>y1</code></dt><dd><p>The second conditional variable in the first bivariate dataset.</p>
</dd>
<dt><code>x2</code></dt><dd><p>The first conditional variable in the second bivariate dataset.</p>
</dd>
<dt><code>y2</code></dt><dd><p>The second conditional variable in the second bivariate dataset.</p>
</dd>
<dt><code>x3</code></dt><dd><p>The first conditional variable in the third bivariate dataset.</p>
</dd>
<dt><code>y3</code></dt><dd><p>The second conditional variable in the third bivariate dataset.</p>
</dd>
<dt><code>x4</code></dt><dd><p>The first conditional variable in the fourth bivariate dataset.</p>
</dd>
<dt><code>y4</code></dt><dd><p>The second conditional variable in the fourth bivariate dataset.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Anscombe (1973) used these datasets to demonstrate that summary statistics are inadequate for describing association.
</p>


<h3>Source</h3>

<p>Anscombe, F. J.  (1973)  Graphs in statistical analysis. <em>American Statistician</em> 27 (1): 17-21.
</p>


<h3>References</h3>

<p>Anscombe, F. J.  (1973)  Graphs in statistical analysis. <em>American Statistician</em> 27 (1): 17-21.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># dev.new(height=3.5)
op &lt;- par(mfrow=c(1,4),mar=c (0,0,2,3), oma = c(5, 4.2, 0, 0))
with(anscombe, plot(x1, y1, xlab = "", ylab = "", main = bquote(paste(italic(r),
" = ",.(round(cor(x1, y1),2)))))); abline(3,0.5) 
with(anscombe, plot(x2, y2, xlab = "", ylab = "",, main = bquote(paste(italic(r),
" = ",.(round(cor(x2, y2),2)))))); abline(3,0.5) 
with(anscombe, plot(x3, y3, xlab = "", ylab = "",, main = bquote(paste(italic(r),
" = ",.(round(cor(x3, y3),2)))))); abline(3,0.5) 
with(anscombe, plot(x4, y4, xlab = "", ylab = "",, main = bquote(paste(italic(r),
" = ",.(round(cor(x4, y4),2)))))); abline(3,0.5) 
mtext(expression(italic(y[1])),side=1, outer = TRUE, line = 3)
mtext(expression(italic(y[2])),side=2, outer = TRUE, line = 2.6)
mtext("(a)",side=3, at = -42, line = .5)
mtext("(b)",side=3, at = -26, line = .5)
mtext("(c)",side=3, at = -10.3, line = .5)
mtext("(d)",side=3, at = 5.5, line = .5)
par(op)
</code></pre>

<hr>
<h2 id='ant.dew'>
Ant honeydew data
</h2><span id='topic+ant.dew'></span>

<h3>Description</h3>

<p>Wright et al. (2000) examined behavior of red wood ants (<em>Formica rufa</em>), a species that harvests honeydew in aphids.  
Worker ants traveled from their nests to nearby trees to forage honeydew from homopterans.  Ants descending trees were laden with food and weighed more, given a particular ant head width, then unladen, ascending ants.  
The authors were interested in comparing regression parameters of the ascending and descending ants to create a predictive model of honeydew foraging load for a given ant size.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ant.dew)</code></pre>


<h3>Format</h3>

<p>A data frame with 72 observations on the following 3 variables.
</p>

<dl>
<dt><code>head.width</code></dt><dd><p>Ant head width in mm</p>
</dd>
<dt><code>ant.mass</code></dt><dd><p>Ant mass in mg</p>
</dd>
<dt><code>direction</code></dt><dd><p>Direction of travel <code>A</code> = ascending, <code>D</code> = descending</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data approximated from Fig. 1 in Wright et al. (2002)
</p>


<h3>Source</h3>

<p>Wright, P. J., Bonser, R., and U. O. Chukwu  (2000) The size-distance relationship in the 
wood ant <em>Formica rufa</em>. <em>Ecological Entomology</em> 25(2): 226-233.
</p>

<hr>
<h2 id='AP.test'>Agresti-Pendergrast test</h2><span id='topic+AP.test'></span>

<h3>Description</h3>

<p>Provides a more powerful alternative to Friedman's test for blocked (dependent) data with a single replicate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AP.test(Y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AP.test_+3A_y">Y</code></td>
<td>
<p>A matrix with treatments in columns and blocks (e.g. subjects) in rows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Agresti-Pendergrast test is more powerful than Friedman's test, given normality, and remains powerful in heavier tailed distributions (Wilcox 2005).  
</p>


<h3>Value</h3>

<p>Returns a dataframe showing the numerator and denominator degrees of freedom, <em>F</em> test statistic, and <em>p</em>-value.
</p>


<h3>Note</h3>

<p>code based on Wilcox (2005).</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Wilcox, R. R.  (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+friedman.test">friedman.test</a></code>, <code><a href="#topic+MS.test">MS.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>temp&lt;-c(2.58,2.63,2.62,2.85,3.01,2.7,2.83,3.15,3.43,3.47,2.78,2.71,3.02,3.14,3.35,
2.36,2.49,2.58,2.86,3.1,2.67,2.96,3.08,3.32,3.41,2.43,2.5,2.85,3.06,3.07)
Y&lt;- matrix(nrow=6,ncol=5,data=temp,byrow=TRUE)
AP.test(Y)</code></pre>

<hr>
<h2 id='asthma'>Asthma repeated measures dataset from Littell et al. (2002)</h2><span id='topic+asthma'></span>

<h3>Description</h3>

<p>This dataset was used by Littell (2002) to demonstrate repeated measures analyses.  The effect of two asthma drugs and a placebo were measured on 24 asthmatic patients.  Each patient was randomly given each drug using an approach to minimize carry-over effects. Forced expiratory volume (FEV1), the volume of air that can be expired after taking a deep breath in one second, was measured.  FEV1 was measured hourly for eight hours following application of the drug.  A baseline measure of FEV1 was also taken 11 hours before application of the treatment.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(asthma)</code></pre>


<h3>Format</h3>

<p>The dataframe has 11 columns:
</p>

<dl>
<dt><code>PATIENT</code></dt><dd><p>The subjects (there were 24 patients).</p>
</dd>
<dt><code>BASEFEV1</code></dt><dd><p>A numerical variable; the baseline forced expiratory volume.</p>
</dd> 
<dt><code>FEV11H</code></dt><dd><p>Forced expiratory volume at 11 hours.</p>
</dd>
<dt><code>FEV12H</code></dt><dd><p>Forced expiratory volume at 12 hours.</p>
</dd>
<dt><code>FEV13H</code></dt><dd><p>Forced expiratory volume at 13 hours.</p>
</dd>
<dt><code>FEV14H</code></dt><dd><p>Forced expiratory volume at 14 hours.</p>
</dd>
<dt><code>FEV15H</code></dt><dd><p>Forced expiratory volume at 15 hours.</p>
</dd>
<dt><code>FEV16H</code></dt><dd><p>Forced expiratory volume at 16 hours.</p>
</dd>
<dt><code>FEV17H</code></dt><dd><p>Forced expiratory volume at 17 hours.</p>
</dd>
<dt><code>FEV18H</code></dt><dd><p>Forced expiratory volume at 18 hours.</p>
</dd>
<dt><code>DRUG</code></dt><dd><p>A factor with three levels <code>"a"</code> = a standard drug treatment, <code>"c"</code> = the drug under development, and <code>"p"</code> = a placebo.</p>
</dd>   	
</dl>



<h3>Source</h3>

<p>Littell, R. C., Stroup, W. W., and R. J. Freund (2002)  <em>SAS for Linear Models</em>.  John 
Wiley and Associates.
</p>

<hr>
<h2 id='auc'>
Area under a receiver operating characteristic (ROC) curve
</h2><span id='topic+auc'></span>

<h3>Description</h3>

<p>A simple algorithm for calculating <em>AUC</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
auc(obs, fit, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auc_+3A_obs">obs</code></td>
<td>

<p>Dichotomous <code>0, 1</code> outcomes (i.e., response values for binomial GLM).
</p>
</td></tr>
<tr><td><code id="auc_+3A_fit">fit</code></td>
<td>

<p>Fitted probabilities from some model.
</p>
</td></tr>
<tr><td><code id="auc_+3A_plot">plot</code></td>
<td>

<p>Logical, indicating whether or not ROC curve plot should be created.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Agresti, A.  (2012) <em>Categorical Data Analysis, 3rd edition</em>.  New York.  Wiley. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
obs &lt;-rbinom(30, 1, 0.5)
fit &lt;- rbeta(30, 1, 2)
auc(obs, fit)
## End(Not run)
</code></pre>

<hr>
<h2 id='baby.walk'>
Baby walking times experimental data
</h2><span id='topic+baby.walk'></span>

<h3>Description</h3>

<p>In general, mammals are able to walk within minutes or hours after birth.  
Human babies, however, generally don't begin to walk until they are between 10 and 18 months of age.  
This occurs because, although humans are born with rudimentary reflexes for walking, they are 
unused, and thus largely disappear by the age of eight weeks.  As a result 
these movements must be relearned by an infant following significant passage of time, 
through a process of trial and error.  Zelazo et al. (1972) performed a series of experiments 
to determine whether certain exercises could allow infants to maintain their walking reflexes, 
and allow them to walk at an earlier age.  Study subjects were 24 white male infants from middle class families, and were assigned to one of four exercise treatments.
</p>
<p>Active exercise (AE): Parents were taught and were told to apply exercises that 
would strengthen the walking reflexes of their infant.   
Passive exercise (PE): Parents were taught and told to apply exercises unrelated to walking.
Test-only (TO):  The investigators did not specify any exercise, but visited and tested the walking reflexes of infants in weeks 1 through 8.  Passive and active exercise infants were also tested in this way.  
Control (C):  No exercises were specified, and infants were only tested at weeks one and eight.  This group was established to account for the potential effect of the walking reflex tests themselves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(baby.walk)</code></pre>


<h3>Format</h3>

<p>A data frame with 22 observations on the following 2 variables.
</p>

<dl>
<dt><code>date</code></dt><dd><p>Age when baby first started walking (in months)</p>
</dd>
<dt><code>treatment</code></dt><dd><p>A factor with levels <code>AE</code> <code>C</code> <code>PE</code> <code>TO</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Ott, R. L., and M. T. Longnecker 2004  <em>A First Course in Statistical Methods</em>.  
Thompson.
</p>


<h3>References</h3>

<p>Zelazo, P. R., Zelazo, N. A., and S. Kolb.  1972.  Walking in the newborn.  <em>Science</em> 176: 
314-315.
</p>

<hr>
<h2 id='bats'>Bat forearm length as a function of bat age</h2><span id='topic+bats'></span>

<h3>Description</h3>

<p>Data from northern myotis bats (<em>Myotis septentrionalis</em>) captured in the field in Vermillion County Indiana in 2000.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bats)</code></pre>


<h3>Format</h3>

<p>The dataframe has 2 columns:
</p>

<dl>
<dt><code>days</code></dt><dd><p>The age of the bats in days.</p>
</dd>
<dt><code>forearm.length</code></dt><dd><p>The length of the forearm in millimeters.</p>
</dd> 
</dl>



<h3>Source</h3>

<p>Krochmal, A. R., and D. W. Sparks (2007)  <em>Journal of Mammalogy</em>. 88(3): 649-656.
</p>

<hr>
<h2 id='Bayes.disc'>
Bayesian graphical summaries for discrete or categorical data.
</h2><span id='topic+Bayes.disc'></span><span id='topic+Bayes.disc.tck'></span>

<h3>Description</h3>

<p>An simple function for for summarizing a Bayesian analysis given discrete or categorical variables and priors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Bayes.disc(Likelihood, Prior, data.name = "data", plot = TRUE, 
c.data = seq(1, length(Prior)), ...)

Bayes.disc.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bayes.disc_+3A_likelihood">Likelihood</code></td>
<td>
<p>A vector of sample distribution probabilities.  This must be in the same order as <code>Prior</code>, i.e. if <code class="reqn">\theta_1</code> is the first element in <code>Prior</code>, then <code class="reqn">data|\theta_1</code> must be the first element in <code>Data</code>.
</p>
</td></tr>
<tr><td><code id="Bayes.disc_+3A_prior">Prior</code></td>
<td>

<p>A vector of prior probabilities, or weights.
</p>
</td></tr>
<tr><td><code id="Bayes.disc_+3A_data.name">data.name</code></td>
<td>
<p>A name for data in conditional statements.
</p>
</td></tr>
<tr><td><code id="Bayes.disc_+3A_plot">plot</code></td>
<td>

<p>Logical, indicating whether a plot should be made.
</p>
</td></tr>
<tr><td><code id="Bayes.disc_+3A_c.data">c.data</code></td>
<td>

<p>A character string of names for discrete classes
</p>
</td></tr>
<tr><td><code id="Bayes.disc_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='bayes.lm'>
Bayesian linear models with uniform priors 
</h2><span id='topic+bayes.lm'></span><span id='topic+print.blm'></span>

<h3>Description</h3>

<p>Gelman et al. (2002) describe general methods for Bayesian implementation of simple linear models (e.g. simple and multiple regression and fixed effect one way ANOVA) with standard non-informative priors uniform on <code class="reqn">\alpha, \sigma^2</code>. The function is not yet suited for multifactor or multivariance (random effect) ANOVAs. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
bayes.lm(Y, X, model = "anova", length = 1000, cred = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes.lm_+3A_y">Y</code></td>
<td>

<p>An <em>n</em> x <em>1</em> column vector (a matrix with one column) containing the response variable.
</p>
</td></tr>
<tr><td><code id="bayes.lm_+3A_x">X</code></td>
<td>

<p>The <em>n</em> x <em>p</em> design matrix
</p>
</td></tr>
<tr><td><code id="bayes.lm_+3A_model">model</code></td>
<td>

<p>One of <code>"anova"</code> or <code>"reg"</code>.  Parameter output labels are changed depending on choice. 
</p>
</td></tr>
<tr><td><code id="bayes.lm_+3A_length">length</code></td>
<td>

<p>Number of draws for posterior. 
</p>
</td></tr>
<tr><td><code id="bayes.lm_+3A_cred">cred</code></td>
<td>

<p>Level for credible interval. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Provides the median and central credible intervals for model parameters.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Gelman, A., Carlin, J. B., Stern, H. S., and D. B. Rubin  (2003)  <em>Bayesian Data Analysis, 2nd edition</em>.  Chapman and Hall/CRC. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcmc.norm.hier">mcmc.norm.hier</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(Fbird)
X &lt;- with(Fbird, cbind(rep(1, 18), vol))
Y &lt;- Fbird$freq
bayes.lm(Y, X, model = "reg")

## End(Not run)
</code></pre>

<hr>
<h2 id='BCI.count'>Barro Colorado Island Tree Counts</h2><span id='topic+BCI.count'></span>

<h3>Description</h3>

<p>This dataset, lifted from <span class="pkg">vegan</span>, contains tree counts in 1-hectare plots in Barro Colorado Island, Panama.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BCI.count)</code></pre>


<h3>Format</h3>

<p>A data frame with 50 plots (rows) of 1 hectare with counts of trees on each
plot with total of 225 species (columns). Full Latin names are used
for tree species.
</p>


<h3>Details</h3>

<p>Data give the numbers of trees at least 10 cm in
diameter at breast height (1.3 m above the ground) in each one hectare
square of forest. Within each one hectare square, all individuals of
all species were tallied and are recorded in this table.
</p>
<p>The data frame contains only the Barro Colorado Island subset of the
original data.
</p>
<p>The quadrats are located in a regular grid. See <code>examples</code> for the
coordinates. 
</p>


<h3>Source</h3>

<p>Condit et al. (2002). Data documentation here follows directly from <span class="pkg">vegan</span>.
</p>


<h3>References</h3>

<p>Condit, R, Pitman, N, Leigh, E.G., Chave, J., Terborgh, J., Foster,
R.B., Nuñez, P., Aguilar, S., Valencia, R., Villa, G., Muller-Landau,
H.C., Losos, E. &amp; Hubbell, S.P. (2002). Beta-diversity in tropical
forest trees. <em>Science</em> 295, 666&ndash;669.
</p>

<hr>
<h2 id='BCI.plant'>
Tree presence/absence data from Barro Colorado island
</h2><span id='topic+BCI.plant'></span>

<h3>Description</h3>

<p>The presence of the tropical trees <em>Alchornea costaricensis</em> and <em>Anacardium excelsum</em> with diameter at breast height equal or larger than 10 cm were recorded on along with environmental factors at Barro Colorado Island in Panama (Kindt and Coe 2005).  These data were originally from (Pyke et al. 2001). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BCI.plant)</code></pre>


<h3>Format</h3>

<p>A data frame with 43 observations on the following 9 variables.
</p>

<dl>
<dt><code>site.no.</code></dt><dd><p>A factor with levels <code>C1</code> <code>C2</code> <code>C3</code> <code>C4</code> <code>p1</code> <code>p10</code> <code>p11</code> <code>p12</code> <code>p13</code> <code>p14</code> <code>p15</code> <code>p16</code> <code>p17</code> <code>p18</code> <code>p19</code> <code>p2</code> <code>p20</code> <code>p21</code> <code>p22</code> <code>p23</code> <code>p24</code> <code>p25</code> <code>p26</code> <code>p27</code> <code>p28</code> <code>p29</code> <code>p3</code> <code>p30</code> <code>p31</code> <code>p32</code> <code>p33</code> <code>p34</code> <code>p35</code> <code>p36</code> <code>p37</code> <code>p38</code> <code>p39</code> <code>p4</code> <code>p5</code> <code>p6</code> <code>p7</code> <code>p8</code> <code>p9</code></p>
</dd>
<dt><code>UTM.E</code></dt><dd><p>UTM easting.</p>
</dd>
<dt><code>UTM.N</code></dt><dd><p>UTM northing.</p>
</dd>
<dt><code>precip</code></dt><dd><p>Precipitation in mm/year.</p>
</dd>
<dt><code>elev</code></dt><dd><p>Elevation in m above sea level.</p>
</dd>
<dt><code>age</code></dt><dd><p>A categorical vector describing age.</p>
</dd>
<dt><code>geology</code></dt><dd><p>A factor describing geology with levels <code>pT</code> <code>Tb</code> <code>Tbo</code> <code>Tc</code> <code>Tcm</code> <code>Tct</code> <code>Tgo</code> <code>Tl</code> <code>Tlc</code>.</p>
</dd>
<dt><code>Alchornea.costaricensis</code></dt><dd><p>Plant presence/absence.</p>
</dd>
<dt><code>Anacardium.excelsum</code></dt><dd><p>Plant presence/absence.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Condit et al. (2002), Kindt et al. (2005).
</p>


<h3>References</h3>

<p>Condit, R, Pitman, N, Leigh, E.G., Chave, J., Terborgh, J., Foster, 
R.B., Nunez, P., Aguilar, S., Valencia, R., Villa, G., Muller-Landau,
H.C., Losos, E. &amp; Hubbell, S.P. (2002). Beta-diversity in tropical
forest trees. <em>Science</em> 295, 666&ndash;669.
</p>
<p>Kindt, R. &amp; Coe, R. (2005) Tree diversity analysis: A manual and software for common   statistical methods for ecological and biodiversity studies from the <span class="pkg">BiodiversityR</span> package.
</p>
<p>Pyke CR, Condit R, Aguilar S and Lao S. (2001). Floristic composition across a climatic gradient in a neotropical lowland forest. <em>Journal of Vegetation Science</em> 12: 553-566.
</p>

<hr>
<h2 id='BDM.test'>Brunner-Dette-Munk test</h2><span id='topic+BDM.test'></span><span id='topic+BDM.2way'></span><span id='topic+print.BDM'></span>

<h3>Description</h3>

<p>One and two way heteroscedastic rank-based permutation tests.  Two way designs are assumed to be factorial, i.e., interactions are tested.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
BDM.test(Y, X)

BDM.2way(Y, X1, X2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BDM.test_+3A_y">Y</code></td>
<td>
<p>Vector of response data.  A quantitative vector</p>
</td></tr>
<tr><td><code id="BDM.test_+3A_x">X</code></td>
<td>
<p>A vector of factor levels for a one-way analysis.  To be used with <code>BDM.test</code></p>
</td></tr>
<tr><td><code id="BDM.test_+3A_x1">X1</code></td>
<td>
<p>A vector of factor levels for the first factor in a two-way factorial design.  To be used with <code>BDM.2way</code>.</p>
</td></tr>
<tr><td><code id="BDM.test_+3A_x2">X2</code></td>
<td>
<p>A vector of factor levels for the second factor in a two-way factorial design.  To be used with <code>BDM.2way</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A problem with the Kruskal-Wallis test is that, while it does not assume normality for groups, it still assumes homoscedasticity 
(i.e. the groups have the same distributional shape).  As a solution Brunner et al. (1997) proposed a heteroscedastic version of 
the Kruskal-Wallis test which utilizes the <em>F</em>-distribution.  Along with being robust to non-normality and heteroscedasticity, 
calculations of exact <em>P</em>-values using the Brunner-Dette-Munk method are not made more complex by tied values.  
This is another obvious advantage over the traditional Kruskal-Wallis approach.    
</p>


<h3>Value</h3>

<p>Returns a list with two components
</p>
<table role = "presentation">
<tr><td><code>Q</code></td>
<td>
<p>The &quot;relative effects&quot; for each group.</p>
</td></tr>
<tr><td><code>Table</code></td>
<td>
<p>An ANOVA type table with hypothesis test results.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Code based on Wilcox (2005)
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Brunner, E., Dette, H., and A. Munk (1997)  Box-type approximations in nonparametric 
factorial designs.  <em>Journal of the American Statistical Association</em>.  92: 1494-1502.
</p>
<p>Wilcox, R. R.  (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kruskal.test">kruskal.test</a></code>, <code><a href="#topic+trim.test">trim.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>rye&lt;-c(50,49.8,52.3,44.5,62.3,74.8,72.5,80.2,47.6,39.5,47.7,50.7)
nutrient&lt;-factor(c(rep(1,4),rep(2,4),rep(3,4)))
BDM.test(Y=rye,X=nutrient)
</code></pre>

<hr>
<h2 id='bear'>Grizzly bear litter sizes
</h2><span id='topic+bear'></span>

<h3>Description</h3>

<p>Counts of grizzly bear (<em>Ursus arctos</em>) litter sizes from the Greater Yellowstone Ecosystem from 1973-2010.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bear)</code></pre>


<h3>Format</h3>

<p>A data frame with 38 observations on the following 5 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>Year.</p>
</dd>
<dt><code>X1.cub</code></dt><dd><p>The number of litters with one cub.</p>
</dd>
<dt><code>X2.cub</code></dt><dd><p>The number of litters with two cubs.</p>
</dd>
<dt><code>X3.cub</code></dt><dd><p>The number of litters with three cubs.</p>
</dd>
<dt><code>X4.cub</code></dt><dd><p>The number of litters with four cubs.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Haroldson, M. A (2010)  Assessing trend and estimating population size from counts of 
unduplicated females. Pgs 10-15 in Schwartz, C. C., Haroldson, M. A., and K. West editors.  
<em>Yellowstone grizzly bear investigations: annual report of the Interagency grizzly bear study team, 2010</em>.  U. S. Geological Survey, Bozeman, MT. 
</p>

<hr>
<h2 id='beetle'>
Wood boring beetle data
</h2><span id='topic+beetle'></span>

<h3>Description</h3>

<p>Saint Germain et al. (2007) modeled the presence absence of a saprophytic wood boring beetle (<em>Anthophylax attenuatus</em>) as a function of the wood density of twenty-four decaying aspen trees (<em>Populus tremuloides</em>) in Western Quebec Canada.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(beetle)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 4 variables.
</p>

<dl>
<dt><code>Snag</code></dt><dd><p>Snag identifier</p>
</dd>
<dt><code>Yrs.since.death</code></dt><dd><p>The number of years since death, determined using dendrochronological methods.</p>
</dd>
<dt><code>Wood.density</code></dt><dd><p>The density of the decaying wood (dry weight/volume) in units of g cm<code class="reqn">-3</code>.</p>
</dd>
<dt><code>ANAT</code></dt><dd><p>Beetle presence/absence (1/0)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Saint-Germain, M., Drapeau, P., and C. Buddle  (2007)  Occurrence patterns of aspen-
feeding wood-borers (Coleoptera: Cerambycidae) along the wood decay
gradient: active selection for specific host types or neutral mechanisms? <em>Ecological Entomology</em>  32: 712-721.
</p>

<hr>
<h2 id='best.agreement'>
Determine agreement of two classifications
</h2><span id='topic+best.agreement'></span><span id='topic+print.max_agree'></span>

<h3>Description</h3>

<p>Distinct classifications will have class labels that may prevent straightforward comparisons.  This algorithm considers all possible permutations of class labels to find a configuration that maximizes agreement on the diagonal of a contingency table comparing two classifications.  Classifications need not have the same number of classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
best.agreement(class1, class2, test = FALSE, rperm = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="best.agreement_+3A_class1">class1</code></td>
<td>
<p>A vector containing class assignments to observations, e.g., a result from <code><a href="stats.html#topic+cutree">cutree</a></code></p>
</td></tr>
<tr><td><code id="best.agreement_+3A_class2">class2</code></td>
<td>
<p>A vector containing class assignments for a second classification</p>
</td></tr>
<tr><td><code id="best.agreement_+3A_test">test</code></td>
<td>
<p>Logical.  Indicates whether or not the null hypothesis, that agreement between <code>class1</code> and <code>class2</code> is no better than random, will be run. </p>
</td></tr>
<tr><td><code id="best.agreement_+3A_rperm">rperm</code></td>
<td>
<p>If <code>test = TRUE</code>, the number of random permutations used in null hypothesis testing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Class assignments are fixed in <code>class1</code>, all possible permutations of class labels in <code>class2</code> are considered to find a configuration that maximizes agreement in the two classifications.  If <code>test=TRUE</code>, a permutation test is run for the null hypothesis that maximum agreement between classifications is no better than random.  This is done by sampling without replacement <code>rperm</code> times from <code>class2</code>, finding maximum agreement between <code>class1</code> and the randomly permuted classifications, and dividing one plus the number of times that maximum agreement between the random classifications and <code>class1</code> was greater than the maximum agreement observed for <code>class1</code> and <code>class2</code>.  Testing can be slow because it will be based on nested loops with <code class="reqn">p x c!</code> steps, where <em>p</em> is <code>nperm</code> and <em>c!</em> is the number of combinatorial permutations possible for categories in <code>class2</code>. 
</p>


<h3>Value</h3>

<p>A object of class <code>max_agree</code>.
</p>
<table role = "presentation">
<tr><td><code>n.possible.perms</code></td>
<td>
<p>Number of permutations considered</p>
</td></tr>
<tr><td><code>n.max.solutions</code></td>
<td>
<p>Number of configurations in which classification agreement is maximized.  The first configuration identified is reported in <code>max.class.names1</code> and <code>max.class.names2</code>.</p>
</td></tr>
<tr><td><code>max.agree</code></td>
<td>
<p>Proportion of observations assigned to the same cluster</p>
</td></tr>
<tr><td><code>max.class.names1</code></td>
<td>
<p>Class labels in the first classification that allow maximum agreement.</p>
</td></tr>
<tr><td><code>max.class.names2</code></td>
<td>
<p>Class labels in the second classification that allow maximum agreement.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>Whether or not test was run.</p>
</td></tr>
<tr><td><code>p.val</code></td>
<td>
<p>If <code>test = TRUE</code>, the <em>p</em>-value for the null hypothesis test described in Details above.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho.  The internal <code>permutations</code> algorithm for obtaining all possible permutations was provided by Benjamin Christoffersen on <em>stackoverflow</em>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cutree">cutree</a></code>, <code><a href="stats.html#topic+hclust">hclust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example comparing a 4 cluster average-linkage solution 
# and a 5 cluster Ward-linakage solution 

avg &lt;- hclust(dist(USArrests), "ave")
avg.4 &lt;- as.matrix(cutree(avg, k = 4))
war &lt;- hclust(dist(USArrests), "ward.D")
war.5 &lt;- as.matrix(cutree(war, k = 5))

ba &lt;- best.agreement(avg.4, war.5, test = TRUE)
ba
</code></pre>

<hr>
<h2 id='bin2dec'>
Conversion between binary digits and decimal numbers 
</h2><span id='topic+bin2dec'></span><span id='topic+dec2bin'></span>

<h3>Description</h3>

<p>The function <code>bin2dec</code> Converts binary representations to digital numbers (e.g., 10101011 = 171).  Fractions, (e.g., 0.11101) will be evaluated to the number of bits provided. The function will not handle codification of whole numbers with fractional parts. The function <code>dec2bin</code> Converts decimal representations to binary and can handle whole numbers, fractional, and numbers with both whole and fractional parts.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bin2dec(digits, round = 4)

dec2bin(num, max.bits = 10, max.rep0 = 6)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bin2dec_+3A_digits">digits</code></td>
<td>

<p>A string of binary digits.
</p>
</td></tr>
<tr><td><code id="bin2dec_+3A_round">round</code></td>
<td>

<p>Rounding for fractional results, defaults to 4.
</p>
</td></tr>
<tr><td><code id="bin2dec_+3A_num">num</code></td>
<td>

<p>A decimal number.
</p>
</td></tr>
<tr><td><code id="bin2dec_+3A_max.bits">max.bits</code></td>
<td>

<p>The maximum number of bits to be used to approximate fractional numbers.
</p>
</td></tr>
<tr><td><code id="bin2dec_+3A_max.rep0">max.rep0</code></td>
<td>

<p>A handler for meaningless repeating zeroes at the end of some binary representations of decimal numbers, e.g., 0.25. Can be turned off by letting <code>max.rep0 = NULL</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a decimal number with fractional, or both whole and fractional parts is provided to <code>dec2bin</code>, a vector with seperate binary expressions for each of these components is returned. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bin2dec(1011001101) #=717
dec2bin(717)
</code></pre>

<hr>
<h2 id='bombus'>Bombus pollen data.
</h2><span id='topic+bombus'></span>

<h3>Description</h3>

<p>To investigate how pollen removal varied with reproductive caste in bemblebees (<em>Bombus</em> sp.) Harder and Thompson (1989) recorded the proportion of pollen removed by thirty five bumblebee queens and twelve worker bees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bombus)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>pollen</code></dt><dd>
<p>A numeric vector indicating the proportion of pollen removed.
</p>
</dd>
<dt><code>caste</code></dt><dd>
<p>A character string vector indicating whether a bee was a worker <code>"W"</code> or a queen <code>"Q"</code>.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Harder, L. D. and Thompson, J. D.  1989.  Evolutionary options for maximizing pollen dispersal in animal pollinated plants.  <em>American Naturalist</em> 133: 323-344.
</p>

<hr>
<h2 id='bone'>
Bone development data
</h2><span id='topic+bone'></span>

<h3>Description</h3>

<p>Neter et al. (1996) described an experiment in which researchers investigated the confounding effect of gender and bone development on growth hormone therapy for prepubescent children.  Gender had two levels: &quot;M&quot; and &quot;F&quot;.  
The bone development factor had three levels indicating the severity of growth impediment before therapy: 1 = severely depressed, 2 = moderately depressed, and 3 = mildly depressed.  
At the start of the experiment 3 children were assigned to each of the six treatment combinations. However 4 of the children were unable to complete the experiment, resulting in an unbalanced design.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bone)</code></pre>


<h3>Format</h3>

<p>A data frame with 14 observations on the following 3 variables.
</p>

<dl>
<dt><code>gender</code></dt><dd><p>A factor with levels <code>F</code> <code>M</code></p>
</dd>
<dt><code>devel</code></dt><dd><p>A factor with levels <code>1</code> <code>2</code> <code>3</code></p>
</dd>
<dt><code>growth</code></dt><dd><p>A numeric vector descibing the growth difference before and after hormone therapy</p>
</dd>
</dl>



<h3>Source</h3>

<p>Neter, J., Kutner, M. H., Nachtsheim, C. J., and Wasserman, W  (1996)  <em>Applied Linear Statistical Models</em>.  McGraw-Hill, Boston MA, USA. 
</p>

<hr>
<h2 id='book.menu'>Pulldown menus for 'asbio' interactive graphical functions
</h2><span id='topic+book.menu'></span>

<h3>Description</h3>

<p>Provides a pulldown GUI menus to allow access to <span class="pkg">asbio</span> statistical and biological graphical demos, e.g. <code><a href="#topic+anm.ci">anm.ci</a></code>, <code><a href="#topic+samp.dist">samp.dist</a></code>, <code><a href="#topic+anm.loglik">anm.loglik</a></code>, etc.  The function <code>demos</code> is deprecated.  The function <code>book.menu</code> currently provides links to over 100 distinct GUIs (many of these are slaves to other GUIs), which in turn provide distinct graphical demonstrations. The GUIs work best with an SDI R interface.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>book.menu()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho and Roy Hill (Roy created the <code>book.menu</code> GUI)</p>


<h3>See Also</h3>

<p><code><a href="#topic+anm.coin">anm.coin</a></code>,  <code><a href="#topic+anm.ci">anm.ci</a></code>,  <code><a href="#topic+anm.die">anm.die</a></code>,  <code><a href="#topic+anm.exp.growth">anm.exp.growth</a></code>,  <code><a href="#topic+anm.geo.growth">anm.geo.growth</a></code>,  <code><a href="#topic+anm.log.growth">anm.log.growth</a></code>, <code><a href="#topic+anm.loglik">anm.loglik</a></code>,  <code><a href="#topic+anm.LVcomp">anm.LVcomp</a></code>,  <code><a href="#topic+anm.LVexp">anm.LVexp</a></code>,  <code><a href="#topic+anm.ls">anm.ls</a></code>,  <code><a href="#topic+anm.ls.reg">anm.ls.reg</a></code>,  <code><a href="#topic+anm.transM">anm.transM</a></code>, <code><a href="#topic+see.lmu.tck">see.lmu.tck</a></code>, <code><a href="#topic+samp.dist">samp.dist</a></code>, <code><a href="#topic+see.HW">see.HW</a></code>,  <code><a href="#topic+see.logic">see.logic</a></code>,  <code><a href="#topic+see.M">see.M</a></code>,   <code><a href="#topic+see.move">see.move</a></code>, <code><a href="#topic+see.nlm">see.nlm</a></code>, <code><a href="#topic+see.norm.tck">see.norm.tck</a></code>,  <code><a href="#topic+see.power">see.power</a></code>,  <code><a href="#topic+see.regression.tck">see.regression.tck</a></code>,   <code><a href="#topic+see.typeI_II">see.typeI_II</a></code>, <code><a href="#topic+selftest.se.tck1">selftest.se.tck1</a></code>,  <code><a href="#topic+shade.norm">shade.norm</a></code>, <code><a href="#topic+Venn">Venn</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
book.menu()

## End(Not run)
</code></pre>

<hr>
<h2 id='boot.ci.M'>Bootstrap CI of M-estimators differences of two samples</h2><span id='topic+boot.ci.M'></span><span id='topic+print.bci'></span>

<h3>Description</h3>

<p>Creates a bootstrap confidence interval for location differences for two samples.  The default location
estimator is the Huber one-step estimator, although any estimator can be used.  The function is based on 
a function written by Wilcox (2005).  Note, importantly, that <em>P</em>-values may be in conflict with the confidence interval bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.ci.M(X1, X2, alpha = 0.05, est = huber.one.step, R = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot.ci.M_+3A_x1">X1</code></td>
<td>
<p>Sample from population one.</p>
</td></tr>
<tr><td><code id="boot.ci.M_+3A_x2">X2</code></td>
<td>
<p>Sample from population two.</p>
</td></tr>
<tr><td><code id="boot.ci.M_+3A_alpha">alpha</code></td>
<td>
<p>Significance level.</p>
</td></tr>
<tr><td><code id="boot.ci.M_+3A_est">est</code></td>
<td>
<p>Location estimator; default is the Huber one step estimator.</p>
</td></tr>
<tr><td><code id="boot.ci.M_+3A_r">R</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with one component, a dataframe containing summary information from the analysis:  
</p>
<table role = "presentation">
<tr><td><code>R.used</code></td>
<td>
<p>The number of bootstrap samples used.  This may not = <code>R</code> if <code>NAs</code> occur because <em>MAD</em> = 0.</p>
</td></tr> 
<tr><td><code>ci.type</code></td>
<td>
<p>The method used to construct the confidence interval.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>The level of confidence used.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>The bootstrap distribution of differences standard error.</p>
</td></tr>
<tr><td><code>original</code></td>
<td>
<p>The original, observed difference.</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>Lower confidence bound.</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>Upper confidence bound.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho and R. R. Wilcox from whom I stole liberally from code in the function <code>m2ci</code> on R-forge</p>


<h3>References</h3>

<p>Manly, B. F. J.  (1997)  <em>Randomization and Monte Carlo methods in Biology, 2nd edition</em>.  
Chapman and Hall, London.
</p>
<p>Wilcox, R. R. (2005) <em>Introduction to Robust Estimation and Hypothesis Testing, 2nd edition</em>.  Elsevier, 
Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrap">bootstrap</a></code>, <code><a href="#topic+ci.boot">ci.boot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
X1&lt;-rnorm(100,2,2.5)
X2&lt;-rnorm(100,3,3)
boot.ci.M(X1,X2)

## End(Not run)
</code></pre>

<hr>
<h2 id='bootstrap'>A simple function for bootstrapping</h2><span id='topic+bootstrap'></span><span id='topic+print.bootstrap'></span>

<h3>Description</h3>

<p>The function serves as a simplified alternative to the function <code><a href="boot.html#topic+boot">boot</a></code> from the library <code>boot</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap(data, statistic, R = 1000, prob = NULL, matrix = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrap_+3A_data">data</code></td>
<td>
<p>Raw data to be bootstrapped.  A vector or quantitative data or a matrix if <code>matrix =TRUE</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_statistic">statistic</code></td>
<td>
<p>A function whose output is a statistic (e.g. a sample mean).  The function must have only one argument, a call to data.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_r">R</code></td>
<td>
<p>The number of bootstrap iterations.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_prob">prob</code></td>
<td>
<p>A vector of probability weights for paramteric bootstrapping.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_matrix">matrix</code></td>
<td>
<p>A logical statement.  If <code>matrix = TRUE</code> then rows in the matrix are sampled as multivariate observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With bootstrapping we sample with replacement from a dataset of size <em>n</em> with n samples <code>R</code> times. At each of the <code>R</code> iterations a statistical summary can be created resulting in a bootstrap distribution of statistics.</p>


<h3>Value</h3>

<p>Returns a list.  The utility function <code>asbio:::print.bootstrap</code> returns summary output.  Invisible items include the resampling distribution of the statistic, the data, the statistic, and the bootstrap samples.  
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Manly, B. F. J.  (1997)  <em>Randomization and Monte Carlo Methods in Biology, 2nd edition</em>.  
Chapman and Hall, London.
</p>


<h3>See Also</h3>

<p><code><a href="boot.html#topic+boot">boot</a></code>, <code><a href="#topic+ci.boot">ci.boot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(vs)
# A partial set of observations from a single plot for a Scandinavian 
# moss/vascular plant/lichen survey.
site18&lt;-t(vs[1,])

#Shannon-Weiner diversity
SW&lt;-function(data){
d&lt;-data[data!=0]
p&lt;-d/sum(d)
-1*sum(p*log(p))
}

bootstrap(site18[,1],SW,R=1000,matrix=FALSE)
</code></pre>

<hr>
<h2 id='bound.angle'>
Angle of azimuth to a boundary.
</h2><span id='topic+bound.angle'></span>

<h3>Description</h3>

<p>The function calculates the angle of azimuth from a Cartesian coordination given in <code>X</code> and <code>Y</code> to a nearest neighbor coordinate 
given by <code>nX</code> and <code>nY</code>.  The nearest neighbor coordinates can be obtained using the function <code><a href="#topic+near.bound">near.bound</a></code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bound.angle(X, Y, nX, nY)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bound.angle_+3A_x">X</code></td>
<td>
<p>Cartesian <em>X</em> coordinate of interest.  
</p>
</td></tr>
<tr><td><code id="bound.angle_+3A_y">Y</code></td>
<td>
<p>Cartesian <em>Y</em> coordinate of interest.
</p>
</td></tr>
<tr><td><code id="bound.angle_+3A_nx">nX</code></td>
<td>
<p>Cartesian <em>X</em> coordinate of nearest neighbor point on a boundary.
</p>
</td></tr>
<tr><td><code id="bound.angle_+3A_ny">nY</code></td>
<td>
<p>Cartesian <em>Y</em> coordinate of nearest neighbor point on a boundary. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the nearest neighbor angles (in degrees) with respect to a four coordinate system ala ARC-GIS Near(Analysis).  
Output angles range from <code class="reqn">-180^{\circ}</code> to <code class="reqn">180^{\circ}</code>: <code class="reqn">0^{\circ}</code> to the East, <code class="reqn">90^{\circ}</code> to the North, <code class="reqn">180^{\circ}</code> (or <code class="reqn">-180^{\circ}</code>) to the West,
and <code class="reqn">-90^{\circ}</code> to the South.  
</p>


<h3>Value</h3>

<p>Returns a vector of nearest neighbor angles.</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="#topic+near.bound">near.bound</a></code>, <code><a href="#topic+prp">prp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>bX&lt;-seq(0,49)/46
bY&lt;-c(4.89000,4.88200,4.87400,4.87300,4.88000,4.87900,4.87900,4.90100,4.90800,
4.91000,4.93300,4.94000,4.91100,4.90000,4.91700,4.93000,4.93500,4.93700,
4.93300,4.94500,4.95900,4.95400,4.95100,4.95800,4.95810,4.95811,4.95810,
4.96100,4.96200,4.96300,4.96500,4.96500,4.96600,4.96700,4.96540,4.96400,
4.97600,4.97900,4.98000,4.98000,4.98100,4.97900,4.98000,4.97800,4.97600,
4.97700,4.97400,4.97300,4.97100,4.97000)

X&lt;-c(0.004166667,0.108333333,0.316666667,0.525000000,0.483333333,0.608333333,
0.662500000,0.683333333,0.900000000,1.070833333)
Y&lt;-c(4.67,4.25,4.26,4.50,4.90,4.10,4.70,4.40,4.20,4.30)
nn&lt;-near.bound(X,Y,bX,bY)

bound.angle(X,Y,nn[,1],nn[,2])
</code></pre>

<hr>
<h2 id='bplot'>
Barplots with error bars (including interval plots)
</h2><span id='topic+bplot'></span>

<h3>Description</h3>

<p>Creates barplots for displaying statistical summaries by treatment (e.g. means, medians, <em>M</em>-estimates of location, standard deviation, variance, etc.) and 
their error estimates by treatment (i.e. standard errors, confidence intervals, <em>IQR</em>s, <em>IQR</em> confidence intervals, and <em>MAD</em> intervals). Custom intervals can also be created.  
The function can also be used to display letters indicating if comparisons of locations are significant after adjustment for simultaneous inference (see <code><a href="#topic+pairw.anova">pairw.anova</a></code>, <code><a href="#topic+pairw.kw">pairw.kw</a></code>, and/or <code><a href="#topic+pairw.fried">pairw.fried</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bplot(y, x, bar.col = "gray", loc.meas = mean, sort = FALSE, order = NULL, int = "SE",
 conf = 0.95, uiw = NULL, liw = NULL, sfrac = 0.1, slty = 1, scol = 1,
 slwd = 1, exp.fact = 1.5, simlett = FALSE, lett.side = 3, lett = NULL,
 cex.lett = 1, names.arg = NULL, ylim = NULL, horiz = FALSE, xpd = FALSE, 
 print.summary = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bplot_+3A_y">y</code></td>
<td>
<p>A quantitative vector representing the response variable.</p>
</td></tr>
<tr><td><code id="bplot_+3A_x">x</code></td>
<td>
<p>A categorical vector representing treatments (e.g. factor levels).</p>
</td></tr>
<tr><td><code id="bplot_+3A_bar.col">bar.col</code></td>
<td>
<p>Color of bar.</p>
</td></tr>
<tr><td><code id="bplot_+3A_loc.meas">loc.meas</code></td>
<td>
<p>Measure of location or other summary statistic, e.g. mean, median, etc.</p>
</td></tr>
<tr><td><code id="bplot_+3A_sort">sort</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then treatments are ordered by their location statistics.</p>
</td></tr>
<tr><td><code id="bplot_+3A_order">order</code></td>
<td>
<p>A vector of length equal to the number of factor levels, specifying the order of bars with respect to the alphanumeric order of their names.</p>
</td></tr>
<tr><td><code id="bplot_+3A_int">int</code></td>
<td>
<p>Type of error bar to be drawn, must be one of <code>"SE"</code>, <code>"CI"</code>, <code><a href="stats.html#topic+IQR">IQR</a></code>, <code>"MAD"</code>, <code>"IQR.CI"</code> or <code>"bootSE"</code>.  IQR-derived confidence intervals are based on <code class="reqn">\pm-1.58 IQR/\sqrt{n}</code> and provide an approximate 95% confidence interval for the difference in two medians.  The measure can be attributed to Chambers et al. (1983, p. 62), given McGill et al. (1978, p. 16). It is based on asymptotic normality of the median and assumes roughly equal sample sizes for the two medians being compared.  The interval is apparently insensitive to the underlying distributions of the samples. The specification <code>"bootSE"</code> gives bootstrap SEs for the location measure using the function <code><a href="#topic+bootstrap">bootstrap</a></code></p>
</td></tr>
<tr><td><code id="bplot_+3A_conf">conf</code></td>
<td>
<p>Level of confidence, 1 - <em>P</em>(type I error).</p>
</td></tr>
<tr><td><code id="bplot_+3A_uiw">uiw</code></td>
<td>
<p>Upper <em>y</em>-coordinate for the error bar, if <code>NULL</code> then this will be computed from <code>int</code>.</p>
</td></tr> 
<tr><td><code id="bplot_+3A_liw">liw</code></td>
<td>
<p>Lower <em>y</em>-coordinate for the error bar, if <code>NULL</code> then this will be computed from <code>int</code>.</p>
</td></tr>  
<tr><td><code id="bplot_+3A_sfrac">sfrac</code></td>
<td>
<p>Scaling factor for the size of the &quot;serifs&quot; (end bars) on the confidence bars, in <em>x</em>-axis units.</p>
</td></tr>
<tr><td><code id="bplot_+3A_slty">slty</code></td>
<td>
<p>Line type for error bars.</p>
</td></tr>
<tr><td><code id="bplot_+3A_scol">scol</code></td>
<td>
<p>Line color for error bars.</p>
</td></tr>
<tr><td><code id="bplot_+3A_slwd">slwd</code></td>
<td>
<p>Line width for error bars.</p>
</td></tr>
<tr><td><code id="bplot_+3A_exp.fact">exp.fact</code></td>
<td>
<p>A multiplication factor indicating how much extra room is made for drawing letters in top of graph.  Only used if <code>simlett = TRUE</code>.</p>
</td></tr>
<tr><td><code id="bplot_+3A_simlett">simlett</code></td>
<td>
<p>A logical statement indicating whether or not letters should be shown above bars indicating that populations means have been determined to be significantly different. </p>
</td></tr>
<tr><td><code id="bplot_+3A_lett.side">lett.side</code></td>
<td>
<p>Side that letters will be drawn on, 1 = bottom, 2 = left, 3 = top, 4 = right.</p>
</td></tr>
<tr><td><code id="bplot_+3A_lett">lett</code></td>
<td>
<p>A vector of letters or some other code to display multiple comparison results.</p>
</td></tr>
<tr><td><code id="bplot_+3A_cex.lett">cex.lett</code></td>
<td>
<p>Character expansion for multiple comparison result letters.</p>
</td></tr>
<tr><td><code id="bplot_+3A_names.arg">names.arg</code></td>
<td>
<p>A vector of names to be plotted below each bar or error bar. If this argument is omitted, then the names are taken from the names attribute of <code>y</code>.</p>
</td></tr>
<tr><td><code id="bplot_+3A_ylim">ylim</code></td>
<td>
<p>Upper and lower limits of the <em>Y</em>-axis</p>
</td></tr>
<tr><td><code id="bplot_+3A_horiz">horiz</code></td>
<td>
<p>Logical value. If <code>FALSE</code>, then bars are drawn vertically with the first bar to the left. If <code>TRUE</code>, then bars are drawn horizontally with the first at the bottom.</p>
</td></tr>
<tr><td><code id="bplot_+3A_xpd">xpd</code></td>
<td>
<p>Logical value. If <code>FALSE</code>, this overrides <code><a href="graphics.html#topic+barplot">barplot</a></code> designation <code>xpd = TRUE</code>, which may cause bars to extend off the plot if <code>ylim</code> is modified.</p>
</td></tr>
<tr><td><code id="bplot_+3A_print.summary">print.summary</code></td>
<td>
<p>Logical value.  If <code>TRUE</code> a summary of the location and dispersion measures used in the plot is printed.</p>
</td></tr>
<tr><td><code id="bplot_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="graphics.html#topic+barplot">barplot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is often desirable to display the results of a pairwise comparison procedure using sample measures of location and error bars.  This functions allows these sorts of plots to be made. The function is essentially a wrapper for the function <code><a href="graphics.html#topic+barplot">barplot</a></code>.
</p>


<h3>Value</h3>

<p>A plot is returned.  Bar centers (ala <code><a href="graphics.html#topic+barplot">barplot</a></code>) are returned invisibly. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Chambers, J. M., Cleveland, W. S., Kleiner, B. and Tukey, P. A. (1983) <em>Graphical Methods for Data Analysis</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>McGill, R., Tukey, J. W. and Larsen, W. A. (1978) Variations of box plots. <em>The American Statistician</em> 32, 12-16.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mad">mad</a></code>, <code><a href="graphics.html#topic+barplot">barplot</a></code>, <code><a href="#topic+pairw.anova">pairw.anova</a></code>, <code><a href="#topic+pairw.kw">pairw.kw</a></code>, <code><a href="#topic+pairw.fried">pairw.fried</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>eggs&lt;-c(11,17,16,14,15,12,10,15,19,11,23,20,18,17,27,33,22,26,28)
trt&lt;-c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,4,4)
bplot(y=eggs, x=factor(trt),int="SE",xlab="Treatment",ylab="Mean number of eggs",
simlett=TRUE, lett=c("b","b","b","a"))
</code></pre>

<hr>
<h2 id='bromus'>Bromus tectorum dataset</h2><span id='topic+bromus'></span>

<h3>Description</h3>

<p>Cheatgrass (<em>Bromus tectorum</em>) is an introduced annual graminoid that has invaded vast areas of sagebrush steppe in the intermountain west. Because it completes its vegetative growth stage relatively early in the summer, it leaves behind senescent biomass that burns easily.  As a result areas with cheatgrass often experience a greater frequency of summer fires. A number of dominant shrub species in sagebrush steppe are poorly adapted to fire.   As a result, frequent fires can change a community formerly dominated by shrubs to one dominated by cheatgrass.  Nitrogen can also have a strong net positive effect on the cheatgrass biomass.  A study was conducted at the Barton Road Long Term Experimental Research site (LTER) in Pocatello Idaho to simultaneously examine the effect of shrub removal and nitrogen addition on graminoid productivity.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bromus)</code></pre>


<h3>Format</h3>

<p>The dataframe has 3 columns:
</p>

<dl>
<dt><code>Plot</code></dt><dd><p>Plot number.</p>
</dd>
<dt><code>Biomass</code></dt><dd><p>Grass biomass in grams per meter squared.</p>
</dd> 
<dt><code>Trt</code></dt><dd><p>Treatment.  <code>C</code> = Control, <code>LN</code> = Low nitrogen, <code>HN</code> = High Nitrogen, <code>SR</code> = Shrub removal.</p>
</dd>
</dl>


<hr>
<h2 id='bv.boxplot'>Bivariate boxplots</h2><span id='topic+bv.boxplot'></span>

<h3>Description</h3>

<p>Creates diagnostic bivariate quelplot ellipses (bivariate boxplots) using the method of Goldberg and Iglewicz (1992).  
The output can be used to check assumptions of bivariate normality and to identify multivariate outliers.  The default <code>robust=TRUE</code>
option relies on on a biweight correlation estimator function written by Everitt (2006).  Quelplots, 
are potentially asymmetric, although the method currently employed here uses a 
single &quot;fence&quot; definition and creates symmetric ellipses.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bv.boxplot(X, Y, robust = TRUE, D = 7, xlab = "X", ylab="Y", pch = 21, 
pch.out = NULL, bg = "gray", bg.out = NULL, hinge.col = 1, fence.col = 1, 
hinge.lty = 2, fence.lty = 3, xlim = NULL, ylim = NULL, names = 1:length(X), 
ID.out = FALSE, cex.ID.out = 0.7, uni.CI = FALSE, uni.conf = 0.95, 
uni.CI.col = 1, uni.CI.lty = 1, uni.CI.lwd = 2, show.points = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bv.boxplot_+3A_x">X</code></td>
<td>
<p>First of two quantitative variables making up the bivariate distribution.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_y">Y</code></td>
<td>
<p>Second of two quantitative variables making up the bivariate distribution.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_robust">robust</code></td>
<td>
<p>Logical.  Robust estimators, i.e. <code>robust = TRUE</code> are recommended.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_d">D</code></td>
<td>
<p>The default <code>D = 7</code> lets the fence be equal to a 99 percent confidence interval for an individual observation.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_xlab">xlab</code></td>
<td>
<p>Caption for <em>X</em> axis.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_ylab">ylab</code></td>
<td>
<p>Caption for <em>Y</em> axis.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_pch">pch</code></td>
<td>
<p>Plotting character(s) for scatterplot.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_pch.out">pch.out</code></td>
<td>
<p>Plotting character for outliers.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_hinge.col">hinge.col</code></td>
<td>
<p>Hinge color.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_fence.col">fence.col</code></td>
<td>
<p>Fence color.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_hinge.lty">hinge.lty</code></td>
<td>
<p>Hinge line type.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_fence.lty">fence.lty</code></td>
<td>
<p>Fence line type.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_xlim">xlim</code></td>
<td>
<p>A two element vector defining the <em>X</em>-limits of the plot.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_ylim">ylim</code></td>
<td>
<p>The <em>Y</em>-limits of the plot.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_bg">bg</code></td>
<td>
<p>Background color for points in scatterplot, defaults to black if <code>pch</code> is not in the range 21:26.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_bg.out">bg.out</code></td>
<td>
<p>Background color for outlying points in scatterplot, defaults to black if <code>pch</code> is not in the range 21:26.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_names">names</code></td>
<td>
<p>An optional vector of names for <em>X</em>, <em>Y</em> coordinates.</p>
</td></tr>  
<tr><td><code id="bv.boxplot_+3A_id.out">ID.out</code></td>
<td>
<p>Logical. Whether or not outlying points should be given labels (from argument <code>name</code> in plot.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_cex.id.out">cex.ID.out</code></td>
<td>
<p>Character expansion for outlying ID labels.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_uni.ci">uni.CI</code></td>
<td>
<p>Logical. If true, univariate confidence intervals for the true median at confidence <code>uni.CI</code> are shown.</p>
</td></tr>  
<tr><td><code id="bv.boxplot_+3A_uni.conf">uni.conf</code></td>
<td>
<p>Univariate confidence, only used if <code>CI.uni = TRUE</code>.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_uni.ci.col">uni.CI.col</code></td>
<td>
<p>Univariate confidence bound line color, only used if <code>CI.uni = TRUE</code>.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_uni.ci.lty">uni.CI.lty</code></td>
<td>
<p>Univariate confidence bound line type, only used if <code>CI.uni = TRUE</code>.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_uni.ci.lwd">uni.CI.lwd</code></td>
<td>
<p>Univariate confidence bound line width, only used if <code>CI.uni = TRUE</code>.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_show.points">show.points</code></td>
<td>
<p>Logical. Whether points should be shown in graph.</p>
</td></tr>
<tr><td><code id="bv.boxplot_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two ellipses are drawn.  The inner is the &quot;hinge&quot; which contains 50 percent of the data.  The outer is the &quot;fence&quot;.  
Observations outside of the &quot;fence&quot; constitute possible troublesome outliers.  
The function <code>bivariate</code> from Everitt (2004) is used to calculate robust biweight measures of correlation, scale, and location if <code>robust = TRUE</code> (the default). 
We have the following form to the quelplot model:
</p>
<p style="text-align: center;"><code class="reqn">E_i =
\sqrt{\frac{X^2_{si} + Y^2_{si} - 2R^*X_{si}Y_{si}}{1-R^{*2}}}.</code>
</p>

<p>where <code class="reqn">X_{si} = (X_i - T^*_X)/S^*_X</code>, and <code class="reqn">Y_{si} = (Y_i - T^*_X)/S^*_Y</code> are standardized values for <code class="reqn">X_i</code> and <code class="reqn">Y_i</code>, respectively,
<code class="reqn">T^*_X</code> and <code class="reqn">T^*_Y</code> are location estimators for <em>X</em> and <em>Y</em>, <code class="reqn">S^*_X</code> and <code class="reqn">S^*_Y</code> are scale estimators for 
<em>X</em> and <em>Y</em>, and <code class="reqn">R^*</code> is a correlation estimator for <em>X</em> and <em>Y</em>.  We have:
</p>
<p style="text-align: center;"><code class="reqn">E_m = median\{E_i:i=1,2,...,n\},</code>
</p>
  
<p>and
</p>
<p style="text-align: center;"><code class="reqn">E_{max} = max\{E_i: E_i^2 &lt; DE^2_m\}.</code>
</p>
 
<p>where <code class="reqn">D</code> is a constant that regulates the distance of the &quot;fence&quot; and &quot;hinge&quot;.
</p>
<p>To draw the &quot;hinge&quot; we have:
</p>
<p style="text-align: center;"><code class="reqn">R_1 = E_m\sqrt{\frac{1 + R^*}{2}},</code>
</p>

<p style="text-align: center;"><code class="reqn">R_2 = E_m\sqrt{\frac{1 - R^*}{2}}.</code>
</p>

<p>To draw the &quot;fence&quot; we have:
</p>
<p style="text-align: center;"><code class="reqn">R_1 = E_{max}\sqrt{\frac{1 + R^*}{2}},</code>
</p>

<p style="text-align: center;"><code class="reqn">R_2 = E_{max}\sqrt{\frac{1 - R^*}{2}}.</code>
</p>

<p>For <code class="reqn">\theta</code> = 0 to 360, let:
</p>
<p style="text-align: center;"><code class="reqn">\Theta_1 = R_1cos(\theta),</code>
</p>

<p style="text-align: center;"><code class="reqn">\Theta_2 = R_2sin(\theta).</code>
</p>

<p>The Cartesian coordinates of the &quot;hinge&quot; and &quot;fence&quot; are:
</p>
<p style="text-align: center;"><code class="reqn">X=T^*_X=(\Theta_1+\Theta_2)S^*_X,</code>
</p>

<p style="text-align: center;"><code class="reqn">Y=T^*_Y=(\Theta_1-\Theta_2)S^*_Y.</code>
</p>

<p>Quelplots, are potentially asymmetric, although the current (and only) method used here defines a single value for <code class="reqn">E_{max}</code> 
and hence creates symmetric ellipses.  Under this implementation at least one point will define <code class="reqn">E_{max}</code>, 
and lie on the &quot;fence&quot;.        
</p>


<h3>Value</h3>

<p>A diagnostic plot is returned.  Invisible objects from the function include location, scale and correlation estimates for <code class="reqn">X</code> and <code class="reqn">Y</code>, 
estimates for <code class="reqn">E_m</code> and <code class="reqn">E_{max}</code>, and a list of outliers (that exceed <code class="reqn">E_{max}</code>).
</p>


<h3>Author(s)</h3>

<p>Ken Aho, the function relies on an Everitt (2006) function for robust <em>M</em>-estimation.</p>


<h3>References</h3>

<p>Everitt, B.  (2006) <em>An R and S-plus Companion to Multivariate Analysis</em>.  Springer.
</p>
<p>Goldberg, K. M., and B. Ingelwicz  (1992)  Bivariate extensions of the boxplot.  
<em>Technometrics</em> 34: 307-320.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+boxplot">boxplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Y1&lt;-rnorm(100, 17, 3)
Y2&lt;-rnorm(100, 13, 2)
bv.boxplot(Y1, Y2)

X &lt;- c(-0.24, 2.53, -0.3, -0.26, 0.021, 0.81, -0.85, -0.95, 1.0, 0.89, 0.59, 
0.61, -1.79, 0.60, -0.05, 0.39, -0.94, -0.89, -0.37, 0.18)
Y &lt;- c(-0.83, -1.44, 0.33, -0.41, -1.0, 0.53, -0.72, 0.33,  0.27, -0.99, 0.15, 
-1.17, -0.61, 0.37, -0.96, 0.21, -1.29, 1.40, -0.21, 0.39)
b &lt;- bv.boxplot(X, Y, ID.out = TRUE, bg.out = "red")
b
</code></pre>

<hr>
<h2 id='bvn.plot'>
Make plots of bivariate normal distributions
</h2><span id='topic+bvn.plot'></span>

<h3>Description</h3>

<p>The function uses functions from <span class="pkg">lattice</span> and <span class="pkg">mvtnorm</span> to make wireframe plots of bivariate normal distributions.  Remember that the covariance
must be less than the product of the marginal standard deviations (square roots of the diagonal elements).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvn.plot(mu = c(0, 0), cv = 0, vr = c(1, 1), res = 0.3, xlab = expression(y[1]),
ylab = expression(y[2]), zlab = expression(paste("f(", y[1], ",", y[2], ")")), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bvn.plot_+3A_mu">mu</code></td>
<td>

<p>A vector containing the joint distribution means.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_cv">cv</code></td>
<td>

<p>A number, indicating the covariance of the two variables.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_vr">vr</code></td>
<td>

<p>The diagonal elements in the variance covariance matrix.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_res">res</code></td>
<td>

<p>Plot resolution.  Smaller values create a more detailed wireframe plot.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_xlab">xlab</code></td>
<td>

<p><em>X</em>-axis label.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_ylab">ylab</code></td>
<td>

<p><em>Y</em>-axis label.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_zlab">zlab</code></td>
<td>

<p><em>Z</em>-axis label.
</p>
</td></tr>
<tr><td><code id="bvn.plot_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code><a href="lattice.html#topic+wireframe">wireframe</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='C.isotope'>
Atmospheric carbon and D14C measurements
</h2><span id='topic+C.isotope'></span>

<h3>Description</h3>

<p>Atmospheric <code class="reqn">\delta ^{14}</code>C (per mille) and CO<code class="reqn">_2</code> (ppm) measurements for La Jolla Pier, California. Latitude: 32.9 Degrees N, Longitude: 117.3 Degrees W, Elevation: 10m; <code class="reqn">\delta</code> <code class="reqn">^{14}</code>C derived from flask air samples      
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(C.isotope)</code></pre>


<h3>Format</h3>

<p>A data frame with 280 observations on the following 5 variables.
</p>

<dl>
<dt><code>Date</code></dt><dd><p>a factor with levels <code> 01-Apr-96</code> <code> 01-Jul-92</code> <code> 01-Jul-93</code> <code> 02-Apr-01</code> <code> 02-Feb-96</code> <code> 02-Nov-94</code> <code> 02-Oct-92</code> <code> 03-Aug-06</code> <code> 03-Aug-92</code> <code> 03-Jan-95</code> <code> 03-Jan-97</code> <code> 03-Jul-95</code> <code> 03-Mar-93</code> <code> 03-May-05</code> <code> 03-May-96</code> <code> 03-Nov-05</code> <code> 04-Apr-94</code> <code> 04-Jun-01</code> <code> 04-Jun-03</code> <code> 04-Mar-03</code> <code> 04-May-01</code> <code> 04-May-07</code> <code> 04-Sep-96</code> <code> 05-Aug-96</code> <code> 05-Jul-05</code> <code> 05-Jun-00</code> <code> 05-Sep-00</code> <code> 06-Aug-02</code> <code> 06-Oct-06</code> <code> 06-Sep-01</code> <code> 06-Sep-07</code> <code> 07-Apr-05</code> <code> 07-Apr-95</code> <code> 07-Aug-07</code> <code> 07-Dec-07</code> <code> 07-Feb-01</code> <code> 07-Feb-03</code> <code> 07-Feb-05</code> <code> 07-Jun-07</code> <code> 07-Mar-01</code> <code> 07-Sep-05</code> <code> 08-Feb-94</code> <code> 08-Feb-95</code> <code> 08-Feb-99</code> <code> 08-Jan-01</code> <code> 08-Jun-95</code> <code> 08-Sep-99</code> <code> 09-Dec-01</code> <code> 09-Feb-93</code> <code> 09-Jan-02</code> <code> 09-Jun-04</code> <code> 09-Nov-00</code> <code> 09-Nov-02</code> <code> 09-Nov-06</code> <code> 09-Sep-02</code> <code> 09-Sep-03</code> <code> 09-Sep-92</code> <code> 10-Apr-03</code> <code> 10-Aug-01</code> <code> 10-Aug-97</code> <code> 10-Aug-99</code> <code> 10-Jan-98</code> <code> 10-Jun-02</code> <code> 10-Nov-95</code> <code> 10-Oct-00</code> <code> 10-Oct-04</code> <code> 10-Oct-97</code> <code> 11-Dec-92</code> <code> 11-Feb-00</code> <code> 11-Jan-07</code> <code> 11-Jan-93</code> <code> 11-Mar-94</code> <code> 11-Mar-96</code> <code> 11-Nov-93</code> <code> 11-Oct-02</code> <code> 12-Apr-93</code> <code> 12-Apr-99</code> <code> 12-Aug-93</code> <code> 12-Jul-02</code> <code> 12-Jun-06</code> <code> 12-Oct-07</code> <code> 13-Feb-98</code> <code> 13-Jan-98</code> <code> 13-Jun-01</code> <code> 13-Mar-95</code> <code> 13-May-02</code> <code> 13-Sep-06</code> <code> 14-Apr-00</code> <code> 14-Aug-00</code> <code> 14-Dec-98</code> <code> 14-Feb-03</code> <code> 14-Jul-00</code> <code> 14-Sep-04</code> <code> 15-Dec-93</code> <code> 15-Feb-06</code> <code> 15-Feb-95</code> <code> 15-May-95</code> <code> 15-Oct-99</code> <code> 16-Apr-96</code> <code> 16-Jul-01</code> <code> 16-Jun-00</code> <code> 16-Nov-03</code> <code> 16-Nov-99</code> <code> 16-Oct-95</code> <code> 17-Dec-02</code> <code> 17-Feb-02</code> <code> 17-Feb-97</code> <code> 17-Jul-06</code> <code> 17-Jul-07</code> <code> 17-Mar-06</code> <code> 17-May-94</code> <code> 17-Nov-99</code> <code> 18-Aug-00</code> <code> 18-Dec-92</code> <code> 18-Jul-97</code> <code> 18-Jun-05</code> <code> 18-Mar-03</code> <code> 18-May-93</code> <code> 18-Nov-94</code> <code> 19-Apr-05</code> <code> 20-Apr-04</code> <code> 20-Mar-00</code> <code> 21-Apr-06</code> <code> 21-Aug-95</code> <code> 21-Dec-04</code> <code> 21-Jan-00</code> <code> 21-Jul-99</code> <code> 21-Jun-02</code> <code> 21-Jun-93</code> <code> 22-Apr-97</code> <code> 22-Feb-00</code> <code> 22-Feb-96</code> <code> 22-Jan-96</code> <code> 22-Jun-94</code> <code> 22-Mar-02</code> <code> 22-May-06</code> <code> 22-May-98</code> <code> 23-Apr-98</code> <code> 23-Feb-07</code> <code> 23-Jul-92</code> <code> 23-Jun-97</code> <code> 23-Mar-01</code> <code> 23-Mar-05</code> <code> 24-Apr-03</code> <code> 24-Aug-94</code> <code> 24-Feb-93</code> <code> 24-Jul-01</code> <code> 24-Jul-02</code> <code> 24-Jun-03</code> <code> 24-Mar-04</code> <code> 25-Apr-02</code> <code> 25-Aug-98</code> <code> 25-Jan-06</code> <code> 25-Oct-96</code> <code> 26-Aug-04</code> <code> 26-Dec-03</code> <code> 26-Feb-04</code> <code> 26-Jan-05</code> <code> 26-Jan-99</code> <code> 26-Jun-96</code> <code> 26-Mar-04</code> <code> 26-May-00</code> <code> 26-May-04</code> <code> 26-Sep-95</code> <code> 27-Jul-04</code> <code> 27-Mar-07</code> <code> 27-Nov-96</code> <code> 27-Oct-05</code> <code> 28-Jul-04</code> <code> 28-Jul-05</code> <code> 29-Aug-03</code> <code> 29-Dec-02</code> <code> 29-Jul-98</code> <code> 29-Jun-98</code> <code> 29-Oct-92</code> <code> 29-Oct-98</code> <code> 30-Jun-97</code> <code> 30-Nov-93</code> <code> 31-Dec-99</code> <code> 31-Jan-04</code> <code> 31-Oct-01</code> <code> 31-Oct-03</code></p>
</dd>
<dt><code>Decimal.date</code></dt><dd><p>A numeric vector</p>
</dd>
<dt><code>CO2</code></dt><dd><p>CO<code class="reqn">_2</code> concentration (in ppm)</p>
</dd>
<dt><code>D14C</code></dt><dd><p><code class="reqn">\delta</code> <code class="reqn">^{14}</code>C (in per mille)</p>
</dd>
<dt><code>D14C.uncertainty</code></dt><dd><p>measurement uncertainty for <code>D14C</code>(in per mille)</p>
</dd>
</dl>



<h3>Source</h3>

<p>H. D. Graven, R. F. Keeling, A. F. Bollenbacher                                 
Scripps CO<code class="reqn">_2</code> Program Scripps Institution of Oceanography (SIO) 
University of California, La Jolla, California USA 92093-0244                                                     
and
</p>
<p>T. P. Guilderson Center for Accelerator Mass Spectrometry (CAMS) 
Lawrence Livermore National Laboratory (LLNL)  
Livermore, California USA  94550
</p>


<h3>References</h3>

<p>H. D. Graven, T. P. Guilderson and R. F. Keeling, Observations of radiocarbon 
in CO<code class="reqn">_2</code> at La Jolla, California, USA 1992-2007: Analysis of the long-term trend. <em>Journal of Geophysical Research</em>.</p>

<hr>
<h2 id='caribou'>
Caribou count data
</h2><span id='topic+caribou'></span>

<h3>Description</h3>

<p>Stratified random sampling was used to estimate the size of the Nelchina herd of Alaskan caribou (<em>Rangifer tarandus</em>) in February 1962 (Siniff and Skoog 1964).  
The total population of sample units (for which responses would be counts of caribou) consisted of 699 four mile<code class="reqn">^2</code> areas.  This population was divided into six strata, and each of these was randomly sampled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(caribou)</code></pre>


<h3>Format</h3>

<p>A data frame with 6 observations on the following 5 variables.
</p>

<dl>
<dt><code>stratum</code></dt><dd><p>Strata; a factor with levels <code>A</code> <code>B</code> <code>C</code> <code>D</code> <code>E</code> <code>F</code></p>
</dd>
<dt><code>N.h</code></dt><dd><p>Strata population size</p>
</dd>
<dt><code>n.h</code></dt><dd><p>Strata sample size</p>
</dd>
<dt><code>x.bar.h</code></dt><dd><p>Strata means</p>
</dd>
<dt><code>var.h</code></dt><dd><p>Strata variances</p>
</dd>
</dl>



<h3>Source</h3>

<p>Siniff, D. B., and R. O. Skoog (1964)  Aerial censusing of caribou using stratified random sampling.  
<em>Journal of Wildlife Management</em> 28: 391-401. 
</p>

<hr>
<h2 id='case0902'>
Dataset of mammal traits from Ramsey and Schaefer (1997)
</h2><span id='topic+case0902'></span>

<h3>Description</h3>

<p>These data were used by Ramsey and Schaefer (1997) to demonstrate multiple regression.  The dataset was originally collected by Sacher and Stafeldt (1974) and provided (for varying sample sizes) average values of brain weight, body weight, gestation period and litter size for 96 placental mammal species. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("case0902")</code></pre>


<h3>Format</h3>

<p>A data frame with 96 observations on the following 5 variables.
</p>

<dl>
<dt><code>Xs</code></dt><dd><p>A factor defining common names for mammal species under examination.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Brain weight (in grams).</p>
</dd>
<dt><code>Xb</code></dt><dd><p>Body weight (in kilograms).</p>
</dd>
<dt><code>Xg</code></dt><dd><p>Gestation period length (in days).</p>
</dd>
<dt><code>Xl</code></dt><dd><p>Litter size.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ramsey, F., and Schafer, D. (1997). <em>The statistical sleuth: a course in methods of data analysis</em>. Cengage Learning.
</p>


<h3>References</h3>

<p>Sacher, G. A., and Staffeldt, E. F. (1974). Relation of gestation time to brain weight for placental mammals: implications for the theory of vertebrate growth.  <em>The American Naturalist</em>, 108(963), 593-615.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(case0902)
</code></pre>

<hr>
<h2 id='case1202'>
Dataset of salary attributes for male and female workers from Ramsey and Schafer (1997)
</h2><span id='topic+case1202'></span>

<h3>Description</h3>

<p>Ramsey and Schafer (1997) used this dataset to illustrate considerations in model selection. The data describe attributes of 61 female and 32 male clerical employees hired between 1965 and 1975 by a bank sued for sexual harassment. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("case1202")</code></pre>


<h3>Format</h3>

<p>A data frame with 93 observations on the following 7 variables.
</p>

<dl>
<dt><code>Yhire</code></dt><dd><p>Annual salary upon hire (US dollars).</p>
</dd>
<dt><code>Y77</code></dt><dd><p>Annual salary in 1977 (US dollars).</p>
</dd>
<dt><code>Xsex</code></dt><dd><p>Sex; a factor with the levels <code>FEMALE</code> and <code>MALE</code>.</p>
</dd>
<dt><code>Xsen</code></dt><dd><p>Seniority (months since first hired).</p>
</dd>
<dt><code>Xage</code></dt><dd><p>Age (in months).</p>
</dd>
<dt><code>Xed</code></dt><dd><p>Education (in years).</p>
</dd>
<dt><code>Xexp</code></dt><dd><p>Experience previous to being hired by the bank (in months).</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ramsey, F., and Schafer, D. (1997). <em>The statistical sleuth: a course in methods of data analysis</em>. Cengage Learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(case1202)
</code></pre>

<hr>
<h2 id='chi.plot'>Chi plots for diagnosing multivariate independence.</h2><span id='topic+chi.plot'></span>

<h3>Description</h3>

<p>Chi-plots (Fisher and Switzer 1983, 2001) provide a method to diagnose multivariate 
non-independence among <em>Y</em> variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chi.plot(Y1, Y2, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chi.plot_+3A_y1">Y1</code></td>
<td>
<p>A <em>Y</em> variable of interest.  Must be quantitative vector.</p>
</td></tr>
<tr><td><code id="chi.plot_+3A_y2">Y2</code></td>
<td>
<p>A second <em>Y</em> variable of interest.  Must also be a quantitative vector.</p>
</td></tr>
<tr><td><code id="chi.plot_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The method relies on calculating all possible pairwise differences within <b>y</b><code class="reqn">_1</code> and within <b>y</b><code class="reqn">_2</code>. Let pairwise differences associated with the first observation in <b>y</b><code class="reqn">_1</code> that are greater than zero be transformed to ones and all other differences be zeros.  Take the sum of the transformed values, and let this sum divided by (1 - <em>n</em>) be be the first element in the 1 x <em>n</em> vector <b>z</b>.
Find the rest of the elements (2,..,<em>n</em>) in <b>z</b> using the same process. 
</p>
<p>Perform the same transformation for the pairwise differences associated with the first observation in <b>y</b><code class="reqn">_2</code>.  Let pairwise differences associated with the first observation in <b>y</b><code class="reqn">_2</code> that are greater than zero be transformed to ones and all other differences be zeros.  Take the sum of the transformed values, and let this sum divided by (1 - <em>n</em>) be be the first element in the 1 x <em>n</em> vector <b>g</b>.
Find the rest of the elements (2,..,<em>n</em>) in <b>g</b> using the same process. 
</p>
<p>Let pairwise differences associated with the first observation in <b>y</b><code class="reqn">_1</code> and the first observation in <code class="reqn">\bold{y}_2</code> that are both greater than zero be transformed to ones and all other differences be zeros. Take the sum of the transformed values, and let this sum divided by (1 - <em>n</em>) be be the first element in the 1 x <em>n</em> vector <b>h</b>.  Find the rest of the elements (2,..,<em>n</em>) in <b>h</b> using the same process.  We let:
</p>
<p style="text-align: center;"><code class="reqn">S = sign((\bold{z} - 0.5)(\bold{g} - 0.5))</code>
</p>

<p style="text-align: center;"><code class="reqn">\chi =(\bold{h} - \bold{z} \times \bold{g})/\sqrt{\bold{z} \times (1 - \bold{z}) \times \bold{g} \times (1 - \bold{g})}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda = 4 \times S \times max[(\bold{z} - 0.5)^2,(\bold{g} - 0.5)^2]</code>
</p>

<p>We plot the resulting paired <code class="reqn">\chi</code> and <code class="reqn">\lambda</code> values for values of <code class="reqn">\lambda</code> less than <code class="reqn">4(1/(n - 1) - 0.5)^2</code>.  Values outside of <code class="reqn">\frac{1.78}{\sqrt{n}}</code> can be considered non-independent. 
</p>


<h3>Value</h3>

<p>Returns a chi-plot.
</p>


<h3>Author(s)</h3>

<p>Ken Aho and Tom Taverner (Tom provided modified original code to eliminate looping)</p>


<h3>References</h3>

<p>Everitt, B.  (2006)  <em>R and S-plus Companion to Multivariate Analysis</em>.  Springer.
</p>
<p>Fisher, N. I, and Switzer, P. (1985)  Chi-plots for assessing dependence.  <em>Biometrika</em>, 72: 
253-265.
</p>
<p>Fisher, N. I., and Switzer, P.  (2001)  Graphical assessment of dependence: is a picture worth 100 tests?  
<em>The American Statistician</em>, 55: 233-239.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bv.boxplot">bv.boxplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Y1&lt;-rnorm(100, 15, 2)
Y2&lt;-rnorm(100, 18, 3.2)
chi.plot(Y1, Y2)
</code></pre>

<hr>
<h2 id='chronic'>Chronic ailment counts for urban and rural women in Australia 
</h2><span id='topic+chronic'></span>

<h3>Description</h3>

<p>Brown et al (1996) showed that Australian women who live in rural areas tended to have fewer visits with general practitioners.  
It was not clear from this data, however, whether this was because they were healthier or because of other factors 
(e.g. shortage of doctors, higher costs of visits, longer distances to travel for visits, etc.). 
To address this Dobson issue (2001) compiled data describing the number of chronic medical conditions 
for women visiting general practitioners in New South Wales.  Women were divided into two groups; those from rural areas, 
and those from urban areas.  All of the women were age 70-75, had the same socioeconomic status and reported to general practitioners three or fewer times in 1996.  
The question of central interest was: &quot;do women who have the same level of general practitioner visits have the same medical need?&quot;  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chronic)</code></pre>


<h3>Format</h3>

<p>A data frame with 49 observations on the following 4 variables.
</p>

<dl>
<dt><code>subject</code></dt><dd><p>The subject number.</p>
</dd>
<dt><code>count</code></dt><dd><p>The number of chronic conditions in a subject.</p>
</dd>
<dt><code>setting</code></dt><dd><p>a factor with levels <code>RURAL</code> <code>URBAN</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dobson, A. J. 2001. <em>An Introduction to Generalized Linear Models, 2nd edition</em>. Chapman and Hall, London. 
</p>


<h3>References</h3>

<p>Brown, W. J.  Bryon, L., Byles, J., et al.  (1996)  Women's health in Australia: establishment of the Australian longitudinal study on women's health.  <em>Journal of Women's Health</em>.  5: 467-472.
</p>

<hr>
<h2 id='ci.boot'>
Bootstrap confidence intervals
</h2><span id='topic+ci.boot'></span><span id='topic+print.ciboot'></span>

<h3>Description</h3>

<p>Bootstrap confidence intervals for the output of function <code>bootstrap</code>.  Up to five different interval estimation methods can be called simultaneously: 
the normal approximation, the basic bootstrap, the percentile method, the bias corrected and accelerated method (BCa), and the studentized bootstrap method. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ci.boot(x, method = "all", sigma.t = NULL, conf = 0.95)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.boot_+3A_x">x</code></td>
<td>

<p>For <code>ci.boot</code> the list output from <code>bootstrap</code>. 
</p>
</td></tr>
<tr><td><code id="ci.boot_+3A_method">method</code></td>
<td>

<p>CI interval method to be used.  One of <code>"all"</code>, <code>"norm"</code>, <code>"basic"</code>, <code>"perc"</code>, <code>"BCa"</code>, or <code>"student"</code>.  Partial matches are allowed.
</p>
</td></tr>
<tr><td><code id="ci.boot_+3A_sigma.t">sigma.t</code></td>
<td>

<p>Vector of standard errors in association with studentized intervals.
</p>
</td></tr>
<tr><td><code id="ci.boot_+3A_conf">conf</code></td>
<td>

<p>Confidence level; 1 - <em>P</em>(Type I error).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Manly, B. F. J.  (1997)  <em>Randomization and Monte Carlo Methods in Biology, 2nd edition</em>.  
Chapman and Hall, London.
</p>


<h3>See Also</h3>

<p><code><a href="boot.html#topic+boot">boot</a></code>, <code><a href="#topic+bootstrap">bootstrap</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(vs)
# A partial set of observations from a single plot for a Scandinavian 
# moss/vascular plant/lichen survey.
site18&lt;-t(vs[1,])

#Shannon-Weiner diversity
SW&lt;-function(data){
d&lt;-data[data!=0]
p&lt;-d/sum(d)
-1*sum(p*log(p))
}

b &lt;- bootstrap(site18[,1],SW)
ci.boot(b)
</code></pre>

<hr>
<h2 id='ci.impt'>Confidence interval for the product of two proportions
</h2><span id='topic+ci.impt'></span>

<h3>Description</h3>

<p>Provides one and two-tailed confidence intervals for the true product of two proportions.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ci.impt(y1, n1, y2 = NULL, n2 = NULL, avail.known = FALSE, pi.2 = NULL, 
conf = .95, x100 = TRUE, alternative = "two.sided", bonf = TRUE, wald = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.impt_+3A_y1">y1</code></td>
<td>

<p>The number of successes associated with the first proportion.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_n1">n1</code></td>
<td>

<p>The number of trials associated with the first proportion.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_y2">y2</code></td>
<td>

<p>The number of successes associated with the second proportion.  Not used if <code>avail.known = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_n2">n2</code></td>
<td>

<p>The number of trials associated with the first proportion.  Not used if <code>avail.known = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_avail.known">avail.known</code></td>
<td>

<p>Logical.  Are the proportions <code class="reqn">\pi_{2i}</code> known?  If <code>avail.known = TRUE</code> these proportions should specified in the <code>pi.2</code> argument.  
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_pi.2">pi.2</code></td>
<td>

<p>Proportions for <code class="reqn">\pi_{2i}</code>.  Required if <code>avail.known = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_conf">conf</code></td>
<td>

<p>Confidence level, i.e., 1 - <code class="reqn">\alpha</code>.
</p>
</td></tr>  
<tr><td><code id="ci.impt_+3A_x100">x100</code></td>
<td>

<p>Logical.  If true, estimate is multiplied by 100.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_alternative">alternative</code></td>
<td>

<p>One of <code>"two.sided", "less", "greater"</code>.  Allows lower, upper, and two-tailed confidence intervals.  If <code>alternative = "two.sided"</code> (the default),  
then a conventional two-sided confidence interval is given.  The specifications <code>alternative = "less"</code> and <code>alternative = "greater"</code> provide lower and upper tailed CIs, respectively.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_bonf">bonf</code></td>
<td>

<p>Logical.  If <code>bonf = TRUE</code>, and the number of requested intervals is greater than one, then Bonferroni-adjusted intervals are returned.
</p>
</td></tr>
<tr><td><code id="ci.impt_+3A_wald">wald</code></td>
<td>

<p>Logical.  If <code>avail.known = TRUE</code> one can apply one of two standard error estimators.  The default is a delta-derived estimator.  If <code>wald = TRUE</code> is specified a modified Wald standard error estimator is used.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> be multinomial random variables with parameters <code class="reqn">n_1</code>, <code class="reqn">\pi_{1i}</code> and <code class="reqn">n_2</code>, <code class="reqn">\pi_{2i}</code>, respectively; where <code class="reqn">i = 1,2,\dots, r</code>.  
Under delta derivation, the log of the products of <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> (or the log of a product of <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> and a constant) is asymptotically normal with mean 
<code class="reqn">log(\pi_{1i} \times \pi_{2i})</code> 
and variance <code class="reqn">(1 - \pi_{1i})/\pi_{1i}n_1 + (1 - \pi_{2i})/ \pi_{2i}n_2</code>. Thus, an asymptotic <code class="reqn">(1 - \alpha)100</code> percent confidence interval for <code class="reqn">\pi_{1i} \times \pi_{2i}</code> is given by:
</p>
<p style="text-align: center;"><code class="reqn">
\hat{\pi}_{1i} \times \hat{\pi}_{2i} \times \exp(\pm z_{1-(\alpha/2)}\hat{\sigma}_i)
</code>
</p>

<p>where: <code class="reqn">\hat{\sigma}^2_i = \frac{(1 - \hat{\pi}_{1i})}{\hat{\pi}_{1i}n_1} + \frac{(1 - \hat{\pi}_{2i})}{\hat{\pi}_{2i}n_2}</code> and <code class="reqn">z_{1-(\alpha/2)}</code> 
is the standard normal inverse CDF at probability <code class="reqn">1 - \alpha</code>.
</p>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Printed results are the parameter estimate and confidence bounds. </p>


<h3>Note</h3>

<p>Method will perform poorly given unbalanced sample sizes.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Aho, K., and Bowyer, T. 2015. Confidence intervals for a product of proportions: Implications for importance values. <em>Ecosphere</em> 6(11): 1-7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.prat">ci.prat</a></code>, <code><a href="#topic+ci.p">ci.p</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ci.impt(30,40, 25,40)
</code></pre>

<hr>
<h2 id='ci.median'>Confidence interval for the median
</h2><span id='topic+ci.median'></span>

<h3>Description</h3>

<p>Calculates the upper and lower confidence bounds for the true median, and calculates true coverage of the interval.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ci.median(x, conf = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.median_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.
</p>
</td></tr>
<tr><td><code id="ci.median_+3A_conf">conf</code></td>
<td>

<p>The desired level of confidence 1 - <em>P</em>(type I error).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Default printed results are the parameter estimate and confidence bounds.  Other <code>invisible</code> objects include:
</p>
<table role = "presentation">
<tr><td><code>coverage</code></td>
<td>
<p>The true coverage of the interval.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Ott, R. L., and M. T. Longnecker (2004) <em>A First Course in Statistical Methods</em>.  
Thompson.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+median">median</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-rnorm(20)
ci.median(x)</code></pre>

<hr>
<h2 id='ci.mu.oneside'>
One sided confidence interval for mu.
</h2><span id='topic+ci.mu.oneside'></span>

<h3>Description</h3>

<p>In some situations we may wish to quantify confidence in the region above or below a mean estimate. For instance, a biologist working with an endangered species may be interested in saying: &quot;I am 95 percent confident that the true mean number of offspring is above a particular threshold.&quot; In a one-sided situation, we essentially let our confidence be 1- 2<code class="reqn">\alpha</code> (instead of 1 - <code class="reqn">\alpha</code>).  
Thus, if our significance level for a two-tailed test is <code class="reqn">\alpha</code>, our one-tailed significance level will be 2<code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mu.oneside(data, conf = 0.95, n = NULL, Var = NULL, xbar = NULL, 
summarized = FALSE, N = NULL, fpc = FALSE, tail = "upper", na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.mu.oneside_+3A_data">data</code></td>
<td>

<p>A vector of quantitative data.  Required if <code>summarized=TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_conf">conf</code></td>
<td>

<p>Level of confidence; 1 - <em>P</em>(type I error).
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_n">n</code></td>
<td>

<p>Sample size.  Required if <code>summarized=TRUE</code>. 
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_var">Var</code></td>
<td>

<p>Sample variance.  Required if <code>summarized=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_xbar">xbar</code></td>
<td>

<p>Sample mean.  Required if <code>summarized=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_summarized">summarized</code></td>
<td>

<p>Logical.  Indicates whether summary statistics instead of raw data should be used.
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_n">N</code></td>
<td>

<p>Population size.  Required if <code>summarized=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_fpc">fpc</code></td>
<td>

<p>Logical.  Indicating whether finite population corrections should be made.
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_tail">tail</code></td>
<td>

<p>Indicates what side the one sided confidence limit should be calculated for.  Choices are <code>"upper"</code> or <code>"lower"</code>.
</p>
</td></tr>
<tr><td><code id="ci.mu.oneside_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, indicate whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Default output is a matrix with the sample mean and either the upper or lower confidence limit.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Bain, L. J., and Engelhardt, M. (1992) <em>Introduction to Probability and Mathematical 
Statistics</em>.  Duxbury press, Belmont, CA, USA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mu.t">ci.mu.t</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>ci.mu.oneside(rnorm(100))
</code></pre>

<hr>
<h2 id='ci.mu.z'>Z and t confidence intervals for mu.</h2><span id='topic+ci.mu.z'></span><span id='topic+ci.mu.t'></span><span id='topic+print.ci'></span>

<h3>Description</h3>

<p>These functions calculate <em>t</em> and <em>z</em> confidence intervals for <code class="reqn">\mu</code>. <em>Z</em> confidence intervals require specification (and thus knowledge) of <code class="reqn">\sigma</code>. Both methods assume underlying normal distributions although this assumption becomes irrelevant for large sample sizes. Finite population corrections are provided if requested.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ci.mu.z(data, conf = 0.95, sigma = 1, summarized = FALSE, xbar = NULL,
fpc = FALSE, N = NULL, n = NULL, na.rm = FALSE)

ci.mu.t(data, conf = 0.95, summarized = FALSE, xbar = NULL, sd = NULL, 
fpc = FALSE, N = NULL, n = NULL, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.mu.z_+3A_data">data</code></td>
<td>
<p>A vector of quantitative data.  Required if <code>summarized = FALSE</code></p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_conf">conf</code></td>
<td>
<p>Confidence level; 1 - <em>P</em>(type I error).</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_sigma">sigma</code></td>
<td>
<p>The population standard deviation.</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_summarized">summarized</code></td>
<td>
<p>A logical statement specifying whether statistical summaries are to be used.  If <code>summarized = FALSE</code>, then the sample mean and the sample standard deviation (<code>t.conf</code> only) are calculated from the vector provided in <code>data</code>.  If <code>summarized = FALSE</code> then the sample mean <code>xbar</code>, the sample size <code>n</code>, and, in the case of <code>ci.mu.t</code>,  the sample standard deviation <code>st.dev</code>, must be provided by the user.</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_xbar">xbar</code></td>
<td>
<p>The sample mean.  Required if <code>summarized = TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_fpc">fpc</code></td>
<td>
<p>A logical statement specifying whether a finite population correction should be made.  If <code>fpc = TRUE</code> the population size <code>N</code> must be specified.</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_n">N</code></td>
<td>
<p>The population size.  Required if <code>fpc=TRUE</code></p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_sd">sd</code></td>
<td>
<p>The sample standard deviation.  Required if <code>summarized=TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_n">n</code></td>
<td>
<p>The sample size.  Required if <code>summarized = TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.mu.z_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, indicate whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ci.mu.z</code> and <code>ci.mu.t</code> calculate confidence intervals for either summarized data or a 
dataset provided in <code>data</code>.  Finite population corrections are made if a user specifies <code>fpc=TRUE</code> and 
provides some value for <code>N</code>.</p>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Default printed results are the parameter estimate and confidence bounds.  Other <code>invisible</code> objects include:
</p>
<table role = "presentation">
<tr><td><code>Margin</code></td>
<td>
<p>the confidence margin.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Lohr, S. L. (1999)  <em>Sampling: Design and Analysis</em>.  Duxbury Press.  Pacific Grove, USA.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code>, <code><a href="stats.html#topic+pt">pt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#With summarized=FALSE 
x&lt;-c(5,10,5,20,30,15,20,25,0,5,10,5,7,10,20,40,30,40,10,5,0,0,3,20,30)
ci.mu.z(x,conf=.95,sigma=4,summarized=FALSE)
ci.mu.t(x,conf=.95,summarized=FALSE)
#With summarized = TRUE
ci.mu.z(x,conf=.95,sigma=4,xbar=14.6,n=25,summarized=TRUE)
ci.mu.t(x,conf=.95,sd=4,xbar=14.6,n=25,summarized=TRUE)
#with finite population correction and summarized = TRUE
ci.mu.z(x,conf=.95,sigma=4,xbar=14.6,n=25,summarized=TRUE,fpc=TRUE,N=100)
ci.mu.t(x,conf=.95,sd=4,xbar=14.6,n=25,summarized=TRUE,fpc=TRUE,N=100)
</code></pre>

<hr>
<h2 id='ci.p'>
Confidence interval estimation for the binomial parameter pi using five popular methods.
</h2><span id='topic+ci.p'></span>

<h3>Description</h3>

<p>Confidence interval formulae for <code class="reqn">\mu</code> are not appropriate for variables describing binary outcomes.  The function <code>p.conf</code> calculates confidence intervals for the binomial parameter <code class="reqn">\pi</code> (probability of success) using raw or summarized data.  By default Agresti-Coull
point estimators are used to estimate <code class="reqn">\pi</code> and <code class="reqn">\sigma_{\hat{\pi}}</code>.  If raw data are to be used (the default) then successes should be indicated as ones and failures as zeros in the <code>data</code> vector.  Finite population corrections can also be specified. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ci.p(data, conf = 0.95, summarized = FALSE, phat = NULL, 
fpc = FALSE, n = NULL, N = NULL, method="agresti.coull", plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.p_+3A_data">data</code></td>
<td>

<p>A vector of binary data.  Required if <code>summarized = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_conf">conf</code></td>
<td>

<p>Level of confidence 1 - <em>P</em>(type I error).
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_summarized">summarized</code></td>
<td>

<p>Logical; indicate whether raw data or summary stats are to be used. 
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_phat">phat</code></td>
<td>

<p>Estimate of <code class="reqn">\pi</code>.  Required if <code>summarized = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_fpc">fpc</code></td>
<td>

<p>Logical.  Indicates whether finite population corrections should be used.  If <code>fpc = TRUE</code> then <code>N</code> must be specified.  Finite population corrections are not possible for <code>method = "exact"</code> or <code>method = "score"</code>.
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_n">n</code></td>
<td>

<p>Sample size.  Required if <code>summarized = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_n">N</code></td>
<td>

<p>Population size.  Required if <code>fpc = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_method">method</code></td>
<td>

<p>Type of method to be used in confidence interval calculations, <code>method ="agresti.coull"</code> is the default.  Other procedures include <code>method="asymptotic"</code> which provides the conventional normal (Wald) approximation,    
<code>method = "score"</code>, <code>method = "LR"</code>, and <code>method="exact"</code> (see <b>Details</b> below). Partial names can be used.  The <code>"exact"</code> method cannot be implemented if <code>summarized=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ci.p_+3A_plot">plot</code></td>
<td>

<p>Logical.  Should likelihood ratio plot be created with estimate from <code>method = "LR"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the binomial distribution, the parameter of interest is the probability of success, <code class="reqn">\pi</code>.  ML estimators for the parameter, <code class="reqn">\pi</code>, and its standard deviation, <code class="reqn">\sigma_\pi</code> are: 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\pi}=\frac{x}{n},</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\sigma}_{\hat{\pi}}=\sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n}}</code>
</p>

<p>where <em>x</em> is the number of successes and <em>n</em> is the number of observations.
</p>
<p>Because the sampling distribution of any ML estimator is asymptotically normal, an &quot;asymptotic&quot; 100(1 - <code class="reqn">\alpha</code>)% confidence interval for <code class="reqn">\pi</code> is found using:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\pi}\pm z_{1-(\alpha/2)}\hat{\sigma}_{\hat{\pi}}.</code>
</p>

<p>This method has also been called the Wald confidence interval.
</p>
<p>These estimators can create extremely inaccurate confidence intervals, particularly for small sample sizes or when <code class="reqn">\pi</code> is near 0 or 1 (Agresti 2012).  A better method is to invert the Wald binomial test statistic and vary values for <code class="reqn">\pi_0</code> in the test statistic numerator and standard error.  The interval consists of values of <code class="reqn">\pi_0</code> 
in which result in a failure to reject null at <code class="reqn">\alpha</code>. Bounds can be obtained by finding the roots of a quadratic expansion of the binomial likelihood function (See Agresti 2012).
This has been called a &quot;score&quot; confidence interval (Agresti 2012).  An simple approximation to this method can be obtained by adding <code class="reqn">z_{1-(\alpha/2)} (\approx 2</code> for <code class="reqn">\alpha = 0.05</code>) to the number of successes and failures (Agresti and Coull 1998).  The resulting Agresti-Coull estimators for <code class="reqn">\pi</code> and <code class="reqn">\sigma_{\hat{\pi}}</code> are:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\pi}=\frac{x+z^2/2}{n+z^2},</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\sigma}_{\hat{\pi}}=\sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n+z^2}}.</code>
</p>

<p>where <code class="reqn">z</code> is the standard normal inverse cdf at probability 1 - <code class="reqn">\alpha/2</code>.
</p>
<p>As above, the 100(1 - <code class="reqn">\alpha</code>)% confidence interval for the binomial parameter <code class="reqn">\pi</code> is found using:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\pi}\pm z_{1-(\alpha/2)}\hat{\sigma}_{\hat{\pi}}.</code>
</p>

<p>The likelihood ratio method <code>method = "LR"</code> finds points in the binomial log-likelihood function where the difference between the maximum likelihood and likelihood function is closest to <code class="reqn">\chi_1^{2}(1 - \alpha)/2</code> 
for support given in <code class="reqn">\pi_0</code>.  As support the function uses 
<code>seq(0.00001, 0.99999, by = 0.00001)</code>. 
</p>
<p>The &quot;exact&quot; method of Clopper and Pearson (1934) is bounded at the nominal limits, but actual coverage may be well below this level, particularly when <em>n</em> is small and <code class="reqn">\pi</code> is near 0 or 1.  
</p>
<p>Agresti (2012) recommends the Agresti-Coull method over the normal approximation, the score method over the Agresti-Coull method, and the likelihood ratio method over all others.  The Clopper Pearson has been repeatedly criticized as being too conservative (Agresti and Coull 2012).   
</p>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  
</p>
<table role = "presentation">
<tr><td><code>pi.hat</code></td>
<td>
<p>Estimate for <code class="reqn">\pi</code>.</p>
</td></tr>
<tr><td><code>S.p.hat</code></td>
<td>
<p>Estimate for <code class="reqn">\sigma_{\hat{\pi}}</code>.</p>
</td></tr>
<tr><td><code>margin</code></td>
<td>
<p>Confidence margin.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>Confidence interval.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function contains only a few of the many methods that have been proposed for confidence interval estimation for <code class="reqn">\pi</code>.
</p>


<h3>Author(s)</h3>

<p>Ken Aho. thanks to Simon Thelwall for finding an error with summarized data under fpc.
</p>


<h3>References</h3>

<p>Agresti, A.  (2012) <em>Categorical Data Analysis, 3rd edition</em>.  New York.  Wiley. 
</p>
<p>Agresti, A., and Coull, B . A. (1998) Approximate is better than 'exact' for interval 
estimation of binomial proportions. <em>The American Statistician</em>. 52: 119-126.
</p>
<p>Clopper, C. and Pearson, S. (1934) The use of confidence or fiducial limits illustrated in 
the case of the Binomial. <em>Biometrika</em> 26: 404-413.
</p>
<p>Ott, R. L., and Longnecker, M. T. (2004) <em>A First Course in Statistical Methods</em>.  
Thompson.
</p>
<p>Wilson, E. B.(1927) Probable inference, the law of succession, and statistical inference. 
<em>Journal of the American Statistical Association</em> 22: 209-212.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mu.z">ci.mu.z</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#In 2001, it was estimated that 56,200 Americans would be diagnosed with 
# non-Hodgkin's lymphoma and that 26,300 would die from it (Cernan et al. 2002).  
# Here we find the 95% confidence interval for the probability of diagnosis, pi. 

ci.p(c(rep(0, 56200-26300),rep(1,26300))) # Agresti-Coull
ci.p(c(rep(0, 56200-26300),rep(1,26300)), method = "LR") # Likelihood Ratio

# summarized = TRUE
n = 56200
x = 26300
phat = x/n

ci.p(summarized = TRUE, phat = phat, n = n) # Agresti-Coull

# Use 2001 US population size as N
N &lt;- 285 * 10^6
ci.p(c(rep(0, 56200-26300),rep(1,26300)), fpc = TRUE, N = N) # Agresti-Coull
ci.p(summarized = TRUE, phat = phat, n = n, N = N, fpc = TRUE) # Agresti-Coull
</code></pre>

<hr>
<h2 id='ci.prat'>
Confidence intervals for the ratio of binomial and multinomial proportions
</h2><span id='topic+ci.prat'></span>

<h3>Description</h3>

<p>A number of methods have been developed for obtaining confidence intervals for the ratio of two binomial proportions.  These include the Wald/Katz-log method (Katz et al. 1978), 
adjusted-log (Walter 1975, Pettigrew et al. 1986), Koopman asymptotic score (Koopman 1984), Inverse hyperbolic sine transformation (Newman 2001), the Bailey method (Bailey (1987), 
and the Noether (1957) procedure. Koopman results are found iteratively for most intervals using root finding.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.prat(y1, n1, y2, n2, conf = 0.95, method = "katz.log", 
bonf = FALSE, tol = .Machine$double.eps^0.25, R = 1000, r = length(y1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.prat_+3A_y1">y1</code></td>
<td>

<p>The ratio numerator number of successes.  A scalar or vector.
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_n1">n1</code></td>
<td>

<p>The ratio numerator number of trials.  A scalar or vector of <code>length(y1)</code>
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_y2">y2</code></td>
<td>

<p>The ratio denominator number of successes.  A scalar or vector of <code>length(y1)</code>
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_n2">n2</code></td>
<td>

<p>The ratio denominator number of trials. A scalar or vector of <code>length(y1)</code>
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_conf">conf</code></td>
<td>

<p>The level of confidence, i.e. 1 - <em>P</em>(type I error). 
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_method">method</code></td>
<td>

<p>Confidence interval method.  One of <code>"adj.log"</code>, <code>"bailey"</code>,  
<code>"boot"</code>, <code>"katz.log"</code>, <code>"koopman"</code>, <code>"sinh-1"</code> or 
<code>"noether"</code>.  Partial distinct names can be used.  
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_bonf">bonf</code></td>
<td>

<p>Logical, indicating whether or not Bonferroni corrections should be applied for simultaneous inference if <code>y1, y2, n1</code> and <code>n2</code> are vectors.
</p>
</td></tr>  
<tr><td><code id="ci.prat_+3A_tol">tol</code></td>
<td>
<p>The desired accuracy (convergence tolerance) for the iterative root finding procedure when finding Koopman intervals. The default is taken to be the smallest positive floating-point number of the workstation implementing the function, raised to the 0.25 power, and will normally be approximately 0.0001.
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_r">R</code></td>
<td>
<p>If method <code>"boot"</code> is chosen, the number of bootstrap iterations.
</p>
</td></tr>
<tr><td><code id="ci.prat_+3A_r">r</code></td>
<td>
<p>The number of ratios to which family-wise inferences are being made.  Assumed to be <code>length(y1)</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> be multinomial random variables with parameters <code class="reqn">n_1, \pi_{1i}</code>,  and  <code class="reqn">n_2, \pi_{2i}</code>, respectively; where <code class="reqn">i = \{1, 2, 3, \dots, r\}</code>.  This encompasses the binomial case in which <code class="reqn">r = 1</code>. We define the true selection ratio for the <em>i</em>th resource of <em>r</em> total resources to be:
</p>
<p style="text-align: center;"><code class="reqn">\theta_{i}=\frac{\pi _{1i}}{\pi _{2i}}</code>
</p>

<p>where <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> represent the proportional use and availability of the <em>i</em>th resource, respectively. Note that if <code class="reqn">r = 1</code> the selection ratio becomes relative risk.  The maximum likelihood estimators for <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> are the sample proportions: 
</p>
<p style="text-align: center;"><code class="reqn">{{\hat{\pi }}_{1i}}=\frac{{{y}_{1i}}}{{{n}_{1}}},</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">{{\hat{\pi }}_{2i}}=\frac{{{y}_{2i}}}{{{n}_{2}}}</code>
</p>

<p>where <code class="reqn">y_{1i}</code> and <code class="reqn">y_{2i}</code> are the observed counts for use and availability for the <em>i</em>th resource.  The estimator for <code class="reqn">\theta_i</code> is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\theta}_{i}=\frac{\hat{\pi}_{1i}}{\hat{\pi }_{2i}}.</code>
</p>


<table>
<tr>
 <td style="text-align: left;">
Method </td><td style="text-align: left;"> Algorithm </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;"> 

Katz-log </td><td style="text-align: left;"> <code class="reqn">\hat\theta_i\times</code> exp<code class="reqn">(\pm z_1-\alpha/2\hat{\sigma}_W)</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">\hat\sigma_W^2=\frac{(1-\hat{\pi} _{1i})}{\hat{\pi}_{1i}n_1}+\frac{(1-\hat{\pi}_{2i})}{\hat{\pi}_{2i}n_2}</code>.  </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">

Adjusted-log </td><td style="text-align: left;"> <code class="reqn">\hat{\theta}_{Ai}\times</code> exp<code class="reqn">(\pm z_1-\alpha /2\hat{\sigma}_A)</code>, </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> where <code class="reqn">\hat{\theta}_{Ai}=\frac{y_{1i}+0.5/n_1+0.5}{y_{2i}+0.5/n_2+0.5}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code class="reqn">\hat{\sigma}_A^2=\frac{1}{y_1+0.5}-\frac{1}{n_1+0.5}+\frac{1}{y_2+0.5}-\frac{1}{n_2+0.5}</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">

Bailey </td><td style="text-align: left;"> <code class="reqn">\hat{\theta} _i\left[\frac{1\pm z_1-\left( \alpha /2 \right)\left( \hat{\pi}_{1i}'/y_{1i}+\hat{\pi}_{2i}'/y_{2i}-z_1-\left(\alpha/2 \right)^2\hat{\pi} _{1i}'\hat{\pi}_{2i}'/9y_{1i}y_{2i} \right)^{1/2}/3}{1-z_{1-\left(\alpha/2 \right)^2}\hat{\pi} _{2i}'/9y_{2i}} \right]^3</code>,</td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> where <code class="reqn">\hat{\pi}_{1i}'</code> = 1 - <code class="reqn">\hat{\pi}_{1i}</code>, and <code class="reqn">\hat{\pi}_{2i}'</code> = 1 - <code class="reqn">\hat{\pi}_{2i}</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">

Inv. hyperbolic sine </td><td style="text-align: left;"> <code class="reqn">\ln({{\hat{\theta }}_{i}})\pm \left[ 2sin{{h}^{-1}}\left( \frac{{{z}_{(1-\alpha /2)}}}{2}\sqrt{\frac{1}{{{y}_{1i}}}-\frac{1}{{{n}_{1}}}+\frac{1}{{{y}_{2i}}}-\frac{1}{{{n}_{2}}}} \right) \right]</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> 

Koopman </td><td style="text-align: left;"> Find <code class="reqn">X^2(\theta_0)</code> = <code class="reqn">\chi _1^2(1 - \alpha)</code>, where </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">  <code class="reqn">{{\tilde{\pi }}_{1i}}=\frac{{{\theta }_{0}}({{n}_{1}}+{{y}_{2i}})+{{y}_{1i}}+{{n}_{2}}-{{[{{\{{{\theta }_{0}}({{n}_{1}}+{{y}_{2i}})+{{y}_{1i}}+
{{n}_{2}}\}}^{2}}-4{{\theta }_{0}}({{n}_{1}}+{{n}_{2}})({{y}_{1i}}+{{y}_{2i}})]}^{0.5}}}{2({{n}_{1}}+{{n}_{2}})}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">

</td><td style="text-align: left;"> <code class="reqn">\tilde{\pi}_{2i}=\frac{{{{\tilde{\pi }}}_{1i}}}{{{\theta }_{0}}}</code>, and <code class="reqn">X^2(\theta_0)=\frac{\left(y_{1i}-n_1\tilde{\pi}_{1i}\right)^2}{n_1 \tilde{\pi }_{1i}(1-\tilde{\pi}_{1i})}\left\{1+\frac{n_1(\theta_0-\tilde{\pi}_{1i})}{n_2(1-\tilde{\pi}_{1i})} \right\}</code>. </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Noether </td><td style="text-align: left;"> <code class="reqn">\hat{\theta}_i\pm z_1-\alpha/2\hat{\sigma}_N</code>,   </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">\hat{\sigma }_{N}^{2}=\hat{\theta }_{i}^{2}\left( \frac{1}{{{y}_{1i}}}-\frac{1}{{{n}_{1}}}+\frac{1}{{{y}_{2i}}}-\frac{1}{{{n}_{2}}} \right)</code>.  
</td>
</tr>

</table>

<p>Exception handling strategies are generally necessary in the cases <code class="reqn">y_1</code> = 0, <code class="reqn">n_1</code> = <code class="reqn">y_1</code>, <code class="reqn">y_2</code> = 0, and <code class="reqn">n_2</code> = <code class="reqn">y_2</code> (see Aho and Bowyer 2015).  
</p>
<p>The bootstrap method currently employs percentile confidence intervals.
</p>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Default output is a matrix with the point and interval estimate. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Agresti, A., Min, Y. (2001) On small-sample confidence intervals for parameters in discrete distributions.  <em>Biometrics</em> 57: 963-97.
</p>
<p>Aho, K., and Bowyer, T. 2015. Confidence intervals for ratios of proportions: implications for selection ratios. <em>Methods in Ecology and Evolution</em> 6: 121-132.
</p>
<p>Bailey, B.J.R. (1987) Confidence limits to the risk ratio.  <em>Biometrics</em> 43(1): 201-205.
</p>
<p>Katz, D., Baptista, J., Azen, S. P., and Pike, M. C. (1978) Obtaining confidence intervals for the risk ratio in cohort studies. <em>Biometrics</em> 34: 469-474
</p>
<p>Koopman, P. A. R. (1984) Confidence intervals for the ratio of two binomial proportions. <em>Biometrics</em> 40:513-517.
</p>
<p>Manly, B. F., McDonald, L. L., Thomas, D. L., McDonald, T. L. and Erickson, W.P. (2002)  <em>Resource Selection by Animals: Statistical Design and Analysis for Field Studies.  2nd  edn.</em>  Kluwer, New York, NY
</p>
<p>Newcombe, R. G. (2001)  Logit confidence intervals and the inverse sinh transformation.  <em>The American Statistician</em> 55: 200-202.
</p>
<p>Pettigrew H. M., Gart, J. J., Thomas, D. G. (1986)  The bias and higher cumulants of the logarithm of a
binomial variate.  <em>Biometrika</em> 73(2): 425-435.
</p>
<p>Walter, S. D. (1975) The distribution of Levins measure of attributable risk. <em>Biometrika</em> 62(2): 371-374.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.p">ci.p</a>, <a href="#topic+ci.prat.ak">ci.prat.ak</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># From Koopman (1984)
ci.prat(y1 = 36, n1 = 40, y2 = 16, n2 = 80, method = "katz")
ci.prat(y1 = 36, n1 = 40, y2 = 16, n2 = 80, method = "koop")
</code></pre>

<hr>
<h2 id='ci.prat.ak'>
Confidence intervals for ratios of proportions when the denominator is known
</h2><span id='topic+ci.prat.ak'></span>

<h3>Description</h3>

<p>It is increasingly possible that resource availabilities on a landscape will be known.  
For instance, in remotely sensed imagery with sub-meter resolution, the areal coverage of 
resources can be quantified to a high degree of precision, at even large spatial scales.  
Included in this function are six methods for computation of confidence intervals for 
a true ratio of proportions when the denominator proportion is known.  The first (adjusted-Wald) 
results from the variance of the estimator <code class="reqn">\hat{\sigma}_{\hat{\pi}}</code> after multiplication by a constant.  
Similarly, the second method(Agresti-Coull-adjusted) adjusts the variance of the estimator <code class="reqn">\hat{\sigma}_{\hat{\pi}_{AC}}</code>, 
where <code class="reqn">\hat{\pi}_{AC}=(y+2)/(n+4)</code>.  The third method (fixed-log) is based on delta derivations of the logged ratio.
The fourth method is Bayesian and based on the beta posterior distribution derived from a binomial likelhood function and a beta prior distribution.  The fifth procedure is an older method based on Noether (1959).  Sixth, bootstrapping methods can also be implemented.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.prat.ak(y1, n1, pi2 = NULL, method = "ac", conf = 0.95, bonf = FALSE, 
bootCI.method = "perc", R = 1000, sigma.t = NULL, r = length(y1), gamma.hyper = 1, 
beta.hyper = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.prat.ak_+3A_y1">y1</code></td>
<td>

<p>The ratio numerator number of successes.  A scalar or vector.
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_n1">n1</code></td>
<td>

<p>The ratio numerator number of trials.  A scalar or vector of <code>length(y1)</code>
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_pi2">pi2</code></td>
<td>

<p>The denominator proportion.  A scalar or vector of <code>length(y1)</code>
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_method">method</code></td>
<td>

<p>One of <code>"ac", "wald", "noether-fixed", "boot", "fixed-log"</code> or <code>"bayes"</code> for the Agresti-Coull-adjusted, adjusted Wald, noether-fixed, bootstrapping, fixed-log and Bayes-beta, methods, respectively.  Partial distinct names can be used. 
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_conf">conf</code></td>
<td>

<p>The level of confidence, i.e. 1 - <em>P</em>(type I error). 
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_bonf">bonf</code></td>
<td>
<p>Logical, indicating whether or not Bonferroni corrections should be applied for simultaneous inference if <code>y1, y2, n1</code> and <code>n2</code> are vectors.
</p>
</td></tr> 
<tr><td><code id="ci.prat.ak_+3A_bootci.method">bootCI.method</code></td>
<td>
<p>If <code>method = "boot"</code> the type of bootstrap confidence interval to calculate.  One of <code>"norm"</code>, <code>"basic"</code>, <code>"perc"</code>, <code>"BCa"</code>, or <code>"student"</code>.  See  
<code><a href="#topic+ci.boot">ci.boot</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_r">R</code></td>
<td>
<p>If <code>method = "boot"</code> the number of bootstrap samples to take.  See <code><a href="#topic+ci.boot">ci.boot</a></code> for more information.
</p>
</td></tr> 
<tr><td><code id="ci.prat.ak_+3A_sigma.t">sigma.t</code></td>
<td>
<p>If <code>method = "boot"</code> and <code>bootCI.methd = "student"</code> a vector of standard errors in association with studentized intervals.   See <code><a href="#topic+ci.boot">ci.boot</a></code> for more information.
</p>
</td></tr> 
<tr><td><code id="ci.prat.ak_+3A_r">r</code></td>
<td>
<p>The number of ratios to which family-wise inferences are being made.  Assumed to be <code>length(y1)</code>. 
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_gamma.hyper">gamma.hyper</code></td>
<td>
<p>If <code>method = "bayes"</code>.  A scalar or vector. Value(s) for the first hyperparameter for the beta prior distribution. 
</p>
</td></tr>
<tr><td><code id="ci.prat.ak_+3A_beta.hyper">beta.hyper</code></td>
<td>
<p>If <code>method = "bayes"</code>.  A scalar or vector. Value(s) for the second hyperparameter for the beta prior distribution.
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Koopman et al. (1984) suggested methods for handling extreme cases of <code class="reqn">y_1</code>, <code class="reqn">n_1</code>, <code class="reqn">y_2</code>, and <code class="reqn">n_2</code> (see below).  These are applied through exception handling here (see Aho and Bowyer 2015). 
</p>
<p>Let <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> be multinomial random variables with parameters <code class="reqn">n_1, \pi_{1i}</code>,  and  <code class="reqn">n_2, \pi_{2i}</code>, respectively; where <code class="reqn">i = \{1, 2, 3, \dots, r\}</code>.  This encompasses the binomial case in which <code class="reqn">r = 1</code>. We define the true selection ratio for the <em>i</em>th resource of <em>r</em> total resources to be:
</p>
<p style="text-align: center;"><code class="reqn">\theta_{i}=\frac{\pi _{1i}}{\pi _{2i}}</code>
</p>

<p>where <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> represent the proportional use and availability of the <em>i</em>th resource, respectively.  If <code class="reqn">r = 1</code> the selection ratio becomes relative risk.  The maximum likelihood estimators for <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> are the sample proportions: 
</p>
<p style="text-align: center;"><code class="reqn">{{\hat{\pi }}_{1i}}=\frac{{{y}_{1i}}}{{{n}_{1}}},</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">{{\hat{\pi }}_{2i}}=\frac{{{y}_{2i}}}{{{n}_{2}}}</code>
</p>

<p>where <code class="reqn">y_{1i}</code> and <code class="reqn">y_{2i}</code> are the observed counts for use and availability for the <em>i</em>th resource.  If <code class="reqn">\pi_{2i}</code>s are known, the estimator for <code class="reqn">\theta_i</code> is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\theta}_{i}=\frac{\hat{\pi}_{1i}}{\pi_{2i}}.</code>
</p>

<p>The function <code>ci.prat.ak</code> assumes that selection ratios are being specified (although other applications are certainly possible).  Therefore it assume that <code class="reqn">y_{1i}</code> must be greater than 0 if <code class="reqn">\pi_{2i} = 1</code>, and assumes that <code class="reqn">y_{1i}</code> must = 0 if <code class="reqn">\pi_{2i} = 0</code>.  Violation of these conditions will produce a warning message.   
</p>

<table>
<tr>
 <td style="text-align: left;">
Method </td><td style="text-align: left;"> Algorithm </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;"> 

Agresti Coull-Adjusted  </td><td style="text-align: left;"> <code class="reqn">{{\hat{\theta}}_{ACi}}\pm {{z}_{1-(\alpha /2)}}\sqrt{{{{\hat{\pi }}}_{AC1i}}(1-{{{\hat{\pi }}}_{AC1i}})/({{n}_{1}}+4){{{\hat{\pi }}}_{AC1i}}\pi _{2i}^{2}}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> where <code class="reqn">{{\hat{\pi}}_{AC1i}}=\frac{{{y}_{1}}+z^2/2}{{{n}_{1}}+z^2}</code>, and <code class="reqn">{{\hat{\theta }}_{ACi}}=\frac{{{\hat{\pi}}_{AC1i}}}{{{\pi }_{2i}}}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">z</code> is the standard normal inverse cdf at probability <code class="reqn">1 - \alpha/2</code> (<code class="reqn">\approx 2</code> when <code class="reqn">\alpha= 0.05</code>).  </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Bayes-beta </td><td style="text-align: left;"> <code class="reqn">(\frac{X_{\alpha/2}}{\pi_{2i}}</code> , <code class="reqn">\frac{X_{1-(\alpha/2)}}{\pi_{2i}})</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">X \sim BETA(y_{1i} + \gamma_{i}, n_1 + \beta - y_{1i})</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Fixed-log </td><td style="text-align: left;"> <code class="reqn">{{\hat{\theta }}_{i}}\times \exp \left( \pm {{z}_{1-\alpha /2}}{{{\hat{\sigma }}}_{F}} \right)</code>, </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> where <code class="reqn">\hat{\sigma}_{^{F}}^{2}=(1-{{\hat{\pi}}_{1i}})/{{\hat{\pi}}_{1i}}{{n}_{1}}.</code> </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Noether-fixed </td><td style="text-align: left;"> <code class="reqn">\frac{{{{\hat{\pi }}}_{1i}}/{{\pi }_{2}}}{1+z_{1-(\alpha /2)}^{2}}1+\frac{z_{1-(\alpha /2)}^{2}}{2{{y}_{1i}}}\pm z_{1-(\alpha /2)}^{2}\sqrt{\hat{\sigma}_{NF}^{2}+\frac{z_{1-(\alpha /2)}^{2}}{4y_{1i}^{2}}}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">\hat{\sigma }_{NF}^{2}=\frac{1-{{{\hat{\pi }}}_{1i}}}{{{n}_{1}}{{{\hat{\pi }}}_{1i}}}</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Wald-adjusted </td><td style="text-align: left;"> <code class="reqn">{{\hat{\theta }}_{i}}\pm {{z}_{1-(\alpha /2)}}\sqrt{{{{\hat{\pi }}}_{1i}}(1-{{{\hat{\pi }}}_{1i}})/{{n}_{1}}{{{\hat{\pi }}}_{1i}}\pi _{2i}^{2}}.</code></td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Default output is a matrix with the point and interval estimate. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Aho, K., and Bowyer, T. 2015. Confidence intervals for ratios of proportions: implications for selection ratios. <em>Methods in Ecology and Evolution</em> 6: 121-132.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.prat">ci.prat</a></code>, <code><a href="#topic+ci.p">ci.p</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ci.prat.ak(3,4,.5)
</code></pre>

<hr>
<h2 id='ci.sigma'>
Confidence interval for sigma squared.
</h2><span id='topic+ci.sigma'></span>

<h3>Description</h3>

<p>The function calculates confidence intervals for <code class="reqn">\sigma^2</code>.  We assume that the parent population is normal.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.sigma(data, conf = 0.95, S.sq = NULL, n = NULL, summarized = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.sigma_+3A_data">data</code></td>
<td>
<p>A vector of quantitative data.  Required if <code>summarized=FALSE</code>.</p>
</td></tr>
<tr><td><code id="ci.sigma_+3A_conf">conf</code></td>
<td>
<p>Level of confidence.  1 - <em>P</em>(type I error).</p>
</td></tr>
<tr><td><code id="ci.sigma_+3A_s.sq">S.sq</code></td>
<td>
<p>Sample variance, required if <code>summarized=TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.sigma_+3A_n">n</code></td>
<td>
<p>Sample size, required if <code>summarized=TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.sigma_+3A_summarized">summarized</code></td>
<td>
<p>Logical.  If <code>summarized=TRUE</code> then the user must supply <code>S.sq</code> and <code>n</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of <code>class = "ci"</code>.  Default printed results are the point estimate and confidence bounds.  Other objects are <code>invisible</code>.</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Bain, L. J., and M. Engelhardt.  1992.  <em>Introduction to Probability and Mathematical 
Statistics</em>.  Duxbury press.  Belmont, CA, USA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mu.z">ci.mu.z</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>ci.sigma(rnorm(20))
</code></pre>

<hr>
<h2 id='ci.strat'>Confidence intervals for stratified random samples.
</h2><span id='topic+ci.strat'></span>

<h3>Description</h3>

<p>A statistical estimate along with its associated confidence interval can be considered to be an inferential statement about the sampled population.  However this statement will only be correct if the method of sampling is considered in the computations of standard errors.  The function <code>ci.strat</code> provides appropriate computations given stratified random sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ci.strat(data, strat, N.h, conf = 0.95, summarized = FALSE, use.t = FALSE, 
n.h = NULL, x.bar.h = NULL, var.h = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.strat_+3A_data">data</code></td>
<td>
<p>A vector of quantitative data.  Required if <code>summarized=FALSE</code>.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_strat">strat</code></td>
<td>
<p>A vector describing strata.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_n.h">N.h</code></td>
<td>

<p>A vector describing the number of experimental units for each of the <em>k</em> strata.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_conf">conf</code></td>
<td>
<p>Level of confidence; 1 - <em>P</em>(type I error).</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_summarized">summarized</code></td>
<td>
<p>Logical.  Indicates whether summarized data are to be used.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_use.t">use.t</code></td>
<td>
<p>Logical.  Indicates whether <em>t</em> or <em>z</em> confidence intervals should be built.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_n.h">n.h</code></td>
<td>
<p>A vector indicating the number of experimental units sampled in each of the <em>k</em> strata. Required if <code>summarized=TRUE</code>.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_x.bar.h">x.bar.h</code></td>
<td>
<p>A vector containing the sample means for each of the <em>k</em> strata. Required if <code>summarized=TRUE</code>
.</p>
</td></tr>
<tr><td><code id="ci.strat_+3A_var.h">var.h</code></td>
<td>
<p>A vector containing the sample variances for each of the <em>k</em> strata. Required if <code>summarized=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the conventional formula for the sample standard error assumes simple random sampling.  There are two other general types of sampling designs: stratified random sampling and cluster sampling.  Since cluster sampling is generally used for surveys involving human demographics we will only describe corrections for stratified random sampling here.  For more information on sample standard error adjustments for cluster sampling see Lohr (1999).   
</p>
<p>For a stratified random sampling design let <em>N</em> be the known total number of units in the defined population of interest, and assume that the population can be logically divided into <em>k</em> strata; <code class="reqn">N=N_1+N_2+N_3+\dots+N_k</code>  (i.e. we are assuming that we know both the total population size, and the population size of each stratum).  We sample each of the <em>k</em> strata with <code class="reqn">n_h</code> observations; <code class="reqn">h=1,2,\dots,k</code>.  
</p>
<p>We estimate the variance in the <em>h</em>th stratum as:
</p>
<p style="text-align: center;"><code class="reqn">S^{2}_{h}=\frac{1}{n_h-1}\sum_{i=1}^{n_k}(X_{hi}-\bar{X}_h)^2</code>
</p>

<p>where <code class="reqn">X_{hi}</code> is the <em>i</em>th observation from the <em>h</em>th strata and <code class="reqn">\bar{X}_h</code> is the <em>h</em>th sample mean.  We estimate the true population total, <em>T</em>, with:
</p>
<p style="text-align: center;"><code class="reqn">\hat{T}=\sum_{h=i}^{k}N_h\bar{X}_h</code>
</p>

<p>We estimate the population mean, <code class="reqn">\mu</code>, with:
</p>
<p style="text-align: center;"><code class="reqn">\bar{X}_{str}=\frac{\hat{T}}{N}</code>
</p>

<p>An unbiased estimator for the standard error of <code class="reqn">\bar{X}_{str}</code> is:
</p>
<p style="text-align: center;"><code class="reqn">S_{\bar{X}_{str}}=\sqrt{\sum_{h=1}^{k}\left(1-\frac{n_h}{N_h}\right)\left(\frac{N_h}{N}\right)^2\left(\frac{S_h^2}{n_h}\right)}</code>
</p>

<p>The standard error of <code class="reqn">\hat{T}</code> is also of interest.  Here is an unbiased estimator:
</p>
<p style="text-align: center;"><code class="reqn">S_{\hat{T}}=\sqrt{\sum_{h=1}^{k}\left(1-\frac{n_h}{N_h}\right)N_h^2\left(\frac{S_h^2}{n_h}\right)}</code>
</p>

<p>Note that these standard errors have both a finite population correction and adjustments for stratification built into them.  Assuming that sample sizes within each stratum are large or that the sampling design has a large number of strata, a 100(1 - <code class="reqn">\alpha</code>)percent confidence interval for <code class="reqn">\mu</code>  and <em>T</em> can be constructed using:
</p>
<p style="text-align: center;"><code class="reqn">\bar{X}_{str}\pm z_{1-\alpha/2}S_{\bar{X}_{str}}</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{T}\pm z_{1-\alpha/2}S_{\hat{T}}</code>
</p>

<p>In situations where sample sizes or the number of strata are small, a <code class="reqn">t(n - k)</code> distribution can (and should) be used for calculation of confidence intervals,  where <code class="reqn">n=n_1+n_2+\dots+n_k</code>.
</p>


<h3>Value</h3>

<p>Returns a list with two items:
</p>
<table role = "presentation">
<tr><td><code>strat.summary</code></td>
<td>
<p>A matrix with columns: <code>N.h,n.h,x.bar.h</code> and <code>var.h</code></p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Confidence intervals for <code class="reqn">\mu</code> and <em>T</em></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Lohr, S. L. (1999) <em>Sampling: Design and Analysis</em>.  Duxbury Press.  Pacific Grove, USA.
</p>
<p>Siniff, D. B., and Skoog, R. O. (1964)  Aerial censusing of caribou using stratified 
random sampling.  <em>Journal of Wildlife Management</em> 28: 391-401.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mu.z">ci.mu.z</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Data from Siniff and Skoog (1964)
Caribou&lt;-data.frame(Stratum=c("A","B","C","D","E","F"),N.h=c(400,30,61,18,70,120),
n.h=c(98,10,37,6,39,21),x.bar.h=c(24.1,25.6,267.6,179,293.7,33.2),
var.h=c(5575,4064,347556,22798,123578,9795))
attach(Caribou)
ci.strat(data,strat=Stratum,N.h=N.h,conf=.95,summarized=TRUE,use.t=FALSE,n.h=n.h,
x.bar.h=x.bar.h,var.h=var.h)
</code></pre>

<hr>
<h2 id='cliff.env'>Environmental data for the community dataset cliff.sp</h2><span id='topic+cliff.env'></span>

<h3>Description</h3>

<p>The data here are a subset of a dataset collected by Aho (2006) which describe the distribution of communities of lichens and vascular and avascular plant species on montane cliffs in Northeast Yellowstone National Park.  Of particular interest was whether substrate (limestone or andesitic conglomerate) or water supply influenced community composition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cliff.env)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>sub</code></dt><dd>
<p>a factor with 2 levels
<code>"Andesite"</code> and <code>"Lime"</code> describing substrate type. 
</p>
</dd>
<dt><code>water</code></dt><dd>
<p>a factor with 3 levels
<code>"W"</code> 
<code>"I"</code>
<code>"D"</code>
indicating wet, intermediate, or dry conditions. 
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Two categorical environmental variables are described for 54 sites.  <code>sub</code> describes the substrate; there are two levels: <code>"Andesite"</code> and <code>"Lime"</code>.  <code>water</code> describes distance of samples from waterfalls which drain the cliff faces; there are three levels <code>"W"</code> indicating wet, <code>"I"</code> indicating intermediate, and <code>"D"</code> indicating dry.
</p>


<h3>Source</h3>

<p>Aho, K.(2006)  <em>Alpine Ecology and Subalpine Cliff Ecology in the Northern Rocky 
Mountains</em>.  Doctoral dissertation, Montana State University, 458 pgs.
</p>

<hr>
<h2 id='cliff.sp'>Yellowstone NP cliff community data</h2><span id='topic+cliff.sp'></span>

<h3>Description</h3>

<p>A subset of a dataset collected by Aho (2006) which describes  the distribution of communities of lichens and vascular and avascular plant species on montane cliffs in Northeast Yellowstone National Park.  Of particular interest was whether substrate (limestone or andesitic conglomerate) or water supply influenced community composition. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cliff.sp)</code></pre>


<h3>Details</h3>

<p>Responses are average counts from two 10 x 10 point frames at 54 sites. Abundance data are for eleven species, 9 lichens, 3 mosses, and 2 vascular plants. Data were gathered in the summer of 2004 on two andesitic/volcanic peaks (Barronette and Abiathar) with sedimentary layers at lower elevations.  
</p>


<h3>Source</h3>

<p>Aho, K.(2006)  <em>Alpine Ecology and Subalpine Cliff Ecology in the Northern Rocky 
Mountains</em>.  Doctoral dissertation, Montana State University, 458 pgs.</p>

<hr>
<h2 id='concrete'>Concrete strength dataset for data mining
</h2><span id='topic+concrete'></span>

<h3>Description</h3>

<p>The actual concrete compressive strength (MPa) for a given mixture under a 
specific age (days) was determined from laboratory assays. Data are in raw form (not scaled). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("concrete")</code></pre>


<h3>Format</h3>

<p>A data frame with 1030 observations on the following 9 variables.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>kg of cement in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X2</code></dt><dd><p>kg of blast furnace slag in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X3</code></dt><dd><p>kg of fly ash in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X4</code></dt><dd><p>kg of water in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X5</code></dt><dd><p>kg of superplasticizer in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X6</code></dt><dd><p>kg of coarse aggregate in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X7</code></dt><dd><p>kg of fine aggregate in a m<code class="reqn">^3</code> mixture.</p>
</dd>
<dt><code>X8</code></dt><dd><p>Age: day(1-365), a numeric vector</p>
</dd>
<dt><code>Y</code></dt><dd><p>Concrete compressive strength in MPa, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The order of variables corresponds to the order in the original data. 
</p>


<h3>Source</h3>

<p>Prof. I-Cheng Yeh
Department of Information Management 
Chung-Hua University, 
Hsin Chu, Taiwan 30067, R.O.C.
e-mail:icyeh@chu.edu.tw
TEL:886-3-5186511
</p>


<h3>References</h3>

<p>Past Usage: 
</p>
<p>Primary
</p>
<p>I-Cheng, Y. (1998) Modeling of strength of high performance concrete using artificial 
neural networks. <em>Cement and Concrete Research</em>, 28(12): 1797-1808 .
</p>
<p>Others
</p>
<p>I-Cheng. Y. (1998) Modeling concrete strength with augment-neuron networks. <em>J. of 
Materials in Civil Engineering, ASCE</em> 10(4): 263-268.
</p>
<p>I-Cheng, Y.  (1999) Design of high performance concrete mixture using neural networks.  
<em>J. of Computing in Civil Engineering, ASCE</em> 13 (1): 36-42.
</p>
<p>I-Cheng, Y. (2003) Prediction of Strength of Fly Ash and Slag Concrete By The Use of 
Artificial Neural Networks.  <em>Journal of the Chinese Institute of Civil and Hydraulic 
Engineering</em> Vol. 15, No. 4, pp. 659-663 (2003).
</p>
<p>I-Cheng, Y. (2003) A mix Proportioning Methodology for Fly Ash and Slag Concrete Using 
artificial neural networks.  <em>Chung Hua Journal of Science and Engineering</em> 1(1): 77-84.
</p>
<p>I-Cheng, Y. (2006). Analysis of strength of concrete using design of experiments and 
neural networks. <em>Journal of Materials in Civil Engineering, ASCE</em>  18(4): 597-604.
</p>
<p>Acknowledgements, Copyright Information, and Availability:
</p>
<p>NOTE: Reuse of this database is unlimited with retention of copyright notice for 
Prof. I-Cheng Yeh.
</p>

<hr>
<h2 id='ConDis.matrix'>Calculation and display of concordant and discordant pairs</h2><span id='topic+ConDis.matrix'></span>

<h3>Description</h3>

<p>Calculates whether pairs of observations from two vectors are concordant discordant or neither.  
These are displayed in the lower diagonal of a symmetric output matrix as 1, -1 or 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ConDis.matrix(Y1, Y2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ConDis.matrix_+3A_y1">Y1</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
<tr><td><code id="ConDis.matrix_+3A_y2">Y2</code></td>
<td>
<p>A vector of quantitative data.  Observations are assumed to be paired
with respective observations from <code>Y1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider all possible combinations of <code class="reqn">(Y_{1i}, Y_{ij})</code> and <code class="reqn">(Y_{2i}, Y_{ij})</code> where <code class="reqn">1&lt;=i&lt;j&lt;=n</code>.  A pair is concordant if <code class="reqn">Y_{1i} &gt; Y_{1j}</code> and <code class="reqn">Y_{2i} &gt; Y_{2j}</code> or if <code class="reqn">Y_{1i} &lt; Y_{1j}</code> and  <code class="reqn">Y_{2i} &lt; Y_{2j}</code>.  Conversely, a pair is discordant if <code class="reqn">Y_{1i} &lt; Y_{1j}</code> and <code class="reqn">Y_{2i} &gt; Y_{2j}</code> or if <code class="reqn">Y_{1i} &gt; Y_{1j}</code> and <code class="reqn">Y_2i &lt; Y_2j</code>.  This information has a number of important uses including calculation of Kendall's <code class="reqn">\tau</code>.</p>


<h3>Value</h3>

<p>A matrix is returned.  Elements in the lower triangle indicate whether observations are concordant (element = <code>1</code>), discordant (element = <code>-1</code>) or neither (element = <code>0</code>).
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Hollander, M., and  Wolfe, D. A. (1999) <em>Nonparametric statistical methods</em>. New York: John Wiley &amp; Sons. 
</p>
<p>Liebetrau, A. M. (1983) <em>Measures of association</em>. Sage Publications, Newbury Park, CA.
</p>
<p>Sokal, R. R., and Rohlf, F. J. (1995)  <em>Biometry</em>.  W. H. Freeman and Co., New York. </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Crab data from Sokal and Rohlf (1998)
crab&lt;-data.frame(gill.wt=c(159,179,100,45,384,230,100,320,80,220,320,210),
body.wt=c(14.4,15.2,11.3,2.5,22.7,14.9,1.41,15.81,4.19,15.39,17.25,9.52))
attach(crab)
crabm&lt;-ConDis.matrix(gill.wt,body.wt)
crabm
</code></pre>

<hr>
<h2 id='corn'>
Corn yield data
</h2><span id='topic+corn'></span>

<h3>Description</h3>

<p>Hoshmand (2006) described a split plot design to test grain yield of corn with respect to corn hybrids (split plots) and nitrogen (in whole plots).  The experiment was replicated at two blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(corn)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 4 variables.
</p>

<dl>
<dt><code>yield</code></dt><dd><p>Corn yield in bushels per acre.</p>
</dd>
<dt><code>hybrid</code></dt><dd><p>Type of hybrid, P = pioneer, levels were: <code>A632xLH38</code> <code>LH74xLH51</code> <code>Mo17xA634</code> <code>P3732</code> <code>P3747</code>.</p>
</dd>
<dt><code>N</code></dt><dd><p>Nitrogen addition in lbs/acre <code>0</code> <code>70</code> <code>140</code> <code>210</code>.</p>
</dd>
<dt><code>block</code></dt><dd><p>A blocking factor with levels <code>1</code> <code>2</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hoshmand, A. R.  (2006) <em>Design of Experiments for Agriculture and the Natural Sciences 2nd Edition</em>.  Chapman and Hall.
</p>

<hr>
<h2 id='crab.weight'>
crab gill and body weight data
</h2><span id='topic+crab.weight'></span>

<h3>Description</h3>

<p>Gill weight and body weight data for 12 striped shore crabs (<em>Pachygrapsus crassipes</em>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(crab.weight)</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on the following 2 variables.
</p>

<dl>
<dt><code>gill.wt</code></dt><dd><p>Gill weight in mg</p>
</dd>
<dt><code>body.wt</code></dt><dd><p>Body weight in grams</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sokal, R. R., and F. J. Rohlf  (2012)  <em>Biometry, 4th edition</em>.  W. H. Freeman and Co., New York. 
</p>

<hr>
<h2 id='crabs'>
Agresti crabs dataset
</h2><span id='topic+crabs'></span>

<h3>Description</h3>

<p>Horseshoe crab satellite counts as a function of crab phenotype.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(crabs)</code></pre>


<h3>Format</h3>

<p>A data frame with 173 observations on the following 5 variables.
</p>

<dl>
<dt><code>color</code></dt><dd><p>A factor with levels <code>1</code> = light medium, <code>2</code> = medium, <code>3</code> = dark medium, <code>4</code> = dark.</p>
</dd>
<dt><code>spine</code></dt><dd><p>A factor with levels <code>1</code> = both good, <code>2</code> = one worn or broken, <code>3</code> = both worn or broken.</p>
</dd>
<dt><code>width</code></dt><dd><p>Crab carapace width in cm.</p>
</dd>
<dt><code>satell</code></dt><dd><p>Number of satellites.</p>
</dd>
<dt><code>weight</code></dt><dd><p>Crab weight in in kg.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Agresti, A.  (2012)  <em>An Introduction to Categorical Data Analysis, 3rd edition</em>.  Wiley, New Jersey.
</p>


<h3>References</h3>

<p>Brockman, H. J.  (1996) Satellite male groups in horseshoe crabs, <em>Limulus polyphemus</em>.  <em>Ethology</em> 102(1) 1-21.
</p>

<hr>
<h2 id='cuckoo'>
Tippett cuckoo egg data</h2><span id='topic+cuckoo'></span>

<h3>Description</h3>

<p>Part of a dataset detailing cuckoo egg lengths found in other birds nests.  Units are millimeters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cuckoo)</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 3 variables.
</p>

<dl>
<dt><code>TP</code></dt><dd><p>Tree pipit</p>
</dd>
<dt><code>HS</code></dt><dd><p>Hedge sparrow</p>
</dd>
<dt><code>RB</code></dt><dd><p>Robin</p>
</dd>
</dl>



<h3>Source</h3>

<p>Tippett, L. H. C. (1952) <em>The Methods of Statistics, 4th Edition</em>.  Wiley.
</p>

<hr>
<h2 id='D.sq'>Mahalanobis distance for two sites using a pooled covariance matrix</h2><span id='topic+D.sq'></span>

<h3>Description</h3>

<p>Allows much easier multivariate comparisons of groups of sites then provided by the function <code>mahalanobis</code> in the <code>base</code> library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.sq(g1, g2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="D.sq_+3A_g1">g1</code></td>
<td>
<p>Community vector for site 1</p>
</td></tr>
<tr><td><code id="D.sq_+3A_g2">g2</code></td>
<td>
<p>Community vector for site 2</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Legendre, P, and L. Legendre  (1998)  <em>Numerical Ecology, 2nd English Edition</em>.  Elsevier, 
Amsterdam, The Netherlands. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>g1&lt;-matrix(ncol=3,nrow=3,data=c(1,0,3,2,1,3,4,0,2))
g2&lt;-matrix(ncol=3,nrow=3,data=c(1,2,4,5,2,3,4,3,1))
D.sq(g1,g2)$D.sq
 </code></pre>

<hr>
<h2 id='death.penalty'>
Florida state death penalty data
</h2><span id='topic+death.penalty'></span>

<h3>Description</h3>

<p>Dataset detailing death penalty 674 homicide trials in the state of Florida from 1976-1987 with respect to verdict, and victim and defendant race.  The data were previously used (Agresti 2012) to demonstrate Simpson's Paradox.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(death.penalty)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 4 variables.
</p>

<dl>
<dt><code>count</code></dt><dd><p>Counts from cross classifications.</p>
</dd>
<dt><code>verdict</code></dt><dd><p>Death penalty verdict <code>No</code> <code>Yes</code>.</p>
</dd>
<dt><code>d.race</code></dt><dd><p>Defendant's race <code>Black</code> <code>White</code>.</p>
</dd>
<dt><code>v.race</code></dt><dd><p>Victims' race <code>Black</code> <code>White</code>.</p>
</dd>
</dl>



<h3>Details</h3>

<p>A reversal of associations or comparisons may occur as a result of lurking variables or aggregating groups.  This is called Simpson's Paradox.  
</p>


<h3>Source</h3>

<p>Agresti, A.  (2012)  <em>Categorical Data Analysis, 3rd edition</em>.  New York.  Wiley. 
</p>
<p>Radelet, M. L., and G. L. Pierce  (1991) Choosing those who will die: race and the death 
penalty in Florida.  <em>Florida Law Review</em>  43(1):1-34.
</p>
<p>Simpson, E. H. (1951) The Interpretation of interaction in contingency tables. <em>Journal of the Royal Statistical Society</em> Ser. B 13: 238-241.
</p>

<hr>
<h2 id='deer'>Maternal deer data </h2><span id='topic+deer'></span>

<h3>Description</h3>

<p>Monteith et al. (2009) examined the maternal life history characteristics of white-tailed deer (Odocoileus virginianus) originating from the Black Hills in southwestern South Dakota and from eastern South Dakota.  Because litter size and dam size affects offspring weight the investigators used proportional birth mass (dam mass/total litter mass) as a measure of reproductive investment by deer.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(deer)</code></pre>


<h3>Format</h3>

<p>The dataframe contains 6 columns
</p>

<dl>
<dt><code>Birth.Yr</code></dt><dd><p>Year of birth.</p>
</dd>   
<dt><code>Litter.size</code></dt><dd><p>Number of offspring.</p>
</dd>         
<dt><code>Region</code></dt><dd><p>Categorical variable with two factor levels.  BH = Black Hills, ER = Eastern Region.</p>
</dd>        
<dt><code>Dam.weight</code></dt><dd><p>Dam weight in kg.</p>
</dd>
<dt><code>Total.birth.mass</code></dt><dd><p>Mass of litter in kg.</p>
</dd>
<dt><code>Prop.mass</code></dt><dd><p>Total birth mass divided by dam weight.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Monteith, K. L, Schmitz, L. E., Jenks, J. A., Delger, J. A., and R. T. Bowyer.  2009.  Growth of male white tailed deer: consequences of maternal effects.  <em>Journal of Mammalogy</em> 90(3): 651-660.</p>

<hr>
<h2 id='deer.296'>
Mule deer telemetry data
</h2><span id='topic+deer.296'></span>

<h3>Description</h3>

<p>Telemetry data for mule deer #296 from the Starkey Experimental Forest in Northeastern Oregon.  Data are high resolution (10 minute) radio collar readings from 8/20/2008 to 11/6/2008.  Also included are data for nearest neighbor locations of forest/grassland boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(deer.296)</code></pre>


<h3>Format</h3>

<p>A data frame with 5423 observations on the following 7 variables.
</p>

<dl>
<dt><code>Time</code></dt><dd><p>Unit of time measurement used at the Starkey Experimental Forest</p>
</dd>
<dt><code>X</code></dt><dd><p>Mule Deer <em>X</em>-coordinate, UTM Easting</p>
</dd>
<dt><code>Y</code></dt><dd><p>Mule Deer <em>Y</em>-coordinate, UTM Northing</p>
</dd>
<dt><code>NEAR_X</code></dt><dd><p>Nearest boundary location <em>X</em> coordinate</p>
</dd>
<dt><code>NEAR_Y</code></dt><dd><p>Nearest boundary location <em>Y</em> coordinate</p>
</dd>
<dt><code>Hab_Type</code></dt><dd><p>Type of habitat</p>
</dd>
<dt><code>NEAR_ANGLE</code></dt><dd><p>A numeric vector containing the angle of azimuth to the nearest point on the boundary with respect to a four quadrant system.  NE = <code class="reqn">0^{\circ}</code> to <code class="reqn">90^{\circ}</code>, NW is &gt; <code class="reqn">90^{\circ}</code> and <code class="reqn">\le 180^{\circ}</code>, SE is &lt; <code class="reqn">0^{\circ}</code> and <code class="reqn">\le -90^{\circ}</code> is &gt; <code class="reqn">-90^{\circ}</code> and <code class="reqn">\le -180^{\circ}</code>.</p>
</dd>
</dl>


<hr>
<h2 id='depression'>
Hamilton depression scores before and after drug treatment 
</h2><span id='topic+depression'></span>

<h3>Description</h3>

<p>Hollander and Wolfe (1999) presented Hamilton depression scale factor measurements for 
9 patients with mixed anxiety and depression.  Measurements were taken at a time preceding administration of tranquilizer, and a time after tranquilizer administration. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(depression)</code></pre>


<h3>Format</h3>

<p>A data frame with 18 observations on the following 3 variables.
</p>

<dl>
<dt><code>subject</code></dt><dd><p>Experimental subject.</p>
</dd>
<dt><code>scale</code></dt><dd><p>Hamilton depression scale score.  0-7 is considered to be normal. Scores of 20 or higher indicate moderate to very severe depression</p>
</dd>
<dt><code>time</code></dt><dd><p>A factor with levels <code>post</code> <code>pre</code> indicating before and after tranquilizer treatment.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hollander, M., and  D. A. Wolfe. 1999. <em>Nonparametric Statistical Methods</em>. New York: John Wiley &amp; Sons. 
</p>

<hr>
<h2 id='DH.test'>Doornik-Hansen test for multivariate normality.</h2><span id='topic+DH.test'></span>

<h3>Description</h3>

<p>The Doornik-Hansen test for multivariate normality is a powerful alternative to the 
Shapiro-Wilk test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
DH.test(Y, Y.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DH.test_+3A_y">Y</code></td>
<td>
<p>An <em>n</em> x <em>p</em> a dataframe of dependent variables.</p>
</td></tr>
<tr><td><code id="DH.test_+3A_y.names">Y.names</code></td>
<td>
<p>Names of <code>Y</code> variables; should be a 1 x <em>p</em> character string.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An assumption of multivariate normality is exceedingly difficult to verify.  Hypothesis 
tests tend to be too stringent, and multivariate diagnostic plots only allow viewing 
of two variables at a time.  Univariate normality of course can be verified using normal 
probability plots.  However while marginal non-normality indicates multivariate non-normality, 
marginal normality does not insure that <em>Y</em> variables collectively follow a multivariate normal 
distribution.  
</p>
<p>The Doornik-Hansen test for multivariate normality (Doornik and Hansen 2008) is based on the 
skewness and kurtosis of multivariate data that is transformed to insure independence.  
The DH test is more powerful than the Shapiro-Wilk test for most tested multivariate 
distributions (Doornik and Hansen 2008).  The function <code>DH.test</code> also runs the Doornik-Hansen 
test for both multivariate and univariate normality.  The later test follows 
directly from the work of Bowman and Shenton (1975), Shenton and Bowman (1977) and D'Agostino (1970).
</p>


<h3>Value</h3>

<p>Returns a list with two objects.
</p>
<table role = "presentation">
<tr><td><code>multi</code></td>
<td>
<p>A dataframe containing multivariate results, i.e. the test statistic, <em>E</em>, the 
degrees of freedom and the <em>p</em>-value.</p>
</td></tr>
<tr><td><code>comp2</code></td>
<td>
<p>A dataframe with <em>p</em> rows detailing univariate tests. Columns in the dataframe contain
the test statistics, degrees of freedom and <em>P</em>-values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>As with all inferential normality tests our null hypothesis is that the underlying population 
is normal, in this case multivariate normal.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>D'Agostino, R. B. (1970). Transformation to normality of the null distribution of g1, <em>Biometrika</em>
57: 679-681.
</p>
<p>Doornik, J.A. and Hansen, H. (2008). An Omnibus test for univariate and multivariate 
normality. <em>Oxford Bulletin of Economics and Statistics</em> 70, 927-939.
</p>
<p>Shenton, L. R. and Bowman, K. O. (1977). A bivariate model for the distribution of b1 and b2,
<em>Journal of the American Statistical Association</em> 72: 206.211.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code>, <code><a href="#topic+bv.boxplot">bv.boxplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)#The ubiquitous multivariate iris data.
DH.test(iris[,1:4],Y.names=names(iris[,1:4]))
</code></pre>

<hr>
<h2 id='dO2'>
Dissolved levels in locations above and below a town 
</h2><span id='topic+dO2'></span>

<h3>Description</h3>

<p>Dissolved O<code class="reqn">_2</code> readings in ppm for 15 random locations above and below a riverside community. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dO2)</code></pre>


<h3>Format</h3>

<p>A data frame with 30 observations on the following 2 variables.
</p>

<dl>
<dt><code>O2</code></dt><dd><p>Dissolved O<code class="reqn">_2</code> levels in ppm.</p>
</dd>
<dt><code>location</code></dt><dd><p>River flow location with respect to town.  Levels are <code>Above</code> <code>Below</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ott, R. L., and M. T. Longnecker  (2004)  <em>A First Course in Statistical Methods</em>.  Thompson. 
</p>

<hr>
<h2 id='drugs'>
Contingency data for high school marijuana, alcohol, and cigarette use
</h2><span id='topic+drugs'></span>

<h3>Description</h3>

<p>Agresti (2012) included a three way contingency table describing cigarette, alcohol, and marijuana use of high school students in Dayton Ohio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(drugs)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 4 variables.
</p>

<dl>
<dt><code>alc</code></dt><dd><p>Alcohol use. A factor with levels <code>N</code> <code>Y</code>.</p>
</dd>
<dt><code>cig</code></dt><dd><p>Cigarette use.  A factor with levels <code>N</code> <code>Y</code>.</p>
</dd>
<dt><code>mari</code></dt><dd><p>Marijuana use. A factor with levels <code>N</code> <code>Y</code></p>
</dd>
<dt><code>count</code></dt><dd><p>Counts for the cross-classification.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Agresti, A.  2012.  <em>Categorical Data Analysis, 3rd edition</em>.  New York.  Wiley. 
</p>

<hr>
<h2 id='e.cancer'>Esophageal cancer data modified slightly to create a balanced three-way 
factorial design</h2><span id='topic+e.cancer'></span>

<h3>Description</h3>

<p>Breslow and Day (1980) studied the effect of age, tobacco, and 
alcohol on esophageal cancer rates at Ile-et-Vilaine, France.  Data 
are altered slightly to make the design balanced, and to allow enough degrees 
of freedom to perform a fully factorial three way ANOVA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(e.cancer)</code></pre>


<h3>Format</h3>

<p>The dataset contains four variables:
</p>

<dl>
<dt>age grp.</dt><dd><p>age group, a factor with four levels: <code>"25-34", "35-44", "45-54", "55-64"</code>, and <code>"65-74"</code>.</p>
</dd>
<dt>alcohol</dt><dd><p>alcohol consumed (g/day).</p>
</dd>	
<dt>tobacco</dt><dd><p>tobacco consumed (g/day).</p>
</dd>	
<dt>cases</dt><dd><p>number of esophageal cancer cases.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Breslow, N. E. and N. E. Day (1980) <em>Statistical Methods in Cancer Research. 1: The 
Analysis of Case-Control Studies</em>. IARC Lyon / Oxford University Press. 
</p>

<hr>
<h2 id='eff.rbd'>
Efficiency of a randomized block design compared to a CRD
</h2><span id='topic+eff.rbd'></span>

<h3>Description</h3>

<p>Calculates the RCBD efficiency ratio for a linear model with one main factor and one blocking factor.  Values greater than 1 indicate that the RCBD has greater efficiency compared to a CRD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eff.rbd(lm)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eff.rbd_+3A_lm">lm</code></td>
<td>

<p>An object of class <code>lm</code>.  The blocking factor must be called <code>"block"</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Kutner, M. H., C. J. Nachtsheim, J. Neter, and W. Li  (2005) <em>Applied Linear Statistical Models</em>. McGraw-Hill Irwin.
</p>

<hr>
<h2 id='enzyme'>
Enzymatic rate data for the phospholipase protein ExoU 
</h2><span id='topic+enzyme'></span>

<h3>Description</h3>

<p>The bacterium <em>Pseudomonas aeruginosa</em> causes disease in human hosts leading to 
sepsis and even death in part by secreting lipases (proteins that break down lipids) 
into cellular environments.  The protein ExoU is a phospholipase produce by particularly 
virulent strains of <em>P. aeruginosa</em>.  Benson et al. (2009) measured of ExoU enzymatic 
activity under varying levels of the fluorescent phospholipase substrate PED6.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(enzyme)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 3 variables.
</p>

<dl>
<dt><code>substrate</code></dt><dd><p>PED6 concentration (in micromoles).</p>
</dd>
<dt><code>rate</code></dt><dd><p>enzymatic rate (nmol of cleaved of PED6 per mg ExoU).</p>
</dd>
<dt><code>sd</code></dt><dd><p>standard deviation of rate for each level of substrate.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Benson, M. A., Schmalzer, K. M., and D. W. Frank (2009) A sensitive fluorescence-based assay for the detection of ExoU mediated PLA2 activity.  <em>Clin Chim Acta</em> 411(3-4): 190-197.
</p>

<hr>
<h2 id='ES.May'>May's effective specialization index</h2><span id='topic+ES.May'></span>

<h3>Description</h3>

<p>May and Beverton (1990) created the effective specialization index to quantify the degree of 
specialization of insects with potential host plants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ES.May(mat, digs = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ES.May_+3A_mat">mat</code></td>
<td>
<p>A symmetric matrix with potential specialist hosts in rows and 
and the number species specializing on each of the host species in columns 
(see details below).</p>
</td></tr>
<tr><td><code id="ES.May_+3A_digs">digs</code></td>
<td>
<p>The number of significant digits in output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the object <code>mat</code> is nonintuitive.  In the rows of the matrix are
species which can be selected by potential specialists (i.e. hosts).  May and Beverton (1990) 
used four oak species.  The columns indicate the degree of specialization of 
potential specialists.  May and Beverton (1990) were interested in the specialization 
of beetles.  The first element (row 1, column 1) in their 4 x 4 matrix contained 
only beetle species found on host 1.  The second element (row 1, column 2) contained 
the number of beetle species found on host 1 and one other host. The third element 
(row 1, column 3) contained the number of beetle species found on host 1 and two 
other hosts.  The fourth element (row 1, column 4) contained the number of beetle 
species occurring on all four hosts.     
</p>


<h3>Value</h3>

<p>Output is a list 
</p>
<table role = "presentation">
<tr><td><code>E.S_coefficients</code></td>
<td>
</td></tr>
<tr><td><code>Nk</code></td>
<td>
<p>The number of distinct specialists.</p>
</td></tr>
<tr><td><code>Pki.matrix</code></td>
<td>
<p>The proportion of potential specialists on the <em>k</em>th host</p>
</td></tr>
<tr><td><code>N.matrix</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>fk.matrix</code></td>
<td>
</td></tr>
<tr><td><code>fk.vector</code></td>
<td>
<p>For the <em>k</em>th host, the proportion of species which are effectively specialized.</p>
</td></tr>
<tr><td><code>Nk.vector</code></td>
<td>
<p>The number of species which are effectively specialized on the <em>k</em>th host.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho and Jessica Fultz</p>


<h3>References</h3>

<p>May, R. M. and Beverton, R. J. H. (1990)  How many species [and discussion].  
<em>Philosophical Transactions: Biological Sciences</em>.  330 (1257) 293-304.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data from May and Beverton (1990)
beetle&lt;-matrix(ncol=4,nrow=4,data=c(5,8,7,8,20,10,9,8,14,15,11,8,15,15,12,8), 
byrow=TRUE)
ES.May(beetle)
</code></pre>

<hr>
<h2 id='exercise.repeated'>Repeated measures data for an exercise experiment.</h2><span id='topic+exercise.repeated'></span>

<h3>Description</h3>

<p>Freund et al. (1986) listed data for a longitudinal study of exercise therapies.  
The data were analyzed using AR1 covariance matrices in mixed models by Fitzmaurice 
et al. (2004).  In the study 37 patients were randomly assigned to one of two 
weightlifting programs. In the first program (TRT 1), repetitions with weights 
were increased as subjects became stronger. In the second program (TRT 2), 
the number of repetitions was fixed but weights were increased as subjects 
became stronger. An index measuring strength was created and recorded at day 
0, 2, 4, 6, 8, 10, and 12.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(exercise.repeated)</code></pre>


<h3>Format</h3>

<p>The dataframe contains a repeated measures dataset describing the strength of 37 subjects with respect to two weightlifting programs.  There are four columns:
</p>

<dl>
<dt>ID</dt><dd><p>Subject ID.</p>
</dd>
<dt>TRT</dt><dd><p>The type of weightlifting treatment (a factor with two levels, <code>1</code> and <code>2</code>).</p>
</dd>
<dt>strength</dt><dd><p>A strength index.</p>
</dd>
<dt>day</dt><dd><p>The day that <code>strength</code> was measured on a subject, measured from the start of the experiment.</p>
</dd>
</dl>
  


<h3>Source</h3>

<p>Fitzmaurice, G. M., Laird, N. M, and Waird, J. H.  (2004) <em>Applied Longitudinal Analysis</em>.  Wiley.
</p>

<hr>
<h2 id='facebook'>
Facebook performance metrics for data mining and machine learning
</h2><span id='topic+facebook'></span>

<h3>Description</h3>

<p>These data concern posts published during the year 2014 on the Facebook page of a popular cosmetics brand.
The data here are 500 of the 790 rows and part of the features analyzed by Moro et al. (2016). The remaining data points were 
omitted due to confidentiality issues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(facebook)</code></pre>


<h3>Format</h3>

<p>A data frame with 500 observations on the following 19 variables.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>Total number of likes of the page containing a post.</p>
</dd>
<dt><code>X2</code></dt><dd><p>Type of content; a factor with levels <code>Link</code>, <code>Photo</code>, <code>Status</code>, and <code>Video</code>.</p>
</dd>
<dt><code>X3</code></dt><dd><p>Manual content category; a factor with levels: <code>action</code> (special offers and contests), <code>product</code> (direct advertisement, explicit brand content), and <code>inspiration</code> (non-explicit brand related content).</p>
</dd>
<dt><code>X4</code></dt><dd><p>Month the post was posted.</p>
</dd>
<dt><code>X5</code></dt><dd><p>Weekday the post was published.</p>
</dd>
<dt><code>X6</code></dt><dd><p>Hour the post was posted</p>
</dd>
<dt><code>X7</code></dt><dd><p>An binary variable indicating if the company paid to Facebook for advertising.</p>
</dd>
<dt><code>Y1</code></dt><dd><p>Lifetime post total reach: the number of people who saw a page post.</p>
</dd>
<dt><code>Y2</code></dt><dd><p>Lifetime number of total impressions: the number of times a post from a page is displayed, whether the post is clicked or not.</p>
</dd>
<dt><code>Y3</code></dt><dd><p>Lifetime engaged users: the total number of people who clicked anywhere in a post (unique users).</p>
</dd>
<dt><code>Y4</code></dt><dd><p>Lifetime number of post consumers: the number of people who clicked anywhere in a post after purchasing something on the page.</p>
</dd>
<dt><code>Y5</code></dt><dd><p>Lifetime number of post consumptions: the number of clicks anywhere in a post by people after purchasing something on the page.</p>
</dd>
<dt><code>Y6</code></dt><dd><p>Lifetime number of post impressions by people who have liked the page.</p>
</dd>
<dt><code>Y7</code></dt><dd><p>Lifetime post reach by people who like the page.</p>
</dd>
<dt><code>Y8</code></dt><dd><p>Lifetime number of people who have liked the page and engaged with the post.</p>
</dd>
<dt><code>Y9</code></dt><dd><p>Number of &quot;comments&quot;&quot; on the post.</p>
</dd>
<dt><code>Y10</code></dt><dd><p>Number of &quot;likes&quot; on the post.</p>
</dd>
<dt><code>Y11</code></dt><dd><p>Number of times the post was &quot;shared.&quot;&quot;</p>
</dd>
<dt><code>Y12</code></dt><dd><p>Total interactions: the sum of &quot;likes,&quot; &quot;comments,&quot; and &quot;shares&quot; of the post.</p>
</dd>
</dl>



<h3>References</h3>

<p>This dataset is publicly available for research. The details are described in (Moro et al., 2016).  Please include this citation if you plan to use this data: 
</p>
<p>S. Moro, P. Rita, Vala, B. (2016) Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach. Journal of Business Research 69(9): 3341-3351. 
</p>

<hr>
<h2 id='Fbird'>Frigatebird drumming frequency data</h2><span id='topic+Fbird'></span>

<h3>Description</h3>

<p>Male magnificent frigatebirds (<em>Fregata magnificens</em>) have an enlarged red throat pouch that has probably evolved as the result of sexual selection.  
During courtship displays males attract females by displaying this pouch and using it to make a drumming sound. Madsen et al. (2004) noted that conditions 
(e.g. oblique viewing angles) often limit females' ability to appraise pouch size exactly.  Since females choose mates based on pouch size, 
a question of interest is whether females could use the pitch of the pouch drumming as an indicator of pouch size. 
Madsen et al. (2004) estimated the pouch volume and fundamental drumming frequency for forty males at Isla Isabel in Nayarit Mexico.  
Eighteen of these observations are in this dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Fbird)</code></pre>


<h3>Format</h3>

<p>The dataframe contains two variables: 
</p>

<dl>
<dt><code>vol</code></dt><dd>
<p>Pouch volume (in cm<code class="reqn">^3</code>). 
</p>
</dd>
<dt><code>freq</code></dt><dd>
<p>Frequency of drumming (in Hz)
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Madsen, V., Balsby, T.J.S., Dabelsteen, T., and J.L. Osorno (2004) Bimodal signaling of 
a sexually selected trait: gular pouch drumming in the magnificent frigatebird. <em>Condor</em> 106: 156-160.
</p>

<hr>
<h2 id='fire'>
Fire data from Yellowstone National Park
</h2><span id='topic+fire'></span>

<h3>Description</h3>

<p>Fires from 1988 constituted the largest conflagration in the history of Yellowstone National Park.  This dataframe lists burned areas for ten Yellowstone stream catchments (Robinson et al. 1994).   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fire)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 2 variables.
</p>

<dl>
<dt><code>fire</code></dt><dd><p>Burn area in, in hectares<code class="reqn">^2</code>.</p>
</dd>
<dt><code>stream</code></dt><dd><p>A factor with levels <code>Blacktail</code> <code>Cache</code> <code>EF.Blacktail</code> <code>Fairy</code> <code>Hellroaring</code> <code>Iron.Springs</code> <code>Pebble</code> <code>Rose</code> <code>SF.Cache</code> <code>Twin</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Robinson, C. T., Minshall, G. W., and S. R. Rushforth  (1994)  The effects of the 1988 
wildfires on diatom assemblages in the streams of Yellowstone National Park.  Technical Report NPS/NRYELL/NRTR-93/XX. 
</p>

<hr>
<h2 id='fly.sex'>
Fly sex and longevity
</h2><span id='topic+fly.sex'></span>

<h3>Description</h3>

<p>Partridge and Farqaur (1981) studied the effect of the number of mating partners on the longevity of fruit flies.  Five different mating treatments were applied to single male fruit flies.  As a concomitant variable thorax length was measured.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fly.sex)</code></pre>


<h3>Format</h3>

<p>A data frame with 125 observations on the following 3 variables.
</p>

<dl>
<dt><code>treatment</code></dt><dd><p>a factor with levels <code>1</code> = One virgin female per day, <code>2</code> = eight virgin females per day, <code>3</code> = a control group with one newly inseminated female per day, <code>4</code> = a control group with eight newly inseminated females per day, 
and <code>5</code> a control group with no added females.</p>
</dd>
<dt><code>longevity</code></dt><dd><p>Age in days.</p>
</dd>
<dt><code>thorax</code></dt><dd><p>Thorax length in mm.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Quinn, G. P., and M. J. Keough.  2002.  <em>Experimental Design and Data Analysis for 
Biologists</em>.  Cambridge University Press. 
</p>


<h3>References</h3>

<p>Partridge, L., and Farquhar, M. (1981), Sexual activity and the lifespan of male fruit flies, <em>Nature</em> 294, 580-581.
</p>

<hr>
<h2 id='frog'>Australian frog calls following fire
</h2><span id='topic+frog'></span>

<h3>Description</h3>

<p>Driscoll and Roberts (1997) examined the impact of fire on the Walpole frog (<em>Geocrinia lutea</em>) in catchments in Western Australia by counting the number of calling males in six paired burn and control sites for three years following spring burning in 1991. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(frog)</code></pre>


<h3>Format</h3>

<p>A data frame with 18 observations on the following 3 variables.
</p>

<dl>
<dt><code>catchment</code></dt><dd><p>A factor with levels <code>angove</code> <code>logging</code> <code>newpipe</code> <code>newquinE</code> <code>newquinW</code> <code>oldquinE</code>.</p>
</dd>
<dt><code>frogs</code></dt><dd><p>The difference in the number of male frog calls for control - burned sites.</p>
</dd>
<dt><code>year</code></dt><dd><p>Year.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Quinn, G. P., and M. J. Keough (2002) <em>Experimental Design and Data Analysis for Biologists</em>. Cambridge University Press.
</p>


<h3>References</h3>

<p>Driscoll, D. A., and J. D. Roberts. 1997. Impact of fuel-reduction burning on the frog Geocrinia lutea in southwest Western Australia. <em>Australian Journal of Ecology</em> 22:334-339.
</p>

<hr>
<h2 id='fruit'>
Fruit weight data from Littell et al. (2002)
</h2><span id='topic+fruit'></span>

<h3>Description</h3>

<p>Valencia orange tree fruit weights are measured at harvest with respect to five irrigation treatment applied in eight blocks in a RCBD.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fruit)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 3 variables.
</p>

<dl>
<dt><code>block</code></dt><dd><p>a factor describing eight blocks</p>
</dd>
<dt><code>irrig</code></dt><dd><p>a factor with levels <code>basin</code> <code>flood</code> <code>spray</code> <code>sprinkler</code> <code>trickle</code></p>
</dd>
<dt><code>fruitwt</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Littell, R. C., Stroup, W. W., and R. J. Freund (2002)  <em>SAS for linear models</em>.  John 
Wiley and Associates.
</p>

<hr>
<h2 id='G.mean'>Geometric mean</h2><span id='topic+G.mean'></span>

<h3>Description</h3>

<p>Calculates the geometric mean.</p>


<h3>Usage</h3>

<pre><code class='language-R'>G.mean(x)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="G.mean_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the geometric mean.</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="#topic+H.mean">H.mean</a></code>, <code><a href="#topic+HL.mean">HL.mean</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-c(2,1,4,5,6,2.4,7,2.2,.002,15,17,.001)
G.mean(x)
</code></pre>

<hr>
<h2 id='g.test'>
Likelihood ratio test for tabular data
</h2><span id='topic+g.test'></span>

<h3>Description</h3>

<p>Provides likelihood ratio tests for one way and multiway tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
g.test(y, correct = FALSE, pi.null = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="g.test_+3A_y">y</code></td>
<td>

<p>A vector of at least 2 elements, or a matrix.  Must contain only non-negative integers.
</p>
</td></tr>
<tr><td><code id="g.test_+3A_correct">correct</code></td>
<td>

<p>Logical.  Indicating whether Yates correction for continuity should be used.
</p>
</td></tr>
<tr><td><code id="g.test_+3A_pi.null">pi.null</code></td>
<td>

<p>Optional vector or matrix of null proportions.  Must sum to one.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>Examples</h3>

<pre><code class='language-R'>obs &lt;- c(6022, 2001)
g.test(obs, pi.null = c(0.75, 0.25))
</code></pre>

<hr>
<h2 id='garments'>
Garment Latin square data from Littell et al. (2002)
</h2><span id='topic+garments'></span>

<h3>Description</h3>

<p>Four materials (A, B, C, D) used in permanent press garments were subjected to a test for shrinkage.  The four materials were placed in a heat chamber with with four settings (pos).  The test was then conducted in four runs (run). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(garments)</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 4 variables.
</p>

<dl>
<dt><code>run</code></dt><dd><p>Test run, a factor with levels <code>1</code> <code>2</code> <code>3</code> <code>4</code></p>
</dd>
<dt><code>pos</code></dt><dd><p>Heat position, a factor with levels <code>1</code> <code>2</code> <code>3</code> <code>4</code></p>
</dd>
<dt><code>mat</code></dt><dd><p>Fabric materials, a factor with levels <code>A</code> <code>B</code> <code>C</code> <code>D</code></p>
</dd>
<dt><code>shrink</code></dt><dd><p>Shrinkage measure, a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Littell, R. C., Stroup, W. W., and R. J. Freund (2002)  <em>SAS for Linear Models</em>.  John 
Wiley and Associates.
</p>

<hr>
<h2 id='Glucose2'>Glucose Levels Following Alcohol Ingestion</h2><span id='topic+Glucose2'></span>

<h3>Description</h3>

<p>The <code>Glucose2</code> data frame has 196 rows and 4 columns.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Subject</code></dt><dd>
<p>a factor with levels
<code>1</code> to <code>7</code> identifying the subject whose glucose
level is measured. 
</p>
</dd>
<dt><code>Date</code></dt><dd>
<p>a factor with levels
<code>1</code> 
<code>2</code>
indicating the occasion in which the experiment was conducted.
</p>
</dd>
<dt><code>Time</code></dt><dd>
<p>a numeric vector giving the time since alcohol ingestion (in min/10).
</p>
</dd>
<dt><code>glucose</code></dt><dd>
<p>a numeric vector giving the blood glucose level (in mg/dl).
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Hand and Crowder (Table A.14, pp. 180-181, 1996) describe data on
the blood glucose levels measured at 14 time points over 5 hours for 7
volunteers who took alcohol at time 0. The same experiment was
repeated on a second date with the same subjects but with a dietary
additive used for all subjects.
</p>


<h3>Note</h3>

<p>Descriptions and details are from the library <span class="pkg">nlme</span>.</p>


<h3>Source</h3>

<p>Pinheiro, J. C. and Bates, D. M. (2000), <em>Mixed-Effects Models in S
and S-PLUS</em>, Springer, New York.  (Appendix A.10)
</p>
<p>Hand, D. and Crowder, M. (1996), <em>Practical Longitudinal Data
Analysis</em>, Chapman and Hall, London.
</p>

<hr>
<h2 id='goats'>Mountain goat data from Yellowstone National Park</h2><span id='topic+goats'></span>

<h3>Description</h3>

<p>Mount goat (<em>Oreomnos americanus</em>) feces data and soil nutrient data for eight different mountains in the Northern Absarokas in Yellowstone National Park.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(goats)</code></pre>


<h3>Format</h3>

<p>The dataframe has 3 columns:
</p>

<dl>
<dt><code>feces</code></dt><dd><p>feces concentration (Percent occurrence per 0.1, m^2 plot).</p>
</dd>
<dt><code>NO3</code></dt><dd><p>Nitrate concentration in ppm.</p>
</dd> 
<dt><code>organic.matter</code></dt><dd><p>Organic matter concentration (LOI) as a percentage.</p>
</dd> 
</dl>



<h3>Source</h3>

<p>Aho, K. (2012)  <em>Management of introduced mountain goats in Yellowstone National Park (vegetation analysis along a mountain goat gradient).  PMIS:  105289</em>.  Report prepared for USDA National Park Service. 150 pp.
</p>

<hr>
<h2 id='grass'>Agricultural factorial design</h2><span id='topic+grass'></span>

<h3>Description</h3>

<p>Littell et al. (2006) describe an experiment to distinguish the effects of three seed growing methods 
on the yield of five turf grass varieties. The seed growing methods were applied to seed from each grass variety.  
Six pots were planted with each variety <code class="reqn">\times</code> method combination.  The pots were placed in a growth chamber with 
uniform conditions and dry matter (in grams) was weighed from above ground clips after four weeks.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(grass)</code></pre>


<h3>Format</h3>

<p>The dataframe has three columns:
</p>

<dl>
<dt><code>yield</code></dt><dd><p>Refers to grass yield.</p>
</dd>
<dt><code>method</code></dt><dd><p>Seed growing method.  A factor with three levels: <code>a,b,c</code>.</p>
</dd>  
<dt><code>variety</code></dt><dd><p>Grass variety. A factor with five levels: <code>1,2,3,4,5</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Littell, R. C., Milliken, G. A., Stroup, W. W., Wolfinger, R. D., and O. Schabenberger  
(2006)  <em>SAS for mixed models 2nd ed</em>.  SAS press.
</p>

<hr>
<h2 id='H.mean'>Harmonic mean</h2><span id='topic+H.mean'></span>

<h3>Description</h3>

<p>Calculates the harmonic mean.</p>


<h3>Usage</h3>

<pre><code class='language-R'>H.mean(x)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="H.mean_+3A_x">x</code></td>
<td>
<p>Vector of quantitative data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the harmonic mean.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="#topic+G.mean">G.mean</a></code>, <code><a href="#topic+HL.mean">HL.mean</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-c(2,1,4,5,6,2.4,7,2.2,.002,15,17,.001)
H.mean(x)
</code></pre>

<hr>
<h2 id='heart'>
Heart rate data from Milliken and Johnson (2009)
</h2><span id='topic+heart'></span>

<h3>Description</h3>

<p>A repeated measures demonstration dataset from Milliken and Johnson (1999).  Heart rate was measured for twenty four subject at four time periods following administration of a treatment.  The treatment types were two active heart drugs and a control.  One treatment was assigned to each subject. 
Thus each drug was administered to eight subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(heart)</code></pre>


<h3>Format</h3>

<p>A data frame with 96 observations on the following 4 variables.
</p>

<dl>
<dt><code>rate</code></dt><dd><p>A numeric vector describing heart rate (bpm).</p>
</dd>
<dt><code>time</code></dt><dd><p>A factor with levels <code>t1</code> <code>t2</code> <code>t3</code> <code>t4</code></p>
</dd>
<dt><code>drug</code></dt><dd><p>A factor with levels <code>AX23</code> <code>BWW9</code> <code>Ctrl</code></p>
</dd>
<dt><code>subject</code></dt><dd><p>A factor describing which subject (in drug) that measurements were made on.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Milliken, G. A., and D. E. Johnson (2008) <em>Analysis of Messy Data: Vol. I. Designed Experiments, 2nd edition</em>. CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#data(heart)
#aov(rate ~ drug * time + Error(subject%in%drug), data = heart)

## End(Not run)
</code></pre>

<hr>
<h2 id='HL.mean'>Hodges-Lehman estimator of location</h2><span id='topic+HL.mean'></span>

<h3>Description</h3>

<p>Calculates the Hodges-Lehman estimate of location &ndash;which is consistent for the true pseudomedian&ndash; using Walsh averages (Hollander and Wolfe 1999, pgs. 51-55). If requested, the function also provides confidence intervals for the true pseudomedian.  In a symmetric distribution the mean, median, and pseudomedian will be identical.</p>


<h3>Usage</h3>

<pre><code class='language-R'>HL.mean(x, conf = NULL, method = "exact")</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HL.mean_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
<tr><td><code id="HL.mean_+3A_conf">conf</code></td>
<td>
<p>A proportion specifying 1 - <em>P</em>(type I error).</p>
</td></tr>
<tr><td><code id="HL.mean_+3A_method">method</code></td>
<td>
<p>method for confidence interval calculation.  One of <code>"approx"</code>, which uses a normal approximation, or <code>"exact"</code>, which uses the Wilcoxon sign-rank quantile function (see Hollander and Wolfe 1999).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Hollander, M., and Wolfe, D. A  (1999) <em>Nonparametric Statistical Methods</em>. New York: John Wiley &amp; Sons.</p>


<h3>See Also</h3>

<p><code><a href="#topic+H.mean">H.mean</a></code>, <code><a href="#topic+G.mean">G.mean</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Hamilton depression scale (Hollander and Wolfe 1999)
x&lt;-c( -0.952, 0.147, -1.022, -0.430, -0.620, -0.590, -0.490,  0.080, -0.010)
HL.mean(x, conf = .96)
</code></pre>

<hr>
<h2 id='huber.mu'>Huber M-estimator of location</h2><span id='topic+huber.mu'></span>

<h3>Description</h3>

<p>The Huber <em>M</em>-estimator is a robust high efficiency estimator of location that has probably been under-utilized by biologists. It is based on maximizing the likelihood of a weighting function.  This is accomplished using an iterative least squares process.  The Newton Raphson algorithm is used here.  The function usually converges fairly quickly (&lt; 10 iterations).  The function uses the Median Absolute Deviation function, <code><a href="stats.html#topic+mad">mad</a></code>.  Note that if MAD = 0, then <code>NA</code> is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber.mu(x, c = 1.28, iter = 20, conv = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huber.mu_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
<tr><td><code id="huber.mu_+3A_c">c</code></td>
<td>
<p>Stop criterion.  The value <code>c = 1.28</code> gives 95% efficiency of the mean given normality.</p>
</td></tr>
<tr><td><code id="huber.mu_+3A_iter">iter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="huber.mu_+3A_conv">conv</code></td>
<td>
<p>Convergence criterion.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns Huber's <em>M</em>-estimator of location.</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

 
<p>Huber, P. J. (2004)  <em>Robust Statistics</em>. Wiley.
</p>
<p>Wilcox, R. R. (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+huber.one.step">huber.one.step</a></code>, <code><a href="#topic+huber.NR">huber.NR</a></code>, <code><a href="stats.html#topic+mad">mad</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
huber.mu(x)
</code></pre>

<hr>
<h2 id='huber.NR'>Huber M-estimator iterative least squares algorithm</h2><span id='topic+huber.NR'></span>

<h3>Description</h3>

<p>Algorithm for calculating fully iterated or one step Huber <em>M</em>-estimators of location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber.NR(x, c = 1.28, iter = 20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huber.NR_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data</p>
</td></tr>
<tr><td><code id="huber.NR_+3A_c">c</code></td>
<td>
<p>Bend criterion.  The value <code>c = 1.28</code> gives 95% efficiency of the mean given normality.
</p>
</td></tr>
<tr><td><code id="huber.NR_+3A_iter">iter</code></td>
<td>
<p>Maximum number of iterations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Huber <em>M</em>-estimator is a robust high efficiency estimator of location that has probably been under-utilized by biologists. It is based on maximizing the likelihood of a weighting function.  This is accomplished using an iterative least squares process.  The Newton Raphson algorithm is used here.  The function usually converges fairly quickly &lt; 10 iterations.  The function uses the Median Absolute Deviation function, <code><a href="stats.html#topic+mad">mad</a></code>.  Note that if MAD = 0, then <code>NA</code> is returned.
</p>


<h3>Value</h3>

<p>Returns iterative least squares iterations which converge to Huber's <em>M</em>-estimator.  The first element in the vector is the sample median.  The second element is the Huber one-step estimate. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

 
<p>Huber, P. J.  (2004)  <em>Robust Statistics</em>. Wiley.
</p>
<p>Wilcox, R. R.   (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+huber.one.step">huber.one.step</a></code>, <code><a href="#topic+huber.mu">huber.mu</a></code>, <code><a href="stats.html#topic+mad">mad</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-rnorm(100)
huber.NR(x)
</code></pre>

<hr>
<h2 id='huber.one.step'>Huber one step M-estimator</h2><span id='topic+huber.one.step'></span>

<h3>Description</h3>

<p>Returns the first Raphson-Newton iteration of the function <code>Huber.NR</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber.one.step(x, c = 1.28)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huber.one.step_+3A_x">x</code></td>
<td>
<p>Vector of quantitative data</p>
</td></tr>
<tr><td><code id="huber.one.step_+3A_c">c</code></td>
<td>
<p>Bend criterion.  The value <code>c = 1.28</code> gives 95% efficiency of the mean given normality.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Huber <em>M</em>-estimator function usually converges fairly quickly, hence the justification of the Huber one step estimator.  The function uses the Median Absolute Deviation function, <code><a href="stats.html#topic+mad">mad</a></code>.  If MAD = 0, then <code>NA</code> is returned.
</p>


<h3>Value</h3>

<p>Returns the Huber one step estimator.</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Huber, P. J.  (2004)  <em>Robust Statistics</em>. Wiley.
</p>
<p>Wilcox, R. R.   (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+huber.mu">huber.mu</a></code>, <code><a href="#topic+huber.NR">huber.NR</a></code>, <code><a href="stats.html#topic+mad">mad</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-rnorm(100)
huber.one.step(x)
</code></pre>

<hr>
<h2 id='illusions'>
Visual illusions illustrating human perception errors.
</h2><span id='topic+illusions'></span>

<h3>Description</h3>

<p>In development, currently displays three illusions.  Illusion 3 is from Yihui Xie's package <span class="pkg">animation</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
illusions(ill.no = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="illusions_+3A_ill.no">ill.no</code></td>
<td>
<p>Integer in 1:3 describing which illusion number to view.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho.  Illusion 3 uses code from Yihui Xie's package animation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>illusions(1)
illusions(2)
illusions(3)
</code></pre>

<hr>
<h2 id='ipomopsis'>
Ipomopsis fruit yield data
</h2><span id='topic+ipomopsis'></span>

<h3>Description</h3>

<p>The following question is based on data from Crawley (2007).  We are interested in the effect of grazing on seed production in the plant scarlet gilia <em>Ipomopsis aggregata</em> .  Forty plants were allocated to two treatments, grazed and ungrazed.  Grazed plants were exposed to rabbits during the first two weeks of stem elongation.  They were then protected from subsequent grazing by the erection of a fence and allowed to continue growth. Because initial plant size may influence subsequent fruit production, the diameter of the top of the rootstock was measured before the experiment began.  At the end of the experiment, fruit production (dry weight in milligrams) was recorded for each of the forty plants.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ipomopsis)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 3 variables.
</p>

<dl>
<dt><code>root</code></dt><dd><p>Rootstock diameter in mm</p>
</dd>
<dt><code>fruit</code></dt><dd><p>Fruit dry weight in mg</p>
</dd>
<dt><code>grazing</code></dt><dd><p>a factor with levels <code>Grazed</code> <code>Ungrazed</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Website associated with &ndash;
Crawley, M. J.  2007.  <em>The R book</em>.  Wiley. 
</p>

<hr>
<h2 id='joint.ci.bonf'>Calculates joint confidence intervals for parameters in linear models using a Bonferroni procedure.</h2><span id='topic+joint.ci.bonf'></span>

<h3>Description</h3>

<p>Creates widened confidence intervals to allow joint consideration of parameter confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
joint.ci.bonf(model, conf = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="joint.ci.bonf_+3A_model">model</code></td>
<td>
<p>A linear model created by <code><a href="stats.html#topic+lm">lm</a></code></p>
</td></tr>
<tr><td><code id="joint.ci.bonf_+3A_conf">conf</code></td>
<td>
<p>level of confidence 1 - <em>P</em>(type I error)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As with all Bonferroni-based methods for joint confidence the resulting intervals 
are exceedingly conservative and thus are prone to type II error.
</p>


<h3>Value</h3>

<p>Returns a dataframe with the upper and lower confidence bounds for each parameter in a linear model.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li. (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+confint">confint</a></code>, <code><a href="stats.html#topic+p.adjust">p.adjust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Soil.C&lt;-c(13,20,10,11,2,25,30,25,23)
Soil.N&lt;-c(1.2,2,1.5,1,0.3,2,3,2.7,2.5)
Slope&lt;-c(15,14,16,12,10,18,25,24,20)
Aspect&lt;-c(45,120,100,56,5,20,5,15,15)
Y&lt;-as.vector(c(20,30,10,15,5,45,60,55,45))
model&lt;-lm(Y~Soil.C+Soil.N+Slope+Aspect)
joint.ci.bonf(model)
</code></pre>

<hr>
<h2 id='K'>
Soil potassium analyses from 8 laboratories
</h2><span id='topic+K'></span>

<h3>Description</h3>

<p>Jacobsen et al. (2002) sent nine &quot;identical&quot; soil samples to eight soil testing 
laboratories in the Great Plains region of the Central United States over a three year period of time. 
Among other characteristics the labs were paid to measure soil potassium.  
A question of interest was whether the labs would produce identical analytical results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(K)</code></pre>


<h3>Format</h3>

<p>A data frame with 72 observations on the following 2 variables.
</p>

<dl>
<dt><code>K</code></dt><dd><p>Soil K in mg/kg</p>
</dd>
<dt><code>lab</code></dt><dd><p>Laboratories, a factor with levels <code>B</code> <code>D</code> <code>E</code> <code>F</code> <code>G</code> <code>H</code> <code>I</code> <code>J</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Jacobsen, J. S., Lorber, S. H., Schaff, B. E., and C. A. Jones (2002)  Variation in soil 
fertility test results from selected Northern Great Plains laboratories.  <em>Commun. Soil Sci. plant Anal.</em>, 33(3&amp;4): 303-319.
</p>

<hr>
<h2 id='Kappa'>Calculates kappa statistic and other classification error statistics</h2><span id='topic+Kappa'></span>

<h3>Description</h3>

<p>The kappa statistic, along with user and producer error rates are conventionally 
used in the remote sensing to describe the effectiveness of ground cover 
classifications.  Since it simultaneously considers both errors of commission 
and omission, kappa can be considered a more conservative measure of 
classification accuracy than the percentage of correctly classified items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kappa(class1, reference)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kappa_+3A_class1">class1</code></td>
<td>
<p>A vector describing a classification of experimental units.</p>
</td></tr>
<tr><td><code id="Kappa_+3A_reference">reference</code></td>
<td>
<p>A vector describing the &quot;correct&quot; classification of the experimental units in <code>class1</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with 4 items 
</p>
<table role = "presentation">
<tr><td><code>ttl_agreement</code></td>
<td>
<p>The percentage of correctly classified items.</p>
</td></tr>
<tr><td><code>user_accuracy</code></td>
<td>
<p>The user accuracy for each category of the classification.</p>
</td></tr>
<tr><td><code>producer_accuracy</code></td>
<td>
<p>The producer accuracy for each category of the classification.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>The kappa statistic.</p>
</td></tr>
<tr><td><code>table</code></td>
<td>
<p>A two way contingency table comparing the user supplied classification to the reference classification.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Jensen, J. R.  (1996)  <em>Introductory digital imagery processing 2nd edition</em>.  Prentice-Hall.</p>


<h3>Examples</h3>

<pre><code class='language-R'>reference&lt;-c("hi","low","low","hi","low","med","med")
class1&lt;-c("hi","hi","low","hi","med","med","med")
Kappa(class1,reference)
</code></pre>

<hr>
<h2 id='km'>Kaplan-Meier survivorship.</h2><span id='topic+km'></span>

<h3>Description</h3>

<p>Calculates survivorship for individuals in a population over time based on the 
method of Kaplan-Meier; cf. Pollock et al. (1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>km(r, d, var = "O", conf = 0.95, age.seq=seq(1,length(r)),
ylab = "Survivorship", xlab = "Age class", type = "b", 
plot.km = TRUE, plot.CI = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="km_+3A_r">r</code></td>
<td>
<p>Numbers of individuals at risk in each age or time class.</p>
</td></tr>
<tr><td><code id="km_+3A_d">d</code></td>
<td>
<p>Vector of the number of deaths in each age or time class.</p>
</td></tr>
<tr><td><code id="km_+3A_var">var</code></td>
<td>
<p>Type of procedure used to calculate variance in confidence intervals <code>"O"</code> = Oakes, <code>"G"</code> = Greenwood.</p>
</td></tr>
<tr><td><code id="km_+3A_conf">conf</code></td>
<td>
<p>Level of confidence for confidence interval calculations; 1 - <em>P</em>(type I error)</p>
</td></tr>
<tr><td><code id="km_+3A_age.seq">age.seq</code></td>
<td>
<p>A sequence of numbers indicating the age classes used.</p>
</td></tr>
<tr><td><code id="km_+3A_ylab">ylab</code></td>
<td>
<p><em>Y</em>-axis label.</p>
</td></tr>
<tr><td><code id="km_+3A_xlab">xlab</code></td>
<td>
<p><em>X</em>-axis label.</p>
</td></tr>
<tr><td><code id="km_+3A_type">type</code></td>
<td>
<p><code>type</code> argument from <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="km_+3A_plot.km">plot.km</code></td>
<td>
<p>Logical. Should plot be created?</p>
</td></tr>
<tr><td><code id="km_+3A_plot.ci">plot.CI</code></td>
<td>
<p>Logical. Should confidence interval be overlaid on plot?</p>
</td></tr>
<tr><td><code id="km_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details for this index are given in Pollock et al. (1989).
</p>


<h3>Value</h3>

<p>Returns a list with the following components
</p>
<table role = "presentation">
<tr><td><code>s.hat</code></td>
<td>
<p>A vector of estimated survivorship probabilities from the 1st age class onward.</p>
</td></tr>
<tr><td><code>Greenwood.Var</code></td>
<td>
<p>The estimated Greenwood variance for each age class.</p>
</td></tr>
<tr><td><code>Oakes.Var</code></td>
<td>
<p>The estimated Oakes variance for each age class.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Upper and lower confidence bound to the true survivorship.</p>
</td></tr>     
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Pollock, K. H., Winterstein, S. R., and Curtis, P. D. (1989) Survival 
analysis in telemetry studies: the staggered entry design.  <em>Journal of Wildlife 
Management</em>.  53(1):7-1.</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Example from Pollock (1989)
r&lt;-c(18,18,18,16,16,16,15,15,13,10,8,8,7)
d&lt;-c(0,0,2,0,0,1,0,1,1,1,0,0,0)

km(r,d)
</code></pre>

<hr>
<h2 id='Kullback'>Kullback test for equal covariance matrices.</h2><span id='topic+Kullback'></span><span id='topic+print.kback'></span>

<h3>Description</h3>

<p>Provides Kullback's (1959) test for multivariate homoscedasticity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kullback(Y, X)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kullback_+3A_y">Y</code></td>
<td>
<p>An <em>n</em> x <em>p</em> matrix of quantitative variables</p>
</td></tr>
<tr><td><code id="Kullback_+3A_x">X</code></td>
<td>
<p>An <em>n</em> x 1 vector of categorical assignments (e.g. factor levels)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multivariate general linear models assume equal covariance matrices for all 
factor levels or factor level combinations. Legendre and Legendre (1998) recommend 
this test for verifying homoscedasticity.  <em>P</em>-values concern a null hypothesis of 
equal population covariance matrices.  <em>P</em>-values from the test are conservative with respect to type I error. 
</p>


<h3>Value</h3>

<p>Returns a dataframe with the test statistic (which follows a chi-square distribution if H<code class="reqn">_0</code> is true), 
the chi-square degrees of freedom, and the calculated <em>p</em>-value.  Invisible objects include the within group dispersion matrix.
</p>


<h3>Author(s)</h3>

<p>Pierre Legendre is the author of the most recent version of this function asbio ver &gt;= 1.0. Stephen Ousley discovered an error in the original code. Ken Aho was the author of the original function</p>


<h3>References</h3>

<p>Kullback, S. (1959)  <em>Information Theory and Statistics</em>.  John Wiley and Sons.
</p>
<p>Legendre, P, and Legendre, L.  (1998) <em>Numerical Ecology, 2nd English edition</em>.  Elsevier, 
Amsterdam, The Netherlands. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y1&lt;-rnorm(100,10,2)
Y2&lt;-rnorm(100,15,2)
Y3&lt;-rnorm(100,20,2)
Y&lt;-cbind(Y1,Y2,Y3)
X&lt;-factor(c(rep(1,50),rep(2,50)))
Kullback(Y,X)
</code></pre>

<hr>
<h2 id='larrea'>
Creosote bush counts 
</h2><span id='topic+larrea'></span>

<h3>Description</h3>

<p>Phillips and MacMahon (1981) conducted an extensive study of <em>Larrea tridentata</em> (creosote bush) distributions in the Mojave 
and Sonoran deserts from several life stage classes based areal coverage: Life stage 1 (102 -103 cm<code class="reqn">^2</code>)	Life stage 2 (103 -104 cm<code class="reqn">^2</code>), and	Life stage 3
(104 -105 cm<code class="reqn">^2</code>).  Data were generated (using variance and mean values, and the function <code><a href="stats.html#topic+rpois">rpois</a></code> to approximate the results of the authors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(larrea)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 3 variables.
</p>

<dl>
<dt><code>class1</code></dt><dd><p>Counts from life stage 1</p>
</dd>
<dt><code>class2</code></dt><dd><p>Counts from life stage 2</p>
</dd>
<dt><code>class3</code></dt><dd><p>Counts from life stage 3</p>
</dd>
</dl>



<h3>References</h3>

<p>Phillips, D. L., and J. A. MacMahon  (1981)  Competition and spacing patterns in desert 
shrubs.  <em>Journal of Ecology</em> 69(1): 97-115. 
</p>

<hr>
<h2 id='life.exp'>
Mouse life expectancy data
</h2><span id='topic+life.exp'></span>

<h3>Description</h3>

<p>Weindruch et al. (1986) compared life expectancy of field mice given different diets.  To accomplish this, the authors randomly assigned 244 mice to one of four diet treatments.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(life.exp)</code></pre>


<h3>Format</h3>

<p>A data frame with 244 observations on the following 2 variables.
</p>

<dl>
<dt><code>lifespan</code></dt><dd><p>Lifespan in weeks</p>
</dd>
<dt><code>treatment</code></dt><dd><p>a factor with levels <code>N/N85</code>: Mice were fed normally both before and after weaning (the slash distinguishes pre and post weaning).  After weaning the diet consisted of 85kcal/week, a conventional total for mice rearing, 
<code>N/R40</code>: Mice were fed normally before weaning, but were given a severely restricted diet of 40 kcal per week after feeding, <code>N/R50</code>: Mice were restricted to 50kcal per week before and after weaning,
<code>R/R50</code></p>
</dd></dl>
<p>: Mice were fed normally before weaning, but their diet was restricted to 50 kcal per week after weaning.

</p>


<h3>Source</h3>

<p>Ramsey, F. L., and D. W. Schafer (1997)  <em>The Statistical Sleuth: A Course in Methods of 
Data Analysis</em>.  Duxbury Press, Belmont, CA. 
</p>


<h3>References</h3>

<p>Weindruch, R., Walford, R. L., Fligiel, S., and D. Guthrie  (1986)  The retardation of aging in mice by dietary restriction: 
longevity, cancer, immunity and lifetime energy intake.  <em>The Journal of Nutrition</em> 116 (4): 641-54.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(life.exp)
## maybe str(life.exp) ; plot(life.exp) ...
</code></pre>

<hr>
<h2 id='lm.select'>
AIC, AICc, BIC, Mallow's Cp, and PRESS evaluation of linear models
</h2><span id='topic+lm.select'></span>

<h3>Description</h3>

<p>The function provide model selection summaries using <em>AIC</em>, <em>AICc</em>, <em>BIC</em>, Mallow's <code class="reqn">C_p</code>, and <em>PRESS</em> for a list of objects of class <code>lm</code> 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
lm.select(lms, deltaAIC = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lm.select_+3A_lms">lms</code></td>
<td>

<p>A list containing linear models.</p>
</td></tr>
<tr><td><code id="lm.select_+3A_deltaaic">deltaAIC</code></td>
<td>
<p>Logical; Should a <code class="reqn">\Delta</code> <em>AIC</em> summary be given with relative likelihoods and Akaike weights?</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Mallow's <code class="reqn">C_p</code> assumes that all models are nested within the first model in the argument <code>lms</code>.  Non-nesting will produce a warning message.</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="#topic+press">press</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- rnorm(100)
X1 &lt;- rnorm(100)
X2 &lt;- rnorm(100)

lms &lt;- list(lm(Y ~ X1), lm(Y ~ X1 + X2))
lm.select(lms)

</code></pre>

<hr>
<h2 id='magnets'>Magnet pain relief data</h2><span id='topic+magnets'></span>

<h3>Description</h3>

<p>Magnets have long been used as an alternative medicine, particularly in the Far East, for speeding the recovery of broken bones and to aid in pain relief.  
Vallbona et al. (1997) tested whether chronic pain experienced by post-polio patients could be treated with magnetic fields applied directly to pain trigger points.  
The investigators identified fifty subjects who not only had post-polio syndrome, but who also experienced muscular or arthritic pain.  
Magnets were applied to pain trigger points in 29 randomly selected subjects, and in the other 21 a placebo was applied.  
The patients were asked to subjectively rate pain on a scale from one to ten before and after application of the magnet or placebo.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(magnets)</code></pre>


<h3>Format</h3>

<p>The dataframe contains 4 columns
</p>

<dl>
<dt><code>Score_1</code></dt><dd><p>Reported pain level before application of treatment.</p>
</dd>   
<dt><code>Score_2</code></dt><dd><p>Reported pain level after application of treatment.</p>
</dd>         
<dt><code>Active</code></dt><dd><p>Categorical variable indicating whether the device applied was active (magnet) or inactive (placebo).</p>
</dd>        
</dl>



<h3>Source</h3>

<p>Vallbona, C. et al  (1997)  Response of pain to static magnetic fields in post-polio patients, 
a double blind pilot study. <em>Archives of Physical Medicine and Rehabilitation</em>.  78: 1200-1203.
</p>

<hr>
<h2 id='MC'>
Simple functions for MCMC demonstrations
</h2><span id='topic+MC'></span><span id='topic+Rf'></span><span id='topic+mat.pow'></span>

<h3>Description</h3>

<p>Function <code>MC</code> creates random Markov Chain from a transitions matrix.  Function <code>Rf</code> presents proportional summaries of discrete states from <code>MC</code>.  Function <code>mat.pow</code> finds the exponential expansion of a matrix.  Required for finding the expectations of a transition matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MC(T, start, length)
Rf(res)
mat.pow(mat, pow)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MC_+3A_t">T</code></td>
<td>

<p>A symmetric transition matrix.
</p>
</td></tr>
<tr><td><code id="MC_+3A_start">start</code></td>
<td>

<p>Starting state
</p>
</td></tr>
<tr><td><code id="MC_+3A_length">length</code></td>
<td>

<p>Length of the chain to be created
</p>
</td></tr>
<tr><td><code id="MC_+3A_res">res</code></td>
<td>

<p>Results from <code>MC</code>.
</p>
</td></tr>
<tr><td><code id="MC_+3A_mat">mat</code></td>
<td>

<p>A symmetric matrix.
</p>
</td></tr>
<tr><td><code id="MC_+3A_pow">pow</code></td>
<td>

<p>Power the matrix is to be raised to.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(nrow = 4, ncol = 4, c(0.5, 0.5, 0, 0, 0.25, 0.5, 0.25,0, 0, 0.25, 0.5, 0.25, 
0, 0, 0.5, 0.5), byrow = TRUE)
pi.0 &lt;- c(1, 0, 0, 0)
Tp10 &lt;- mat.pow(A, 10)
chain &lt;- MC(A, 1, 100)
Rf(chain)
</code></pre>

<hr>
<h2 id='MC.test'>
Monte Carlo hypothesis testing for two samples.
</h2><span id='topic+MC.test'></span>

<h3>Description</h3>

<p><code>MC.test</code> calculates a permutation distribution of test statistics from a Welch<em>t</em>-test.  It compares this distribution to an initial test statistic calculated using non-permuted data, to derive an empirical <em>P</em>-value.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MC.test(Y,X, perm = 1000, alternative = "not.equal", paired = FALSE, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MC.test_+3A_y">Y</code></td>
<td>

<p>Response data.
</p>
</td></tr>
<tr><td><code id="MC.test_+3A_x">X</code></td>
<td>

<p>Categorical explanatory variable.
</p>
</td></tr>
<tr><td><code id="MC.test_+3A_perm">perm</code></td>
<td>

<p>Number of iterations.
</p>
</td></tr>
<tr><td><code id="MC.test_+3A_paired">paired</code></td>
<td>
<p>Logical: Are sample paired?</p>
</td></tr>
<tr><td><code id="MC.test_+3A_alternative">alternative</code></td>
<td>

<p>Alternative hypothesis.  One of three options: <code>"less","greater"</code>, or <code>"not.equal"</code>.  These provide lower-tail, upper-tail, and two-tailed tests.
</p>
</td></tr>
<tr><td><code id="MC.test_+3A_print">print</code></td>
<td>
<p>Logical: automatically print a pretty summary of results (default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method follows the description of Manly (1998) for a two-sample test.  Upper and lower tailed tests are performed by finding the portion of the distribution greater than or equal to the observed <em>t</em> test statistic (upper-tailed) or less than or equal to the observed test statistic (lower-tailed). A two tailed test is performed by multiplying the portion of the null distribution greater than or equal to the absolute value of the observed test statistic and less than or equal to the absolute value of the observed test statistic times minus one.  Results from the test will be similar to <code>oneway_test</code> from the library <code>coin</code> because it is based on an equivalent test statistic.  As with <code>t.test</code>, pairing is assumed to occur within levels of <em>X</em>.  That is, the responses <em>Y = 11</em> and <em>Y = 2</em> occur in the same pair (block) below.
</p>
<p><code>Y &lt;- c(11,12,13,2,3,4)</code>
</p>
<p><code>X &lt;- c(1,1,1,2,2,2)</code>
</p>


<h3>Value</h3>

<p>Returns a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>observed.test.statistic</code></td>
<td>
<p><em>t</em>-statistic calculated from non-permuted (original)data.</p>
</td></tr>
<tr><td><code>no_of_permutations_exceeding_observed_value</code></td>
<td>
<p>The number of times a Monte Carlo derived test statistic was more extreme than the initial observed test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Empirical <em>P</em>-value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho, thanks to Vince Buonaccorsi who found an error under <code>paired = TRUE</code>.</p>


<h3>References</h3>

<p>Manly, B. F. J. (1997) <em>Randomization and Monte Carlo Methods in Biology, 2nd edition</em>.  Chapman and Hall, London.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Y&lt;-c(runif(100,1,3),runif(100,1.2,3.2))
X&lt;-factor(c(rep(1,100),rep(2,100)))
MC.test(Y,X,alternative="less")
</code></pre>

<hr>
<h2 id='mcmc.norm.hier'>
Gibbs sampling of normal hierarchical models
</h2><span id='topic+mcmc.norm.hier'></span><span id='topic+norm.hier.summary'></span>

<h3>Description</h3>

<p>These functions are designed for Gibbs sampling comparison of groups with normal hierarchical models (see Gelman 2003), and for providing appropriate summaries.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
mcmc.norm.hier(data, length = 1000, n.chains = 5)

norm.hier.summary(M, burn.in = 0.5, cred = 0.95, conv.log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcmc.norm.hier_+3A_data">data</code></td>
<td>

<p>A numerical matrix with groups in columns and observations in rows.
</p>
</td></tr>
<tr><td><code id="mcmc.norm.hier_+3A_length">length</code></td>
<td>

<p>An integer specifying the length of MCMC chains.
</p>
</td></tr>
<tr><td><code id="mcmc.norm.hier_+3A_n.chains">n.chains</code></td>
<td>

<p>The number of chains to be computed for each parameter
</p>
</td></tr>
<tr><td><code id="mcmc.norm.hier_+3A_m">M</code></td>
<td>

<p>An output array from <code>mcmc.norm.hier</code>.
</p>
</td></tr>
<tr><td><code id="mcmc.norm.hier_+3A_burn.in">burn.in</code></td>
<td>

<p>The burn in period for the chains.  The default value, 0.5, indicates that only the latter half of chains should be used for calculating summaries. 
</p>
</td></tr>
<tr><td><code id="mcmc.norm.hier_+3A_cred">cred</code></td>
<td>

<p>Credibility interval width. 
</p>
</td></tr>
<tr><td><code id="mcmc.norm.hier_+3A_conv.log">conv.log</code></td>
<td>

<p>A logical argument indicating whether convergence for <code class="reqn">\sigma</code> and <code class="reqn">\tau</code> should be considered on a log scale.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An important Bayesian application is the comparison of groups within a normal hierarchical model.  
We assume that the data from each group are independent and from normal populations with means 
<code class="reqn">\theta[j]</code>, <code class="reqn">j = (1,...,J)</code>, and a common variance, <code class="reqn">\sigma^2</code>. We also assume that group means, 
are normally distributed with an unknown mean, <code class="reqn">\mu</code>, and an unknown variance , <code class="reqn">\tau^2</code>.  
A uniform prior distribution is assumed for <code class="reqn">\mu, log\sigma</code> and <code class="reqn">\tau</code>; <code class="reqn">\sigma</code> is 
logged to facilitate conjugacy.  The function <code>mcmc.norm.hier</code> provides posterior distributions 
of <code class="reqn">\theta[j]</code>'s, <code class="reqn">\mu, \sigma</code> and <code class="reqn">\tau</code>.  The distributions are derived from univariate 
conditional distributions from the multivariate likelihood function.  These conditional distributions 
provide a situation conducive to MCMC Gibbs sampling. Gelman et al. (2003) provide excellent summaries of these sorts of models.  
</p>
<p>The function <code>mcmc.summary</code> provides statistical summaries for the output array from <code>mcmc.norm.hier</code> including credible intervals (empirically derived directly from chains) and the Gelman/Rubin convergence criterion, <code class="reqn">\hat{R}</code>.
</p>


<h3>Value</h3>

<p>The function <code>mcmc.norm.hier</code> returns a three dimensional (step x variable x chain) array.  The function <code>mcmc.summary</code> returns a summary table containing credible intervals and the Gelman/Rubin convergence criterion, <code class="reqn">\hat{R}</code>.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Gelman, A., Carlin, J. B., Stern, H. S., and D. B. Rubin (2003) <em>Bayesian Data Analysis, 2nd edition</em>.  Chapman and Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+R.hat">R.hat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(cuckoo)
mcmc.norm.hier(cuckoo,10,2)

## End(Not run)
</code></pre>

<hr>
<h2 id='ML.k'>
Maximum likelihood algorithm for determining the binomial dispersal coefficient
</h2><span id='topic+ML.k'></span>

<h3>Description</h3>

<p>The function uses the maximum likelihood method described by Bliss and R. A. Fisher (1953) to determine maximum likelihood estimates for the binomial parameters <em>m</em> (the mean) and <em>k</em> (a parameter describing aggregation/dispersion). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ML.k(f, x, res = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ML.k_+3A_f">f</code></td>
<td>
<p>A vector of frequencies for objects in <code>x</code> (must be integers).
</p>
</td></tr>
<tr><td><code id="ML.k_+3A_x">x</code></td>
<td>

<p>A vector of counts, must be sequential integers.
</p>
</td></tr>
<tr><td><code id="ML.k_+3A_res">res</code></td>
<td>

<p>Resolution for the ML estimator.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with two items
</p>
<table role = "presentation">
<tr><td><code>k</code></td>
<td>
<p>The negative binomial dispersion parameter, <em>k</em></p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>The negative binomial distribution mean, <em>m</em></p>
</td></tr>
</table>


<h3>Note</h3>

<p>The program is slow at the current resolution.  Later iterations will use linear interpolation, or Fortran loops, or both.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Bliss, C. I., and R. A. Fisher (1953)  Fitting the negative binomial distribution to biological data.  <em>Biometrics</em> 9: 176-200.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dnbinom">dnbinom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>mites &lt;- seq(0, 8)
freq &lt;- c(70, 38, 17, 10, 9, 3, 2, 1, 0)
ML.k(freq, mites) 
</code></pre>

<hr>
<h2 id='Mode'>Sample mode</h2><span id='topic+Mode'></span>

<h3>Description</h3>

<p>Calculates the sample mode; i.e. the most frequent outcome in a dataset.  Non-existence of the mode will return a message.  Several errors in earlier versions were corrected in asbio 0.4.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mode(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Mode_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the sample mode or an error message if the mode does not exist.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Bain, L. J., and M. Engelhardt (1992)  <em>Introduction to Probability and Mathematical 
Statistics</em>.  Duxbury press.  Belmont, CA, USA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+H.mean">H.mean</a></code>, <code><a href="#topic+HL.mean">HL.mean</a></code>, <code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+median">median</a></code>, <code><a href="#topic+huber.mu">huber.mu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-round(rnorm(100000,mean=10,sd=2),0)
Mode(x)
</code></pre>

<hr>
<h2 id='modlevene.test'>Modified Levene's test</h2><span id='topic+modlevene.test'></span><span id='topic+print.mltest'></span>

<h3>Description</h3>

<p>Conducts the modified Levene's test for homoscedastic populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
modlevene.test(y, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modlevene.test_+3A_y">y</code></td>
<td>
<p>Vector of quantitative ressponses, e.g., residuals from a linear model.</p>
</td></tr>
<tr><td><code id="modlevene.test_+3A_x">x</code></td>
<td>
<p>Vector of factor levels.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The modified Levene's test is a test for homoscedasticity that (unlike the classic <em>F</em>-test) is robust to violations of normality (Conover et al. 1981).  In a Modified Levene's test we calculate <code class="reqn">d_{ij}=|e_{ij} - \tilde{e}_{i}|</code> where <code class="reqn">\tilde{e}_i</code> is the <em>i</em>th factor level residual median.  We then run an ANOVA on the <code class="reqn">d_{ij}</code>'s.  If the <em>p</em>-value is &lt; <code class="reqn">\alpha</code>, we reject the null and conclude that the population error variances are not equal.  
</p>


<h3>Value</h3>

<p>An ANOVA table is returned with the modified Levene's test results.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li. (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fligner.test">fligner.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>eggs&lt;-c(11,17,16,14,15,12,10,15,19,11,23,20,18,17,27,33,22,26,28)
trt&lt;-as.factor(c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,4,4))
lm1&lt;-lm(eggs~trt)
modlevene.test(residuals(lm1),trt)

</code></pre>

<hr>
<h2 id='montane.island'>
Mountain island biogeographic data
</h2><span id='topic+montane.island'></span>

<h3>Description</h3>

<p>Lomolino et al. (1989) investigated the relationship between the area of montane  forest patches (islands) and the richness of mammal fauna in the Southwestern United States.  This dataset contains richness and area information for 27 montane islands. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(montane.island)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 3 variables.
</p>

<dl>
<dt><code>Island.name</code></dt><dd><p>a factor with levels <code>Abajos</code> <code>Animas</code> <code>Blacks</code> <code>Capitans</code> <code>Catalinas</code> <code>Chirucahuas</code> <code>Chuskas</code> <code>Guadalupes</code> <code>Huachucas</code> <code>Hualapais</code> <code>Lasals</code> <code>Magdalenas</code> <code>Manzanos</code> <code>Mogollon</code> <code>Mt. Taylor</code> <code>N. Rincon</code> <code>N. Uncompaghre</code> <code>Navajo</code> <code>Organs</code> <code>Pinalenos</code> <code>Prescotts</code> <code>S. Kabib</code> <code>Sacramentos</code> <code>San Mateos</code> <code>Sandias</code> <code>Santa Ritas</code> <code>Zunis</code>.</p>
</dd>
<dt><code>Richness</code></dt><dd><p>A numeric vector; the number of species.</p>
</dd>
<dt><code>Area</code></dt><dd><p>A numeric vector; area in km<code class="reqn">^2</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Lomolino, M. V., Brown, J. H., and R. Davis (1989)  Island biogeography of montane 
forest mammals in the American Southwest.  <em>Ecology</em> 70: 180-194. 
</p>

<hr>
<h2 id='moose.sel'>
Datasets for resource use and availability
</h2><span id='topic+mule.sel'></span><span id='topic+goat.sel'></span><span id='topic+quail.sel'></span><span id='topic+elk.sel'></span><span id='topic+bighorn.sel'></span><span id='topic+bighornAZ.sel'></span><span id='topic+moose.sel'></span><span id='topic+juniper.sel'></span>

<h3>Description</h3>

<p>A collection of datasets which can be used to calculate and compare selection ratios. Datasets are: <code>goat.sel, mule.sel, quail.sel, elk.sel, bighorn.sel, bighornAZ.sel, juniper.sel</code> and are described (briefly) in Manly et al. (2002) and Aho and Bowyer (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(moose.sel)
data(goat.sel)
data(quail.sel)
data(elk.sel)
data(bighorn.sel)
data(bighornAZ.sel)
data(juniper.sel)
</code></pre>


<h3>Format</h3>

<p>Dataframes with observations on the following variables.
</p>

<dl>
<dt><code>resources</code></dt><dd><p>A factor listing resource types.</p>
</dd>
<dt><code>avail</code></dt><dd><p>Proportional availability (for datasets without n2 and y2).</p>
</dd>
<dt><code>y1</code></dt><dd><p>A numeric vector: number of times the resource was used.</p>
</dd>
<dt><code>y2</code></dt><dd><p>A numeric vector: number of time the resource was observed.</p>
</dd>
<dt><code>n1</code></dt><dd><p>A numeric vector: number of times that all resources were used.</p>
</dd>
<dt><code>n2</code></dt><dd><p>A numeric vector: number of times that all resources were observed.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Manly BF, McDonald LL, Thomas DL, McDonald TL, Erickson WP (2002) <em>Resource Selection by Animals: Statistical Design and Analysis for Field Studies.  2nd  edn</em>.  Kluwer, New York
</p>


<h3>References</h3>

<p>Aho, K., and Bowyer, T. 2015. Confidence intervals for ratios of proportions: implications for selection ratios. <em>Methods in Ecology and Evolution</em> 6: 121-132.  </p>

<hr>
<h2 id='mosquito'>
Mosquito wing length data
</h2><span id='topic+mosquito'></span>

<h3>Description</h3>

<p>Sokal and Rohlf (2012) describe an experiment to gauge the variability in wing length in female mosquitos (<em>Aedes intrudens</em>).  
Four females were randomly selected from three cages and two measurements were made on the left wing of each female.  
Both cage and female (in cage) can be seen as random effects.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mosquito)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 4 variables.
</p>

<dl>
<dt><code>length</code></dt><dd><p>Wing length in micrometers</p>
</dd>
<dt><code>cage</code></dt><dd><p>Cage number.</p>
</dd>
<dt><code>female</code></dt><dd><p>Female (in cage) number</p>
</dd>
<dt><code>measures</code></dt><dd><p>Measurement (in female in cage) number, i.e. pseudoreplicates in female.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sokal, R. R., and F. J. Rohlf (2012)  <em>Biometry, 4th edition</em>.  W. H. Freeman and Co., New York. 
</p>

<hr>
<h2 id='MS.test'>Mack-Skillings test</h2><span id='topic+MS.test'></span>

<h3>Description</h3>

<p>Runs a Mack-Skillings test for situations applicable to rank-based permutation procedures with blocking and more than one replicate for treatments in a block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MS.test(Y, X, reps)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MS.test_+3A_y">Y</code></td>
<td>
<p>A matrix of response data. The <code>MS.test</code> function requires that response data are organized in columns (see example below).</p>
</td></tr>
<tr><td><code id="MS.test_+3A_x">X</code></td>
<td>
<p>A vector of treatments.  The length of the vector should be equal to the number of rows in the response matrix.</p>
</td></tr>
<tr><td><code id="MS.test_+3A_reps">reps</code></td>
<td>
<p>The number of replicates in each treatment (unbalanced designs cannot be analyzed).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When we have more than one replication within a block, and the number of replications is equal for all treatments, we can use the Mack-Skillings test (Mack and Skillings 1980) as a rank based permutation procedure to test for main effect differences.  If ties occur the value of the significance level is only approximate.  Hollander and Wolfe (1996) provide a method for finding exact <em>P</em>-values by deriving a test statistic distribution allowing ties.  
</p>


<h3>Value</h3>

<p>Returns a dataframe summarizing the degrees of freedom, test statistic and <em>p</em>-value.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Campbell, J. A., and O. Pelletier (1962)  Determination of niacin (niacinamide) in cereal 
products.  <em>J. Assoc.  Offic. Anal.  Chem.</em>  45: 449-453. 
</p>
<p>Hollander, M., and  D. A. Wolfe (1999) <em>Nonparametric Statistical Methods</em>. New York: John Wiley &amp; Sons. 
</p>
<p>Mack, G. A., and J. H. Skillings (1980)  A Friedman-type rank test for main effects in a 
two-factor ANOVA.  <em>Journal of the American Statistical Association</em>.  75: 947-951.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+friedman.test">friedman.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#data from Campbell and Pelletier (1962) 
Niacin0&lt;-c(7.58,7.87,7.71,8.00,8.27,8,7.6,7.3,7.82,8.03,7.35,7.66)
Niacin4&lt;-c(11.63,11.87,11.40,12.20,11.70,11.80,11.04,11.50,11.49,11.50,10.10,11.70)
Niacin8&lt;-c(15.00,15.92,15.58,16.60,16.40,15.90,15.87,15.91,16.28,15.10,14.80,15.70)
Niacin&lt;-cbind(Niacin0,Niacin4,Niacin8)
lab&lt;-c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))
MS.test(Niacin, lab, reps=3)
</code></pre>

<hr>
<h2 id='myeloma'>
Patient responses to myeloma drug treatments
</h2><span id='topic+myeloma'></span>

<h3>Description</h3>

<p>Murakami et al. (1997) studied the effect of drugs treatments on levels of serum beta-2 microglobulin in patients with multiple myeloma.   
Serum beta-2 microglobulin is produced in the body as a result of myelomas, and thus can be used as an indicator of the severity of disease
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(myeloma)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 2 variables.
</p>

<dl>
<dt><code>mglobulin</code></dt><dd><p>Levels of serum beta-2 microglobulin in mg/l</p>
</dd>
<dt><code>drug</code></dt><dd><p>Drug treatment strategy.  <code>Control</code> = sumerifon alone, <code>Trt</code> = malphalan and sumerifon.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ott, R. L., and M. T. Longnecker  (2004)  <em>A First Course in Statistical Methods</em>.  Thompson. 
</p>


<h3>References</h3>

<p>Murakami, H., Ogawara, H., Morita, K.,  Saitoh, T., Matsushima, T., Tamura, J.,   Sawamura, M.,  Karasawa, M.,  Miyawaki, M.,, Schimano, S., Satoh, S., and  J Tsuchiy (1997)
Serum beta-2-microglobulin in patients with multiple myeloma treated with alpha interferon.  <em>Journal of Medicine</em> 28(5-6):311-8. 
</p>

<hr>
<h2 id='near.bound'>Nearest neighbor boundary coordinates
</h2><span id='topic+near.bound'></span>

<h3>Description</h3>

<p>Finds nearest neighbor boundary Cartesian coordinates for use as arguments in function <code><a href="#topic+prp">prp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
near.bound(X, Y, bX, bY)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="near.bound_+3A_x">X</code></td>
<td>
<p>A vector of Cartesian <em>X</em>-coordinates (e.g. UTMs) describing an animal's locations (e.g. telemetry data).
</p>
</td></tr>
<tr><td><code id="near.bound_+3A_y">Y</code></td>
<td>

<p>A vector of Cartesian <em>Y</em> coordinates (e.g. UTMs) describing an animal's locations (e.g. telemetry data).
</p>
</td></tr>
<tr><td><code id="near.bound_+3A_bx">bX</code></td>
<td>

<p>A vector of boundary <em>X</em>-coordinates.
</p>
</td></tr>
<tr><td><code id="near.bound_+3A_by">bY</code></td>
<td>

<p>A vector of boundary <em>Y</em>-coordinates.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns Cartesian <em>X,Y</em> coordinates of nearest neighbor locations on a boundary.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prp">prp</a></code>, <code><a href="#topic+bound.angle">bound.angle</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>bX&lt;-seq(0,49)/46
bY&lt;-c(4.89000,4.88200,4.87400,4.87300,4.88000,4.87900,4.87900,4.90100,4.90800,
4.91000,4.93300,4.94000,4.91100,4.90000,4.91700,4.93000,4.93500,4.93700,
4.93300,4.94500,4.95900,4.95400,4.95100,4.95800,4.95810,4.95811,4.95810,
4.96100,4.96200,4.96300,4.96500,4.96500,4.96600,4.96700,4.96540,4.96400,
4.97600,4.97900,4.98000,4.98000,4.98100,4.97900,4.98000,4.97800,4.97600,
4.97700,4.97400,4.97300,4.97100,4.97000)

X&lt;-c(0.004166667,0.108333333,0.316666667,0.525000000,0.483333333,0.608333333,
0.662500000,0.683333333,0.900000000,1.070833333)
Y&lt;-c(4.67,4.25,4.26,4.50,4.90,4.10,4.70,4.40,4.20,4.30)
near.bound(X,Y,bX,bY)
</code></pre>

<hr>
<h2 id='one.sample.t'>One sample t-test</h2><span id='topic+one.sample.t'></span>

<h3>Description</h3>

<p>Provides a one-sample hypothesis test.  The test assumes that the underlying population is normal.</p>


<h3>Usage</h3>

<pre><code class='language-R'>one.sample.t(data = NULL, null.mu = 0, xbar = NULL, sd = NULL, n = NULL, 
alternative = "two.sided", conf = 0.95, na.rm = FALSE, fpc = FALSE, N = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="one.sample.t_+3A_data">data</code></td>
<td>
<p>A vector of quantitative data.  Not required if <code>xbar</code> and <code>n</code> are supplied by the user.</p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_null.mu">null.mu</code></td>
<td>
<p>The expectation for the null distribution.</p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_xbar">xbar</code></td>
<td>
<p>Sample mean.  Not required if <code>is.null(data)==FALSE</code></p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_sd">sd</code></td>
<td>
<p>The sample standard deviation. Not required if <code>is.null(data)==FALSE</code></p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_n">n</code></td>
<td>
<p>The sample size. Not required if <code>is.null(data)==FALSE</code></p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_alternative">alternative</code></td>
<td>
<p>Type of test.  One of three must be specified <code>"two.sided", "less"</code>, or <code>"greater"</code></p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_conf">conf</code></td>
<td>
<p>Confidence level.</p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, indicate whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_fpc">fpc</code></td>
<td>
<p>A logical statement specifying whether a finite population correction should be made.  If <code>fpc = TRUE</code> the population size <code>N</code> must be specified.</p>
</td></tr>
<tr><td><code id="one.sample.t_+3A_n">N</code></td>
<td>
<p>The population size.  Required if <code>fpc=TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function can use either raw data <code>is.null(data)==FALSE</code> or summarized data if <code>is.null(data)==TRUE</code>.  With the later <code>xbar</code>, and <code>n</code> must be specified by the user.
</p>


<h3>Value</h3>

<p>Returns a test statistic and a <em>p</em>-value.
</p>


<h3>Author(s)</h3>

<p>Ken Aho.  Thanks to Samuel Hale for identifying a function bug.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pt">pt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>one.sample.t(null.mu = 131, xbar = 126, sd = 12, n = 85, 
alternative = "two.sided")
</code></pre>

<hr>
<h2 id='one.sample.z'>One sample z-test</h2><span id='topic+one.sample.z'></span><span id='topic+print.oneSamp'></span>

<h3>Description</h3>

<p>Provides a one-sample hypothesis test.  The test assumes that the underlying population is normal and furthermore that <code class="reqn">\sigma</code> is known.</p>


<h3>Usage</h3>

<pre><code class='language-R'>one.sample.z(data = NULL, null.mu = 0, xbar = NULL, sigma, n = NULL, 
alternative = "two.sided", conf = 0.95, na.rm = FALSE, fpc = FALSE, N = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="one.sample.z_+3A_data">data</code></td>
<td>
<p>A vector of quantitative data.  Not required if <code>xbar</code> and <code>n</code> are supplied by the user.</p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_null.mu">null.mu</code></td>
<td>
<p>The expectation for the null distribution.</p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_xbar">xbar</code></td>
<td>
<p>Sample mean.  Not required if <code>is.null(data)==FALSE</code></p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_sigma">sigma</code></td>
<td>
<p>The null distribution standard deviation</p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_n">n</code></td>
<td>
<p>The sample size. Not required if <code>is.null(data)==FALSE</code></p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_alternative">alternative</code></td>
<td>
<p>Type of test.  One of three must be specified <code>"two.sided", "less"</code>, or <code>"greater"</code></p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_conf">conf</code></td>
<td>
<p>Confidence level.</p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, indicate whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_fpc">fpc</code></td>
<td>
<p>A logical statement specifying whether a finite population correction should be made.  If <code>fpc = TRUE</code> the population size <code>N</code> must be specified.</p>
</td></tr>
<tr><td><code id="one.sample.z_+3A_n">N</code></td>
<td>
<p>The population size.  Required if <code>fpc=TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function can use either raw data <code>is.null(data)==FALSE</code> or summarized data if <code>is.null(data)==TRUE</code>.  With the later <code>xbar</code> and <code>n</code> must be specified by the user.
</p>


<h3>Value</h3>

<p>Returns a test statistic and a <em>p</em>-value.
</p>


<h3>Author(s)</h3>

<p>Ken Aho.  Thanks to Anderson Canteli for identifying a bug in the function for <span class="pkg">asbio</span> versions &lt; 1.9-6.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>one.sample.z(null.mu = 131, xbar = 126, sigma = 12, n = 85, alternative = "two.sided")
</code></pre>

<hr>
<h2 id='paik'>
Paik diagrams
</h2><span id='topic+paik'></span>

<h3>Description</h3>

<p>Paik diagrams for the representation of Simpsons Paradox in three way tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
paik(formula, counts, resp.lvl = 2, data, circle.mult = 0.4, xlab = NULL, 
ylab = NULL, leg.title = NULL, leg.loc = NULL, show.mname = FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="paik_+3A_formula">formula</code></td>
<td>

<p>A two sided formula, e.g. <code>Y ~ X1 + X2</code>, with cross-classified categorical variables. The second explanatory variable, i.e. <code>X2</code>, 
is used as the trace variable whose levels are distinguished in the graph with different colors.  Interactions and nested terms are not allowed. 
</p>
</td></tr>
<tr><td><code id="paik_+3A_counts">counts</code></td>
<td>

<p>A vector of counts for the associated categorical variables in <code>formula</code>. 
</p>
</td></tr>
<tr><td><code id="paik_+3A_resp.lvl">resp.lvl</code></td>
<td>

<p>The level in <em>Y</em> of primary interest.  See example below.
</p>
</td></tr>
<tr><td><code id="paik_+3A_data">data</code></td>
<td>

<p>Dataframe containing variables in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="paik_+3A_circle.mult">circle.mult</code></td>
<td>

<p>Multiplier for circle radii in the diagram.
</p>
</td></tr>
<tr><td><code id="paik_+3A_xlab">xlab</code></td>
<td>

<p><em>X</em>-axis label.  By default this is defined as the categories in the first explanatory variable, <code>X1</code>.
</p>
</td></tr>
<tr><td><code id="paik_+3A_ylab">ylab</code></td>
<td>

<p><em>Y</em>-axis label.  By default these will be proportions with respect to the specified level of interest in the response. 
</p>
</td></tr>
<tr><td><code id="paik_+3A_leg.title">leg.title</code></td>
<td>

<p>Legend title.  By default the conditioning variable name.
</p>
</td></tr>
<tr><td><code id="paik_+3A_leg.loc">leg.loc</code></td>
<td>

<p>Legend location.  A <code>legend</code> location keyword; <code>"bottomright"</code>, <code>"bottom"</code>, <code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, <code>"topright"</code>, <code>"right"</code> or <code>"center"</code>. 
</p>
</td></tr>
<tr><td><code id="paik_+3A_show.mname">show.mname</code></td>
<td>
<p> Logical, indicating whether or not the words &quot;Marginal prop&quot; should printed in the graph above the dotted line indicating marginal proportions. 
</p>
</td></tr>
<tr><td><code id="paik_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Agresti, A. (2012) <em>Categorical Data Analysis, 3rd edition</em>.  New York.  Wiley. 
</p>
<p>Paik M. (1985) A graphical representation of a three-way contingency table: Simpson's paradox and correlation.
<em>American Statistician</em> 39:53-54.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tcltk)

data(death.penalty)# from Agresti 2012 

op &lt;- par(mfrow=c(1,2), mar=c(4,4,0,0))
paik(verdict ~ d.race + v.race, counts = count, data = death.penalty, 
leg.title = "Victims race", xlab = "Defendants race", 
ylab = "Proportion receiving death penalty")
par(mar=c(4,2,0,2))
paik(verdict ~ v.race + d.race, counts = count, data = death.penalty, 
xlab = "Victims race", leg.title = "Defendants race",leg.loc="topleft", 
ylab = "", yaxt = "n")
par(op)

if(interactive()){
if(any(names(sessionInfo()$otherPkgs)=="asbio")) vignette(package = "asbio", "simpson")
}
</code></pre>

<hr>
<h2 id='pairw.anova'>Conducts pairwise post hoc and planned comparisons associated with an ANOVA</h2><span id='topic+pairw.anova'></span><span id='topic+lsdCI'></span><span id='topic+bonfCI'></span><span id='topic+tukeyCI'></span><span id='topic+scheffeCI'></span><span id='topic+dunnettCI'></span><span id='topic+scheffe.cont'></span><span id='topic+bonf.cont'></span><span id='topic+print.pairw'></span>

<h3>Description</h3>

<p>The function <code>pairw.anova</code> replaces the defunct <code>Pairw.test</code>. Conducts all possible pairwise tests with adjustments to <em>P</em>-values using one of five methods: Least Significant difference (LSD), Bonferroni, Tukey-Kramer honest significantly difference (HSD), Scheffe's method, or Dunnett's method. 
Dunnett's method requires specification of a control group, and does not return adjusted <em>P</em>-values.  The functions <code>scheffe.cont</code> and <code>bonf.cont</code> allow Bonferroni and Scheffe's family-wise adjustment of individual planned pairwise contrasts.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pairw.anova(y, x, conf.level = 0.95, method = "tukey", 
MSE = NULL, df.err = NULL, control = NULL)

lsdCI(y, x, conf.level = 0.95, MSE = NULL, df.err = NULL)

bonfCI(y, x, conf.level = 0.95, MSE = NULL, df.err = NULL)

tukeyCI(y, x, conf.level = 0.95, MSE = NULL, df.err = NULL)

scheffeCI(y, x, conf.level = 0.95, MSE = NULL, df.err = NULL)

dunnettCI(y, x, conf.level = 0.95, control = NULL)

scheffe.cont(y, x, lvl = c("x1", "x2"), conf.level = 0.95, 
MSE = NULL, df.err = NULL)

bonf.cont(y, x, lvl = c("x1", "x2"), conf.level = 0.95, 
MSE = NULL, df.err = NULL, comps = 1)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairw.anova_+3A_y">y</code></td>
<td>
<p>A quantitative vector containing the response variable</p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_x">x</code></td>
<td>
<p>A categorical vector containing the groups (e.g. factor levels or treatments)</p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_conf.level">conf.level</code></td>
<td>
<p>1 - <em>P</em>(type I error)</p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_method">method</code></td>
<td>
<p>One of five possible choices: <code>"lsd", "bonf", "tukey", "scheffe", "dunnett"</code></p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_mse">MSE</code></td>
<td>
<p>Value of MSE from the ANOVA model.  Default = <code>NULL</code></p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_df.err">df.err</code></td>
<td>
<p>Degrees of freedom error from the omnibus ANOVA.  Default = <code>NULL</code></p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_control">control</code></td>
<td>
<p>Control group for Dunnett's test.</p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_lvl">lvl</code></td>
<td>
<p>A two element vector defining two factor levels to be compared using Scheffe's and the Bonferroni method.</p>
</td></tr>
<tr><td><code id="pairw.anova_+3A_comps">comps</code></td>
<td>
<p>The number of comparisons to be made in the Bonferroni method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adjustment of comparison type I error for simultaneous inference is a contentious subject and will not be discussed here.  For description of methods go to Kutner et al. (2005). For models where the number of factors is <code class="reqn">\ge 2</code>, MSE and the residual degrees of freedom (used in the computation of confidence intervals for all pairwise methods used here) will vary depending on the experimental design and the number of factors.  
Thus, for multifactor designs the user should specify the residual degrees of freedom and MSE from the overall ANOVA.  This will be unnecessary for one-way ANOVAs.</p>


<h3>Value</h3>

<p>The function <code>pairw.anova</code> and the confidence interval functions it calls return a list of <code>class = "pairw"</code>.  For all but the LSD test (which also returns LSD) and Dunnett's test (which does not return adjusted <em>P</em>-values), the utility function <code>print.pairw</code> returns a descriptive head and a six column summary dataframe containing: 
</p>
<p>1) the type of contrast (names are taken from levels in <code>x</code>),
</p>
<p>2) the mean difference, 
</p>
<p>3) the lower confidence bound of the true mean difference, 
</p>
<p>4) the upper confidence bound of the true mean difference, 
</p>
<p>5) the hypothesis decision, given the prescribed significance level, and 
</p>
<p>6) the adjusted <em>P</em>-value.
</p>
<p>Other <code>invisible</code> objects include:
</p>
<table role = "presentation">
<tr><td><code>cont</code></td>
<td>
<p>a vector of contrasts.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>The confidence level.</p>
</td></tr>
<tr><td><code>band</code></td>
<td>
<p>A two column matrix containing the lower and upper confidence bounds.</p>
</td></tr>
</table>
<p>The <code>pairw</code> class also has a utility function <code><a href="#topic+plot.pairw">plot.pairw</a></code> which provides either a barplot of location measures with errors and letters indicating whether true effects are significant and the defined significance level (argument <code>type = 1</code>) or confidence intervals for the true difference of each comparison (argument <code>type = 2</code>).  See code below and and <code><a href="#topic+plot.pairw">plot.pairw</a></code> for examples.    
</p>


<h3>Note</h3>

<p>Different forms of these functions have existed for years without implementation into libraries.  My version here, based on the function <code><a href="base.html#topic+outer">outer</a></code> is unique.</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and Li., W  (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.pairw">plot.pairw</a></code>.  Functions from library <span class="pkg">mult.comp</span> provide more sophisticated comparisons including customized contrasts and one tailed tests.</p>


<h3>Examples</h3>

<pre><code class='language-R'>eggs&lt;-c(11,17,16,14,15,12,10,15,19,11,23,20,18,17,27,33,22,26,28)
trt&lt;-as.factor(c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,4,4))

pairw.anova(y = eggs, x = trt, method = "lsd")##LSD method
pairw.anova(y = eggs, x = trt, method = "bonf")##Bonferroni
pairw.anova(y = eggs, x = trt, method = "scheffe")##Sheffe
tukey &lt;- pairw.anova(y = eggs, x = trt, method = "tukey")##Tukey HSD

plot(tukey)
# you can also try plot(tukey, type = 2)

blood.count &lt;- data.frame(bc=c(7.4,8.5,7.2,8.24,9.84,8.32,9.76,8.8,
7.68,9.36,12.8,9.68,12.16,9.2,10.55), trt=c(rep("C",6),rep("A",4),rep("B",5)))
with(blood.count,pairw.anova(y=bc,x=trt,control="C",method="dunnett"))## Dunnett

scheffe.cont(y = eggs, x = trt, lvl = c(1, 3)) 
scheffe.cont(y = eggs, x = trt, lvl = c(1,2))

bonf.cont(y = eggs, x = trt, lvl = c(1,3), comps = 2) 
bonf.cont(y = eggs, x=trt, lvl = c(1,2), comps = 2) 
</code></pre>

<hr>
<h2 id='pairw.fried'>Multiple pairwise comparison procedure to accompany a Friedman test.</h2><span id='topic+pairw.fried'></span><span id='topic+FR.multi.comp'></span>

<h3>Description</h3>

<p>Replaces now defunct <code>FR.multi.comp</code>.  As with ANOVA we can examine multiple pairwise comparisons from a Friedman test after we have rejected the overall null hypothesis.  
However we will need to account for family-wise type I error in these comparisons which will be non-orthogonal.  A conservative multiple comparison method used here is based on the Bonferroni procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pairw.fried(y, x, blocks, nblocks, conf = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairw.fried_+3A_y">y</code></td>
<td>
<p>A vector of responses, i.e. quantitative data.</p>
</td></tr>
<tr><td><code id="pairw.fried_+3A_x">x</code></td>
<td>
<p>A categorical vector of factor levels.</p>
</td></tr>
<tr><td><code id="pairw.fried_+3A_blocks">blocks</code></td>
<td>
<p>A categorical vector of blocks.</p>
</td></tr>
<tr><td><code id="pairw.fried_+3A_nblocks">nblocks</code></td>
<td>
<p>The number of blocks.</p>
</td></tr>
<tr><td><code id="pairw.fried_+3A_conf">conf</code></td>
<td>
<p>The level of confidence.  1 - <em>P</em>(type I error).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of <code>class = "pairw"</code>.  The utility print function returns a descriptive head and a six column summary dataframe containing: 
</p>
<p>1) the type of contrast (names are taken from levels in <code>x</code>),
</p>
<p>2) the mean rank difference,
</p>
<p>3) the lower confidence bound of the true mean rank difference,
</p>
<p>4) the upper confidence bound of the true mean rank difference, 
</p>
<p>5) the hypothesis decision given the prescribed significance level, and
</p>
<p>6) the adjusted <em>P</em>-value.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Fox, J. R., and Randall, J. E. (1970)  Relationship between forearm tremor and the biceps electromyogram.  <em>Journal of Applied Physiology</em>  29: 103-108.
</p>
<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+friedman.test">friedman.test</a></code>, <code><a href="#topic+plot.pairw">plot.pairw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Data from Fox and Randall (1970)
tremors &lt;- data.frame(freq = c(2.58, 2.63, 2.62, 2.85, 3.01, 2.7, 2.83, 3.15, 
3.43, 3.47, 2.78, 2.71, 3.02, 3.14, 3.35, 2.36, 2.49, 2.58, 2.86, 3.1, 2.67, 
2.96, 3.08, 3.32, 3.41, 2.43, 2.5, 2.85, 3.06, 3.07), weights = 
factor(rep(c(7.5, 5, 2.5, 1.25, 0), 6)), block = factor(rep (1 : 6, each = 5)))

fr &lt;- with(tremors, pairw.fried(y = freq, x = weights, blocks = block, nblocks = 6, conf = .95))
fr
plot(fr, loc.meas = median, int = "IQR")
# you can also try: plot(fr, type = 2, las = 2)
</code></pre>

<hr>
<h2 id='pairw.kw'>Multiple pairwise comparison procedure to accompany a Kruskal-Wallis test</h2><span id='topic+pairw.kw'></span><span id='topic+KW.multi.comp'></span>

<h3>Description</h3>

<p>Replaces the defunct <code>KW.multi.comp</code>. As with ANOVA we can examine multiple pairwise comparisons from a Kruskal-Wallis test after we have rejected our omnibus null hypothesis.  
However we will need to account for the fact that these comparisons will be non-orthogonal.  A conservative multiple comparison method used here is based on the Bonferroni inequality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pairw.kw(y, x, conf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairw.kw_+3A_y">y</code></td>
<td>
<p>The response variable.  A vector of quantitative responses.</p>
</td></tr>
<tr><td><code id="pairw.kw_+3A_x">x</code></td>
<td>
<p>An explanatory variable.  A vector of factor levels.</p>
</td></tr>
<tr><td><code id="pairw.kw_+3A_conf">conf</code></td>
<td>
<p>The level of desired confidence, 1 - <em>P</em>(type I error).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of <code>class = "pairw"</code>.  The utility print function returns a descriptive head and a six column summary dataframe containing: 
</p>
<p>1) the type of contrast (names are taken from levels in <code>x</code>),
</p>
<p>2) the mean rank difference, 
</p>
<p>3) the lower confidence bound of the true mean rank difference, 
</p>
<p>4) the upper confidence bound of the true mean rank difference, 
</p>
<p>5) the hypothesis decision given the prescribed significance level, 
</p>
<p>6) the adjusted <em>P</em>-value.
</p>


<h3>Author(s)</h3>

<p>Ken Aho and Richard Boyce.  Richard provided an adjustment for ties.  Thanks to Paule Bodson-Clermont for pointing out issues with the default behaviour of <code><a href="base.html#topic+rank">rank</a></code>, leading to incorrect answers from <code>pair.kw</code> given missing vaues.
</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.</p>


<h3>See Also</h3>

<p><code><a href="#topic+pairw.anova">pairw.anova</a></code>, <code><a href="#topic+pairw.fried">pairw.fried</a></code>, <code><a href="#topic+plot.pairw">plot.pairw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>rye.data &lt;- data.frame(rye = c(50, 49.8, 52.3, 44.5, 62.3, 74.8, 72.5, 80.2, 
47.6, 39.5, 47.7,50.7), nutrient = factor(c(rep(1, 4), rep(2, 4), rep(3, 4))))
kw &lt;- with(rye.data, pairw.kw(y = rye, x = nutrient, conf = .95))
kw
plot(kw, loc.meas = median, int = "IQR")
# you can also try: plot(kw, type = 2)
</code></pre>

<hr>
<h2 id='pairw.oneway'>
Welch tests controlled for simultaneous inference
</h2><span id='topic+pairw.oneway'></span>

<h3>Description</h3>

<p>Conducts all possible pairwise Welch tests with adjustments to <em>P</em>-values using methods from <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairw.oneway(y, x, conf = 0.95, digits = 5, method = "holm")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairw.oneway_+3A_y">y</code></td>
<td>

<p>Response variable
</p>
</td></tr>
<tr><td><code id="pairw.oneway_+3A_x">x</code></td>
<td>

<p>Explanatory variable
</p>
</td></tr>
<tr><td><code id="pairw.oneway_+3A_conf">conf</code></td>
<td>

<p>Confidence level
</p>
</td></tr>
<tr><td><code id="pairw.oneway_+3A_digits">digits</code></td>
<td>

<p>Number of digits in results
</p>
</td></tr>
<tr><td><code id="pairw.oneway_+3A_method">method</code></td>
<td>

<p>Generalized method for controlling family wise type one error.  These must be methods from <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e., <code>"holm"</code>, <code>"hochberg"</code>, <code>"hommel"</code>, <code>"bonferroni"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>, <code>"none"</code>.  Names can be abbreviated. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>pairw.oneway</code> and the confidence interval functions it calls return a list of <code>class = "pairw"</code>. 
</p>
<p>1) the type of contrast (names are taken from levels in x),
</p>
<p>2) the mean difference,
</p>
<p>3) the lower confidence bound of the true mean difference,
</p>
<p>4) the upper confidence bound of the true mean difference,
</p>
<p>5) the hypothesis decision, given the prescribed significance level, and
</p>
<p>6) the adjusted <em>P</em>-value.
</p>
<p>Other <code>invisible</code> objects include:
</p>
<table role = "presentation">
<tr><td><code>cont</code></td>
<td>
<p>a vector of contrasts.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>The confidence level.</p>
</td></tr>
<tr><td><code>band</code></td>
<td>
<p>A two column matrix containing the lower and upper confidence bounds.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that while <em>P</em>-values will be adjusted for simultaneous inference (unless <code>method = "none"</code>), confidence interval width are generally <em>not adjusted</em>.  In particular, CI widths correspond to Welch SEs and Satterthwaite <em>t</em> degrees of freedoms  Thus they control for heteroscedasticity, however they do not control for family-wise levels of <code class="reqn">\alpha</code> unless <code>method = "bonferroni"</code>, under which the restrictive confidence level <code class="reqn">1 - (\alpha/2r)</code> is used, where <em>r</em> is the number of comparisons. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho and Peter Eckert
</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and Li., W  (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, <code><a href="#topic+pairw.anova">pairw.anova</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(30)
x &lt;- as.factor(c(rep(1,10), rep(2,10), rep(3, 10)))
p &lt;- pairw.oneway(y,x)
p
plot(p)
</code></pre>

<hr>
<h2 id='panel.cor.res'>Functions for customizing correlation matrices</h2><span id='topic+panel.cor.res'></span><span id='topic+panel.lm'></span>

<h3>Description</h3>

<p>The functions here can be used to customize upper and lower triangles in 
correlation matrices.  In particular <code>panel.cor.res</code> provides correlation 
coefficients (any alternative from <code><a href="stats.html#topic+cor">cor</a></code> can be used) and <em>p</em>-values for correlation 
tests.  The function <code>panel.lm</code> puts linear fitted lines from simple linear 
regression in scatterplots.  Note that the function <code><a href="graphics.html#topic+panel.smooth">panel.smooth</a></code> provides a 
smoother fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>panel.cor.res(x, y, digits = 2, meth = "pearson", cex.cor=1)
panel.lm(x, y, col = par("col"), bg = NA, pch = par("pch"), cex = 1,
col.line = 2,lty = par("lty"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="panel.cor.res_+3A_x">x</code></td>
<td>
<p>variable 1 in  correlation</p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_y">y</code></td>
<td>
<p>variable 2 in correlation</p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_digits">digits</code></td>
<td>
<p>number of digits in text for <code>panel.cor.res</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_meth">meth</code></td>
<td>
<p>type of correlation coefficient from <code>panel.cor.res</code>, one of <code>"pearson"</code>, <code>"spearman"</code>, <code>"kendall"</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_cex.cor">cex.cor</code></td>
<td>
<p>size of text in <code>panel.lm</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_col">col</code></td>
<td>
<p>color of points in <code>panel.lm</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_bg">bg</code></td>
<td>
<p>background color of points in <code>panel.lm</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_pch">pch</code></td>
<td>
<p>type of symbols for points in <code>panel.lm</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_cex">cex</code></td>
<td>
<p>symbol size in <code>panel.lm</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_lty">lty</code></td>
<td>
<p>line type in <code>panel.lm</code></p>
</td></tr>
<tr><td><code id="panel.cor.res_+3A_col.line">col.line</code></td>
<td>
<p>color of lines in <code>panel.lm</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="stats.html#topic+cor.test">cor.test</a></code>, <code><a href="graphics.html#topic+panel.smooth">panel.smooth</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(asthma)

pairs(asthma, cex.labels=1, cex=.95, gap=.1, lower.panel = panel.cor.res,
upper.panel = panel.lm)
</code></pre>

<hr>
<h2 id='partial.R2'>Partial correlations of determination in multiple regression</h2><span id='topic+partial.R2'></span>

<h3>Description</h3>

<p>Calculates the partial correlation of determination for a variable of interest in a multiple regression.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
partial.R2(nested.lm, ref.lm)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partial.R2_+3A_nested.lm">nested.lm</code></td>
<td>
<p>A linear model without the variable of interest.</p>
</td></tr>
<tr><td><code id="partial.R2_+3A_ref.lm">ref.lm</code></td>
<td>
<p>A linear model with the variable of interest.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Coefficients of partial determination measure the proportional reduction in sums of squares after a variable of interest, <em>X</em>, is introduced into a model.  We can see how this would be of interest in a multiple regression.  
</p>


<h3>Value</h3>

<p>The partial <code class="reqn">R^2</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li. (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+partial.resid.plot">partial.resid.plot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Soil.C&lt;-c(13,20,10,11,2,25,30,25,23)
Soil.N&lt;-c(1.2,2,1.5,1,0.3,2,3,2.7,2.5)
Slope&lt;-c(15,14,16,12,10,18,25,24,20)
Aspect&lt;-c(45,120,100,56,5,20,5,15,15)
Y&lt;-as.vector(c(20,30,10,15,5,45,60,55,45))

lm.with&lt;-lm(Y~Soil.C+Soil.N+Slope+Aspect)
lm.without&lt;-update(lm.with, ~. - Soil.N)

partial.R2(lm.without,lm.with)
</code></pre>

<hr>
<h2 id='partial.resid.plot'>Partial residual plots for interpretation of multiple regression.</h2><span id='topic+partial.resid.plot'></span>

<h3>Description</h3>

<p>The function creates partial residual plots which help a user graphically determine the effect of a single predictor with respect to all other predictors in a multiple regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partial.resid.plot(x, smooth.span = 0.8, lf.col = 2, sm.col = 4,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partial.resid.plot_+3A_x">x</code></td>
<td>
<p>A output object of class <code>lm</code> or class <code>glm</code></p>
</td></tr>
<tr><td><code id="partial.resid.plot_+3A_smooth.span">smooth.span</code></td>
<td>
<p>Degree of smoothing for smoothing line.</p>
</td></tr>
<tr><td><code id="partial.resid.plot_+3A_lf.col">lf.col</code></td>
<td>
<p>Color for linear fit.</p>
</td></tr>
<tr><td><code id="partial.resid.plot_+3A_sm.col">sm.col</code></td>
<td>
<p>Color for smoother fit.</p>
</td></tr>
<tr><td><code id="partial.resid.plot_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates partial residual plots (see Kutner et al. 2002).  Smoother lines from <code><a href="stats.html#topic+lowess">lowess</a></code> and linear fits from <code><a href="stats.html#topic+lm">lm</a></code> are imposed over plots to help an investigator determine the effect of a particular <em>X</em> variable on <em>Y</em> with all other variables in the model.  The function automatically inserts explanatory variable names on axes.
</p>


<h3>Value</h3>

<p>Returns <em>p</em> partial residual plots, where <em>p</em> = the number of explanatory variables.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li. (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.</p>


<h3>See Also</h3>

<p><code><a href="#topic+partial.R2">partial.R2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(interactive()){
Soil.C&lt;-c(13,20,10,11,2,25,30,25,23)
Soil.N&lt;-c(1.2,2,1.5,1,0.3,2,3,2.7,2.5)
Slope&lt;-c(15,14,16,12,10,18,25,24,20)
Aspect&lt;-c(45,120,100,56,5,20,5,15,15)
Y&lt;-c(20,30,10,15,5,45,60,55,45)
x &lt;- lm(Y ~ Soil.N + Soil.C + Slope + Aspect)
op &lt;- par(mfrow=c(2,2),mar=c(5,4,1,1.5))
partial.resid.plot(x)
par(op)
}
</code></pre>

<hr>
<h2 id='PCB'>
PCBs and herring egg thickness
</h2><span id='topic+PCB'></span>

<h3>Description</h3>

<p>Thirteen sites in the Great Lakes were selected for a study to quantify PCB 
concentrations in 1982 and 1996 (Hughes et al. 1998).  At each site 9-13 American 
herring gull (<em>Larus smithsonianus</em>) eggs were randomly collected and tested for PCB content.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PCB)</code></pre>


<h3>Format</h3>

<p>A data frame with 26 observations on the following 3 variables.
</p>

<dl>
<dt><code>nest</code></dt><dd><p>Nest number</p>
</dd>
<dt><code>level</code></dt><dd><p>PCB levels microgram/gram of dry weight</p>
</dd>
<dt><code>year</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ott, R. L., and M. T. Longnecker  (2004)  <em>A First Course in Statistical Methods</em>.  Thompson. 
</p>


<h3>References</h3>

<p>Hughes, K. D., Weselogh, D. V., and B. M. Braune (1998) The ratio of DDE to PCB 
concentrations in Great Lakes herring gull eggs and its use in interpreting contaminants data. <em>Journal of Great Lakes Research</em> 24(1): 12-31. 
</p>

<hr>
<h2 id='perm.fact.test'>Permutation test for two and three way factorial designs</h2><span id='topic+perm.fact.test'></span>

<h3>Description</h3>

<p>Provides permutation tests for two and three way designs, using permutations of of the response vector with respect to factor levels.  One way permutation tests are provided by <code><a href="#topic+MC.test">MC.test</a></code>, and the function <code>oneway_test</code> in <code>coin</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perm.fact.test(Y, X1, X2, X3 = NA, perm = 100, method = "a")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="perm.fact.test_+3A_y">Y</code></td>
<td>
<p>A vector of response data.  A quantitative vector.</p>
</td></tr>
<tr><td><code id="perm.fact.test_+3A_x1">X1</code></td>
<td>
<p>A vector of factor levels describing factor one.</p>
</td></tr>
<tr><td><code id="perm.fact.test_+3A_x2">X2</code></td>
<td>
<p>A vector of factor levels describing factor two.</p>
</td></tr>
<tr><td><code id="perm.fact.test_+3A_x3">X3</code></td>
<td>
<p>If necessary, a vector of factor levels describing factor three.</p>
</td></tr>
<tr><td><code id="perm.fact.test_+3A_perm">perm</code></td>
<td>
<p>Number of permutations.</p>
</td></tr>
<tr><td><code id="perm.fact.test_+3A_method">method</code></td>
<td>
<p>Either <code>"a"</code> or <code>"b"</code>, see below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Manly (1997) describes five factorial permutation methods which allow testing of interactions.  None of these should be considered to be extensively tested or strongly supported by the statistical literature.
(a) In the first method observations are randomly allocated to factorial treatments preserving the sample size for each treatment.  
Permutation distributions of the <em>F</em> statistics for A, B, and AB are used for statistical tests.
(b) In the second method observations are randomized as above but permutation distributions of MSA, MSB and MSAB are obtained. 
(c) Edgington (1995) recommended a restricted randomization procedure where observations within a main effect are randomized while holding other effects constant.  
Either mean squares or <em>F</em> statistics can be used to create permutation distributions.  
Edgington emphasized that testing interactions with this method are not possible, but that by randomizing over all AB combinations (as in alternative &quot;a&quot; above) provides a test statistic sensitive to interactions.       
(d) Still and White (1981) recommended a restricted testing procedure (as in (c) above) but recommended testing interactions after &quot;subtracting&quot; main effects.  
(e) Ter Braak (1992) recommended replacing observations by their residuals from the initial linear model.  These are then permuted, assuming that sample sizes were equal to original sample sizes across interactions of treatments.  Permutation distributions of the <em>F</em> statistics for A, B, and AB are then used for statistical tests.
Manly (1997) recommends methods a, b, d, or e. Methods a and b are currently implemented.
</p>


<h3>Value</h3>

<p>A dataframe is returned describing initial <em>F</em> test statistics for main effects and interactions, degrees of freedom, and permutation <em>P</em>-values.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Edgington, E. S. (1995)  <em>Randomization Tests, 3rd edition</em>.  Marcel Dekker, New York.  
</p>
<p>Manly, B. F. J. (1997)  <em>Randomization and Monte Carlo Methods in Biology, 2nd edition</em>.  
Chapman and Hall, London.
</p>
<p>Still, A. W., and A. P. White  (1981)  The approximate randomization test as an 
alternative to the <em>F</em> test in analysis of variance.  <em>British Journal of Mathematics and Statistical Psychology</em>.  34: 243-252.
</p>
<p>Ter Braak, C. F. J.  (1992)  Permutation versus bootstrap significance tests in multiple 
regression and ANOVA.  In Jockel, K. J. (ed). <em>Bootstrapping and Related Techniques</em>.  Springer-Verlag, Berlin.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MC.test">MC.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lizard&lt;-data.frame(ants=c(13,242,105,8,59,20,515,488,88,18,44,21,182,21,7,24,312,68,
460,1223,990,140,40,27),size=factor(c(rep(1,12),rep(2,12))),
month=factor(rep(rep(c(1,2,3,4),each=3),2)))
attach(lizard)
perm.fact.test(ants,month,size,perm=100, method = "b")
</code></pre>

<hr>
<h2 id='pika'>
Nitrogen content of soils under pika haypiles
</h2><span id='topic+pika'></span>

<h3>Description</h3>

<p>Aho (1998) hypothesized that pikas worked as ecosystem engineers by building relatively rich soils (via decomposing haypiles and fecal accumulations) in otherwise barren scree.  
Soils from twenty one paired on-haypile and off-haypile sites were gathered from Rendezvous Peak Grand Teton National Park to determine if the habitats differed in total soil nitrogen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pika)</code></pre>


<h3>Format</h3>

<p>A data frame with 22 observations on the following 2 variables.
</p>

<dl>
<dt><code>Haypile</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>On.Off..N</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Aho, K., Huntly N., Moen J., and T. Oksanen (1998) Pikas (<em>Ochotona princeps</em>: Lagomorpha) as allogenic engineers in an alpine ecosystem. <em>Oecologia</em>.  114 (3): 405-409. 
</p>

<hr>
<h2 id='plantTraits'>Plant traits for 136 species</h2><span id='topic+plantTraits'></span>

<h3>Description</h3>

<p>This dataset, from the library <span class="pkg">cluster</span>, describes 136 plant species
according to biological attributes (morphological or reproductive).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(plantTraits)</code></pre>


<h3>Format</h3>

<p>A data frame with 136 observations on the following 31 variables.
</p>

<dl>
<dt><code>pdias</code></dt><dd><p>Diaspore mass (mg).</p>
</dd>
<dt><code>longindex</code></dt><dd><p>Seed bank longevity.</p>
</dd>
<dt><code>durflow</code></dt><dd><p>Flowering duration.</p>
</dd>
<dt>height</dt><dd><p>Plant height, an ordered factor with levels '1' &lt; '2' &lt;
... &lt; '8'.</p>
</dd>
<dt><code>begflow</code></dt><dd><p>Time of first flowering, an ordered factor with levels
'1' &lt; '2' &lt; '3' &lt; '4' &lt; '5' &lt; '6' &lt; '7' &lt; '8' &lt; '9'.</p>
</dd>
<dt><code>mycor</code></dt><dd><p>Mycorrhizae, an ordered factor with levels '0'never &lt; '1'
sometimes&lt; '2'always.</p>
</dd>
<dt><code>vegaer</code></dt><dd><p>Aerial vegetative propagation, an ordered factor with
levels '0'never &lt; '1' present but limited&lt; '2'important.</p>
</dd>
<dt><code>vegsout</code></dt><dd><p>Underground vegetative propagation, an ordered factor
with 3 levels identical to 'vegaer' above.</p>
</dd>
<dt><code>autopoll</code></dt><dd><p>Selfing pollination, an ordered factor with levels
'0'never &lt; '1'rare &lt; '2' often&lt; the rule'3'.</p>
</dd>
<dt><code>insects</code></dt><dd><p>Insect pollination, an ordered factor with 5 levels '0'
&lt; ... &lt; '4'.</p>
</dd>
<dt><code>wind</code></dt><dd><p>Wind pollination, an ordered factor with 5 levels '0' &lt; ...
&lt; '4'.</p>
</dd>
<dt><code>lign</code></dt><dd><p>A binary factor with levels '0:1', indicating if plant is
woody.</p>
</dd>
<dt><code>piq</code></dt><dd><p>A binary factor indicating if plant is thorny.</p>
</dd>
<dt><code>ros</code></dt><dd><p>A binary factor indicating if plant is rosette.</p>
</dd>
<dt><code>semiros</code></dt><dd><p>Semi-rosette plant, a binary factor ('0': no; '1': yes).</p>
</dd>
<dt><code>leafy</code></dt><dd><p>Leafy plant, a binary factor.</p>
</dd>
<dt><code>suman</code></dt><dd><p>Summer annual, a binary factor.</p>
</dd>
<dt><code>winan</code></dt><dd><p>Winter annual, a binary factor.</p>
</dd>
<dt><code>monocarp</code></dt><dd><p>Monocarpic perennial, a binary factor.</p>
</dd>
<dt><code>polycarp</code></dt><dd><p>Polycarpic perennial, a binary factor.</p>
</dd>
<dt><code>seasaes</code></dt><dd><p>Seasonal aestival leaves, a binary factor.</p>
</dd>
<dt><code>seashiv</code></dt><dd><p>Seasonal hibernal leaves, a binary factor.</p>
</dd>
<dt><code>seasver</code></dt><dd><p>Seasonal vernal leaves, a binary factor.</p>
</dd>
<dt><code>everalw</code></dt><dd><p>Leaves always evergreen, a binary factor.</p>
</dd>
<dt><code>everparti</code></dt><dd><p>Leaves partially evergreen, a binary factor.</p>
</dd>
<dt><code>elaio</code></dt><dd><p>Fruits with an elaiosome (dispersed by ants), a binary
factor.</p>
</dd>
<dt><code>endozoo</code></dt><dd><p>Endozoochorous fruits, a binary factor.</p>
</dd>
<dt><code>epizoo</code></dt><dd><p>Epizoochorous fruits, a binary factor.</p>
</dd>
<dt><code>aquat</code></dt><dd><p>Aquatic dispersal fruits, a binary factor.</p>
</dd>
<dt><code>windgl</code></dt><dd><p>wind dispersed fruits,  a binary factor.</p>
</dd>
<dt><code>unsp</code></dt><dd><p>Unspecialized mechanism of seed dispersal, a binary factor.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Most of factor attributes are not disjunctive. For example, a  plant can be 
usually pollinated by insects but sometimes self-pollination can occur.</p>


<h3>Note</h3>

<p>The description here follows directly from that in <span class="pkg">cluster</span>.</p>


<h3>Source</h3>

<p>Vallet, Jeanne (2005) <em>Structuration de communautes vegetales et
analyse comparative de traits biologiques le long d'un gradient
d'urbanisation</em>. Memoire de Master 2
'Ecologie-Biodiversite-Evolution'; Universite Paris Sud XI, 30p.+
annexes (in french).
</p>
<p>Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M. (2005).  <em>Cluster
Analysis Basics and Extensions</em>; unpublished.
</p>

<hr>
<h2 id='plot.pairw'>
Plots confidence intervals and/or bars with letters indicating significant differences for objects from class pairw
</h2><span id='topic+plot.pairw'></span>

<h3>Description</h3>

<p>Provides a utility confidence interval plotting function for objects of <code>class = "pairw"</code>, e.g., objects from <code>pairw.anova</code>, <code>pair.fried</code>, and <code>pairw.kw</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pairw'
plot(x, type = 1, lcol = 1, lty = NULL, lwd = NULL,
cap.length = 0.1, xlab = "", main = NULL, explanation = TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.pairw_+3A_x">x</code></td>
<td>

<p>An object of class <code>pairw</code>.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_type">type</code></td>
<td>

<p>Two types of plots can be made.  Type 1 is a barplot with identical letters over bars if the differences are not significant after adjustment for simultaneous inference.  Type 1 plots can be modified using <code><a href="#topic+bplot">bplot</a></code> arguments.  A type 2 plot shows confidence intervals for true differences.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_lcol">lcol</code></td>
<td>

<p>Confidence bar line color for a type 2 plot, see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_lty">lty</code></td>
<td>

<p>Confidence bar line type, see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_lwd">lwd</code></td>
<td>

<p>Confidence bar line width, see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_cap.length">cap.length</code></td>
<td>

<p>Widths for caps on interval bars (in inches).
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_xlab">xlab</code></td>
<td>

<p>X-axis label.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_main">main</code></td>
<td>

<p>Main caption.  Defaults to a descriptive head.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_explanation">explanation</code></td>
<td>

<p>Logical.  If <code>TRUE</code> (default) provides plot explanation with text.
</p>
</td></tr>
<tr><td><code id="plot.pairw_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code><a href="#topic+bplot">bplot</a></code> or <code><a href="graphics.html#topic+barplot">barplot</a></code> for type 1 and 2 graphs, respectively.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho.  Letters for type 1 graphs obtained using the function <code><a href="multcompView.html#topic+multcompLetters">multcompLetters</a></code> which uses the algorithm of Peipho (2004).
</p>


<h3>References</h3>

<p>Piepho, H-P (2004) An algorithm for a letter-based representation of all-pairwise comparisons. <em>Journal of Computational and Graphical Statistics</em> 13(2): 456-466.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pairw.anova">pairw.anova</a></code>, <code><a href="#topic+pairw.fried">pairw.fried</a></code>, <code><a href="#topic+pairw.kw">pairw.kw</a></code>, <code><a href="graphics.html#topic+barplot">barplot</a></code>, <code><a href="#topic+bplot">bplot</a></code>, <code><a href="multcompView.html#topic+multcompLetters">multcompLetters</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eggs&lt;-c(11,17,16,14,15,12,10,15,19,11,23,20,18,17,27,33,22,26,28)
trt&lt;-as.factor(c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,4,4))

# Type 1 plot
plot(pairw.anova(y = eggs, x = trt, method = "scheffe", conf = .8), int = "CI",
conf = .8)
# Type 2 plot
plot(pairw.anova(y = eggs, x = trt, method = "scheffe", conf = .8), type = 2)

# Data from Fox and Randall (1970)
tremors &lt;- data.frame(freq = c(2.58, 2.63, 2.62, 2.85, 3.01, 2.7, 2.83, 3.15,
3.43, 3.47, 2.78, 2.71, 3.02, 3.14, 3.35, 2.36, 2.49, 2.58, 2.86, 3.1, 2.67,
2.96, 3.08, 3.32, 3.41, 2.43, 2.5, 2.85, 3.06, 3.07), weights =
factor(rep(c(7.5, 5, 2.5, 1.25, 0), 6)), block = factor(rep (1 : 6, each = 5)))

plot(with(tremors, pairw.fried(y = freq, x = weights, blocks = block, nblocks =
6, conf = .95)), loc.meas = median, int = "IQR", bar.col = "lightgreen",
lett.side = 4, density = 3, horiz = TRUE) # Note how blocking increases power

rye.data &lt;- data.frame(rye = c(50, 49.8, 52.3, 44.5, 62.3, 74.8, 72.5, 80.2,
47.6, 39.5, 47.7,50.7), nutrient = factor(c(rep(1, 4), rep(2, 4), rep(3, 4))))

plot(with(rye.data, pairw.kw(y = rye, x = nutrient, conf = .95)), type = 2)
</code></pre>

<hr>
<h2 id='plotAncova'>
Creates plots for one way ANCOVAs 
</h2><span id='topic+plotAncova'></span>

<h3>Description</h3>

<p>ANCOVA plots are created, potentially with distinct line types and/or symbols and colors for treatments.  A legend relating ciphers to treatments is also included.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
plotAncova(model, pch = NULL, lty = NULL, col = NULL, leg.loc = "topright", 
leg.cex = 1, leg.bty = "o", leg.bg = par("bg"), legend.title = NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotAncova_+3A_model">model</code></td>
<td>

<p>Result from <code><a href="stats.html#topic+lm">lm</a></code>. An additive model results in a common slope plot.  An interaction model results in distinct slopes for treatments 
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_pch">pch</code></td>
<td>

<p>A scalar, or a vector of length <em>n</em> defining symbols for treatments. 
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_lty">lty</code></td>
<td>

<p>A scalar, or a vector of length <em>n</em> defining line types for treatments. 
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_col">col</code></td>
<td>

<p>A scalar, or a vector of length <em>n</em> defining color for symbols and lines. 
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_leg.loc">leg.loc</code></td>
<td>

<p>Location of the legend. <code>"n"</code> suppresses the legend.
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_leg.cex">leg.cex</code></td>
<td>

<p>Character expansion from <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_leg.bty">leg.bty</code></td>
<td>

<p>Box type from <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_leg.bg">leg.bg</code></td>
<td>

<p>Background color from <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_legend.title">legend.title</code></td>
<td>

<p>Legend <code>title</code> from <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
<tr><td><code id="plotAncova_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an ANCOVA plot and model coefficients.  Slopes and intercepts for factor level lines are also stored as invisible output (see Examples).  
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(20)
y &lt;- 3 * x + rnorm(20)
cat &lt;- c(rep("A",5),rep("B",5),rep("C",5),rep("D",5))
l &lt;- lm(y ~ x * cat)
plotAncova(l, leg.loc = "bottomright")

# Access intercepts and slopes
pa &lt;- plotAncova(l)
pa
</code></pre>

<hr>
<h2 id='plotCI.reg'>Plots a simple linear regression along with confidence and prediction intervals.
</h2><span id='topic+plotCI.reg'></span>

<h3>Description</h3>

<p>Plots the fitted line from a simple linear regression (y ~ x) and (if requested) confidence and prediction intervals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
plotCI.reg(x, y, conf = 0.95, CI = TRUE, PI = TRUE, resid = FALSE, reg.col = 1, 
CI.col = 2, PI.col = 4, reg.lty = 1, CI.lty = 2, PI.lty = 3, reg.lwd = 1, 
CI.lwd = 1, resid.lty = 3, resid.col = 4,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCI.reg_+3A_x">x</code></td>
<td>
<p>The explanatory variable, a numeric vector.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_y">y</code></td>
<td>
<p>The response variable, a numeric vector</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_conf">conf</code></td>
<td>
<p>The level of confidence; 1 - <em>P</em>(type I error)</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_ci">CI</code></td>
<td>
<p>Logical; should the confidence interval be plotted?</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_pi">PI</code></td>
<td>
<p>Logical; should the prediction interval be plotted?</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_resid">resid</code></td>
<td>
<p>Logical; should residuals be plotted?</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_reg.col">reg.col</code></td>
<td>
<p>Color of the fitted regression line.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_ci.col">CI.col</code></td>
<td>
<p>Color of the confidence interval lines.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_pi.col">PI.col</code></td>
<td>
<p>Color of the prediction interval lines.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_reg.lty">reg.lty</code></td>
<td>
<p>Line type for the fitted regression line.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_ci.lty">CI.lty</code></td>
<td>
<p>Line type for the confidence interval.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_pi.lty">PI.lty</code></td>
<td>
<p>Line type for the confidence interval.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_reg.lwd">reg.lwd</code></td>
<td>
<p>Line width for the regression line.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_ci.lwd">CI.lwd</code></td>
<td>
<p>Line widths for the confidence and prediction intervals.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_resid.lty">resid.lty</code></td>
<td>
<p>Line width for the regression line.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_resid.col">resid.col</code></td>
<td>
<p>Line color for residual lines.</p>
</td></tr>
<tr><td><code id="plotCI.reg_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot with a regression line and (if requested) confidence and prediction intervals</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <code><a href="stats.html#topic+predict">predict</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>y&lt;-c(1,2,1,3,4,2,3,4,3,5,6)
x&lt;-c(2,3,1,4,5,4,5,6,7,6,8)
plotCI.reg(x,y)
</code></pre>

<hr>
<h2 id='PM2.5'>
PM 2.5 pollutant data from Pocatello Idaho
</h2><span id='topic+PM2.5'></span>

<h3>Description</h3>

<p>PM 2.5 pollutants (those less than 2.5 microns in diameter) can be directly emitted from sources such as forest fires, or can form when gases discharged from power plants, industries and automobiles react in the air. Once inhaled, these particles can affect the heart and lungs and cause serious health problems. The DEQ began monitoring PM 2.5 pollutants in Pocatello Idaho in November 1998. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PM2.5)</code></pre>


<h3>Format</h3>

<p>A data frame with 65 observations on the following 2 variables.
</p>

<dl>
<dt><code>Yr.mos</code></dt><dd><p>Year and month.  A factor with levels <code>1998 11</code> <code>1998 12</code> <code>1999 1</code> <code>1999 10</code> <code>1999 11</code> <code>1999 12</code> <code>1999 2</code> <code>1999 3</code> <code>1999 4</code> <code>1999 5</code> <code>1999 6</code> <code>1999 7</code> <code>1999 8</code> <code>1999 9</code> <code>2000 1</code> <code>2000 10</code> <code>2000 11</code> <code>2000 12</code> <code>2000 2</code> <code>2000 3</code> <code>2000 4</code> <code>2000 5</code> <code>2000 6</code> <code>2000 7</code> <code>2000 8</code> <code>2000 9</code> <code>2001 1</code> <code>2001 10</code> <code>2001 11</code> <code>2001 12</code> <code>2001 2</code> <code>2001 3</code> <code>2001 4</code> <code>2001 5</code> <code>2001 6</code> <code>2001 7</code> <code>2001 8</code> <code>2001 9</code> <code>2002 1</code> <code>2002 10</code> <code>2002 11</code> <code>2002 12</code> <code>2002 2</code> <code>2002 3</code> <code>2002 4</code> <code>2002 5</code> <code>2002 6</code> <code>2002 7</code> <code>2002 8</code> <code>2002 9</code> <code>2003 1</code> <code>2003 10</code> <code>2003 11</code> <code>2003 12</code> <code>2003 2</code> <code>2003 3</code> <code>2003 4</code> <code>2003 5</code> <code>2003 6</code> <code>2003 7</code> <code>2003 8</code> <code>2003 9</code> <code>2004 1</code> <code>2004 2</code> <code>2004 3</code></p>
</dd>
<dt><code>PM2.5</code></dt><dd><p>A numeric vector describing PM 2.5 pollutant levels in <code class="reqn">mu</code>g/<code class="reqn">m^2</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Idaho department of Environmental Quality
</p>

<hr>
<h2 id='polyamine'>
Polyamine data from Hollander and  Wolfe (1999)
</h2><span id='topic+polyamine'></span>

<h3>Description</h3>

<p>Polyamines are a class of organic compounds having two or more primary amino groups.  They appear to have a number of important functions including regulation of cell proliferation, cell differentiation, and cell death.  Polyamine plasma levels taken for healthy children of different ages were summarized by Hollander and Wolfe (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(polyamine)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 2 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>Child age in years (0 indicates newborn)</p>
</dd>
<dt><code>p.amine</code></dt><dd><p>Polyamine level in blood</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hollander, M., and  D. A. Wolfe  (1999) <em>Nonparametric Statistical Methods</em>. New York: John Wiley &amp; Sons. 
</p>

<hr>
<h2 id='portneuf'>
Portneuf River longitudinal N and P data
</h2><span id='topic+portneuf'></span>

<h3>Description</h3>

<p>Portneuf River data from the Siphon Road site near Pocatello Idaho, downstream from an elemental P refinery.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(portneuf)</code></pre>


<h3>Format</h3>

<p>A data frame with 176 observations on the following 3 variables.
</p>

<dl>
<dt><code>date</code></dt><dd><p>Dates from 1998-01-15 to 2011-08-16</p>
</dd>
<dt><code>TKN</code></dt><dd><p>Total Kjeldahl nitrogen (measured as a percentage)</p>
</dd>
<dt><code>total.P</code></dt><dd><p>Total phosphorous (mg/L)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Idaho State Department of Environmental Quality
</p>

<hr>
<h2 id='potash'>
Potash/cotton strength data
</h2><span id='topic+potash'></span>

<h3>Description</h3>

<p>An oft-cited RCBD example is an agricultural experiment which evaluates the effect of levels of of soil K<code class="reqn">_2</code>O (potash) on 
the breaking strength of cotton fibers (Cochran and Cox 1957).  Five levels of K<code class="reqn">_2</code>O were used in the soil subplots (
36, 54, 72, 108, and 144 lbs per acre) and a single sample of cotton was taken from each of five subplot.  
The experiment had three blocks, and each of the K<code class="reqn">_2</code>O treatments was randomly assigned to the five subplots within each block.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(potash)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 3 variables.
</p>

<dl>
<dt><code>treatment</code></dt><dd><p>a factor with levels <code>36</code> <code>54</code> <code>72</code> <code>108</code> <code>144</code></p>
</dd>
<dt><code>block</code></dt><dd><p>a factor with levels <code>1</code> <code>2</code> <code>3</code></p>
</dd>
<dt><code>strength</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cochran, W. G. and G. M. Cox  (1957) <em>Experimental Designs (Second Edition)</em>. New York: John Wiley &amp; Sons.
</p>

<hr>
<h2 id='potato'>Fisher's Rothamsted potato data
</h2><span id='topic+potato'></span>

<h3>Description</h3>

<p>In his &quot;Statistical Methods for Research Workers&quot; Fisher (1925) introduced the world to ANOVA using data from the  Rothamsted Agricultural Experimental Station.  In one example, Fisher compared potato yield (per plant) for twelve potato varieties and three fertilizer treatments (a basal manure application, along with sulfur and chloride addition).   
Three replicates were measured for each of the 12 x 3 = 36 treatment combinations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(potato)</code></pre>


<h3>Format</h3>

<p>A data frame with 108 observations on the following 4 variables.
</p>

<dl>
<dt><code>Yield</code></dt><dd><p>Potato yield in lbs per plant</p>
</dd>
<dt><code>Variety</code></dt><dd><p>Potato variety: <code>Ajax</code> <code>Arran comrade</code> <code>British queen</code> <code>Duke of York</code> <code>Epicure</code> <code>Great Scot</code> <code>Iron duke</code> <code>K of K</code> <code>Kerrs pink</code> <code>Nithsdale</code> <code>Tinwald perfection</code> <code>Up-to-date</code></p>
</dd>
<dt><code>Fert</code></dt><dd><p>Fertilizer type: <code>B</code> = basal manure, <code>Cl</code> = chloride addition, <code>S</code> = sulfur addition.</p>
</dd>
<dt><code>Patch</code></dt><dd><p>Feld patch number <code>1</code> <code>2</code> <code>3</code> <code>4</code> <code>5</code> <code>6</code> <code>7</code> <code>8</code> <code>9</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Fisher, R. A. (1925)  <em>Statistical Methods for Research Workers, 1st edition</em>.  Oliver and Boyd,  Edinburgh
</p>
<p>Thanks to Bob O'Hara for finding a data entry error for this dataset for versions of asbio &lt;= 1.8-2.
</p>

<hr>
<h2 id='power.z.test'>Power analysis for a one sample z-test</h2><span id='topic+power.z.test'></span>

<h3>Description</h3>

<p>A power analysis for a one sample <em>z</em>-test. The function requires <code class="reqn">\alpha</code>, <code class="reqn">\sigma</code>, 
the effect size, the type of test (one tailed or two-tailed), and either power 
(1 - <code class="reqn">\beta</code>) or <em>n</em> (sample size).  If <em>n</em> is provided, then power is calculated.  Conversely, 
if one provides power, but not <em>n</em>, then the required <em>n</em> is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
power.z.test(sigma = 1, n = NULL, power = NULL, alpha = 0.05, effect = NULL, 
test = c("two.tail", "one.tail"), strict = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power.z.test_+3A_sigma">sigma</code></td>
<td>
<p>The population standard deviation.</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_n">n</code></td>
<td>
<p>The sample size.  Not required if <code>power</code> is specified.</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_power">power</code></td>
<td>
<p>The desired power.  Not required if <code>n</code> is specified.</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_alpha">alpha</code></td>
<td>
<p>Probability of type I error.</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_effect">effect</code></td>
<td>
<p>Effect size.</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_test">test</code></td>
<td>
<p>One of two choices: <code>"two.tail"</code> or <code>"one.tail"</code>.</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_strict">strict</code></td>
<td>
<p>Causes the function to use a strict interpretation of power in a two-sided test.  
If <code>strict = TRUE</code> then power for a two sided test will include the probability of rejection 
in the opposite tail of the true effect. If <code>strict = FALSE</code> (the default) power will be half the value of <code class="reqn">\alpha</code> if the true effect size is zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list
</p>
<table role = "presentation">
<tr><td><code>sigma</code></td>
<td>
<p>The prescribed population variance.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>The power.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The type I error probability.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>The type of test prescribed.</p>
</td></tr>
<tr><td><code>effect</code></td>
<td>
<p>The effect size.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Bain, L. J., and M. Engelhardt (1992)  <em>Introduction to Probability and Mathematical 
Statistics</em>.  Duxbury press.  Belmont, CA, USA.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>power.z.test(sigma=6,effect=5,power=.9,test="one.tail")
</code></pre>

<hr>
<h2 id='press'>
prediction sum of squares
</h2><span id='topic+press'></span>

<h3>Description</h3>

<p>Calculates PREdiction Sum of Squares (<em>PRESS</em>) for a linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
press(lm, as.R2 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="press_+3A_lm">lm</code></td>
<td>

<p>An object of class <code>lm</code>.
</p>
</td></tr>
<tr><td><code id="press_+3A_as.r2">as.R2</code></td>
<td>
 
<p>Logical.  Whether or not output should be expressed as predicted <code class="reqn">R^2</code>, i.e., <code class="reqn">PRESS/TSS</code>.   
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The press statistic is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^{n}d_i^2</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">d_i = \frac{e_i}{1-h_{ii}}</code>
</p>
 
<p>where <code class="reqn">h_{ii}</code> is the <em>i</em>th diagonal element in the hat matrix.
</p>


<h3>Value</h3>

<p>Returns the <em>PRESS</em> statistic.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li  (2005)  <em>Applied Linear Statistical Models, 5th edition.</em>  McGraw-Hill, Boston.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- rnorm(100)
X &lt;- rnorm(100)
press(lm(Y ~ X))
</code></pre>

<hr>
<h2 id='Preston.dist'>
Preston diversity analysis
</h2><span id='topic+Preston.dist'></span>

<h3>Description</h3>

<p>A diversity and richness analysis method based on the Preston (1948) log-normal distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Preston.dist(counts, start = 0.2, cex.octave = 1, cex.legend = 1, cex.pt = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Preston.dist_+3A_counts">counts</code></td>
<td>

<p>Vector of counts for species in a community dataset. 
</p>
</td></tr>
<tr><td><code id="Preston.dist_+3A_start">start</code></td>
<td>

<p>Starting value for non-linear least squares estimation of <em>a</em> in <code class="reqn">n = n_0 \times e^{-aR^2}</code>.
</p>
</td></tr>
<tr><td><code id="Preston.dist_+3A_cex.octave">cex.octave</code></td>
<td>

<p>Character expansion for octave labels.
</p>
</td></tr>
<tr><td><code id="Preston.dist_+3A_cex.legend">cex.legend</code></td>
<td>

<p>Character expansion for legend.</p>
</td></tr>
<tr><td><code id="Preston.dist_+3A_cex.pt">cex.pt</code></td>
<td>

<p>Character expansion for symbols.</p>
</td></tr>
<tr><td><code id="Preston.dist_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Preston (1948) proposed that after a log<code class="reqn">_2</code> transformation species abundances, grouped in bins representing 
a doubling of abundance (octaves), would be normally distributed.  Thus, after this transformation most 
species in a sample would have intermediate abundance, and there would be relatively few rare or ubiquitous species.  
The Preston model is based on the Gaussian function: <code class="reqn">n = n_0 \times e^{-aR^2}</code>, where, <code class="reqn">n_0</code> is the 
number of species contained in the modal octave, <em>n</em> is the number of species contained in an octave <em>R</em> 
octaves from the modal octave, and <em>a</em> is an unknown parameter.  The parameter <em>a</em> is estimated using the function 
<code><a href="stats.html#topic+nls">nls</a></code>, using a starting value, 0.2, recommended by Preston.  The area under Preston curve provides an 
extrapolated estimate of richness and thus an indication of the adequacy of a sampling effort.  Preston called a 
line placed at the 0th octave the veil line.  He argued that species with abundances below the veil line have not 
been detected due to inadequate sampling.  
</p>


<h3>Value</h3>

<p>Graph of the Preston log-normal distribution for a dataset given by &quot;counts&quot;, and a summary of the analysis 
including the fitted Gaussian equation, the estimated number of species, and an estimate for the percentage 
of sampling that was completed i.e. <code>[length(counts)/Est.no.of.spp]*100</code>.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Preston, F.W.  (1948)  The commonness and rarity of species. <em>Ecology</em> 29, 254-283. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dnorm">dnorm</a></code>, <code><a href="stats.html#topic+nls">nls</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BCI.count)
BCI.ttl&lt;-apply(BCI.count,2,sum)
Preston.dist(BCI.ttl)
</code></pre>

<hr>
<h2 id='prostate'>
Prostate cancer data
</h2><span id='topic+prostate'></span>

<h3>Description</h3>

<p>Hastie et al. (2001) describe a cancer research study that attempted to associate prostate specific antigens and and a number of prognostic measures in the context of advanced prostate cancer.
</p>
<p>Data in the experiment were collected from 97 men who were about to undergo radial prostectomies. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prostate)</code></pre>


<h3>Format</h3>

<p>A data frame with 97 observations on the following 4 variables.
</p>

<dl>
<dt><code>PSA</code></dt><dd><p>Serum prostate-specific albumin level (mg/ml).</p>
</dd>
<dt><code>vol</code></dt><dd><p>Tumor volume (cc).</p>
</dd>
<dt><code>weight</code></dt><dd><p>Prostate weight (g).</p>
</dd>
<dt><code>Gleason</code></dt><dd><p>Pathologically determined grade of disease.  Summed scores were either 6, 7, or 8 with higher scores indicating worse prognosis.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li  (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston. 
</p>


<h3>References</h3>

<p>Hastie, T., R. Tibshirani, and J. Friedman (2009) <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition</em>. Springer.
</p>

<hr>
<h2 id='prp'>
Perpendicularity</h2><span id='topic+prp'></span><span id='topic+print.prp.index'></span>

<h3>Description</h3>

<p>Calculates a perpendicularity index, <code class="reqn">\eta</code>, for animal spatial movements.  The index has a [0, 1] range with 0 indicating a perfectly parallel movement with respect to boundary or edge and 1 indicating perfectly perpendicular movement.  Other summaries are also provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
prp(Time, S.X, S.Y, N.X, N.Y, habitat = NULL, near.angle = NULL, 
F.0.NA = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prp_+3A_time">Time</code></td>
<td>

<p>A numeric vector containing the times when spatial coordinates were recorded.
</p>
</td></tr>
<tr><td><code id="prp_+3A_s.x">S.X</code></td>
<td>

<p><em>X</em>-coordinates of animal.
</p>
</td></tr>
<tr><td><code id="prp_+3A_s.y">S.Y</code></td>
<td>

<p><em>Y</em>-coordinates of animal.
</p>
</td></tr>
<tr><td><code id="prp_+3A_n.x">N.X</code></td>
<td>

<p><em>X</em>-coordinate of nearest point on boundary.  These data can be obtained from function <code><a href="#topic+near.bound">near.bound</a></code> or from ARCGIS Near output.
</p>
</td></tr>
<tr><td><code id="prp_+3A_n.y">N.Y</code></td>
<td>

<p><em>Y</em>-coordinate of nearest point on boundary.  These data can be obtained from function <code><a href="#topic+near.bound">near.bound</a></code> or from ARCGIS Near output.
</p>
</td></tr>
<tr><td><code id="prp_+3A_habitat">habitat</code></td>
<td>

<p>A character vector of habitat categories.
</p>
</td></tr>
<tr><td><code id="prp_+3A_near.angle">near.angle</code></td>
<td>

<p>A numeric vector containing the angle of azimuth to the nearest point on the boundary with respect to a four quadrant system.  NE = <code class="reqn">0^{\circ}</code> to <code class="reqn">90^{\circ}</code>, NW is &gt; <code class="reqn">90^{\circ}</code> and <code class="reqn">\le 180^{\circ}</code>, SE is &lt; <code class="reqn">0^{\circ}</code> and <code class="reqn">\le - 90^{\circ}</code> is &gt; <code class="reqn">-90^{\circ}</code> and <code class="reqn">\le -180^{\circ}</code>.  This output can be obtained from function <code><a href="#topic+bound.angle">bound.angle</a></code> or from ARCGIS Near output.
</p>
</td></tr>
<tr><td><code id="prp_+3A_f.0.na">F.0.NA</code></td>
<td>

<p>A logical argument specifying whether or not a time interval in which F = 0 should be made <code>NA</code> (see Figure from examples)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This index for perpendicularity, <code class="reqn">\eta</code> is based on the following rules:
</p>
<p>if <code class="reqn">\delta \le 90^o</code> then <code class="reqn">\eta</code> = <code class="reqn">\delta/90^o</code>; if <code class="reqn">90^o &lt; \delta \le 135^o</code> then <code class="reqn">\eta</code> = <code class="reqn">[90^o - (\delta - 90^o)]/90^o</code>; if <code class="reqn">135^o &lt; \delta \le 180^o</code> then <code class="reqn">\eta</code> = <code class="reqn">(\delta - 90^o)/90^o</code> 
</p>
<p>For notation create Figures from examples.
</p>


<h3>Value</h3>

<p>Returns a list with four or five items.
</p>
<table role = "presentation">
<tr><td><code>lines</code></td>
<td>
<p>A matrix with <em>n</em> - 1 rows containing line lengths for the lines <em>A, B, C, D,</em> and <em>F</em>.  See figure in examples below.</p>
</td></tr>
<tr><td><code>angles</code></td>
<td>
<p>A matrix with <em>n</em> - 1 rows containing line lengths for the angles <code class="reqn">\kappa</code>, <code class="reqn">\gamma</code> and <code class="reqn">\delta</code>.  See Figure in examples below.</p>
</td></tr>
<tr><td><code>moment.by.moment</code></td>
<td>
<p>This component provides a matrix with <em>n</em> - 1 rows.  Included are the columns: <code>End.time</code>, <code>Eta.Index</code>, <code>Delta</code>, <code>Habitat</code>, and <code>Brdr chng</code>.  The columns <code>Habitat</code>, and <code>Brdr chng</code> are excluded if <code>habitat = NULL</code> or <code>near.angle = NULL</code>.</p>
</td></tr>
<tr><td><code>P.summary</code></td>
<td>
<p>Contains averages and standard errors for <code class="reqn">\eta</code>.</p>
</td></tr>
<tr><td><code>crossing.summary</code></td>
<td>
<p>Crossing binomial summaries.  Provided if <code>habitat</code> and <code>near.angle</code> are specified.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Kie, J.G., A.A. Ager, and R.T. Bowyer  (2005)  Landscape-level movements of North American 
elk (<em>Cervus elaphus</em>): effects of habitat patch structure and topography. <em>Landscape Ecology</em> 20:289-300.
</p>
<p>McGarigal K., SA Cushman, M.C. Neel, and E. Ene  (2002) <em>FRAGSTATS: Spatial Pattern
Analysis Program for Categorical Maps</em>. Computer software program produced by the
authors at the University of Massachusetts, Amherst.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+near.bound">near.bound</a></code>, <code><a href="#topic+bound.angle">bound.angle</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###Diagram describing prp output.  
y&lt;-rnorm(100,0,5)
plot(seq(1,100),sort(y),type="l",xaxt="n",yaxt="n",lwd=2,xlab="",ylab="")
op &lt;- par(font=3)

segments(52,-12,46,sort(y)[46],lty=1,col=1,lwd=1)##A
segments(90,-8,85,sort(y)[85],lty=1,col=1,lwd=1)##B
segments(46,sort(y)[46],85,sort(y)[85],lty=1)##F
segments(90,-8,46,sort(y)[46],lty=2)##D
arrows(52,-12,90,-8,length=.1,lwd=3)##C
arrows(20,-12,20,8,lty=2,col="gray",length=.1)#North
arrows(20,sort(y)[46],95,sort(y)[46],length=.1,lty=2,col="gray")
arrows(20,-12,95,-12,length=.1,lty=2,col="gray")#East

text(20,9,"N",col="gray");text(97,-12, "E", col= "gray");text(97,sort(y)[46], "E",
col= "gray")
text(49.5,-12.5,"a");text(92.5,-8.5,"b")
text(45.5,-5.5,"A",font=4,col=1);text(70,-9,"C",font=4,col=1);text(91.5,-1.75,"B",
font=4,col=1)
text(44,sort(y)[46]+1,"c");text(67.5,-2.5,"D",font=4,col=1);text(65,3.9,"F",font=4,
col=1)
text(87,sort(y)[87]+1,"d");text(57,-10,expression(kappa),col=1);
text(81,sort(y)[87]-3,expression(gamma),col=1);text(57,1.3,expression(theta),col=1)
text(64,-11.5,expression(beta),col=1)

library(plotrix)
draw.arc(50,-12,6,1.35,col=1);draw.arc(50,-12,6,.3,col=1);draw.arc(50,-12,6,0.02,
col=1)
draw.arc(46,sort(y)[46],7,.01,col=1);draw.arc(46,sort(y)[46],7,.5,col="white")
draw.arc(85,sort(y)[85],6,-2.7,col=1);draw.arc(85,sort(y)[85],6,-1.4,col="white",
lwd=2)
legend("topleft",c(expression(paste(kappa, " = acos[(",C^2," + ",X^2," - ",D^2,")
/2CX]")),
expression(paste(gamma," = acos[(",Y^2," + ",F^2," - ",D^2,")/2YF]")),
expression(paste(theta," = atan[(",y[f]," - ",y[n],")/(",x[f]," - ",x[n],")]")),
expression(paste(beta, " = atan[(",y[epsilon]," - ",y[alpha],")/(",x[epsilon],
" - ",x[alpha],")]"))),
bty="n",cex=.9,inset=-.025)

###Figure for demo dataset.
bX&lt;-seq(0,49)/46

bY&lt;-c(4.89000,4.88200,4.87400,4.87300,4.88000,4.87900,4.87900,4.90100,4.90800,
4.91000,4.93300,4.94000,4.91100,4.90000,4.91700,4.93000,4.93500,4.93700,
4.93300,4.94500,4.95900,4.95400,4.95100,4.95800,4.95810,4.95811,4.95810,
4.96100,4.96200,4.96300,4.96500,4.96500,4.96600,4.96700,4.96540,4.96400,
4.97600,4.97900,4.98000,4.98000,4.98100,4.97900,4.98000,4.97800,4.97600,
4.97700,4.97400,4.97300,4.97100,4.97000)

X&lt;-c(0.004166667,0.108333333,0.316666667,0.525000000,0.483333333,0.608333333,
0.662500000,0.683333333,0.900000000,1.070833333)
Y&lt;-c(4.67,4.25,4.26,4.50,4.90,4.10,4.70,4.40,4.20,4.30)

plot(bX,bY,type="l",lwd=2,xlab="",ylab="",ylim=c(4,5.1))
lines(X,Y)

for(i in 1:9)arrows(X[i],Y[i],X[i+1],Y[i+1],length=.1,lwd=1,angle=20)
mx&lt;-rep(1,9)
my&lt;-rep(1,9)
for(i in 1:9)mx[i]&lt;-mean(c(X[i],X[i+1]))
for(i in 1:9)my[i]&lt;-mean(c(Y[i],Y[i+1]))
for(i in 1:9)text(mx[i],my[i],i,font=2,cex=1.3)

nn&lt;-near.bound(X,Y,bX,bY)
prp(seq(1,10),X,Y,nn[,1],nn[,2])$moment.by.moment
par(op)

## End(Not run)
</code></pre>

<hr>
<h2 id='pseudo.v'>Jacknife pseudo-values</h2><span id='topic+pseudo.v'></span>

<h3>Description</h3>

<p>The function returns jackknife pseudovalues which can then be used to create statistical summaries, e.g. the jackknife parameter estimate, and the jackknife standard error.  The function can be run on univariate data <code>(matrix = FALSE)</code> or multivariate data <code>(matrix =TRUE)</code>.  In the later case matrix rows are treated as multivariate observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseudo.v(data, statistic, order = 1, matrix = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pseudo.v_+3A_data">data</code></td>
<td>
<p>A vector <code>(matrix =FALSE)</code> or matrix <code>(matrix=TRUE)</code> of quantitative data.</p>
</td></tr>
<tr><td><code id="pseudo.v_+3A_statistic">statistic</code></td>
<td>
<p>A function whose output is a statistic (e.g. a sample mean).  The function must have only one argument, a call to <code>data</code>.</p>
</td></tr>
<tr><td><code id="pseudo.v_+3A_order">order</code></td>
<td>
<p>The order of jackknifing to be used.</p>
</td></tr>
<tr><td><code id="pseudo.v_+3A_matrix">matrix</code></td>
<td>
<p>A logical statement.  If <code>matrix = TRUE</code> then rows in the matrix are sampled as multivariate observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the first order jackknife procedure a statistic <code class="reqn">\hat{\theta}</code> is calculated using all <em>n</em> samples, it is then calculated with the first observation removed <code class="reqn">\hat{\theta}</code><code class="reqn">_{-1}</code>, with only the second observation removed, <code class="reqn">\hat{\theta}</code><code class="reqn">_{-2}</code>, and so on.  This process is repeated for all <em>n</em> samples.  The resulting vector of size <em>n</em> contains pseudovalues for their respective observations.
</p>


<h3>Value</h3>

<p>A vector of first-order jackknife pseudovalues is returned.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Manly, B. F. J.  (1997)  <em>Randomization and Monte Carlo Methods in Biology, 2nd edition</em>.
Chapman and Hall, London.</p>


<h3>See Also</h3>

<p><code><a href="boot.html#topic+empinf">empinf</a></code>, <code><a href="boot.html#topic+boot">boot</a></code>, <code><a href="#topic+bootstrap">bootstrap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cliff.sp)
siteCD1&lt;-data.frame(t(cliff.sp[1,]))

#Shannon-Weiner diversity
SW&lt;-function(data){
d&lt;-data[data!=0]
p&lt;-d/sum(d)
-1*sum(p*log(p))
}

pv&lt;-pseudo.v(siteCD1,SW)
</code></pre>

<hr>
<h2 id='qq.Plot'>
Normal quantile plots for single or multiple factor levels
</h2><span id='topic+qq.Plot'></span>

<h3>Description</h3>

<p>Provides quantile plots for one or more factor levels overlaid on a single graph.  If <code>plot.CI = TRUE</code>, then
code for bootstrapped confidence provided in the documentation for <code><a href="boot.html#topic+boot">boot</a></code> is applied to create confidence envelopes. If <code>plot.CI = FALSE</code>, <code><a href="stats.html#topic+qqnorm">qqnorm</a></code> and <code><a href="stats.html#topic+qqline">qqline</a></code> are used to create overlaid normal probability plots given multiple categories in <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
qq.Plot(y, x = NULL, col = NULL, pch = NULL, main = "", R = 5000, fit.lty = 1,
env.lty = 2, conf = 0.95, type = "point", ylim = NULL, xlim = NULL, xlab = NULL,
ylab = NULL, plot.CI = FALSE, standy = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qq.Plot_+3A_y">y</code></td>
<td>

<p>The response variable
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_x">x</code></td>
<td>

<p>A categorical variable to subset <em>y</em>
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_col">col</code></td>
<td>

<p>A scalar or vector with length equivalent to the number of levels in <em>x</em>, describing colors of points and lines for levels in <em>x</em>.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_pch">pch</code></td>
<td>

<p>A scalar or vector with length equivalent to the number of levels in <em>x</em>, describing symbols for levels in <em>x</em>.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_main">main</code></td>
<td>

<p>Main title.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_r">R</code></td>
<td>

<p>Number of bootstrap samples for calculating confidence envelopes
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_fit.lty">fit.lty</code></td>
<td>

<p>Line type for fit line(s).
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_env.lty">env.lty</code></td>
<td>

<p>Line type for fit line(s).
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_conf">conf</code></td>
<td>

<p>Level of confidence in confidence envelopes.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_type">type</code></td>
<td>

<p>Type of bootstrapped confidence envelope.  One of <code>"point"</code> or <code>"overall"</code>.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_xlim">xlim</code></td>
<td>

<p>A two element vector defining the lower and upper <em>x</em>-axis limits .
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_ylim">ylim</code></td>
<td>

<p>A two element vector defining the lower and upper <em>y</em>-axis limits .
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_xlab">xlab</code></td>
<td>

<p><em>X</em>-axis label.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_ylab">ylab</code></td>
<td>

<p><em>Y</em>-axis label.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_plot.ci">plot.CI</code></td>
<td>

<p>Logical, specifying whether or not confidence ellipses should be plotted.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_standy">standy</code></td>
<td>

<p>Logical, specifying if observations should be standardized.
</p>
</td></tr>
<tr><td><code id="qq.Plot_+3A_...">...</code></td>
<td>

<p>Other arguments from <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qqnorm">qqnorm</a></code>, <code><a href="stats.html#topic+qqline">qqline</a></code>,  <code><a href="boot.html#topic+envelope">envelope</a></code>, <code><a href="boot.html#topic+boot">boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(50)
x &lt;- c(rep(1, 25), rep(2, 25))
qq.Plot(y, x)
</code></pre>

<hr>
<h2 id='r.bw'>Biweight midvariance, and biweight midcorrelation. 
</h2><span id='topic+r.bw'></span>

<h3>Description</h3>

<p>Calculates biweight midvariance if one variable is given and biweight midvariances, midcovariance and midcorrelation if two variables are given. Biweight midcorrelation is a robust alternative to Pearson's <em>r</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.bw(X, Y=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r.bw_+3A_x">X</code></td>
<td>
<p>A numeric vector
</p>
</td></tr>
<tr><td><code id="r.bw_+3A_y">Y</code></td>
<td>
<p>An optional second numeric variable.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Biweight statistics are robust to violations of normality.   Like the sample median the sample midvariance has a breakdown point of approximately 0.5.  The triefficiency of the biweight midvariance was the highest for any of the 150 measures of scale compared by Lax (1985). 
</p>


<h3>Value</h3>

<p>Returns the biweight variance if one variable is given, and the biweight midvariances, midcovariance and midcorrelation if two variables are given. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Lax, D. A.  (1985)  Robust estimators of scale: finite sample performance in long-tailed symmetric distributions.  <em>Journal of the American Statistical Association</em>, 80 736-741.
</p>
<p>Wilcox, R. R.  (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+r.pb">r.pb</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-rnorm(100)
y&lt;-rnorm(100)
r.bw(x,y)
</code></pre>

<hr>
<h2 id='r.dist'>
Visualize the sampling distribution of Pearson's product moment correlation
</h2><span id='topic+r.dist'></span><span id='topic+see.r.dist.tck'></span>

<h3>Description</h3>

<p>Stumbling points for many methods of inference for the true correlation <code class="reqn">\rho</code> and for independence are: 1) asymmetry, 2) explicit bounds on <code class="reqn">\rho</code>,  and 3) dependence on sample size, of the sampling distribution of <em>r</em>.  
</p>
<p>The functions here allow visualization of these characteristics.  The algorithm used for the sampling distribution of <em>r</em> is based on the first two steps in an asymptotic series (see Kenney and Keeping 1951).    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.dist(rho, r, n)
see.r.dist.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r.dist_+3A_rho">rho</code></td>
<td>

<p>Population correlation
</p>
</td></tr>
<tr><td><code id="r.dist_+3A_r">r</code></td>
<td>

<p>A numeric vector containing possible estimates of <code class="reqn">rho</code>.
</p>
</td></tr>
<tr><td><code id="r.dist_+3A_n">n</code></td>
<td>

<p>Sample size, an integer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All distributions are standardized to have an area of one.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Kenney, J. F. and E. S. Keeping (1951) <em>Mathematics of Statistics, Pt. 2, 2nd ed</em>. Van Nostrand, Princeton, NJ. 
</p>
<p>Weisstein, E. W. (2012) Correlation Coefficient&ndash;Bivariate Normal Distribution. From MathWorld&ndash;A Wolfram Web Resource. <a href="http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html">http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html</a> 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># dev.new(height=3.5)
op &lt;- par(mfrow=c(1,2),mar=c (0,0,1.5,3), oma = c(5, 4.2, 0, 0))
vals &lt;- r.dist(0.9, seq(-1, 1, .001), 5)
plot(seq(-1, 1, .001), vals, type = "l",ylab = "", xlab = "")
vals &lt;- r.dist(0.5, seq(-1, 1, .001), 5)
lines(seq(-1, 1, .001), vals, lty = 2)
vals &lt;- r.dist(0.0, seq(-1, 1, .001), 5)
lines(seq(-1, 1, .001), vals, lty = 3)
legend("topleft", lty = c(1, 2, 3), title = expression(paste(italic(n)," = 5")), 
legend = c(expression(paste(rho, " = 0.9")),expression(paste(rho, " = 0.5")),
expression(paste(rho, " = 0"))),bty = "n") 

vals &lt;- r.dist(0.9, seq(-1, 1, .001), 30)
plot(seq(-1, 1, .001), vals, type = "l",xlab= "", ylab= "")
vals &lt;- r.dist(0.5, seq(-1, 1, .001), 30)
lines(seq(-1, 1, .001), vals, lty = 2)
vals &lt;- r.dist(0.0, seq(-1, 1, .001), 30)
lines(seq(-1, 1, .001), vals, lty = 3)
legend("topleft", lty = c(1, 2, 3), title = expression(paste(italic(n)," = 30")), 
legend = c(expression(paste(rho, " = 0.9")),expression(paste(rho, " = 0.5")),
expression(paste(rho, " = 0"))), bty = "n") 
mtext(side = 2, expression(paste(italic(f),"(",italic(r),")")), outer = TRUE, line = 3)
mtext(side = 1, expression(italic(r)), outer = TRUE, line = 3, at = .45)
par(op)
</code></pre>

<hr>
<h2 id='R.hat'>
R hat MCMC convergence statistic
</h2><span id='topic+R.hat'></span>

<h3>Description</h3>

<p>The degree of convergence of a random Markov Chain can be estimated using the Gelman-Rubin convergence statistic, <code class="reqn">\hat{R}</code>,
based on the stability of outcomes between and within <em>m</em> chains of the same length, <em>n</em>.       
Values close to one indicate convergence to the underlying distribution.  Values greater than 1.1 indicate inadequate convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
R.hat(M, burn.in = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="R.hat_+3A_m">M</code></td>
<td>

<p>An <em>n</em> x <em>m</em> numeric matrix of Markov Chains. 
</p>
</td></tr>
<tr><td><code id="R.hat_+3A_burn.in">burn.in</code></td>
<td>

<p>The proportion of each chains to be used as a burn in period.  The default value, 0.5, means that only the latter half of the chains will be used in computing <code class="reqn">\hat{R}</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Gelman et al. (2003, pg. 296) provides insufficient details to reproduce this function.  To get the real function see Gelman and Rubin (1992).  The authors list one other change in their Statlab version of this function.  They recommend multiplying <code>sqrt(postvar/W)</code> by <code>sqrt((df + 3)/t(df + 1))</code>. The original code and this function can produce estimates below 1.  
</p>


<h3>Author(s)</h3>

<p>Ken Aho and unknown StatLib author
</p>


<h3>References</h3>

<p>Gelman, A. and D. B. Rubin  (1992) <em>Inference from iterative simulation using multiple 
sequences (with discussion)</em>. Statistical Science, 7:457-511.
</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., and D. B. Rubin (2003)  <em>Bayesian Data Analysis, 2nd edition</em>.  Chapman and Hall/CRC.
</p>

<hr>
<h2 id='r.pb'>Percentage bend correlation</h2><span id='topic+r.pb'></span>

<h3>Description</h3>

<p>The percentage bend correlation is a robust alternative to Pearson's product moment correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.pb(X, Y, beta = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r.pb_+3A_x">X</code></td>
<td>
<p>A quantitative vector</p>
</td></tr>
<tr><td><code id="r.pb_+3A_y">Y</code></td>
<td>
<p>A second quantitative vector</p>
</td></tr>
<tr><td><code id="r.pb_+3A_beta">beta</code></td>
<td>
<p>Bend criterion</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The percentage bend correlation belongs to class of correlation measures which protect against marginal distribution (<em>X</em> and <em>Y</em>) outliers.  In this way it is similar to Kendall's <code class="reqn">\tau</code>, Spearman's <code class="reqn">\rho</code>, and biweight midcovariance.  A second class of robust correlation measures which take in to consideration the overall structure of the data (<em>O</em> estimators) are discussed by Wilcox (2005, pg. 389).  A value for the bend criterion <code>beta</code> is required in the <code>R.pb</code> function; <code>beta</code> = 0.2 is recommended by Wilcox (2005).
</p>


<h3>Value</h3>

<p>A dataframe with the correlation, test statistic and <em>P</em>-value for the null hypothesis of independence are returned.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Wilcox, R. R.  (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+r.bw">r.bw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-rnorm(100)
y&lt;-rnorm(100)
r.pb(x,y)
</code></pre>

<hr>
<h2 id='Rabino_CO2'>
CSIRO d13C-CO2 data from Rubino et al., A revised 1000 year atmospheric  13C-CO2 record from Law Dome and South Pole, Antarctica
</h2><span id='topic+Rabino_del13C'></span><span id='topic+Rabino_CO2'></span>

<h3>Description</h3>

<p>Rabino et al. (2013) provided: CSIRO <code class="reqn">\delta^{13}</code>C  and CO<code class="reqn">_2</code> measures covering 1000 years.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Rabino_CO2")</code></pre>


<h3>Format</h3>


<dl>
<dt><code>Sample.type</code></dt><dd><p>A factor with levels <code>firn</code> and <code>ice</code>.</p>
</dd>
<dt><code>depth</code></dt><dd><p>Depth of core (in meters).</p>
</dd>
<dt><code>effective.age</code></dt><dd><p>Age of CO<code class="reqn">_2</code> (in years AD).</p>
</dd>
<dt><code>d13C.CO2</code></dt><dd><p><code class="reqn">\delta^{13}</code>C (per mille).</p>
</dd>
<dt><code>CO2</code></dt><dd><p>CO<code class="reqn">_2</code> level (in ppm).</p>
</dd>
<dt><code>uncertainty</code></dt><dd><p>Uncertainty in measures (in ppm (CO<code class="reqn">_2</code>) or per mille (<code class="reqn">\delta^{13}</code>C)).</p>
</dd>
</dl>



<h3>Source</h3>

<p>Rubino, M., Etheridge, D. M., Trudinger, C. M., Allison, C. E., Battle, M. O., Langenfelds, R. L., ... &amp; Jenk, T. M. (2013). A revised 1000 year atmospheric <code class="reqn">\delta^{13}</code>C-CO<code class="reqn">_2</code> record from Law Dome and South Pole, Antarctica. <em>Journal of Geophysical Research: Atmospheres</em>, 118(15), 8482-8499
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Rabino_CO2)
data(Rabino_del13C)

op &lt;- par(mar=c(5,4.5,1,4.5))
with(Rabino_del13C, plot(effective.age, 
d13C.CO2, xlab = "Year", type='p', 
col = 1, pch = 21, bg = 'red', ylab = ''))
axis(2, col = 'red', col.axis = 'red')
mtext(side = 2, expression(paste(delta,' ','
'^13,'C  (per mille)')), col = 'red', 
line = 3, cex = 1.2)
par(new = TRUE)

with(Rabino_CO2, plot(effective.age, 
CO2, type='p', col=1,pch = 21, 
bg = 'blue', axes = FALSE, xlab = "", ylab = ""))
axis(4, col = 'blue', col.axis = 'blue')
mtext(side=4,expression(paste('Atmospheric ', 
CO[2], ' (ppm)')), 
line = 3, col = 'blue', cex = 1.2)
par(op)
</code></pre>

<hr>
<h2 id='rat'>
Rat glycogen data from Sokal and Rohlf (2012)
</h2><span id='topic+rat'></span>

<h3>Description</h3>

<p>This dataset from Sokal and Rohlf (2012) can be used to demonstrate pseudoreplication. Six rats were randomly given one of three treatments: &quot;control&quot;, &quot;compound 217&quot;, and &quot;compound 217 + sugar&quot;.  After a short period of time the rats were euthanized and the glycogen content of their livers was measured.  Two glycogen measurements were made for three different preparations of each liver.  Clearly the liver preparations and measurements on those preparations are nested in each rat, and are not independent. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rat)</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following 4 variables.
</p>

<dl>
<dt><code>glycogen</code></dt><dd><p>A numeric vector describing glycogen levels.  Units are arbitrary.</p>
</dd>
<dt><code>diet</code></dt><dd><p>Nutritional compound: 1 = &quot;control&quot;, 2 = &quot;compound 217&quot;, 3 = &quot;compound 217 + sugar&quot;.</p>
</dd>
<dt><code>rat</code></dt><dd><p>Rat animal number.</p>
</dd>
<dt><code>liver</code></dt><dd><p>Liver preparation.</p>
</dd>
<dt><code>measure</code></dt><dd><p>Measurement number.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sokal, R. R., and Rohlf, F. J. (2012)  <em>Biometry, 4th edition</em>.  W. H. Freeman and Co., New York. 
</p>

<hr>
<h2 id='refinery'>Refinery CO dataset</h2><span id='topic+refinery'></span>

<h3>Description</h3>

<p>In the early 1990s an oil refinery northeast of San Francisco agreed with local air quality regulators [the Bay Area Air Quality Management District (BAAQMD)] to reduce carbon monoxide emissions.  Baselines for reductions were to be based on measurements of CO made by refinery personnel, and by independent measurements from BAAQMD scientists for the roughly the same time period 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(refinery)</code></pre>


<h3>Format</h3>

<p>The dataframe contains three columns:
</p>

<dl>
<dt><code>CO</code></dt><dd><p>Carbon monoxide.  Measured in ppm.</p>
</dd>
<dt><code>Source</code></dt><dd><p>The source of measurements; either refinery or BAAQMD.</p>
</dd>
<dt><code>Date</code></dt><dd><p>Month/Day/Year</p>
</dd>
</dl>


<hr>
<h2 id='rinvchisq'>
Random draws from a scaled inverse chi-square distribution
</h2><span id='topic+rinvchisq'></span>

<h3>Description</h3>

<p>The distribution is an important component of Bayesian normal hierarchical models with uniform priors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
rinvchisq(n, df, scale = 1/df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rinvchisq_+3A_n">n</code></td>
<td>

<p>The number of random draws.
</p>
</td></tr>
<tr><td><code id="rinvchisq_+3A_df">df</code></td>
<td>

<p>Degrees of freedom parameter.
</p>
</td></tr>
<tr><td><code id="rinvchisq_+3A_scale">scale</code></td>
<td>

<p>Scale non-centrality parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Code based on a function with same name in package <span class="pkg">goeR</span>.
</p>


<h3>See Also</h3>

<p>The function is a wrapper for <code><a href="stats.html#topic+rchisq">rchisq</a></code>.</p>

<hr>
<h2 id='rmvm'>
A multivariate normal dataset for data mining
</h2><span id='topic+rmvm'></span>

<h3>Description</h3>

<p>Contains a <em>Y</em> variable constrained to be a random function of fifteen <em>X</em> variables, which, in turn, are generated from a multivariate normal distribution with no correlation between dimensions.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("rmvm")</code></pre>


<h3>Format</h3>

<p>A data frame with 500 observations on the following 16 variables.
</p>

<dl>
<dt><code>Y</code></dt><dd><p>A response vector defined to be: <code class="reqn">Y =  X_1 + X_2 + X_3 + X_4 + X_5 + X_6 + X_7 +
X_8 + X_9 + X_{10} + X_{11} + X_{12} + X_{13} + X_{14} + X_{15} + \epsilon</code> where <code class="reqn">\epsilon \sim N(0, 1)</code>.</p>
</dd>
<dt><code>X1</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X2</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X3</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X4</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X5</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X6</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X7</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X8</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X9</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X10</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X11</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X12</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X13</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X14</code></dt><dd><p>A random predictor</p>
</dd>
<dt><code>X15</code></dt><dd><p>A random predictor</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data used by Derryberry et al. (in review) to consider high dimensional model selection applications.  
</p>


<h3>References</h3>

<p>Derryberry, D., Aho, K., Peterson, T., Edwards, J.  (In review).  Finding the &quot;best&quot; second order regression model in a polynomial number of steps.  <em>American Statistician</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Code used to create data
## Not run: 
sigma &lt;- matrix(nrow = 15, ncol = 15, 0)
diag(sigma) = 1
mvn &lt;- rmvnorm(n=500, mean=rnorm(15), sigma=sigma)
Y &lt;- mvn[,1] + mvn[,2] + mvn[,3] + mvn[,4] + mvn[,4] + mvn[,5] + mvn[,6] + mvn[,7] +
mvn[,8] + mvn[,9] + mvn[,10] + mvn[,11] + mvn[,12] + mvn[,13] + mvn[,14] + mvn[15] + rnorm(500)
rmvm &lt;- data.frame(cbind(Y, mvn))
names(rmvm) &lt;- c("Y", paste("X", 1:15, sep = ""))

## End(Not run)
</code></pre>

<hr>
<h2 id='samp.dist'>Animated and/or snapshot representations of a statistic's sampling distribution</h2><span id='topic+samp.dist'></span><span id='topic+samp.dist.snap'></span><span id='topic+samp.dist.method.tck'></span><span id='topic+samp.dist.tck'></span><span id='topic+samp.dist.snap.tck1'></span><span id='topic+samp.dist.snap.tck2'></span><span id='topic+dirty.dist'></span><span id='topic+samp.dist.n'></span>

<h3>Description</h3>

<p>This help page describes a series of <span class="pkg">asbio</span> functions for depicting sampling distributions.  The function <code>samp.dist</code> samples from a parent distribution without replacement with sample size = <code>s.size</code>, 
<code>R</code> times.  At each iteration a statistic requested in <code>stat</code> is calculated. Thus a distribution of <code>R</code> statistic estimates is created.  
The function <code>samp.dist</code> shows this distribution as an animated <code>anim = TRUE</code> or non-animated <code>anim = FALSE</code> density histogram.   
Sampling distributions for up to four different statistics utilizing two different parent distributions are possible using <code>samp.dist</code>.  
Sampling distributions can be combined in various ways by specifying a function in <code>func</code> (see below). 
The function <code>samp.dist.n</code> was designed to show (with animation) how sampling distributions vary with sample size, and is still under development.  
The function <code>samp.dist.snap</code> creates snapshots, i.e. simultaneous views of a sampling distribution at particular sample sizes. 
The function <code>dirty.dist</code> can be used to create contaminated parent distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
samp.dist(parent = NULL, parent2 = NULL, biv.parent = NULL, s.size = 1, s.size2
 = NULL, R = 1000, nbreaks = 50, stat = mean, stat2 = NULL, stat3 = NULL, stat4 
 = NULL, xlab = expression(bar(x)), func = NULL, show.n = TRUE, show.SE = FALSE, 
 anim = TRUE, interval = 0.01, col.anim = "rainbow", digits = 3, ...)

samp.dist.snap(parent = NULL, parent2 = NULL, biv.parent = NULL, stat = mean, 
stat2 = NULL, stat3 = NULL, stat4 = NULL, s.size = c(1, 3, 6, 10, 20, 50), 
s.size2 = NULL, R = 1000, func = NULL, xlab = expression(bar(x)), 
show.SE = TRUE, fits = NULL, show.fits = TRUE, xlim = NULL, ylim = NULL, ...)

samp.dist.method.tck()

samp.dist.tck(statc = "mean")

samp.dist.snap.tck1(statc = "mean")

samp.dist.snap.tck2(statc = "mean")

dirty.dist(s.size, parent = expression(rnorm(1)), 
cont = expression(rnorm(1, mean = 10)), prop.cont = 0.1)

samp.dist.n(parent, R = 500, n.seq = seq(1, 30), stat = mean, xlab = expression(bar(x)), 
    nbreaks = 50, func = NULL, show.n = TRUE, 
    show.SE = FALSE, est.density = TRUE, col.density = 4, lwd.density = 2, 
    est.ylim = TRUE, ylim = NULL, anim = TRUE, interval = 0.5, 
    col.anim = NULL, digits = 3, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samp.dist_+3A_parent">parent</code></td>
<td>
<p>A vector or vector generating function, describing the parental distribution.  
Any collection of values can be used. When using random value generators for 
parental distributions, for CPU efficiency (and accuracy) one should use 
<code>parent = expression(rpdf(s.size, ...))</code>. Datasets exceeding 100000 observations are not recommended.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_parent2">parent2</code></td>
<td>
<p>An optional second parental distribution (see <code>parent</code> above), 
useful for the construction of sampling distributions of test statistics.  
When using random value generators use <code>parent2 = expression(rpdf(s.size2, ...))</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_biv.parent">biv.parent</code></td>
<td>
<p>A bivariate (two column) distribution.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_s.size">s.size</code></td>
<td>
<p>An integer defining sample size (or a vector of integers in the case of <code>samp.dist.snap</code>) to be taken at each of <code>R</code> iterations from the parental distribution.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_s.size2">s.size2</code></td>
<td>
<p>An optional integer defining a second sample size if a second statistic is to be calculated.  Again, this will be a vector of integers in the of <code>samp.dist.snap</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_r">R</code></td>
<td>
<p>The number of samples to be taken from parent distribution(s).</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_nbreaks">nbreaks</code></td>
<td>
<p>Number of breaks in the histogram.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_stat">stat</code></td>
<td>
<p>The statistic whose sampling distribution is to be represented.  Will work for any summary statistic that only requires a call to data; e.g. <code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+var">var</a></code>, <code><a href="stats.html#topic+median">median</a></code>, etc.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_stat2">stat2</code></td>
<td>
<p>An optional second statistic. Useful for conceptualizing sampling distributions of test statistics.  Calculated from sampling <code>parent2</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_stat3">stat3</code></td>
<td>
<p>An optional third statistic. The sampling distribution is created from the same sample data used for <code>stat</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_stat4">stat4</code></td>
<td>
<p>An optional fourth statistic. The sampling distribution is created from the same sample data used for <code>stat2</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_xlab">xlab</code></td>
<td>
<p><em>X</em>-axis label.</p>
</td></tr>  
<tr><td><code id="samp.dist_+3A_func">func</code></td>
<td>
<p>An optional function used to manipulate a sampling distribution or to combine the sampling distributions of two or more statistics.  
The function must contain the following arguments (although they needn't all be used in the function):  
<code>s.dist</code>, <code>s.dist2</code>, <code>s.size</code>, and <code>s.size2</code>.  When sampling from a 
single parent distribution use <code>s.dist3</code> in the place of <code>s.dist2</code>.  
For an estimator involving two parent distributions and four statistics, six arguments will be required: 
<code>s.dist</code>, <code>s.dist2</code>, <code>s.dist3</code>, <code>s.dist4</code>. 
<code>s.size</code>, and <code>s.size2</code> , <code>s.dist3</code>, and  as non-fixed arguments (see example below).</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_show.n">show.n</code></td>
<td>
<p>A logical command, <code>TRUE</code> indicates that sample size for <code>parent</code> will be displayed.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_show.se">show.SE</code></td>
<td>
<p>A logical command, <code>TRUE</code> indicates that bootstrap standard error for the statistic will be displayed.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_anim">anim</code></td>
<td>
<p>A logical command indicating whether or not animation should be used.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_interval">interval</code></td>
<td>
<p>Animation speed.  Decreasing <code>interval</code> increases speed.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_col.anim">col.anim</code></td>
<td>
<p>Color to be used in animation.  Three changing color palettes: <code><a href="grDevices.html#topic+rainbow">rainbow</a></code>, <code><a href="grDevices.html#topic+gray">gray</a></code>, <code><a href="grDevices.html#topic+heat.colors">heat.colors</a></code>, or &quot;fixed&quot; color types can be used.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_digits">digits</code></td>
<td>
<p>The number of digits to be displayed in the bootstrap standard error.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_fits">fits</code></td>
<td>
<p>Fitted distributions for <code>samp.dist.snap</code>  A function with two argument: <code>s.size</code> and <code>s.size2</code></p>
</td></tr> 
<tr><td><code id="samp.dist_+3A_show.fits">show.fits</code></td>
<td>
<p>Logical indicating whether or not fits should be shown (fits 
will not be shown if no fitting function is specified regardless of whether this is <code>TRUE</code> or <code>FALSE</code></p>
</td></tr>
<tr><td><code id="samp.dist_+3A_xlim">xlim</code></td>
<td>
<p>A two element numeric vector defining the upper and lower limits of the <em>X</em>-axis.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_ylim">ylim</code></td>
<td>
<p>A two element numeric vector defining the upper and lower limits of the <em>Y</em>-axis.</p>
</td></tr> 
<tr><td><code id="samp.dist_+3A_statc">statc</code></td>
<td>
<p>Presets for certain statistics.  Currently one of <code>"custom"</code>, <code>"mean"</code>, 
<code>"median"</code>, <code>"trimmed mean"</code>, <code>"Winsorized mean"</code>, 
<code>"Huber estimator"</code>, &quot;H-L estimator&quot;, <code>"sd"</code>, <code>"var"</code>, <code>"IQR"</code>,
<code>"MAD"</code>, <code>"(n-1)S^2/sigma^2"</code>, <code>"F*"</code>, <code>"t* (1 sample)"</code>,
<code>"t* (2 sample)"</code>, <code>"Pearson correlation"</code> or <code>"covariance"</code>.
</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_cont">cont</code></td>
<td>
<p>A distribution representing a source of contamination in the parent population.  Used by function <code>dirty.dist</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_prop.cont">prop.cont</code></td>
<td>
<p>The proportion of the parent distribution that is contaminated by <code>code</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_n.seq">n.seq</code></td>
<td>
<p>A range of sample sizes for <code>samp.dist.n</code></p>
</td></tr>
<tr><td><code id="samp.dist_+3A_est.density">est.density</code></td>
<td>
<p>A logical command for <code>samp.dist.n</code>. if <code>TRUE</code> then a density line is plotted over the histogram.  Only used if <code>fix.n = true</code>.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_col.density">col.density</code></td>
<td>
<p>The color of the density line for <code>samp.dist.n</code>.  See <code>est.density</code> above.</p>
</td></tr>
<tr><td><code id="samp.dist_+3A_lwd.density">lwd.density</code></td>
<td>
<p>The width of the density line for <code>samp.dist.n</code>.  See <code>est.density</code> above.</p>
</td></tr> 
<tr><td><code id="samp.dist_+3A_est.ylim">est.ylim</code></td>
<td>
<p>Logical.  If <code>TRUE</code> <em>Y</em>-axis limits are estimated logically for the animation in <code>samp.dist.n</code>.  Consistent <em>Y</em>-axis limits make animations easier to visualize.  Only used if <code>fix.n = TRUE</code>.</p>
</td></tr> 
<tr><td><code id="samp.dist_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="graphics.html#topic+plot.histogram">plot.histogram</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sampling distributions of individual statistics can be created with <code>samp.dist</code>, or the function can be used in more sophisticated ways, e.g. 
to create sampling distributions of ratios of statistics, i.e. <em>t</em>*, <em>F</em>* etc. (see examples below). To provide pedagogical clarity animation for figures is provided.    
To calculate bivariate statistics, specify the parent distribution with <code>biv.parent</code> and the statistic with <code>func</code> (see below). 
</p>
<p>Two general uses of the function <code>samp.dist</code> are possible.
1) One can demonstrate the accumulation of statistics for a single sample size using animation.  
This is useful because as more and more statistics are acquired the frequentist paradigm associated with sampling distributions becomes better represented (i.e the number of estimates is closer to infinity).  This is elucidated by allowing the default <code>fix.n = TRUE</code>.  Animation will be provided with the default <code>anim = TRUE</code>.  Up two parent distributions, up to two sample sizes, and up to four distinct statistics (i.e. four distinct sampling distributions, representing four distinct estimators) can be used.  The arguments <code>stat</code> and <code>stat3</code> will be drawn from <code>parent</code>, while <code>stat3</code> and <code>stat4</code> will be drawn from <code>parent2</code>.  These distributions can be manipulated and combined in an infinite number of ways with an auxiliary function called in the argument <code>func</code> (see examples below).  This allows depiction of sampling distributions made up of multiple estimators, e.g. test statistics.  
2) One can provide simultaneous snapshots of a sampling distribution at a particular sample size with the function <code>samp.dist.snap</code>. 
</p>
<p>Loading the package <span class="pkg">tcltk</span> allows use of the functions <code>samp.dist.tck</code>, <code>samp.dist.method.tck</code>, <code>samp.dist.snap.tck1</code> and <code>samp.dist.snap.tck2</code>, 
which provide interactive GUIs that run <code>samp.dist</code>.
</p>


<h3>Value</h3>

<p>Returns a representation of a statistic's sampling distribution in the form of a histogram.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##Central limit theorem
#Snapshots of four sample sizes.
samp.dist.snap(parent=expression(rexp(s.size)), s.size = c(1,5,10,50), R = 1000)

##sample mean animation
samp.dist(parent=expression(rexp(s.size)), col.anim="heat.colors", interval=.3)

##Distribution of t-statistics from a pooled variance t-test under valid and invalid assumptions
#valid
t.star&lt;-function(s.dist1, s.dist2, s.dist3, s.dist4, s.size = 6, s.size2 = 
s.size2){
MSE&lt;-(((s.size - 1) * s.dist3) + ((s.size2 - 1) * s.dist4))/(s.size + s.size2-2)
func.res &lt;- (s.dist1 - s.dist2)/(sqrt(MSE) * sqrt((1/s.size) + (1/s.size2)))
func.res}

samp.dist(parent = expression(rnorm(s.size)), parent2 = 
expression(rnorm(s.size2)), s.size=6, s.size2 = 6, R=1000, stat = mean, 
stat2 = mean, stat3 = var, stat4 = var, xlab = "t*", func = t.star)

curve(dt(x, 10), from = -6, to = 6, add = TRUE, lwd = 2)
legend("topleft", lwd = 2, col = 1, legend = "t(10)")

#invalid; same population means (null true) but different variances and other distributional 
#characteristics.
samp.dist(parent = expression(runif(s.size, min = 0, max = 2)), parent2 = 
expression(rexp(s.size2)), s.size=6, s.size2 = 6, R = 1000, stat = mean, 
stat2 = mean, stat3 = var, stat4 = var, xlab = "t*", func = t.star)

curve(dt(x, 10),from = -6, to = 6,add = TRUE, lwd = 2)
legend("topleft", lwd = 2, col = 1, legend = "t(10)")

## Pearson's R
require(mvtnorm)
BVN &lt;- function(s.size) rmvnorm(s.size, c(0, 0), sigma = matrix(ncol = 2, 
nrow = 2, data = c(1, 0, 0, 1)))
samp.dist(biv.parent = expression(BVN(s.size)), s.size = 20, func = cor, xlab = "r")
                                                  
#Interactive GUI, require package 'tcltk'
samp.dist.tck("S^2")
samp.dist.snap.tck1("Huber estimator")
samp.dist.snap.tck2("F*")

## End(Not run)
</code></pre>

<hr>
<h2 id='samp.dist.mech'>
Animated representation of sampling distribution basics
</h2><span id='topic+samp.dist.mech'></span><span id='topic+samp.dist.mech.tck'></span>

<h3>Description</h3>

<p>Mountain goats are randomly sampled 10 at a time and weighed [goat weights are normal <em>N</em>(90.5, 225)], a mean weight is calculated from these measures and added to collection of mean weights in the form of a histogram. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
samp.dist.mech(rep, int = 0.05)

samp.dist.mech.tck()

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samp.dist.mech_+3A_rep">rep</code></td>
<td>

<p>Number of samples.  Should not greatly exceed 100.
</p>
</td></tr>
<tr><td><code id="samp.dist.mech_+3A_int">int</code></td>
<td>
<p>The time interval for animation (in seconds).  Smaller intervals speed up animation</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Nice goat image from <a href="https://all-free-download.com/">https://all-free-download.com/</a> 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='savage'>
Mammalian BMR and biomass data from Savage et al. (2004)
</h2><span id='topic+savage'></span>

<h3>Description</h3>

<p>Compilation of mammalian BMR and biomass data from the large
data sets used in the studies of Hart (1971),
Heusner (1991), Lovegrove (2000, 2003) and White &amp;
Seymour (2003).  Data compiled by Savage (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("savage")</code></pre>


<h3>Format</h3>

<p>A data frame with 1006 observations on the following 9 variables.
</p>

<dl>
<dt><code>Order</code></dt><dd><p>Mammal order.</p>
</dd>
<dt><code>Family</code></dt><dd><p>Mammal family.</p>
</dd>
<dt><code>Species</code></dt><dd><p>Mammal genus and species.</p>
</dd>
<dt><code>Mass</code></dt><dd><p>Biomass in grams.</p>
</dd>
<dt><code>BMR</code></dt><dd><p>Basal metabolic rate in watts</p>
</dd>
<dt><code>AvgMass</code></dt><dd><p>Average mass, given multiple reports for a particular species.</p>
</dd>
<dt><code>AvgBMR</code></dt><dd><p>Average BMR, given multiple reports for a particular species.</p>
</dd>
<dt><code>References</code></dt><dd><p>Authorities from whom data were obtained.</p>
</dd>
<dt><code>Notes</code></dt><dd><p>Note concerning a repeated species name.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Savage, 548 V.M., Gillooly, J.F., Woodruff, W.H., West, G.B., Allen, A.P., Enquist, B.J., 
Brown, J.H. (2004) The predominance of quarter-power scaling in biology. <em>Functional 
Ecology</em>, 18, 257-282.
</p>


<h3>References</h3>

<p>Hart, J.S. (1971) <em>Rodents in Comparative Physiology of Thermoregulation</em>, Vol. II Mammals (ed. G.C. Whittow),
pp. 2-149. Academic Press, New York.
</p>
<p>Heusner, A.A. (1991) Size and power in mammals. <em>Journal of Experimental Biology</em> 160, 25-54.
</p>
<p>Lovegrove, B.G. (2000) The zoogeography of mammalian basal metabolic rate. <em>American Naturalist</em> 156, 201-219.
</p>
<p>Lovegrove, B.G. (2003) The influence of climate on the metabolic rate of small mammals: a slow-fast metabolic continuum.  <em>Journal of Comparative Physiology B</em> 173, 87-112.
</p>
<p>White, C.R. and Seymour, R.S. (2003) Mammalian basal metabolic rate is proportional to
584 body mass 2/3. <em>Proceedings of the National Academy of Sciences</em>, 100, 4046-4049.
</p>

<hr>
<h2 id='sc.twin'>Matched pairs schizophrenia data</h2><span id='topic+sc.twin'></span>

<h3>Description</h3>

<p>Scientists have long been concerned with identifying physiological characteristics which result in a disposition for schizophrenia.  Early studies suggested that the volume of particular brain regions of schizophrenic patients may differ from non-afflicted individuals.  However these studies often contained confounding variables (e.g. socioeconomic status, genetics) which obscured brain volume/ schizophrenia relationships (Ramsey and Schafer 1997).  To control for confounding variables Suddath et al. (1990) examined 15 pairs of monozygotic twins where one twin was schizophrenic and the other was not.  Twins were located from an intensive search throughout the United States and Canada.  The authors used magnetic resonance imaging to measure brain volume of particular regions in the twin's brains. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sc.twin)</code></pre>


<h3>Format</h3>

<p>The dataframe has 2 columns:
</p>

<dl>
<dt><code>unaffected</code></dt><dd><p>Left hippocampus volumes for unaffected twins.</p>
</dd>
<dt><code>affected</code></dt><dd><p>Left hippocampus volumes for affected twins.</p>
</dd>
</dl>


<hr>
<h2 id='se.jack'>
Jackknife standard error from a set of pseudovalues
</h2><span id='topic+se.jack'></span><span id='topic+se.jack1'></span>

<h3>Description</h3>

<p>Calculates the conventional jackknife standard error from a set of pseudovalues. The function <code>se.jack</code> provides Tukey's jackknife estimator.  The function <code>se.jack</code> provides a measure associated with first order jackknife estimates of species richness (Heltsche and Forester 1983).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
se.jack(x)


se.jack1(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="se.jack_+3A_x">x</code></td>
<td>

<p>A numeric vector of pseudovalue, for instance from function <code><a href="#topic+pseudo.v">pseudo.v</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Heltshe, J. F., and N. E. Forrester  (1983)  Estimating species richness using the jackknife procedure.  <em>Biometrics</em> 39: 1-12. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pseudo.v">pseudo.v</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>trag &lt;- c(59, 49, 75, 43, 94, 68, 77, 78, 63, 71, 31, 59, 53, 48, 65, 73, 50, 59, 50, 57)
p &lt;- pseudo.v(trag, statistic = mean)
se.jack(p[,2])
</code></pre>

<hr>
<h2 id='sedum.ts'>
CO2 exchange time series data 
</h2><span id='topic+sedum.ts'></span>

<h3>Description</h3>

<p>Gurevitch et al. (1986) demonstrated time series analysis with data describing change in CO<code class="reqn">_2</code> concentration of airstreams passing over a <em>Sedum wrightii</em> test plant.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sedum.ts)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 3 variables.
</p>

<dl>
<dt><code>exchange</code></dt><dd><p>CO<code class="reqn">_2</code> exchange, measured as: [change in CO<code class="reqn">_2</code> concentration (g/mg)]/ plant fresh mass (g).  Thus units are 1/mg.  
Positive values indicate net CO<code class="reqn">_2</code> uptake while negative values indicate net CO2 output. </p>
</dd>
<dt><code>time</code></dt><dd><p>A numeric vector indicating two hour intervals</p>
</dd>
<dt><code>treatment</code></dt><dd><p><code>Dry</code> = water withheld for several week, <code>Wet</code> = plant well watered.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gurevitch, J. and S. T. Chester, Jr  (1986)  Analysis of repeated measures experiments.  <em>Ecology</em> 67(1): 251-255.
</p>

<hr>
<h2 id='see.accPrec.tck'>
Interactive depiction of precision and accuracy
</h2><span id='topic+see.accPrec.tck'></span>

<h3>Description</h3>

<p>Slider GUI for examining the interaction of precision and accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.accPrec.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.ancova.tck'>
Visualize ANCOVA mechanics
</h2><span id='topic+see.ancova.tck'></span>

<h3>Description</h3>

<p>An interactive GUI to view ANCOVA meachnics.  Exp. power tries to simulate explanatory power in the concomitant variable.  It simply results in (1 - Exp. power) <code class="reqn">\times</code> Residual SE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.ancova.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.anova.tck'>
Interactive depiction of the ANOVA mechanism
</h2><span id='topic+see.anova.tck'></span>

<h3>Description</h3>

<p>Slider control of the means and (constant) variability of three factor level populations.  An ANOVA is run based on a random sample of these populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.anova.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.cor.range.tck'>
Depict the effect of range on correlation
</h2><span id='topic+see.cor.range.tck'></span>

<h3>Description</h3>

<p>Function interactively depicts the effect of the data range on association measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.cor.range.tck(sd = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="see.cor.range.tck_+3A_sd">sd</code></td>
<td>

<p>Amount of noise added to linear association.  Residuals around line pulled from a normal distribution centered at zero with this standard deviation.  
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Based on a figure from <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">https://en.wikipedia.org/wiki/Correlation_and_dependence</a>
</p>

<hr>
<h2 id='see.exppower.tck'>
Visualize exponential power functions
</h2><span id='topic+see.exppower.tck'></span>

<h3>Description</h3>

<p>Visualize exponential power functions, including a Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.exppower.tck()
</code></pre>


<h3>Details</h3>

<p>The normal distribution and Gaussian distribution are based on an exponential power function:
</p>
<p style="text-align: center;"><code class="reqn">f(x)=exp(-|x|^{m})</code>
</p>

<p>Letting <code class="reqn">m = 2</code> results in a Gaussian distribution.  Standardizing this so that the area under the curve = 1 results in the standard normal distribution. 
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+book.menu">book.menu</a></code>
</p>

<hr>
<h2 id='see.HW'>
Visualize the Hardy Weinberg equilibrium
</h2><span id='topic+see.HW'></span><span id='topic+see.HW.tck'></span>

<h3>Description</h3>

<p>Allows interactive depiction of the Hardy Weinberg equilibrium.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.HW(parg)
see.HW.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="see.HW_+3A_parg">parg</code></td>
<td>
<p>Proportion of the allele <em>p</em> in the population, i.e. a number between 0 and 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves and depicts the Hardy Weinberg equilibrium, i.e:
</p>
<p style="text-align: center;"><code class="reqn">pp + 2pq + qq = 1</code>
</p>



<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.lma.tck'>
ANOVA linear models
</h2><span id='topic+see.lma.tck'></span>

<h3>Description</h3>

<p>Derives ANOVA linear model using matrix algebra
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.lma.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.lmr.tck'>
Regression linear model derivation from linear algebra
</h2><span id='topic+see.lmr.tck'></span><span id='topic+pm1'></span>

<h3>Description</h3>

<p>Given Y and X matrices a regression linear model is demonstrated using matrix algebra.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.lmr.tck()
pm1(Y, X, sz=1, showXY = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="see.lmr.tck_+3A_y">Y</code></td>
<td>

<p>Response variable
</p>
</td></tr>
<tr><td><code id="see.lmr.tck_+3A_x">X</code></td>
<td>

<p>Explanatory variables
</p>
</td></tr>
<tr><td><code id="see.lmr.tck_+3A_sz">sz</code></td>
<td>

<p>Text expansion factor
</p>
</td></tr>
<tr><td><code id="see.lmr.tck_+3A_showxy">showXY</code></td>
<td>

<p>Logical, indicating whether or not <em>X</em> and <em>Y</em> matrices should be shown.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>X</em> requires a <em>Y</em> intercept variable <code class="reqn">X_0</code> and at least one other variable.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code></p>

<hr>
<h2 id='see.lmu.tck'>
Unbalanced and balanced linear models
</h2><span id='topic+see.lmu.tck'></span><span id='topic+pm'></span>

<h3>Description</h3>

<p>The default design is balanced, as a result Type I = Type II = Type III SS.  A student can then delete one or more Y responses, and corresponding X responses to see create an unbalanced design.  Now the types of SS will no longer be equal.  Furthermore, the order that X1 and X2 are specified will now matter in the case of Type I SS, although it will not matter for type II and III SS. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.lmu.tck()

pm(Y, X1, X2, X1X2, change.order = FALSE, delete = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="see.lmu.tck_+3A_y">Y</code></td>
<td>
<p>Response variable.</p>
</td></tr>
<tr><td><code id="see.lmu.tck_+3A_x1">X1</code></td>
<td>

<p>First column in design matrix with effect coding.
</p>
</td></tr>
<tr><td><code id="see.lmu.tck_+3A_x2">X2</code></td>
<td>

<p>Second column in design matrix.   
</p>
</td></tr>
<tr><td><code id="see.lmu.tck_+3A_x1x2">X1X2</code></td>
<td>

<p>An interaction column.  The product of design matrix columns one and two
</p>
</td></tr>
<tr><td><code id="see.lmu.tck_+3A_change.order">change.order</code></td>
<td>

<p>A logical command specifying whether or not the order of <code>X1</code> and <code>X2</code> should changed in the model specification.
</p>
</td></tr>
<tr><td><code id="see.lmu.tck_+3A_delete">delete</code></td>
<td>

<p>when <code>delete != 0</code> an observation number to be deleted.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(interactive()){
if(any(names(sessionInfo()$otherPkgs)=="asbio")) vignette(package = "asbio", "typeISS_key")
}
</code></pre>

<hr>
<h2 id='see.logic'>
Interactive worksheet for logical and fallacious arguments
</h2><span id='topic+see.logic'></span>

<h3>Description</h3>

<p>It is vital that scientists understand what logical and fallacious arguments are.  This worksheet provides a pedagogical tool for considering logic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.logic()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Salmon, W (1963) <em>Logic</em>.  Prentice-Hall
</p>


<h3>See Also</h3>

<p><code><a href="#topic+book.menu">book.menu</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
see.logic()

## End(Not run)
</code></pre>

<hr>
<h2 id='see.M'>Visualization of the M-estimation function
</h2><span id='topic+see.M'></span>

<h3>Description</h3>

<p>The function provides interactive visualization of robust <em>M</em> estimation of location.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.M()
</code></pre>


<h3>Details</h3>

<p>The value <em>c</em> = 1.28 gives 95 percent efficiency of the mean given normality.  The sample median and mean can be considered special cases of <em>M</em>-estimators.  The value <em>c</em> = 0 provides the sample median, while the value, <code class="reqn">c = \infty</code> gives the sample mean.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Wilcox, R. R. (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+huber.mu">huber.mu</a></code>, <code><a href="#topic+huber.NR">huber.NR</a></code>
</p>

<hr>
<h2 id='see.mixedII'>
Depiction of the effect of random level selection on inferences concerning fixed effects
</h2><span id='topic+see.mixedII'></span>

<h3>Description</h3>

<p>The levels for a fixed factor are shown in rows, while the columns are levels for a random factor.  
Thus, the table depicts a mixed model.  Assume that the values in the table are population means.  
For instance, the true mean of random level R1 for the fixed level F1 is 1.  Using information from all random factor levels, 
the null hypothesis for the fixed factor is true.  That is, <code class="reqn">\mu_{F1} = \mu_{F2} = \mu_{F3}</code>.  
However when we select a subset of random levels, this is obscured.  In fact, for any subset of random factor levels it appears as if there is evidence against H<code class="reqn">_0</code>, 
i.e. there appears to be variability among the fixed factor level means.  
Thus, to avoid inflation of type I error (rejection of a true null hypothesis) 
we must consider the interaction of the random and fixed factors when considering inference for the fixed factor level populations.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.mixedII()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho, thanks to Ernest Keeley 
</p>


<h3>References</h3>

<p>Maxwell, S. E., and H. D. Delaney (2003) <em>Designing Experiments and Analyzing Data: A Model Comparison Perspective, 2nd edition</em>. Routledge Academic.
</p>

<hr>
<h2 id='see.mnom.tck'>
Interactive depiction of the multinomial distribution
</h2><span id='topic+see.mnom.tck'></span>

<h3>Description</h3>

<p>tcltk GUI representation of the multinomial in a simple (binomial) context. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.mnom.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.move'>
Interactive visualization of least squares regression.  
</h2><span id='topic+see.move'></span><span id='topic+see.adddel'></span>

<h3>Description</h3>

<p>Scatterplot points can be moved with <code>see.move</code>, while points can be added and deleted with <code>see.adddel</code>. The function <code>see.move</code> is an appropriation from <span class="pkg">tcltk</span> demos, with a few bells and whistles added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.move()
see.adddel()
</code></pre>


<h3>Author(s)</h3>

<p>the R Development Core Team for <code>see.move</code>, Ken Aho for <code>see.adddel</code>. 
</p>

<hr>
<h2 id='see.nlm'>
Visualize important non-linear functions
</h2><span id='topic+see.nlm'></span>

<h3>Description</h3>

<p>A number of important equation forms require that their parameters be estimated using the non-linear least squares.  Here are six.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.nlm()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Crawley, M. J.  (2007)  <em>The R Book</em>.  Wiley.
</p>

<hr>
<h2 id='see.norm.tck'>Visualize pdfs</h2><span id='topic+see.normcdf.tck'></span><span id='topic+see.beta.tck'></span><span id='topic+see.betacdf.tck'></span><span id='topic+see.bin.tck'></span><span id='topic+see.bincdf.tck'></span><span id='topic+see.chi.tck'></span><span id='topic+see.chicdf.tck'></span><span id='topic+see.disc.unif.tck'></span><span id='topic+see.disc.unifcdf.tck'></span><span id='topic+see.exp.tck'></span><span id='topic+see.expcdf.tck'></span><span id='topic+see.F.tck'></span><span id='topic+see.Fcdf.tck'></span><span id='topic+see.gam.tck'></span><span id='topic+see.gamcdf.tck'></span><span id='topic+see.geo.tck'></span><span id='topic+see.geocdf.tck'></span><span id='topic+see.hyper.tck'></span><span id='topic+see.hypercdf.tck'></span><span id='topic+see.logis.tck'></span><span id='topic+see.logiscdf.tck'></span><span id='topic+see.lnorm.tck'></span><span id='topic+see.lnormcdf.tck'></span><span id='topic+see.nbin.tck'></span><span id='topic+see.nbincdf.tck'></span><span id='topic+see.norm.tck'></span><span id='topic+see.pois.tck'></span><span id='topic+see.poiscdf.tck'></span><span id='topic+see.t.tck'></span><span id='topic+see.tcdf.tck'></span><span id='topic+see.unif.tck'></span><span id='topic+see.unifcdf.tck'></span><span id='topic+see.weib.tck'></span><span id='topic+see.weibcdf.tck'></span><span id='topic+see.pdfdriver.tck'></span><span id='topic+see.pdfdriver'></span>

<h3>Description</h3>

<p>Interactive GUIs for visualizing how distributions change with changing values of pdf parameters, e.g. <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>.  The basic ideas here are lifted largely from a clever function from Greg Snow's package <span class="pkg">TeachingDemos</span>. The functions <code>see.pdfdriver.tck</code> and <code>see.pdfdriver</code> are <span class="pkg">tcltk</span> utility functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.norm.tck()
see.normcdf.tck()
see.beta.tck()
see.betacdf.tck()
see.bin.tck()
see.bincdf.tck()
see.chi.tck()
see.chicdf.tck()
see.disc.unif.tck()
see.disc.unifcdf.tck()
see.exp.tck()
see.expcdf.tck()
see.F.tck()
see.Fcdf.tck()
see.gam.tck()
see.gamcdf.tck()
see.geo.tck()
see.geocdf.tck()
see.hyper.tck()
see.hypercdf.tck()
see.logis.tck()
see.logiscdf.tck()
see.nbin.tck()
see.nbincdf.tck()
see.lnorm.tck()
see.lnormcdf.tck()
see.pois.tck()
see.poiscdf.tck()
see.t.tck()
see.tcdf.tck()
see.unif.tck()
see.unifcdf.tck()
see.weib.tck()
see.weibcdf.tck()
see.pdfdriver.tck()
see.pdfdriver(pdf, show.cdf = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="see.norm.tck_+3A_pdf">pdf</code></td>
<td>
<p>Name of probability density function</p>
</td></tr>
<tr><td><code id="see.norm.tck_+3A_show.cdf">show.cdf</code></td>
<td>
<p>Logical, indicating whether or not the cumulative distribution function should be shown.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
see.norm.tck()

## End(Not run)
</code></pre>

<hr>
<h2 id='see.power'>
Interactive depiction of type I and type II error and power
</h2><span id='topic+see.power'></span><span id='topic+see.power.tck'></span>

<h3>Description</h3>

<p>Provides an interactive pedagogical display of power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.power(alpha = NULL, sigma = NULL, n = NULL, effect = NULL,
test = "lower", xlim = c(-3, 3), strict = FALSE)

see.power.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="see.power_+3A_alpha">alpha</code></td>
<td>
<p>Type I error.
</p>
</td></tr>
<tr><td><code id="see.power_+3A_sigma">sigma</code></td>
<td>
<p>Standard deviation of underlying population.
</p>
</td></tr>
<tr><td><code id="see.power_+3A_n">n</code></td>
<td>

<p>sample size
</p>
</td></tr>
<tr><td><code id="see.power_+3A_effect">effect</code></td>
<td>

<p>Effect size
</p>
</td></tr>
<tr><td><code id="see.power_+3A_test">test</code></td>
<td>

<p>Type of test, one of <code>c("lower","upper","two")</code>.
</p>
</td></tr>
<tr><td><code id="see.power_+3A_xlim">xlim</code></td>
<td>

<p><em>X</em>-axis limits
</p>
</td></tr>
<tr><td><code id="see.power_+3A_strict">strict</code></td>
<td>
<p>Causes the function to use a strict interpretation of power in a two-sided test.  If <code>strict = TRUE</code>
then power for a two sided test will include the probability of rejection in the opposite tail of the true effect. If <code>strict = FALSE</code>
(the default) power will be half the value of <code class="reqn">\alpha</code> if the true effect size is zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>see.power</code> provides an interactive display of power.  The function <code>see.power.tck</code> provides a <span class="pkg">tcltk</span> GUI to manipulate <code>see.power</code>.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.rEffect.tck'>
Visualize random effects model
</h2><span id='topic+see.rEffect.tck'></span><span id='topic+r.eff'></span>

<h3>Description</h3>

<p>An experiment to ascertain the effect of two randomly selected brands of soil fertilizer 
on wheat yield.  In the upper figure two brands of fertilizer (1 and 2) 
are randomly chosen from a population of potential choices.  The mean yields produced by the 
population of fertilizers <code class="reqn">E(Y|A_i)</code> are normally distributed.  That is, it is possible to 
select a factor level that will result in very small average yields, or one that will 
result in large average yields, but it is more likely that a chosen factor level will 
produce some intermediate average effect.  We proceed with the experiment by assigning two 
experimental units (two wheat fields) to each fertilizer.  We assume that the yield of 
fields is normally distributed for each fertilizer, and furthermore that the factor 
levels are homoscedastic. We weigh our evidence against the H<code class="reqn">_0</code> of a non-zero population variance by estimating the 
variability among factor levels.  The more that yield varies with respect to nutrient treatments the more evidence we will have against H<code class="reqn">_0</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.rEffect.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.regression.tck'>
Demonstration of regression mechanics
</h2><span id='topic+see.regression.tck'></span>

<h3>Description</h3>

<p>Population and sample regression lines are interactively depicted.  The same random observations generated by the true error distribution is used for both models. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.regression.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.roc.tck'>
Interactive depiction of ROC curves
</h2><span id='topic+see.roc.tck'></span>

<h3>Description</h3>

<p>Sliders allow users to change distinctness of dichotomous classes (success and failure).  
This will affect the ROC curve.  One can also change the criteria defining what constitutes a success.  
While this will not change the ROC curve (which compares true positive and false negative rates at all possible success cutoff), 
it The will change empirical rates of true positives, true negatives, false positives, and false negatives given the defined cutoff.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'> see.roc.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho, inspired by a graphical demo at 
<a href="http://www.anaesthetist.com/mnm/stats/roc/Findex.htm">http://www.anaesthetist.com/mnm/stats/roc/Findex.htm</a> 
</p>

<hr>
<h2 id='see.smooth.tck'>
Interactive smoother demonstrations
</h2><span id='topic+see.smooth.tck'></span>

<h3>Description</h3>

<p>LOWESS, kernel, and spline smoothers are depicted, using <span class="pkg">tcltk</span> widgets.</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.smooth.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho, appropriated ideas from demo in library <span class="pkg">tcltk</span>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+loess">loess</a></code>, <code><a href="stats.html#topic+ksmooth">ksmooth</a></code>, <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>
</p>

<hr>
<h2 id='see.ttest.tck'>
Visualize t-tests
</h2><span id='topic+see.ttest.tck'></span>

<h3>Description</h3>

<p>Interactive GUI for demonstrating <em>t</em>-tests
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
see.ttest.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='see.typeI_II'>
Interactive depiction of type I and II error
</h2><span id='topic+see.typeI_II'></span>

<h3>Description</h3>

<p>The function provides a <span class="pkg">tcltk</span> GUI illustrating type I, type II error, and power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>see.typeI_II()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+see.power">see.power</a></code>,<code><a href="#topic+power.z.test">power.z.test</a></code>
</p>

<hr>
<h2 id='selftest.se.tck1'>
Interactive self-testing questions
</h2><span id='topic+selftest.ANVOVA_design.tck'></span><span id='topic+selftest.ANOVAsiminf.tck1'></span><span id='topic+selftest.ANOVAmixed.tck1'></span><span id='topic+selftest.ANVOVA_design_review.tck'></span><span id='topic+selftest.corr.tck1'></span><span id='topic+selftest.conf.tck1'></span><span id='topic+selftest.bayes4.tck'></span><span id='topic+selftest.bayes5.tck'></span><span id='topic+selftest.H0.tck'></span><span id='topic+selftest.jack.tck'></span><span id='topic+selftest.ML_OLS.tck'></span><span id='topic+selftest.nonparametric6.tck'></span><span id='topic+selftest.pdfs.tck'></span><span id='topic+selftest.prob.tck'></span><span id='topic+selftest.regGLM.tck1'></span><span id='topic+selftest.regchar.tck1'></span><span id='topic+selftest.regdiag.tck1'></span><span id='topic+selftest.regdiag.tck2'></span><span id='topic+selftest.regdiag.tck3'></span><span id='topic+selftest.regapproaches.tck1'></span><span id='topic+selftest.regapproaches.tck2'></span><span id='topic+selftest.regapproaches.tck3'></span><span id='topic+selftest.regapproaches.tck4'></span><span id='topic+selftest.sampd.tck1'></span><span id='topic+selftest.science.tck1'></span><span id='topic+selftest.se.tck1'></span><span id='topic+selftest.stats.tck'></span><span id='topic+selftest.stats.tck1'></span><span id='topic+selftest.ttest.tck'></span><span id='topic+selftest.codettest.tck'></span><span id='topic+selftest.typeIISS.tck1'></span>

<h3>Description</h3>

<p>These functions provide interactive multiple-choice questions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selftest.se.tck1()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>

<hr>
<h2 id='Semiconductor'>Split plot computer chip data from Littell et al. (2006)</h2><span id='topic+Semiconductor'></span>

<h3>Description</h3>

<p>Littell et al. (2006) use the data here to introduce analysis of split plot 
designs using mixed models.  Twelve silicon wafers were randomly selected from 
a lot, and were randomly assigned to four different processing modes.  
Resistance on the chips was measured in four different positions (four different 
chips) on each wafer.  Mode of processing and position of chips were fixed 
factors, while wafer was a random effect.    The experimental units with respect 
to process are the wafers.  The experimental units with respect to position 
are individual chips.  Thus the wafer is the whole plot, whereas the positions 
(chips) are split plot units 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Semiconductor)</code></pre>


<h3>Format</h3>

<p>The dataframe contains four columns:
</p>

<dl>
<dt><code>Resistance</code></dt><dd><p>The response variable of interest.  Measured in ohms.</p>
</dd>
<dt><code>Process</code></dt><dd><p>The explanatory variable of interest.  The type of process used to create the computer chips.  A factor with 4 levels.</p>
</dd>
<dt><code>Wafer</code></dt><dd><p>The whole plot containing four chips.  There were four wafers tested, i.e. four levels, <code>1,2,3,4</code>.</p>
</dd>
<dt><code>Chip</code></dt><dd><p>Position on the wafer.  These are split plots within the whole plots.  Four levels: <code>1,2,3,4</code>.</p>
</dd>   
</dl>



<h3>Source</h3>

<p>Littell, R. C., Milliken, G. A., Stroup, W. W., Wolfinger, R. D., and O. Schabenberger  
(2006)  <em>SAS for Mixed Models 2nd ed</em>.  SAS press.
</p>

<hr>
<h2 id='SexDeterm'>
Fern environmental sex determination data
</h2><span id='topic+SexDeterm'></span>

<h3>Description</h3>

<p>Sex determination (male and female) data at ecologically relevant glucose, N, and P concentrations and stoichiometries, at both ambient and elevated levels of CO<code class="reqn">_2</code>. The term &quot;ameristic&quot; denotes gametophytes with only male gametangia, while the term &quot;meristic&quot; refers to gametophytes with female or female and male gametangia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SexDeterm")</code></pre>


<h3>Format</h3>

<p>A data frame with 156 observations on the following 11 variables.
</p>

<dl>
<dt><code>CO2.Level</code></dt><dd><p>a factor with levels <code>Ambient</code> <code>Elevated</code> CO2 levels</p>
</dd>
<dt><code>Block</code></dt><dd><p>a numeric vector, the elevated CO2 experiment was completed in 2 blocks</p>
</dd>
<dt><code>Glucose.Level</code></dt><dd><p>the number of C atoms relative to the number of P atoms, with 5 indicating the presence of 6 micromolar glucose and 0 indicating the absence of glucose in the growth media</p>
</dd>
<dt><code>N.Level</code></dt><dd><p>the number of N atoms relative to the number of P atoms</p>
</dd>
<dt><code>P.Level</code></dt><dd><p>the number of P atoms relative to the number of N atoms</p>
</dd>
<dt><code>C.N.P</code></dt><dd><p>the ratio of C to N to P atoms, a factor with levels <code>1:1</code> <code>1:2</code> <code>1:3</code> <code>1:4</code> <code>16:1</code> <code>16:2</code> <code>16:3</code> <code>16:4</code> <code>32:1</code> <code>32:2</code> <code>32:3</code> <code>32:4</code> <code>48:1</code> <code>48:2</code> <code>48:3</code> <code>48:4</code> <code>5:1:1</code> <code>5:1:2</code> <code>5:1:3</code> <code>5:1:4</code> <code>5:16:1</code> <code>5:16:2</code> <code>5:16:3</code> <code>5:16:4</code> <code>5:32:1</code> <code>5:32:2</code> <code>5:32:3</code> <code>5:32:4</code> <code>5:48:1</code> <code>5:48:2</code> <code>5:48:3</code> <code>5:48:4</code></p>
</dd>
<dt><code>Total.Gametophyte.No.</code></dt><dd><p>the total number of gametophytes in each population</p>
</dd>
<dt><code>No..of.Ameristic.Gametophytes</code></dt><dd><p>the number of ameristic (male) gametophytes in each gametophyte population</p>
</dd>
<dt><code>No..of.Meristic.Gametophytes</code></dt><dd><p>the number of meristic (female and hermaphrodite) gametophytes in each gametophyte population</p>
</dd>
<dt><code>Ameristic.Meristic.Ratio</code></dt><dd><p>the ratio of ameristic gametophytes to meristic gametophytes (sex ratio)</p>
</dd>
<dt><code>Pct..Ameristic.Gametophytes</code></dt><dd><p>the percentage of ameristic gametophytes per total gametophyte population</p>
</dd>
</dl>



<h3>References</h3>

<p>Goodnoe, T. T., Hill, J. P., Aho, K. (2016)  Effects of variation in carbon, nitrogen and phosphorous molarity and stoichiometry on sex determination in the fern <em>Ceratopteris richardii</em>.  <em>Botany</em> 94(4): 249-259.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SexDeterm)
</code></pre>

<hr>
<h2 id='shad'>
American gizzard shad data
</h2><span id='topic+shad'></span>

<h3>Description</h3>

<p>Hollander and Wolfe (1999) describe young of year lengths at four sites for American gizzard shad, <em>Dorosoma cepedianum</em>, a fish of the herring family. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(shad)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 2 variables.
</p>

<dl>
<dt><code>length</code></dt><dd><p>Fish length in cm</p>
</dd>
<dt><code>site</code></dt><dd><p>a factor with levels <code>I</code> <code>II</code> <code>III</code> <code>IV</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Hollander, M., and  D. A. Wolfe  (1999) <em>Nonparametric Statistical Methods</em>. New York: John Wiley &amp; Sons. 
</p>

<hr>
<h2 id='shade.norm'>Shading functions for interpretation of pdf probabilities.
</h2><span id='topic+shade'></span><span id='topic+shade.norm'></span><span id='topic+shade.t'></span><span id='topic+shade.F'></span><span id='topic+shade.chi'></span><span id='topic+shade.bin'></span><span id='topic+shade.poi'></span><span id='topic+shade.wei'></span>

<h3>Description</h3>

<p>Creates plots with lower, upper, two-tailed, and middle of the distribution shading for popular pdfs. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
shade.norm(x = NULL, from = NULL, to = NULL, sigma = 1, mu = 0,
tail = "lower", show.p = TRUE, show.d = FALSE, show.dist = TRUE, digits = 5,
legend.cex = .9, shade.col="gray",...)

shade.t(x = NULL, from = NULL, to = NULL, nu = 3, tail = "lower", 
show.p = TRUE, show.d = FALSE, show.dist = TRUE, digits = 5,legend.cex = .9, 
shade.col="gray",...)

shade.F(x = NULL, from = NULL, to = NULL, nu1 = 1, nu2 = 5, 
tail = "lower", show.p = TRUE, show.d = FALSE, show.dist = TRUE, 
prob.to.each.tail = 0.025, digits = 5, legend.cex = .9,shade.col="gray",...)

shade.chi(x = NULL, from = NULL, to = NULL, nu = 1, tail = "lower", 
show.p = TRUE, show.d = FALSE, show.dist = TRUE, prob.to.each.tail = 0.025, 
digits = 5,legend.cex = .9,shade.col="gray",...)

shade.bin(x=NULL,from=NULL,to=NULL,n=1,p=0.5,tail="X=x",show.p=TRUE,
show.dist=TRUE, show.d=FALSE,legend.cex = .9,digits=5, ...)

shade.poi(x=NULL,from=NULL,to=NULL,lambda=5,tail="X=x",show.p=TRUE,
show.dist=TRUE, show.d=FALSE,legend.cex = .9,digits=5, ...)

shade.wei(x = NULL, from = NULL, to = NULL, theta = 1, beta = 1, tail = "lower", 
show.p = TRUE, show.d = FALSE, show.dist = TRUE, prob.to.each.tail = 0.025, 
digits = 5, legend.cex = 0.9, shade.col = "gray", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shade.norm_+3A_x">x</code></td>
<td>

<p>A quantile, i.e. <code class="reqn">X = x</code>, or if <code>tail = "two.custom"</code> ins <code>shade.norm</code>, a two element vector specifying the upper bound of the lower tail and the lower bound of the upper tail. 
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_from">from</code></td>
<td>

<p>To be used with <code>tail = "middle"</code>; the value <em>a</em> in <code class="reqn">P(a &lt; X &lt; b)</code>. 
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_to">to</code></td>
<td>

<p>To be used with <code>tail = "middle"</code>; the value <em>b</em> in <code class="reqn">P(a &lt; X &lt; b)</code>. 
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_sigma">sigma</code></td>
<td>

<p>Standard deviation for the nomral distribution.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_mu">mu</code></td>
<td>

<p>Mean of the normal distribution.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_tail">tail</code></td>
<td>

<p>One of four possibilities: <code>"lower"</code> provides lower tail shading, <code>"upper"</code> provides upper tail shading, <code>"two"</code> provides two tail shading, and <code>"middle"</code> provide shading in the middle of the pdf, between <code>"from"</code> and <code>"to"</code>.  The additional option <code>"two.custom"</code> is allowed for <code>shade.norm</code> and <code>shade.t</code>. This allows calculation of asymmetric two tailed probabilities.  It requires that the argument <code>x</code> is a two element vector with elements denoting the upper bound of the lower tail and the lower bound of the upper tail.  For discrete pdfs (binomial and Poisson) the possibility <code>"X=x"</code> is also allowed, and will be equivalent to the density. Two tailed probability is not implemented for <code>shade.poi</code>.  
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_show.p">show.p</code></td>
<td>

<p>Logical; indicating whether probabilities are to be shown.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_show.d">show.d</code></td>
<td>

<p>Logical; indicating whether densities are to be shown.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_show.dist">show.dist</code></td>
<td>

<p>Logical; indicating whether parameters for the distribution are to be shown.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_nu">nu</code></td>
<td>

<p>Degrees of freedom.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_nu1">nu1</code></td>
<td>

<p>Numerator degrees of freedom for the <em>F</em>-distribution.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_nu2">nu2</code></td>
<td>

<p>Denominator degrees of freedom for the <em>F</em>-distribution.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_prob.to.each.tail">prob.to.each.tail</code></td>
<td>

<p>Probability to be apportioned to each tail in the <em>F</em> and Chi-square distributions if <code>tail = "two"</code>.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_digits">digits</code></td>
<td>

<p>Number of digits to be reported in probsabilities and densities.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_n">n</code></td>
<td>

<p>The number of trials for the binomial pdf.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_p">p</code></td>
<td>

<p>The binomial probability of success.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_lambda">lambda</code></td>
<td>

<p>The Poisson parameter (i.e. rate).
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_legend.cex">legend.cex</code></td>
<td>

<p>Character expansion for legends in plots.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_shade.col">shade.col</code></td>
<td>

<p>Color of probability shading.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_theta">theta</code></td>
<td>

<p>Pdf parameter.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_beta">beta</code></td>
<td>

<p>Pdf parameter.
</p>
</td></tr>
<tr><td><code id="shade.norm_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot with the requested pdf and probability shading.
</p>


<h3>Note</h3>

<p>Lower-tailed chi-squared probabilities are not plotted correctly for df &lt; 3.  
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##normal
shade.norm(x=1.2,sigma=1,mu=0,tail="lower")
shade.norm(x=1.2,sigma=1,mu=0,tail="upper")
shade.norm(x=1.2,sigma=1,mu=0,tail="two")
shade.norm(from=-.4,to=0,sigma=1,mu=0,tail="middle")
shade.norm(from=0,to=0,sigma=1,mu=0,tail="middle")
shade.norm(x=c(-0.2, 2),sigma=1,mu=0,tail="two.custom")

##t
shade.t(x=-1,nu=5,tail="lower")
shade.t(x=-1,nu=5,tail="upper")
shade.t(x=-1,nu=5,tail="two")
shade.t(from=.5,to=.7,nu=5,tail="middle")
                                                                                        
##F
shade.F(x=2,nu1=15,nu2=8,tail="lower")
shade.F(x=2,nu1=15,nu2=8,tail="upper")
shade.F(nu1=15,nu2=8,tail="two",prob.to.each.tail=0.025)
shade.F(from=.5,to=.7,nu1=15,nu2=10,tail="middle")

##Chi.sq
shade.chi(x=2,nu=5,tail="lower")
shade.chi(x=2,nu=5,tail="upper")
shade.chi(nu=7,tail="two",prob.to.each.tail=0.025)
shade.chi(from=.5,to=.7,nu=5,tail="middle")

##binomial
shade.bin(x=5,n=20,tail="X=x",show.d=TRUE)
shade.bin(x=5,n=20,tail="lower")
shade.bin(x=5,n=20,tail="two")
shade.bin(from=8,to=12,n=20,tail="middle")

##Poisson
shade.poi(x=5,lambda=6,tail="X=x",show.d=TRUE)
shade.poi(x=5,lambda=7,tail="lower")
shade.poi(x=5,lambda=8,tail="upper")
shade.poi(from=8,to=12,lambda=7,tail="middle")

## End(Not run)
</code></pre>

<hr>
<h2 id='shade.norm.tck'>GUI display of probability 
</h2><span id='topic+shade.bin.tck'></span><span id='topic+shade.chi.tck'></span><span id='topic+shade.F.tck'></span><span id='topic+shade.norm.tck'></span><span id='topic+shade.poi.tck'></span><span id='topic+shade.t.tck'></span>

<h3>Description</h3>

<p>Provides <span class="pkg">tcltk</span> GUIs to manage <span class="pkg">asbio</span> <code><a href="#topic+shade">shade</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
shade.bin.tck()

shade.chi.tck()

shade.F.tck()

shade.norm.tck()

shade.poi.tck()

shade.t.tck()
</code></pre>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shade">shade</a></code></p>

<hr>
<h2 id='simberloff'>
Compilations of genus and species counts from Simberloff (1970)
</h2><span id='topic+simberloff'></span>

<h3>Description</h3>

<p>A compilation of taxonomic (species and genus) counts for a wide array of organism groups for island and associated mainland locations.  Taken from Simberloff (1970).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("simberloff")</code></pre>


<h3>Format</h3>

<p>A data frame with 204 observations on the following 12 variables.
</p>

<dl>
<dt><code>Location</code></dt><dd><p>Island and mainland location.</p>
</dd>
<dt><code>Designation</code></dt><dd><p>A factor with levels <code>Island</code> <code>Mainland</code>.</p>
</dd>
<dt><code>Hypothesized.source</code></dt><dd><p>Hypothesized mainland location for particular island location.</p>
</dd>
<dt><code>No.spp.</code></dt><dd><p>The number of species</p>
</dd>
<dt><code>Obs.S.G</code></dt><dd><p>Observed species/genus (S/G) ratio</p>
</dd>
<dt><code>E.S.G.</code></dt><dd><p>Expected S/G ratio, based on random sampling from mainland pool of species.</p>
</dd>
<dt><code>prop..obs..cogeners</code></dt><dd><p>The proportion of observed cogeners, only reported for bird species.</p>
</dd>
<dt><code>prop..exp..cogeners</code></dt><dd><p>The proportion of expected cogeners based on random sampling from the associated mainland pool of species, only reported for bird species.</p>
</dd>
<dt><code>Authority</code></dt><dd><p>Source of information for compilation.</p>
</dd>
<dt><code>Life.form</code></dt><dd><p>A factor with levels <code>Ants</code> <code>Land birds</code> <code>Passerine birds</code> <code>Vascular plants</code>.</p>
</dd>
<dt><code>Notes.1</code></dt><dd><p>Notes from Simberloff (1970)</p>
</dd>
<dt><code>Notes.2</code></dt><dd><p>Additional notes from Simberloff (1970)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Simberloff, D. (1970) Taxonomic diversity of island biotas. <em>Evolution</em> 24, 23-47.
</p>

<hr>
<h2 id='skew'>Sample skewness and kurtosis</h2><span id='topic+skew'></span><span id='topic+kurt'></span>

<h3>Description</h3>

<p>Functions for skewness and kurtosis.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
skew(x,method="unbiased")

kurt(x,method="unbiased")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skew_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
<tr><td><code id="skew_+3A_method">method</code></td>
<td>
<p>The type of method used for computation of skew and kurtosis.  Two choices are possible for skewness: <code>"moments"</code> and <code>"unbiased"</code>, and three choices are possible for kurtosis: <code>"unbiased", "moments"</code>, and <code>"excess"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Aside from centrality and variability we can describe distributions with respect to their shape.  Two important shape descriptors are skewness and kurtosis.  Skewness describes the relative density in the tails of a distribution while kurtosis describes the peakedness of a distribution. When quantified for a population skewness and kurtosis are denoted as <code class="reqn">\gamma_1</code> and <code class="reqn">\gamma_2</code> respectively.  For a symmetric distribution skewness will equal zero; i.e. <code class="reqn">\gamma_1</code> = 0.  A distribution with more density in its right-hand tail will have  <code class="reqn">\gamma_1</code> &gt; 0, while one with more density in its left-hand tail will have  <code class="reqn">\gamma_1</code> &lt; 0.  These distributions are often referred to as positively-skewed and negatively-skewed respectively.  If a distribution is normally peaked (mesokurtic) then <code class="reqn">\gamma_2</code> = 3.  As a result the number three is generally subtracted from kurtosis estimates so that a normal distribution will have <code class="reqn">\gamma_2</code>  = 0 .  Thus strongly peaked (leptokurtic) distributions will have <code class="reqn">\gamma_2</code> &gt; 0, while flat-looking (platykurtic) distributions will have a kurtosis <code class="reqn">\gamma_2</code> &lt; 0. 
</p>
<p>Several types of skewness and kurtosis estimation are possible. 
</p>
<p>For method of moments estimation let: 
</p>
<p style="text-align: center;"><code class="reqn">m_j = (1/n)\sum_i({X_i-\bar{X}})^j,</code>
</p>

<p>then the method of moments skewness is: <code class="reqn">m_3/m_{2}^{3/2}</code>, the method of moments kurtosis is: <code class="reqn">m_4/m_2^2</code>, and the excess method of moments kurtosis is <code class="reqn">m_4/m_2^2 -3</code>. 
</p>
<p>These estimators are biased low, particularly given small sample sizes.  A more complex estimator is required to account for this bias.  This is provided by <code>method = "unbiased"</code> in <code>skew</code> and <code>kurt</code>.
</p>


<h3>Value</h3>

<p>Output will be the sample skewness or kurtosis.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>Examples</h3>

<pre><code class='language-R'>exp&lt;-rexp(10000)
skew(exp)
kurt(exp)
</code></pre>

<hr>
<h2 id='SM.temp.moist'>
Alpine soil temperature and moisture time series
</h2><span id='topic+SM.temp.moist'></span>

<h3>Description</h3>

<p>Soil temperature and water availability from Mt. Washburn in Yellowstone National Park.  Data were taken at soil depth of 5cm from a late snowmelt site at UTM 4960736.977	544792.225 zone 12T NAD 83, elevation 3070m.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SM.temp.moist)</code></pre>


<h3>Format</h3>

<p>A data frame with 30 observations on the following 4 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>A numeric vector describing year.</p>
</dd>
<dt><code>day</code></dt><dd><p>The &quot;day of year&quot;, whereby Jan 1 = day 1 and Dec 32 = day 365 (366 for leap years).</p>
</dd>
<dt><code>Temp_C</code></dt><dd><p>Temperature in degrees Celsius.</p>
</dd>
<dt><code>Moisture</code></dt><dd><p>Soil water availability sensor reading.  A reading of 35 is approximately equal to -1.5 MPa.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Aho, K. (2006)  <em>Alpine Ecology and Subalpine Cliff Ecology in the Northern Rocky 
Mountains</em>.  Doctoral dissertation, Montana State University, 458 pgs.
</p>

<hr>
<h2 id='snore'>
Snoring and heart disease contingency data 
</h2><span id='topic+snore'></span>

<h3>Description</h3>

<p>Norton and Dunn (1985) compiled data from four family practice clinics in Toronto to quantify the association between snoring and heart disease for 2484 subjects.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(snore)</code></pre>


<h3>Format</h3>

<p>A data frame with 2484 observations on the following 3 variables.
</p>

<dl>
<dt><code>snoring</code></dt><dd><p>A factor with levels <code>every.night</code> <code>nearly.ever.night</code> <code>never</code> <code>occasional</code></p>
</dd>
<dt><code>ord.snoring</code></dt><dd><p>Agresti (21012) transformed the explanatory levels to ordinal values in his analysis of this data.</p>
</dd>
<dt><code>disease</code></dt><dd><p>Presence/absence of heart disease</p>
</dd>
</dl>



<h3>Source</h3>

<p>Norton, P. G., and E. V. Dunn  (1985)  Snoring as a risk factor for disease: an 
epidemiological survey.  <em>British Medical Journal</em> 291: 630-632. 
</p>

<hr>
<h2 id='so2.us.cities'>SO2 data for 32 US cities with respect to 6 explanatory variables</h2><span id='topic+so2.us.cities'></span>

<h3>Description</h3>

<p>Of concern for public health officials and biologists are models of air 
pollution as a function of environmental characteristics.  Using a meta-analysis of 
government publications Sokal and Rolf (1995) compiled an interesting dataset which 
investigates air pollution (measured as annual mean SO<code class="reqn">_2</code> concentration per m<code class="reqn">^3</code>) 
as a function of six environmental variables for 32 cities in the United States.  
Whenever the data were available they are based on averages of three years 1969, 1970, 
and 1971.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(so2.us.cities)</code></pre>


<h3>Format</h3>

<p>The dataset contains 8 variables:
</p>

<dl>
<dt><code>City</code></dt><dd><p>US city.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Average annual SO<code class="reqn">_2</code> concentration per m<code class="reqn">^3</code>.</p>
</dd>   
<dt><code>X1</code></dt><dd><p>Average annual temperature (degrees Celsius).</p>
</dd>
<dt><code>X2</code></dt><dd><p>Number of industrial companies with more than 20 employees.</p>
</dd>
<dt><code>X3</code></dt><dd><p>Population size (1970 census) in thousands.</p>
</dd>
<dt><code>X4</code></dt><dd><p>Average Annual average wind speed.</p>
</dd>
<dt><code>X5</code></dt><dd><p>Average Annual precipitation (cm).</p>
</dd>
<dt><code>X6</code></dt><dd><p>Average number of days with precipitation.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sokal, R. R., and F. J. Rohlf (2012) <em>Biometry, 4th ed</em>.  Freeman.
</p>

<hr>
<h2 id='stan.error'>Variance and standard error estimators for the sampling distribution of the sample mean</h2><span id='topic+stan.error'></span><span id='topic+stan.error.sq'></span>

<h3>Description</h3>

<p>Estimator for the variance for the sampling distribution of the sample mean, i.e. <code class="reqn">S^2/n</code>, and the standard deviation of the sampling distribution, i.e. <code class="reqn">S/\sqrt(n)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stan.error(x)
stan.error.sq(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stan.error_+3A_x">x</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr></table>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+sd">sd</a></code></p>

<hr>
<h2 id='starkey'>DEM data from the Starkey experimental forest in NE Oregon</h2><span id='topic+starkey'></span>

<h3>Description</h3>

<p>UTM northing and easting data along with 18 other environmental variables describing the
Starkey experimental forest. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(starkey)</code></pre>

<hr>
<h2 id='suess'>
del14C in the atmosphere from 1700-1950
</h2><span id='topic+suess'></span>

<h3>Description</h3>

<p>Six reservoir model prediction of the <code class="reqn">\delta^14</code>C in the atmosphere from approximately 1700-1950 as provided by Bacastow and Keeling (1973).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("suess")</code></pre>


<h3>Format</h3>

<p>A data frame with 149 observations on the following 3 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>Year</p>
</dd>
<dt><code>del14C</code></dt><dd><p>Levels of <code class="reqn">\delta^14</code>C</p>
</dd>
<dt><code>Source</code></dt><dd><p>Sources used by Bacastow et al. (1973). lermanN = Northern Hemisphere measures from Lerman (1970), lermanS = Southern Hemisphere measures from Lerman (1970), suess = Northern Hemisphere measures from Suess (1955, 1965), stuiver = Northern Hemisphere measures from Stuiver (1963).</p>
</dd>
</dl>



<h3>Source</h3>

<p>Bacastow, R., Keeling, C. D., Woodwell, G. M., &amp; Pecan, E. V. (1973). Atmospheric carbon dioxide and radiocarbon in the natural carbon cycle. II. Changes from AD 1700 to 2070 as deduced from a geochemical model (No. CONF-720510&ndash;). Univ. of California, San Diego, La Jolla; Brookhaven National Lab., Upton, NY (USA).
</p>


<h3>References</h3>

<p>Secondary sources used by Bacastow et al. (1973):
</p>
<p>Lerman, J. C., Mook, W. G., &amp; Vogel, J. C. (1970). C14 in tree rings from different localities. In <em>Radiocarbon Variations and Absolute Chronology</em>. Proceedings, XII Nobel Symposium. New York: Wiley. p (pp. 275-301).
</p>
<p>Stuiver, M. (1963). Yale natural radiocarbon measurements IX. <em>Radiocarbon</em>, 11, 545-658.
</p>
<p>Suess, H. E. (1965). Secular variations of the cosmic-ray-produced carbon 14 in the atmosphere and their interpretations. <em>Journal of Geophysical Research</em>, 70(23), 5937-5952.
</p>
<p>Suess, H. E. (1955). Radiocarbon concentration in modern wood. <em>Science</em>, 122(3166), 415-417.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(suess)
with(suess, plot(Year, del14C, col = Source, pch = as.numeric(Source)))
with(suess, legend("topright", legend = levels(Source), col = 1:4, pch = 1:4))
lines(lowess(suess$Year, suess$del14C, f = .25), lwd = 2)
</code></pre>

<hr>
<h2 id='trag'>
Salsify height dataset
</h2><span id='topic+trag'></span>

<h3>Description</h3>

<p>Heights of salsify <em>Tragapogon dubius</em> at the Barton Road long term experimental site in Pocatello Idaho. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(trag)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following variable.
</p>

<dl>
<dt><code>height</code></dt><dd><p><em>T. dubius</em> plant height in cm</p>
</dd>
</dl>


<hr>
<h2 id='transM'>Transition matrix analysis</h2><span id='topic+transM'></span><span id='topic+anm.transM'></span><span id='topic+anm.TM.tck'></span>

<h3>Description</h3>

<p>Creates a plot showing expected numbers of individuals in specified age classes or life stages given survivorship probabilities from a transition matrix (cf. Caswell 2000).  The function <code>anm.transM</code> provides an animated view of the population growth curves.  The function <code>anm.TM.tck</code> provides a <span class="pkg">tcltk</span> GUI to run <code>anm.TM.tck</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transM(A, init, inter = 100, stage.names = c("All grps",1:(ncol(A))), 
leg.room = 1.5, ...)

anm.transM(A,init,inter=100,stage.names =c("All grps",1:(ncol(A))),
leg.room = 1.5, anim.interval=0.1,...)

anm.TM.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transM_+3A_a">A</code></td>
<td>
<p>Transition matrix containing survivorship probabilities and fecundities see Caswell (2000).
</p>
</td></tr>
<tr><td><code id="transM_+3A_init">init</code></td>
<td>

<p>A numeric vector containing initial numbers in each age class of interest. 
</p>
</td></tr>
<tr><td><code id="transM_+3A_inter">inter</code></td>
<td>

<p>Number of time intervals for which population numbers are to be calculated.  
</p>
</td></tr>
<tr><td><code id="transM_+3A_stage.names">stage.names</code></td>
<td>

<p>A character vector giving life stage names.
</p>
</td></tr>
<tr><td><code id="transM_+3A_leg.room">leg.room</code></td>
<td>

<p>A <em>Y</em>-axis multiplier intended to create room for a legend.
</p>
</td></tr>
<tr><td><code id="transM_+3A_anim.interval">anim.interval</code></td>
<td>

<p>Speed of animation in frames per second.
</p>
</td></tr>
<tr><td><code id="transM_+3A_...">...</code></td>
<td>

<p>Additional arguments for <code><a href="base.html#topic+plot">plot</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot and proportions of the population in each age class for the number of time intervals in <code>inter</code>.
</p>


<h3>Author(s)</h3>

<p>Ken Aho
</p>


<h3>References</h3>

<p>Caswell, H  (2000) <em>Matrix Population Models: Construction, Analysis and Interpretation, 2nd Edition</em>. Sinauer Associates, Sunderland, Massachusetts.
</p>
<p>Gurevitch, J., Scheiner, S. M., and G. A. Fox (2006)  <em>The Ecology of Plants</em>.  Sinauer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Endangered cactus data data from Gurevitch et al. (2006)
A&lt;-matrix(nrow=3,ncol=3,data=c(.672,0,.561,0.018,0.849,0,0,0.138,0.969),
byrow=TRUE)
init&lt;-c(10,2,1)
transM(A,init,inter=100,stage.names=c("All","Sm. Juv.","Lg. Juv.","Adults"),
xlab="Years from present",ylab="n")
#animated version
## Not run: 
anm.transM(A,init,inter=100,stage.names=c("All","Sm. Juv.","Lg. Juv.","Adults"),
xlab="Years from present",ylab="n")

## End(Not run)
</code></pre>

<hr>
<h2 id='trim.me'>Trim data</h2><span id='topic+trim.me'></span>

<h3>Description</h3>

<p>Trims observations above and below the central <code class="reqn">(1 - 2\lambda</code>) part of an an ordered vector of data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim.me(Y, trim = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trim.me_+3A_y">Y</code></td>
<td>
<p>A vector of quantitative data.</p>
</td></tr>
<tr><td><code id="trim.me_+3A_trim">trim</code></td>
<td>
<p>Proportion (0-1) to be trimmed from each tail of an ordered version of <code>Y</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a trimmed data vector.</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-c(2,1,4,5,6,2.4,7,2.2,.002,15,17,.001)
trim.me(x)
</code></pre>

<hr>
<h2 id='trim.ranef.test'>Robust test for random factors using trimmed means.</h2><span id='topic+trim.ranef.test'></span>

<h3>Description</h3>

<p>Provides a robust hypothesis test for the null: <em>Var</em>(<em>X</em>) = 0, for a population of random factor levels. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim.ranef.test(Y, X, tr = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trim.ranef.test_+3A_y">Y</code></td>
<td>
<p>Vector of response data. A quantitative vector.</p>
</td></tr>
<tr><td><code id="trim.ranef.test_+3A_x">X</code></td>
<td>
<p>Vector of factor levels</p>
</td></tr>
<tr><td><code id="trim.ranef.test_+3A_tr">tr</code></td>
<td>
<p>Amount of trimming.  A number from 0-0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Robust analyses for random effect designs are particularly important since standard random effects models provide poor control over type I error when assumptions of normality and homoscedasticity are violated.   Specifically, Wilcox (1994) showed that even with equal sample sizes, and moderately large samples, actual probability of type I error can exceed 0.3 if normality and homoscedasticity are violated.  
</p>


<h3>Value</h3>

<p>Returns a list with three components dataframe describing numerator and denominator degrees of freedom, the <em>F</em> test statistic and the <em>p</em>-value.
</p>


<h3>Note</h3>

<p>code based on Wilcox (2005)</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Wilcox, R. R. (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rye&lt;-c(50,49.8,52.3,44.5,62.3,74.8,72.5,80.2,47.6,39.5,47.7,50.7)
nutrient&lt;-factor(c(rep(1,4),rep(2,4),rep(3,4)))
trim.ranef.test(rye,nutrient,tr=.2)
</code></pre>

<hr>
<h2 id='trim.test'>Robust one way trimmed means test.</h2><span id='topic+trim.test'></span>

<h3>Description</h3>

<p>A robust heteroscedastic  procedure using trimmed means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim.test(Y, X, tr = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trim.test_+3A_y">Y</code></td>
<td>
<p>A vector of responses.  A quantitative vector</p>
</td></tr>
<tr><td><code id="trim.test_+3A_x">X</code></td>
<td>
<p>A vector of factor levels.</p>
</td></tr>
<tr><td><code id="trim.test_+3A_tr">tr</code></td>
<td>
<p>The degree of trimming.  A value from 0-0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method utilized here is based on the simple idea of replacing means with trimmed means and standard error estimates, based on all the data, with the standard error of the trimmed mean (Wilcox 2005).  The method has the additional benefit of being resistant to heteroscedasticity due to the use of the Welch method for calculating degrees of freedom.  With no trimming the degrees of freedom reduce to those of the one way Welch procedure in <code><a href="stats.html#topic+oneway.test">oneway.test</a></code>.
</p>


<h3>Value</h3>

<p>Returns a dataframe with numerator and denominator degrees of freedom, a test statistic, and a <em>p</em>-value based on the <em>F</em>-distribution.
</p>


<h3>Note</h3>

<p>code based on Wilcox (2005) 
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Wilcox, R. R.  (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+oneway.test">oneway.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>rye&lt;-c(50,49.8,52.3,44.5,62.3,74.8,72.5,80.2,47.6,39.5,47.7,50.7)
nutrient&lt;-factor(c(rep(1,4),rep(2,4),rep(3,4)))
trim.test(rye,nutrient,tr=.2)
</code></pre>

<hr>
<h2 id='tukey.add.test'>Tukey's test of additivity.</h2><span id='topic+tukey.add.test'></span><span id='topic+print.addtest'></span>

<h3>Description</h3>

<p>With an RBD we are testing the null hypothesis that there is no treatment effect in any block.  As a result randomized block designs including RBDs, Latin Squares, and spherical repeated measures assume that there is no interaction effect between blocks and main factors (i.e. main effects and block are additive).  We can test this assumption with the Tukey's test for additivity.  We address the following hypotheses:
</p>
<p>H<code class="reqn">_0</code>: Main effects and blocks are additive, versus H<code class="reqn">_A</code>: Main effects and blocks are non-additive.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
tukey.add.test(y, A, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tukey.add.test_+3A_y">y</code></td>
<td>
<p>Response variable. Vector of quantitative data.</p>
</td></tr>
<tr><td><code id="tukey.add.test_+3A_a">A</code></td>
<td>
<p>Main effects.  Generally a vector of categorical data.</p>
</td></tr>
<tr><td><code id="tukey.add.test_+3A_b">B</code></td>
<td>
<p>Blocking variable.  A vector of categories (blocks).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tukey's test for additivity is best for detecting simple block x treatment interactions; for instance, when lines in an interaction plot cross.  As a result interaction plots should be used for diagnosis of other types of interactions.  A high probability of type II error results from the inability Tukey's additivity test to detect complex interactions (Kirk 1995).  As a result a conservative value of  should be used, i.e. 0.1 - 0.25. 
</p>


<h3>Value</h3>

<p>Returns a table with test results.
</p>


<h3>Author(s)</h3>

<p>Orginal author unknown.  Modified by K. Aho</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and W. Li. (2005)  <em>Applied Linear Statistical Models, 5th edition</em>.  McGraw-Hill, Boston.
</p>
<p>Kirk, R. E.  1995.  <em>Experimental Design</em>.  Brooks/Cole.  Pacific Grove, CA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>treatment&lt;-as.factor(c(36,54,72,108,144,36,54,72,108,144,36,54,72,108,144))
block&lt;-as.factor(c(rep(1,5),rep(2,5),rep(3,5)))
strength&lt;-c(7.62,8.14,7.76,7.17,7.46,8,8.15,7.73,7.57,7.68, 7.93,7.87,7.74, 7.8,7.21)
tukey.add.test(strength,treatment,block)
</code></pre>

<hr>
<h2 id='veneer'>
Veneer data from Littell et al. (2002)
</h2><span id='topic+veneer'></span>

<h3>Description</h3>

<p>Four examples of each of five brands of a synthetic wool veneer material were subjected to a friction test and a measure of wear was determined for each experimental unit. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(veneer)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 2 variables.
</p>

<dl>
<dt><code>wear</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>brand</code></dt><dd><p>a factor with levels <code>ACME</code> <code>AJAX</code> <code>CHAMP</code> <code>TUFFY</code> <code>XTRA</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Littell, R. C., Stroup, W. W., and R. J. Freund (2002)  <em>SAS for Linear Models</em>.  John 
Wiley and Associates. </p>

<hr>
<h2 id='Venn'>Venn probability diagrams for an event with two outcomes</h2><span id='topic+Venn'></span><span id='topic+Venn.tck'></span>

<h3>Description</h3>

<p>The user specifies the probabilities of two outcomes, and if applicable, their intersection.  A Venn diagram is returned. The universe, S, will generally not have unit area, but in many applications will be a good approximation.  The area of the intersection will also be an approximation.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Venn(A, B, AandB = 0, labA = "A", labB = "B", cex.text = .95, ...)

Venn.tck()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Venn_+3A_a">A</code></td>
<td>
<p>Probability of event A</p>
</td></tr>
<tr><td><code id="Venn_+3A_b">B</code></td>
<td>
<p>Probability of event B</p>
</td></tr>
<tr><td><code id="Venn_+3A_aandb">AandB</code></td>
<td>
<p>Probability of the intersection of A and B</p>
</td></tr>
<tr><td><code id="Venn_+3A_laba">labA</code></td>
<td>
<p>Label assigned to event A in the diagram</p>
</td></tr>
<tr><td><code id="Venn_+3A_labb">labB</code></td>
<td>
<p>Label assigned to event B in the diagram</p>
</td></tr>
<tr><td><code id="Venn_+3A_cex.text">cex.text</code></td>
<td>
<p>Character expansion for text.</p>
</td></tr>
<tr><td><code id="Venn_+3A_...">...</code></td>
<td>
<p>Additional arguments from <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Venn diagram is returned.  
</p>


<h3>Author(s)</h3>

<p>K. Aho</p>


<h3>References</h3>

<p>Bain, L. J., and M. Engelhardt (1992)  <em>Introduction to Probability and Mathematical 
Statistics</em>.  Duxbury press.  Belmont, CA, USA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Venn(A=.3,B=.2,AandB=.06)
</code></pre>

<hr>
<h2 id='vs'>
Scandinavian site by species community matrix
</h2><span id='topic+vs'></span><span id='topic+varespec'></span>

<h3>Description</h3>

<p>Scandinavian, lichen, bryophyte, and vascular plant data from Vare et al. (1995).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(vs)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations (sites) on 44 variables (species).
</p>


<h3>Details</h3>

<p>Lifted from dataframe <code>{varespec}</code> in package <span class="pkg">vegan</span>.
</p>


<h3>Source</h3>

<p>The dataset <code>{varespec}</code> in package <span class="pkg">vegan</span>
</p>


<h3>References</h3>

<p>Vare, H., Ohtonen, R., and J. Oksanen (1995) Effects of reindeer grazing on understory vegetation in dry Pinus sylvestris forests. <em>Journal of Vegetation Science</em> 6: 523-530.
</p>

<hr>
<h2 id='wash.rich'>
Species richness and environmental variables from Mt Washburn
</h2><span id='topic+wash.rich'></span>

<h3>Description</h3>

<p>Aho and Weaver (2010) examined the effect of environmental characteristics on alpine vascular plant species richness on Mount Washburn (3124m) a volcanic peak in north-central Yellowstone National Park.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wash.rich)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 7 variables.
</p>

<dl>
<dt><code>site</code></dt><dd><p>Site identifier.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Species richness.</p>
</dd>
<dt><code>X1</code></dt><dd><p>Percent Kjeldahl (total) soil N.</p>
</dd>
<dt><code>X2</code></dt><dd><p>Slope in degrees.</p>
</dd>
<dt><code>X3</code></dt><dd><p>Aspect in degrees from true north.</p>
</dd>
<dt><code>X4</code></dt><dd><p>Percent cover of surface rock.</p>
</dd>
<dt><code>X5</code></dt><dd><p>Soil pH.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Aho, K., and T. Weaver (2010)  Ecology of alpine nodes: environments, communities, 
and ecosystem evolution (Mount Washburn; Yellowstone Natl. Park).  <em>Arctic, Antarctic, and Alpine Research</em>.  40(2): 139-151. 
</p>

<hr>
<h2 id='webs'>Spider web length data</h2><span id='topic+webs'></span>

<h3>Description</h3>

<p>Gosline et al. (1984) applied heat to strands of spider web to determine whether the structure underlying webs was rubber-like. Data are estimated from a scatterplot in Gosline et al.. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(webs)</code></pre>


<h3>Format</h3>

<p>The dataframe contains 4 columns
</p>

<dl>
<dt>obs</dt><dd><p>Observation number.</p>
</dd>   
<dt>relative length</dt><dd><p>Relative strand strand length after heat application.</p>
</dd>         
<dt>temp.C</dt><dd><p>Temp in degrees Celsius.</p>
</dd>        
<dt>residuals</dt><dd><p>Residuals from the linear model length~temp.C.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gosline, J. M., Denny, M. W. and Demont, M. E. (1984). Spider silk as rubber.
<em>Nature</em> 309, 551-552.</p>

<hr>
<h2 id='wheat'>Agricultural randomized block design</h2><span id='topic+wheat'></span>

<h3>Description</h3>

<p>Allard (1966) sought to quantify variation in the yield in wheat grasses.  
Five wheat crosses were selected from a breeding program and were grown at 
four randomly selected locations where the wheat would be grown commercially.  
At each location crosses (families) were randomly assigned to particular 
sections of fields, i.e. at each location a one way randomized block design 
was conducted.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wheat)</code></pre>


<h3>Format</h3>

<p>The dataframe has four columns:
</p>

<dl>
<dt>yield</dt><dd><p>Refers to wheat yield.</p>
</dd>
<dt>loc</dt><dd><p>Refers to randomly selected locations where wheat were grown commercially.  A factor with four levels: <code>1,2,3,4</code>.</p>
</dd>
<dt>block</dt><dd><p>Refers to the replicate block within location.  A factor with four levels: <code>1,2,3,4</code>. Within each block five wheat crosses were randomly assigned and grown.</p>
</dd>  
<dt>cross</dt><dd><p>Refers to wheat crosses.  A factor with five levels: <code>1,2,3,4,5</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Littell, R. C., Milliken, G. A., Stroup, W. W., Wolfinger, R. D., and O. Schabenberger  
(2006)  <em>SAS for Mixed Models 2nd ed</em>.  SAS press.
</p>

<hr>
<h2 id='whickham'>
Whickham contingency table data for smokers and survivorship
</h2><span id='topic+whickham'></span>

<h3>Description</h3>

<p>Appleton et al. (1996) summarized a study from the Whickham district of England 
to quantify the association of smoking, age, and death.  1,314 women were interviewed 
in the early 1970s with respect to their smoking habits.  Twenty years later the women were relocated and 
classified with respect to survival at the time of the follow up (yes or no), 
whether they smoked at the time of the original interview (yes or no), 
and age at the time of the original study (1 = 18-24, 2 = 35-64, 3 = &gt;65).   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(whickham)</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on the following 4 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>A factor with levels <code>1</code> <code>2</code> <code>3</code>.</p>
</dd>
<dt><code>survival</code></dt><dd><p>A factor with levels <code>N</code> <code>Y</code>.</p>
</dd>
<dt><code>smoke</code></dt><dd><p>A factor with levels <code>N</code> <code>Y</code>.</p>
</dd>
<dt><code>count</code></dt><dd><p>Cross-classification count.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Appleton, D. R., French, J. M., Vanderpump, M. P. J.  (1996)  Ignoring a covariate: AN example of Simpson's paradox.  <em>The American Statistician</em> 50(4): 340-341.
</p>

<hr>
<h2 id='wildebeest'>
Wildebeest carcass categorical data
</h2><span id='topic+wildebeest'></span>

<h3>Description</h3>

<p>To test the &quot;predation-sensitive food&quot; hypothesis, which predicts that both food and predation limit prey populations, 
Sinclair and Arcese (1995) examined wildebeest (<em>Connochaetes taurinus</em>) carcasses in the Serengeti.  
The degree of malnutrition in animals was measured by marrow content since marrow will contain the last fat reserves in ungulates.  
Carcasses were cross-classified with respect to three categorical variables: sex (M, F), cause of death (predation, non-predation), 
and marrow type (SWF = Solid White Fatty, indicating healthy animals, OG = Opaque Gelatinous, indicating malnourishment, and TG = Translucent Gelatinous, the latter indicating severe malnourishment).   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wildebeest)</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on the following 4 variables.
</p>

<dl>
<dt><code>marrow</code></dt><dd><p>A factor with levels <code>OG</code> <code>SWF</code> <code>TG</code>.</p>
</dd>
<dt><code>sex</code></dt><dd><p>A factor with levels <code>F</code> <code>M</code>.</p>
</dd>
<dt><code>predation</code></dt><dd><p>A factor with levels <code>N</code> <code>P</code>.</p>
</dd>
<dt><code>count</code></dt><dd><p>Count in each cell</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sinclair, A. R. E., and P. Arcese (1995)  Population consequences of predation-sensitive foraging: the Serengeti wildebeest.  <em>Ecology</em>  76(3):  882-891.
</p>

<hr>
<h2 id='win'>Winsorize data</h2><span id='topic+win'></span>

<h3>Description</h3>

<p>Winsorizes the proportion of ordered data given by <code>lambda</code> from each tail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
win(x, lambda = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="win_+3A_x">x</code></td>
<td>
<p>A vector of data.</p>
</td></tr>
<tr><td><code id="win_+3A_lambda">lambda</code></td>
<td>
<p>A proportion from 0-1 giving the amount of data to be Winsorized in each tail of an ordered dataset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Winsorization we  we replace responses that are not in the central <code class="reqn">1 - 2\lambda</code> part of an ordered sample with the minimum and maximum responses of the central part of the sample.  
</p>


<h3>Value</h3>

<p>Returns Winsorized data.
</p>


<h3>Author(s)</h3>

<p>Ken Aho</p>


<h3>References</h3>

<p>Wilcox, R. R. (2005)  <em>Introduction to Robust Estimation and Hypothesis Testing, Second 
Edition</em>.  Elsevier, Burlington, MA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-c(2,1,4,5,6,2.4,7,2.2,.002,15,17,.001)
win(x)</code></pre>

<hr>
<h2 id='wine'>
White wine quality data for data mining
</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>These data concern white variants of the Portuguese &quot;Vinho Verde&quot; wine.
Quality is an ordinal variable based on the median assessment of 
of at least 3 wine experts. Each expert graded wine quality between 0 (very bad) and 10 (excellent).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("wine")</code></pre>


<h3>Format</h3>

<p>A data frame with 4898 observations on the following 12 variables.
</p>

<dl>
<dt><code>Y</code></dt><dd><p>Wine quality.</p>
</dd>
<dt><code>X1</code></dt><dd><p>Volatile acidity.</p>
</dd>
<dt><code>X2</code></dt><dd><p>Citric acid content.</p>
</dd>
<dt><code>X3</code></dt><dd><p>Residual Sugar content.</p>
</dd>
<dt><code>X4</code></dt><dd><p>Chloride content.</p>
</dd>
<dt><code>X5</code></dt><dd><p>Free sulfur dioxide content.</p>
</dd>
<dt><code>X6</code></dt><dd><p>Total sulfur dioxide content.</p>
</dd>
<dt><code>X7</code></dt><dd><p>Density.</p>
</dd>
<dt><code>X8</code></dt><dd><p>pH: <code class="reqn">-\log_{10}</code> [H<code class="reqn">^{+}</code>].</p>
</dd>
<dt><code>X9</code></dt><dd><p>Sulphate content.</p>
</dd>
<dt><code>X10</code></dt><dd><p>Alcohol content.</p>
</dd>
<dt><code>X11</code></dt><dd><p>Fixed acidity.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009
</p>


<h3>References</h3>

<p>Past Usage:
</p>
<p>P. Cortez, A. Cerdeira, F. Almeida, T. Matos, Reis, J.(2009).  
Modeling wine preferences by data mining from physicochemical properties.
<em>Decision Support Systems</em> 47(4):547-553. 
</p>

<hr>
<h2 id='world.co2'>World CO2 levels, by country, from 1980 to 2006</h2><span id='topic+world.co2'></span>

<h3>Description</h3>

<p>The Carbon Dioxide Information Analysis Center (CDIAC) has compiled extensive data, detailing total carbon dioxide emissions from the consumption and flaring of fossil fuels (in millions of metric tons of carbon dioxide).  Data can be broken down by country.  More up-to-date data can be found in this package at <code><a href="#topic+world.emissions">world.emissions</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(world.co2)</code></pre>


<h3>Format</h3>

<p>The dataframe contains 16 columns
</p>

<dl>
<dt><code>Year</code></dt><dd><p>The year of CO<code class="reqn">_2</code> measure (1980-2006)</p>
</dd></dl>
<p>.   
</p>
<dl>
<dt><code>Afghanistan</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Afghanistan from 1980-2006 (1x<code class="reqn">10^6</code> metric tons).</p>
</dd>         
<dt><code>Belgium</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Belgium...</p>
</dd>        
<dt><code>Brazil</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Brazil...</p>
</dd>
<dt><code>Canada</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Canada...</p>
</dd>
<dt><code>China</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in China...</p>
</dd>
<dt><code>Finland</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Finland...</p>
</dd>
<dt><code>Ghana</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Ghana...</p>
</dd>
<dt><code>Italy</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Italy...</p>
</dd>        
<dt><code>Japan</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Japan...</p>
</dd>
<dt><code>Kenya</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Kenya...</p>
</dd>
<dt><code>Mexico</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Mexico...</p>
</dd>        
<dt><code>Saudi.Arabia</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in Saudi Arabia...</p>
</dd>
<dt><code>United.Arab.Emirates</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in the United Arab Emirates..</p>
</dd>
<dt><code>United.States</code></dt><dd><p>CO<code class="reqn">_2</code> emissions in United States...</p>
</dd>
<dt><code>World.Total</code></dt><dd><p>CO<code class="reqn">_2</code> emissions totals for the world...</p>
</dd>
</dl>



<h3>Source</h3>

<p>The U.S. Carbon Dioxide Information Analysis Center (CDIAC).</p>

<hr>
<h2 id='world.emissions'>
Greenhouse gas emissions from Our World in Data
</h2><span id='topic+world.emissions'></span>

<h3>Description</h3>

<p>A subset of the complete CO<code class="reqn">_2</code> and Greenhouse Gas Emissions dataset maintained by Our World in Data (<a href="https://ourworldindata.org/">https://ourworldindata.org/</a>) through 2019. The data follow a format of 1 row per &ldquo;country&rdquo; per year.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("world.emissions")</code></pre>


<h3>Format</h3>

<p>A data frame with 23708 observations on the following 15 variables.
</p>

<dl>
<dt><code>iso_code</code></dt><dd><p>Three-letter summary code for countries (ISO 3166-1 alpha-3). </p>
</dd>
<dt><code>country</code></dt><dd><p>A character vector identifying country.</p>
</dd>
<dt><code>year</code></dt><dd><p>Year data were collected, 1750-2019</p>
</dd>
<dt><code>co2</code></dt><dd><p>Annual production-based emissions of carbon dioxide (CO<code class="reqn">_2</code>), measured in million tonnes. This is based on territorial emissions, which do not account for emissions from traded goods.</p>
</dd>
<dt><code>coal_co2</code></dt><dd><p>Annual production-based emissions of CO<code class="reqn">_2</code> from coal, measured in million tonnes. </p>
</dd>
<dt><code>flaring_co2</code></dt><dd><p>Annual production-based emissions of CO<code class="reqn">_2</code> from flaring, measured in million tonnes. </p>
</dd>
<dt><code>gas_co2</code></dt><dd><p>Annual production-based emissions of CO<code class="reqn">_2</code> from gas, measured in million tonnes. </p>
</dd>
<dt><code>oil_co2</code></dt><dd><p>Annual production-based emissions of CO<code class="reqn">_2</code> from oil, measured in million tonnes. </p>
</dd>
<dt><code>other_industry_co2</code></dt><dd><p>Annual production-based emissions of CO<code class="reqn">_2</code> from other industry sources, measured in million tonnes. Based on territorial emissions,.</p>
</dd>
<dt><code>total_ghg</code></dt><dd><p>Total greenhouse gas emissions, including land use change and forestry, measured in million tonnes of CO<code class="reqn">_2</code>-equivalents.</p>
</dd>
<dt><code>methane</code></dt><dd><p>Total methane emissions, measured in million tonnes of CO<code class="reqn">_2</code>-equivalents.</p>
</dd>
<dt><code>nitrous_oxide</code></dt><dd><p>Total nitrous oxide emissions, measured in million tonnes of CO<code class="reqn">_2</code>-equivalents.</p>
</dd>
<dt><code>primary_energy_consumption</code></dt><dd><p>Primary energy consumption, measured in terawatt-hours per year.</p>
</dd>
<dt><code>population</code></dt><dd><p>Population by country, available from 1800 to 2021 based on Gapminder data, HYDE, and UN Population Division (2019) estimates.</p>
</dd>
<dt><code>gdp</code></dt><dd><p>Gross domestic product measured in international-$ using 2011 prices to adjust for price changes over time (inflation) and price differences between countries. Calculated by multiplying GDP per capita with population.</p>
</dd>
<dt><code>continent</code></dt><dd><p>Continent.  Caribbean countries are distinguished from other North American countries.  Additionally a level called <code>"Redundant"</code> is included to parse redundant entries in the <code>country</code> column, e.g., the &ldquo;countries&rdquo; <code>Libya</code> and <code>Africa</code> contain redundant information.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Thanks to BIOL 6651 students at ISU who annotated these data: Laurel Faurot, Sawyer Finley, Spencer Roop, Therese Balkenbush, Lauren Tucker, Jessica Call and Riley Lanfear.
</p>


<h3>Source</h3>

<p><a href="https://github.com/owid/co2-data">https://github.com/owid/co2-data</a>
</p>


<h3>References</h3>

<p>According to Our World in Data (<a href="https://ourworldindata.org/">https://ourworldindata.org/</a>), CO<code class="reqn">_2</code> data are sourced from the Global Carbon Project (<a href="https://www.globalcarbonproject.org">https://www.globalcarbonproject.org</a>) which releases updates of CO<code class="reqn">_2</code> emissions data annually. Greenhouse gas emissions (including methane, and nitrous oxide) are sourced from the CAIT Climate Data Explorer (<a href="https://www.climatewatchdata.org:443/?source=cait">https://www.climatewatchdata.org:443/?source=cait</a>), and downloaded from the Climate Watch Portal (<a href="https://www.climatewatchdata.org">https://www.climatewatchdata.org</a>. Energy consumption data this data are sourced from a combination of two sources The Statistical Review of World Energy
<a href="https://www.bp.com/en/global/corporate/energy-economics.html">https://www.bp.com/en/global/corporate/energy-economics.html</a> and World Bank Development Indicators
<a href="https://databank.worldbank.org/source/world-development-indicators">https://databank.worldbank.org/source/world-development-indicators</a>.  Although The Statistical Review of World Energy is published annually, it does not provide data for all countries. For countries absent from this dataset, we calculated primary energy by multiplying the World Bank, World Development Indicators metric Energy use per capita by total population figures. The World Bank sources its metric from the International Energy Agency (IEA). Other variables were collected from a variety of sources including the United Nations, Gapminder, and the Maddison Project Database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(world.emissions)
</code></pre>

<hr>
<h2 id='world.pop'>Population levels in various countries from 1980-2006</h2><span id='topic+world.pop'></span>

<h3>Description</h3>

<p>Population levels of 13 countries from 1980-2006.  Population numbers are rounded to the nearest 100,000.  More up-to-date data can be found in this package at <code><a href="#topic+world.emissions">world.emissions</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(world.pop)</code></pre>


<h3>Format</h3>

<p>The dataframe contains 14 columns
</p>

<dl>
<dt><code>Year</code></dt><dd><p>The year of population measurements (1980-2006)</p>
</dd>   
<dt><code>Afghanistan</code></dt><dd><p>Population in Afghanistan from 1980-2006, rounded to the nearest 100,000.</p>
</dd>         
<dt><code>Brazil</code></dt><dd><p>Population in Brazil...</p>
</dd>
<dt><code>Canada</code></dt><dd><p>Population in Canada...</p>
</dd>
<dt><code>China</code></dt><dd><p>Population in China...</p>
</dd>
<dt><code>Finland</code></dt><dd><p>Population in Finland...</p>
</dd>
<dt><code>Italy</code></dt><dd><p>Population in Italy...</p>
</dd>        
<dt><code>Japan</code></dt><dd><p>Population in Japan...</p>
</dd>
<dt><code>Kenya</code></dt><dd><p>Population in Kenya...</p>
</dd>
<dt><code>Mexico</code></dt><dd><p>Population in Mexico...</p>
</dd>        
<dt><code>Saudi.Arabia</code></dt><dd><p>Population in Saudi Arabia...</p>
</dd>
<dt><code>United.Arab.Emirates</code></dt><dd><p>Population in the United Arab Emirates...</p>
</dd>
<dt><code>United.States</code></dt><dd><p>Population in United States...</p>
</dd>
<dt><code>World.Total</code></dt><dd><p>Population totals for the world...</p>
</dd>
</dl>



<h3>Source</h3>

<p>US census bureau: <a href="https://www.census.gov/programs-surveys/international-programs/about/idb.html">https://www.census.gov/programs-surveys/international-programs/about/idb.html</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
