<!DOCTYPE html><html lang="en"><head><title>Help for package ldmppr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ldmppr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ldmppr-package'><p>ldmppr: Estimate and Simulate from Location Dependent Marked Point Processes</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#C_theta2_i'><p>calculates c_theta</p></a></li>
<li><a href='#check_model_fit'><p>Check the fit of estimated self-correcting model on the reference point pattern dataset</p></a></li>
<li><a href='#conditional_sum'><p>calculates sum of values &lt; t</p></a></li>
<li><a href='#conditional_sum_logical'><p>calculates sum of values &lt; t</p></a></li>
<li><a href='#dist_one_dim'><p>calculates distance in one dim</p></a></li>
<li><a href='#estimate_parameters_sc'><p>Estimate parameters of the self-correcting model using log-likelihood optimization</p></a></li>
<li><a href='#estimate_parameters_sc_parallel'><p>Estimate parameters of the self-correcting model using log-likelihood maximization in parallel</p></a></li>
<li><a href='#extract_covars'><p>Extract covariate values from a set of rasters</p></a></li>
<li><a href='#full_product'><p>calculates full product for one grid point</p></a></li>
<li><a href='#full_sc_lhood'><p>calculates full self-correcting log-likelihood</p></a></li>
<li><a href='#generate_mpp'><p>Generate a marked process given locations and marks</p></a></li>
<li><a href='#interaction_st'><p>calculates spatio-temporal interaction</p></a></li>
<li><a href='#medium_example_data'><p>Medium Example Data</p></a></li>
<li><a href='#part_1_1_full'><p>calculates part 1-1 full</p></a></li>
<li><a href='#part_1_2_full'><p>calculates part 1-2 full</p></a></li>
<li><a href='#part_1_3_full'><p>calculates part 1-3</p></a></li>
<li><a href='#part_1_4_full'><p>calculates part 1-4</p></a></li>
<li><a href='#part_1_full'><p>calculates part 1 of the likelihood</p></a></li>
<li><a href='#part_2_full'><p>calculates part 2 of the likelihood</p></a></li>
<li><a href='#plot_mpp'><p>Plot a marked point process</p></a></li>
<li><a href='#power_law_mapping'><p>Gentle decay (power-law) mapping function from sizes to arrival times</p></a></li>
<li><a href='#predict_marks'><p>Predict values from the mark distribution</p></a></li>
<li><a href='#scale_rasters'><p>Scale a set of rasters</p></a></li>
<li><a href='#sim_spatial_sc'><p>Simulate the spatial component of the self-correcting model</p></a></li>
<li><a href='#sim_temporal_sc'><p>Simulate the temporal component of the self-correcting model</p></a></li>
<li><a href='#simulate_mpp'><p>Simulate a realization of a location dependent marked point process</p></a></li>
<li><a href='#simulate_sc'><p>Simulate from the self-correcting model</p></a></li>
<li><a href='#small_example_data'><p>Small Example Data</p></a></li>
<li><a href='#spat_interaction'><p>calculates spatial interaction</p></a></li>
<li><a href='#temporal_sc'><p>calculates temporal likelihood</p></a></li>
<li><a href='#toroidal_dist_matrix_optimized'><p>Optimized function to compute toroidal distance matrix over a rectangular domain</p></a></li>
<li><a href='#train_mark_model'><p>Train a flexible model for the mark distribution</p></a></li>
<li><a href='#vec_dist'><p>calculates euclidean distance</p></a></li>
<li><a href='#vec_to_mat_dist'><p>calculates euclidean distance between a vector and a matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimate and Simulate from Location Dependent Marked Point
Processes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lane Drew &lt;lanetdrew@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A suite of tools for estimating, assessing model fit, simulating from, and visualizing location dependent marked point processes characterized by regularity in the pattern.
    You provide a reference marked point process, a set of raster images containing location specific covariates, and select the estimation algorithm and type of mark model.
    'ldmppr' estimates the process and mark models and allows you to check the appropriateness of the model using a variety of diagnostic tools.
    Once a satisfactory model fit is obtained, you can simulate from the model and visualize the results.
    Documentation for the package 'ldmppr' is available in the form of a vignette.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.12), terra, doParallel, xgboost, ranger, parsnip,
dials, bundle, recipes, rsample, tune, workflows, magrittr,
hardhat, ggplot2, spatstat.geom, spatstat.explore, nloptr, GET,
progress, dplyr, future, furrr, yardstick</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lanedrew/ldmppr">https://github.com/lanedrew/ldmppr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lanedrew/ldmppr/issues">https://github.com/lanedrew/ldmppr/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-24 20:44:49 UTC; lanedrew</td>
</tr>
<tr>
<td>Author:</td>
<td>Lane Drew <a href="https://orcid.org/0009-0006-5427-4092"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  Andee Kaplan <a href="https://orcid.org/0000-0002-2940-889X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-24 21:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ldmppr-package'>ldmppr: Estimate and Simulate from Location Dependent Marked Point Processes</h2><span id='topic+ldmppr'></span><span id='topic+ldmppr-package'></span>

<h3>Description</h3>

<p>A suite of tools for estimating, assessing model fit, simulating from, and visualizing location dependent marked point processes characterized by regularity in the pattern. You provide a reference marked point process, a set of raster images containing location specific covariates, and select the estimation algorithm and type of mark model. 'ldmppr' estimates the process and mark models and allows you to check the appropriateness of the model using a variety of diagnostic tools. Once a satisfactory model fit is obtained, you can simulate from the model and visualize the results. Documentation for the package 'ldmppr' is available in the form of a vignette.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Lane Drew <a href="mailto:lanetdrew@gmail.com">lanetdrew@gmail.com</a> (<a href="https://orcid.org/0009-0006-5427-4092">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Andee Kaplan (<a href="https://orcid.org/0000-0002-2940-889X">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/lanedrew/ldmppr">https://github.com/lanedrew/ldmppr</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/lanedrew/ldmppr/issues">https://github.com/lanedrew/ldmppr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling 'rhs(lhs)'.
</p>

<hr>
<h2 id='C_theta2_i'>calculates c_theta</h2><span id='topic+C_theta2_i'></span>

<h3>Description</h3>

<p>calculates c_theta
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C_theta2_i(xgrid, ygrid, tgrid, data, params, bounds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="C_theta2_i_+3A_xgrid">xgrid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="C_theta2_i_+3A_ygrid">ygrid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="C_theta2_i_+3A_tgrid">tgrid</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="C_theta2_i_+3A_data">data</code></td>
<td>
<p>a matrix of data.</p>
</td></tr>
<tr><td><code id="C_theta2_i_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
<tr><td><code id="C_theta2_i_+3A_bounds">bounds</code></td>
<td>
<p>a vector of bounds for time, x, and y.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the product.
</p>

<hr>
<h2 id='check_model_fit'>Check the fit of estimated self-correcting model on the reference point pattern dataset</h2><span id='topic+check_model_fit'></span>

<h3>Description</h3>

<p>Allows the user to perform global envelope tests for the nonparametric L, F, G, J, E, and V summary functions from the <code>spatstat</code> package.
These tests serve as a goodness of fit measure for the estimated model relative to the reference dataset of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_model_fit(
  reference_data,
  t_min = 0,
  t_max = 1,
  sc_params = NULL,
  anchor_point = NULL,
  raster_list = NULL,
  scaled_rasters = FALSE,
  mark_model = NULL,
  xy_bounds = NULL,
  include_comp_inds = FALSE,
  thinning = TRUE,
  correction = "none",
  competition_radius = 15,
  n_sim = 2500,
  save_sims = TRUE,
  verbose = TRUE,
  seed = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_model_fit_+3A_reference_data">reference_data</code></td>
<td>
<p>a ppp object for the reference dataset.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_t_min">t_min</code></td>
<td>
<p>minimum value for time.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_t_max">t_max</code></td>
<td>
<p>maximum value for time.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_sc_params">sc_params</code></td>
<td>
<p>vector of parameter values corresponding to (alpha_1, beta_1, gamma_1, alpha_2, beta_2, alpha_3, beta_3, gamma_3).</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_anchor_point">anchor_point</code></td>
<td>
<p>vector of (x,y) coordinates of point to condition on.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_raster_list">raster_list</code></td>
<td>
<p>a list of raster objects.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_scaled_rasters">scaled_rasters</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether the rasters have been scaled.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_mark_model">mark_model</code></td>
<td>
<p>a model object (typically from <code>train_mark_model</code>).</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>a vector of domain bounds (2 for x, 2 for y).</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_include_comp_inds">include_comp_inds</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to generate and use competition indices as covariates.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_thinning">thinning</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to use the thinned or unthinned simulated values.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_correction">correction</code></td>
<td>
<p>type of correction to apply (&quot;none&quot; or &quot;toroidal&quot;).</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_competition_radius">competition_radius</code></td>
<td>
<p>distance for competition radius if <code>include_comp_inds</code> is 'TRUE'.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_n_sim">n_sim</code></td>
<td>
<p>number of simulated datasets to generate.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_save_sims">save_sims</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to save and return the simulated datasets.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_verbose">verbose</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to show progress of model checking.</p>
</td></tr>
<tr><td><code id="check_model_fit_+3A_seed">seed</code></td>
<td>
<p>an integer value to set the seed for reproducibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function relies on the <code>spatstat</code> package for the calculation of the point pattern metrics
and the <code>GET</code> package for the global envelope tests. The L, F, G, J, E, and V functions are a collection of
non-parametric summary statistics that describe the spatial distribution of points and marks in a point pattern.
See the documentation for [spatstat.explore::Lest()], [spatstat.explore::Fest()], [spatstat.explore::Gest()],
[spatstat.explore::Jest()], [spatstat.explore::Emark()], and [spatstat.explore::Vmark()] for more information.
Also, see the [GET::global_envelope_test()] function for more information on the global envelope tests.
</p>


<h3>Value</h3>

<p>a list containing a combined global envelope test, individual global envelope tests for the L, F, G, J, E, and V functions, and simulated metric values (if specified).
</p>


<h3>References</h3>

<p>Baddeley, A., Rubak, E., &amp; Turner, R. (2015). *Spatial Point Patterns:
Methodology and Applications with R*. Chapman and Hall/CRC Press, London.
ISBN 9781482210200. Available at:
<a href="https://www.routledge.com/Spatial-Point-Patterns-Methodology-and-Applications-with-R/Baddeley-Rubak-Turner/p/book/9781482210200">https://www.routledge.com/Spatial-Point-Patterns-Methodology-and-Applications-with-R/Baddeley-Rubak-Turner/p/book/9781482210200</a>.
</p>
<p>Myllymäki, M., &amp; Mrkvička, T. (2023). GET: Global envelopes in R.
<em>arXiv:1911.06583 [stat.ME]</em>. <a href="https://doi.org/10.48550/arXiv.1911.06583">doi:10.48550/arXiv.1911.06583</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Note: The example below is provided for illustrative purposes and may take some time to run.

# Load the small example data
data(small_example_data)

# Load the example mark model that previously was trained on the small example data
file_path &lt;- system.file("extdata", "example_mark_model.rds", package = "ldmppr")
mark_model &lt;- bundle::unbundle(readRDS(file_path))

# Load the raster files
raster_paths &lt;- list.files(system.file("extdata", package = "ldmppr"),
                           pattern = "\\.tif$", full.names = TRUE)
raster_paths &lt;- raster_paths[!grepl("_med\\.tif$", raster_paths)]
rasters &lt;- lapply(raster_paths, terra::rast)

# Scale the rasters
scaled_raster_list &lt;- scale_rasters(rasters)

# Generate the reference pattern
reference_data &lt;- generate_mpp(
  locations = small_example_data[, c("x", "y")],
  marks = small_example_data$size,
  xy_bounds = c(0, 25, 0, 25)
)

# Define an anchor point
M_n &lt;- as.matrix(small_example_data[1, c("x", "y")])

# Specify the estimated parameters of the self-correcting process
# Note: These would generally be estimated using estimate_parameters_sc
# or estimate_parameters_sc_parallel. These values are estimates from
# the small_example_data generating script.
estimated_parameters &lt;- c(
  1.42936311, 8.59251417, 0.02153924, 1.89763856,
  2.33256061, 1.09522235, 2.66250000, 0.16499789
)

# Check the model fit
example_model_fit &lt;- check_model_fit(
  reference_data = reference_data,
  t_min = 0,
  t_max = 1,
  sc_params = estimated_parameters,
  anchor_point = M_n,
  raster_list = scaled_raster_list,
  scaled_rasters = TRUE,
  mark_model = mark_model,
  xy_bounds = c(0, 25, 0, 25),
  include_comp_inds = TRUE,
  thinning = TRUE,
  correction = "none",
  competition_radius = 10,
  n_sim = 100,
  save_sims = FALSE,
  verbose = TRUE,
  seed = 90210
)

plot(example_model_fit$combined_env)

</code></pre>

<hr>
<h2 id='conditional_sum'>calculates sum of values &lt; t</h2><span id='topic+conditional_sum'></span>

<h3>Description</h3>

<p>calculates sum of values &lt; t
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditional_sum(obs_t, eval_t, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conditional_sum_+3A_obs_t">obs_t</code></td>
<td>
<p>a vector of observed t values.</p>
</td></tr>
<tr><td><code id="conditional_sum_+3A_eval_t">eval_t</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="conditional_sum_+3A_y">y</code></td>
<td>
<p>a vector of values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the conditional sum.
</p>

<hr>
<h2 id='conditional_sum_logical'>calculates sum of values &lt; t</h2><span id='topic+conditional_sum_logical'></span>

<h3>Description</h3>

<p>calculates sum of values &lt; t
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditional_sum_logical(obs_t, eval_t, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conditional_sum_logical_+3A_obs_t">obs_t</code></td>
<td>
<p>a vector of observed t values.</p>
</td></tr>
<tr><td><code id="conditional_sum_logical_+3A_eval_t">eval_t</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="conditional_sum_logical_+3A_y">y</code></td>
<td>
<p>a vector of values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the conditional sum.
</p>

<hr>
<h2 id='dist_one_dim'>calculates distance in one dim</h2><span id='topic+dist_one_dim'></span>

<h3>Description</h3>

<p>calculates distance in one dim
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist_one_dim(eval_t, obs_t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dist_one_dim_+3A_eval_t">eval_t</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="dist_one_dim_+3A_obs_t">obs_t</code></td>
<td>
<p>a vector of t values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>distance between a single t and the vector of all t values.
</p>

<hr>
<h2 id='estimate_parameters_sc'>Estimate parameters of the self-correcting model using log-likelihood optimization</h2><span id='topic+estimate_parameters_sc'></span>

<h3>Description</h3>

<p>Estimate the parameters of the self-correcting model using the [nloptr::nloptr()] function given a formatted dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_parameters_sc(
  data,
  x_grid = NULL,
  y_grid = NULL,
  t_grid = NULL,
  parameter_inits = NULL,
  upper_bounds = NULL,
  opt_algorithm = "NLOPT_LN_SBPLX",
  nloptr_options = list(maxeval = 400, xtol_rel = 1e-05, maxtime = NULL),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_parameters_sc_+3A_data">data</code></td>
<td>
<p>a matrix or data frame of times and locations in the form (time, x, y).</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_x_grid">x_grid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_y_grid">y_grid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_t_grid">t_grid</code></td>
<td>
<p>a vector of grid values for t.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_parameter_inits">parameter_inits</code></td>
<td>
<p>a vector of parameter initialization values.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_upper_bounds">upper_bounds</code></td>
<td>
<p>a vector of upper bounds for time, x, and y.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_opt_algorithm">opt_algorithm</code></td>
<td>
<p>the NLopt algorithm to use for optimization.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_nloptr_options">nloptr_options</code></td>
<td>
<p>a list of named options for [nloptr::nloptr()] including &quot;maxeval&quot;, &quot;xtol_rel&quot;, and &quot;maxtime&quot;.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_+3A_verbose">verbose</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to show progress of optimization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the parameters of the self-correcting model presented in Møller et al. (2016) using the full likelihood.
Details regarding the self-correcting model and the estimation procedure can be found in the references.
</p>


<h3>Value</h3>

<p>an [nloptr::nloptr()] object with details of the optimization including solution.
</p>


<h3>References</h3>

<p>Møller, J., Ghorbani, M., &amp; Rubak, E. (2016). Mechanistic spatio-temporal point process models
for marked point processes, with a view to forest stand data. <em>Biometrics</em>, 72(3), 687–696.
<a href="https://doi.org/10.1111/biom.12466">doi:10.1111/biom.12466</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the small example data
data(small_example_data)
small_example_data &lt;- small_example_data %&gt;%
  dplyr::mutate(time = power_law_mapping(size, .5)) %&gt;%
  dplyr::select(time, x, y)

# Define the grid values
x_grid &lt;- seq(0, 25, length.out = 5)
y_grid &lt;- seq(0, 25, length.out = 5)
t_grid &lt;- seq(0, 1, length.out = 5)

# Define the parameter initialization values
parameter_inits &lt;- c(1.5, 8.5, .015, 1.5, 3.2, .75, 3, .08)

# Define the upper bounds
upper_bounds &lt;- c(1, 25, 25)

# Estimate the parameters
estimate_parameters_sc(
  data = small_example_data,
  x_grid = x_grid,
  y_grid = y_grid,
  t_grid = t_grid,
  parameter_inits = parameter_inits,
  upper_bounds = upper_bounds,
  opt_algorithm = "NLOPT_LN_SBPLX",
  nloptr_options = list(
    maxeval = 25,
    xtol_rel = 1e-2
  ),
  verbose = TRUE
)

</code></pre>

<hr>
<h2 id='estimate_parameters_sc_parallel'>Estimate parameters of the self-correcting model using log-likelihood maximization in parallel</h2><span id='topic+estimate_parameters_sc_parallel'></span>

<h3>Description</h3>

<p>Estimate the parameters of the self-correcting model using [nloptr::nloptr()] given a set of delta values.
Makes use of parallel computation to allow the user to identify the optimal delta value more quickly
given available computational resources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_parameters_sc_parallel(
  data,
  x_grid = NULL,
  y_grid = NULL,
  t_grid = NULL,
  delta_values = NULL,
  parameter_inits = NULL,
  upper_bounds = NULL,
  opt_algorithm = "NLOPT_LN_SBPLX",
  nloptr_options = list(maxeval = 400, xtol_rel = 1e-05, maxtime = NULL),
  verbose = TRUE,
  num_cores = parallel::detectCores() - 1,
  set_future_plan = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_parameters_sc_parallel_+3A_data">data</code></td>
<td>
<p>a data frame of locations and sizes labelled (&quot;x&quot;, &quot;y&quot;, &quot;size&quot;).</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_x_grid">x_grid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_y_grid">y_grid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_t_grid">t_grid</code></td>
<td>
<p>a vector of grid values for t.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_delta_values">delta_values</code></td>
<td>
<p>a vector of delta values.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_parameter_inits">parameter_inits</code></td>
<td>
<p>a vector of parameter initialization values.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_upper_bounds">upper_bounds</code></td>
<td>
<p>a vector of upper bounds for time, x, and y.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_opt_algorithm">opt_algorithm</code></td>
<td>
<p>the NLopt algorithm to use for maximization.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_nloptr_options">nloptr_options</code></td>
<td>
<p>a list of named options for nloptr including &quot;maxeval&quot;, &quot;xtol_rel&quot;, and &quot;maxtime&quot;.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_verbose">verbose</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to show progress of optimization.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_num_cores">num_cores</code></td>
<td>
<p>number of cores to use in parallel estimation.</p>
</td></tr>
<tr><td><code id="estimate_parameters_sc_parallel_+3A_set_future_plan">set_future_plan</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to change the parallelization plan for use in the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details regarding the self-correcting model and the estimation procedure can be found in the references.
</p>


<h3>Value</h3>

<p>a list containing the optimal obtained values and the full [nloptr::nloptr()] results for all provided delta values.
</p>


<h3>References</h3>

<p>Møller, J., Ghorbani, M., &amp; Rubak, E. (2016). Mechanistic spatio-temporal point process models
for marked point processes, with a view to forest stand data. <em>Biometrics</em>, 72(3), 687–696.
<a href="https://doi.org/10.1111/biom.12466">doi:10.1111/biom.12466</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: This function is designed to be run in parallel and may be computationally intensive.


# Load the small example data
data(small_example_data)

# Define the grid values
x_grid &lt;- seq(0, 25, length.out = 5)
y_grid &lt;- seq(0, 25, length.out = 5)
t_grid &lt;- seq(0, 1, length.out = 5)

# Define the delta values
delta_values &lt;- seq(0.25, 1, by = 0.25)

# Define the parameter initialization values
parameter_inits &lt;- c(1.5, 8.5, .015, 1.5, 3.2, .75, 3, .08)

# Define the upper bounds
upper_bounds &lt;- c(1, 25, 25)

# Estimate the parameters in parallel
estimate_parameters_sc_parallel(
  data = small_example_data,
  x_grid = x_grid,
  y_grid = y_grid,
  t_grid = t_grid,
  delta_values = delta_values,
  parameter_inits = parameter_inits,
  upper_bounds = upper_bounds,
  opt_algorithm = "NLOPT_LN_SBPLX",
  nloptr_options = list(
    maxeval = 50,
    xtol_rel = 1e-2
  ),
  verbose = TRUE,
  set_future_plan = TRUE
)


</code></pre>

<hr>
<h2 id='extract_covars'>Extract covariate values from a set of rasters</h2><span id='topic+extract_covars'></span>

<h3>Description</h3>

<p>Extract covariate values from a set of rasters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_covars(locations, raster_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_covars_+3A_locations">locations</code></td>
<td>
<p>a data frame of (x,y) locations with names &quot;x&quot; and &quot;y&quot;.</p>
</td></tr>
<tr><td><code id="extract_covars_+3A_raster_list">raster_list</code></td>
<td>
<p>a list of raster objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of covariates drawn from the provided rasters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example raster data
raster_paths &lt;- list.files(system.file("extdata", package = "ldmppr"),
  pattern = "\\.tif$", full.names = TRUE
)
rasters &lt;- lapply(raster_paths, terra::rast)

# Scale the rasters
scaled_raster_list &lt;- scale_rasters(rasters)

# Load example locations
locations &lt;- small_example_data %&gt;%
  dplyr::select(x, y) %&gt;%
  as.matrix()

# Extract covariates
example_covars &lt;- extract_covars(locations, scaled_raster_list)
head(example_covars)

</code></pre>

<hr>
<h2 id='full_product'>calculates full product for one grid point</h2><span id='topic+full_product'></span>

<h3>Description</h3>

<p>calculates full product for one grid point
</p>


<h3>Usage</h3>

<pre><code class='language-R'>full_product(xgrid, ygrid, tgrid, data, params)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="full_product_+3A_xgrid">xgrid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="full_product_+3A_ygrid">ygrid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="full_product_+3A_tgrid">tgrid</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="full_product_+3A_data">data</code></td>
<td>
<p>a matrix of data.</p>
</td></tr>
<tr><td><code id="full_product_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the product.
</p>

<hr>
<h2 id='full_sc_lhood'>calculates full self-correcting log-likelihood</h2><span id='topic+full_sc_lhood'></span>

<h3>Description</h3>

<p>calculates full self-correcting log-likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>full_sc_lhood(xgrid, ygrid, tgrid, tobs, data, params, bounds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="full_sc_lhood_+3A_xgrid">xgrid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="full_sc_lhood_+3A_ygrid">ygrid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="full_sc_lhood_+3A_tgrid">tgrid</code></td>
<td>
<p>a vector of grid values for t.</p>
</td></tr>
<tr><td><code id="full_sc_lhood_+3A_tobs">tobs</code></td>
<td>
<p>a vector of observed values for t.</p>
</td></tr>
<tr><td><code id="full_sc_lhood_+3A_data">data</code></td>
<td>
<p>a matrix of times and locations.</p>
</td></tr>
<tr><td><code id="full_sc_lhood_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
<tr><td><code id="full_sc_lhood_+3A_bounds">bounds</code></td>
<td>
<p>a vector of bounds for time, x, and y.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>evaluation of full log-likelihood.
</p>

<hr>
<h2 id='generate_mpp'>Generate a marked process given locations and marks</h2><span id='topic+generate_mpp'></span>

<h3>Description</h3>

<p>Creates an object of class &quot;ppp&quot; that represents a marked point pattern in the two-dimensional plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_mpp(locations, marks = NULL, xy_bounds = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_mpp_+3A_locations">locations</code></td>
<td>
<p>a data frame of (x,y) locations with names &quot;x&quot; and &quot;y&quot;.</p>
</td></tr>
<tr><td><code id="generate_mpp_+3A_marks">marks</code></td>
<td>
<p>a vector of marks.</p>
</td></tr>
<tr><td><code id="generate_mpp_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>a vector of domain bounds (2 for x, 2 for y).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ppp object with marks.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data
data(small_example_data)

# Generate a marked point process
generate_mpp(
  locations = small_example_data %&gt;% dplyr::select(x, y),
  marks = small_example_data$size,
  xy_bounds = c(0, 25, 0, 25)
)

</code></pre>

<hr>
<h2 id='interaction_st'>calculates spatio-temporal interaction</h2><span id='topic+interaction_st'></span>

<h3>Description</h3>

<p>calculates spatio-temporal interaction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interaction_st(data, params)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interaction_st_+3A_data">data</code></td>
<td>
<p>a matrix of times and locations.</p>
</td></tr>
<tr><td><code id="interaction_st_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of interaction probabilities for every point.
</p>

<hr>
<h2 id='medium_example_data'>Medium Example Data</h2><span id='topic+medium_example_data'></span>

<h3>Description</h3>

<p>A medium sized example dataset consisting of 111 observations in a (50m x 50m) square domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("medium_example_data")
</code></pre>


<h3>Format</h3>

<p>## 'medium_example_data'
A data frame with 111 rows and 3 columns:
</p>

<dl>
<dt>x</dt><dd><p>x coordinate</p>
</dd>
<dt>y</dt><dd><p>y coordinate</p>
</dd>
<dt>size</dt><dd><p>Size</p>
</dd>
</dl>
<p>...

</p>


<h3>Details</h3>

<p>The dataset was generated using the Snodgrass dataset available at https://data.ess-dive.lbl.gov/view/doi:10.15485/2476543.
</p>
<p>The full code to generate this dataset is available in the package's 'data_raw' directory.
</p>


<h3>Source</h3>

<p>Real example dataset. Code to generate it can be found in 'data_raw/medium_example_data.R'.
</p>

<hr>
<h2 id='part_1_1_full'>calculates part 1-1 full</h2><span id='topic+part_1_1_full'></span>

<h3>Description</h3>

<p>calculates part 1-1 full
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part_1_1_full(data, params)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="part_1_1_full_+3A_data">data</code></td>
<td>
<p>a matrix of locations and times.</p>
</td></tr>
<tr><td><code id="part_1_1_full_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>full likelihood evaluation for part 1.
</p>

<hr>
<h2 id='part_1_2_full'>calculates part 1-2 full</h2><span id='topic+part_1_2_full'></span>

<h3>Description</h3>

<p>calculates part 1-2 full
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part_1_2_full(data, params)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="part_1_2_full_+3A_data">data</code></td>
<td>
<p>a matrix of locations and times.</p>
</td></tr>
<tr><td><code id="part_1_2_full_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>full likelihood evaluation for part 2.
</p>

<hr>
<h2 id='part_1_3_full'>calculates part 1-3</h2><span id='topic+part_1_3_full'></span>

<h3>Description</h3>

<p>calculates part 1-3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part_1_3_full(xgrid, ygrid, tgrid, data, params, bounds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="part_1_3_full_+3A_xgrid">xgrid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="part_1_3_full_+3A_ygrid">ygrid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="part_1_3_full_+3A_tgrid">tgrid</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="part_1_3_full_+3A_data">data</code></td>
<td>
<p>a matrix of times and locations.</p>
</td></tr>
<tr><td><code id="part_1_3_full_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
<tr><td><code id="part_1_3_full_+3A_bounds">bounds</code></td>
<td>
<p>a vector of time, x, and y bounds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>full likelihood evaluation for part 3.
</p>

<hr>
<h2 id='part_1_4_full'>calculates part 1-4</h2><span id='topic+part_1_4_full'></span>

<h3>Description</h3>

<p>calculates part 1-4
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part_1_4_full(data, params)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="part_1_4_full_+3A_data">data</code></td>
<td>
<p>a matrix of times and locations.</p>
</td></tr>
<tr><td><code id="part_1_4_full_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>full likelihood evaluation for part 4.
</p>

<hr>
<h2 id='part_1_full'>calculates part 1 of the likelihood</h2><span id='topic+part_1_full'></span>

<h3>Description</h3>

<p>calculates part 1 of the likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part_1_full(xgrid, ygrid, tgrid, data, params, bounds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="part_1_full_+3A_xgrid">xgrid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="part_1_full_+3A_ygrid">ygrid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="part_1_full_+3A_tgrid">tgrid</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="part_1_full_+3A_data">data</code></td>
<td>
<p>a matrix of times and locations.</p>
</td></tr>
<tr><td><code id="part_1_full_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
<tr><td><code id="part_1_full_+3A_bounds">bounds</code></td>
<td>
<p>a vector of bounds for time, x, and y.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>full evaluation of first part of likelihood.
</p>

<hr>
<h2 id='part_2_full'>calculates part 2 of the likelihood</h2><span id='topic+part_2_full'></span>

<h3>Description</h3>

<p>calculates part 2 of the likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part_2_full(xgrid, ygrid, tgrid, data, params, bounds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="part_2_full_+3A_xgrid">xgrid</code></td>
<td>
<p>a vector of grid values for x.</p>
</td></tr>
<tr><td><code id="part_2_full_+3A_ygrid">ygrid</code></td>
<td>
<p>a vector of grid values for y.</p>
</td></tr>
<tr><td><code id="part_2_full_+3A_tgrid">tgrid</code></td>
<td>
<p>a vector of grid values for t.</p>
</td></tr>
<tr><td><code id="part_2_full_+3A_data">data</code></td>
<td>
<p>a matrix of times and locations.</p>
</td></tr>
<tr><td><code id="part_2_full_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
<tr><td><code id="part_2_full_+3A_bounds">bounds</code></td>
<td>
<p>a vector of bounds for time, x, and y.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>full evaluation of second part of likelihood.
</p>

<hr>
<h2 id='plot_mpp'>Plot a marked point process</h2><span id='topic+plot_mpp'></span>

<h3>Description</h3>

<p>Plot a marked point process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_mpp(mpp_data, pattern_type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_mpp_+3A_mpp_data">mpp_data</code></td>
<td>
<p>ppp object with marks or data frame with columns (x, y, size).</p>
</td></tr>
<tr><td><code id="plot_mpp_+3A_pattern_type">pattern_type</code></td>
<td>
<p>type of pattern to plot (&quot;reference&quot; or &quot;simulated&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot object of the marked point process.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data
data(small_example_data)
mpp_data &lt;- generate_mpp(
  locations = small_example_data %&gt;% dplyr::select(x, y),
  marks = small_example_data$size,
  xy_bounds = c(0, 25, 0, 25)
)

# Plot the marked point process
plot_mpp(mpp_data, pattern_type = "reference")

</code></pre>

<hr>
<h2 id='power_law_mapping'>Gentle decay (power-law) mapping function from sizes to arrival times</h2><span id='topic+power_law_mapping'></span>

<h3>Description</h3>

<p>Gentle decay (power-law) mapping function from sizes to arrival times
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_law_mapping(sizes, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power_law_mapping_+3A_sizes">sizes</code></td>
<td>
<p>vector of sizes to be mapped to arrival times.</p>
</td></tr>
<tr><td><code id="power_law_mapping_+3A_delta">delta</code></td>
<td>
<p>numeric value (greater than 0) for the exponent in the mapping function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of arrival times.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a vector of sizes
sizes &lt;- runif(100, 0, 100)

# Map the sizes to arrival times using a power-law mapping with delta = .5
power_law_mapping(sizes, .5)

</code></pre>

<hr>
<h2 id='predict_marks'>Predict values from the mark distribution</h2><span id='topic+predict_marks'></span>

<h3>Description</h3>

<p>Predict values from the mark distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_marks(
  sim_realization,
  raster_list = NULL,
  scaled_rasters = FALSE,
  mark_model = NULL,
  xy_bounds = NULL,
  include_comp_inds = FALSE,
  competition_radius = 15,
  correction = "none"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_marks_+3A_sim_realization">sim_realization</code></td>
<td>
<p>a data frame containing a thinned or unthinned realization from <code>simulate_sc</code>.</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_raster_list">raster_list</code></td>
<td>
<p>a list of raster objects.</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_scaled_rasters">scaled_rasters</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether the rasters have been scaled.</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_mark_model">mark_model</code></td>
<td>
<p>a model object (typically from <code>train_mark_model</code>).</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>a vector of domain bounds (2 for x, 2 for y).</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_include_comp_inds">include_comp_inds</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to generate and use competition indices as covariates.</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_competition_radius">competition_radius</code></td>
<td>
<p>distance for competition radius if <code>include_comp_inds</code> is 'TRUE'.</p>
</td></tr>
<tr><td><code id="predict_marks_+3A_correction">correction</code></td>
<td>
<p>type of correction to apply (&quot;none&quot; or &quot;toroidal&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of predicted mark values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate a realization
generating_parameters &lt;- c(2, 8, .02, 2.5, 3, 1, 2.5, .2)
M_n &lt;- matrix(c(10, 14), ncol = 1)
generated_locs &lt;- simulate_sc(
  t_min = 0,
  t_max = 1,
  sc_params = generating_parameters,
  anchor_point = M_n,
  xy_bounds = c(0, 25, 0, 25)
)

# Load the raster files
raster_paths &lt;- list.files(system.file("extdata", package = "ldmppr"),
  pattern = "\\.tif$", full.names = TRUE
)
rasters &lt;- lapply(raster_paths, terra::rast)

# Scale the rasters
scaled_raster_list &lt;- scale_rasters(rasters)

# Load the example mark model
file_path &lt;- system.file("extdata", "example_mark_model.rds", package = "ldmppr")
example_mark_model &lt;- readRDS(file_path)

# Unbundle the model
mark_model &lt;- bundle::unbundle(example_mark_model)

# Predict the mark values
predict_marks(
  sim_realization = generated_locs$thinned,
  raster_list = scaled_raster_list,
  scaled_rasters = TRUE,
  mark_model = mark_model,
  xy_bounds = c(0, 25, 0, 25),
  include_comp_inds = TRUE,
  competition_radius = 10,
  correction = "none"
)

</code></pre>

<hr>
<h2 id='scale_rasters'>Scale a set of rasters</h2><span id='topic+scale_rasters'></span>

<h3>Description</h3>

<p>Scale a set of rasters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_rasters(raster_list, reference_resolution = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scale_rasters_+3A_raster_list">raster_list</code></td>
<td>
<p>a list of raster objects.</p>
</td></tr>
<tr><td><code id="scale_rasters_+3A_reference_resolution">reference_resolution</code></td>
<td>
<p>the resolution to resample the rasters to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of scaled raster objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create two example rasters
rast_a &lt;- terra::rast(
  ncol = 10, nrow = 10,
  xmin = 0, xmax = 10,
  ymin = 0, ymax = 10,
  vals = runif(100)
)

rast_b &lt;- terra::rast(
  ncol = 10, nrow = 10,
  xmin = 0, xmax = 10,
  ymin = 0, ymax = 10,
  vals = runif(100)
)

# Scale example rasters in a list
rast_list &lt;- list(rast_a, rast_b)
scale_rasters(rast_list)

</code></pre>

<hr>
<h2 id='sim_spatial_sc'>Simulate the spatial component of the self-correcting model</h2><span id='topic+sim_spatial_sc'></span>

<h3>Description</h3>

<p>Simulate the spatial component of the self-correcting model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_spatial_sc(M_n, params, nsim_t, xy_bounds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_spatial_sc_+3A_m_n">M_n</code></td>
<td>
<p>a vector of (x,y)-coordinates for largest point.</p>
</td></tr>
<tr><td><code id="sim_spatial_sc_+3A_params">params</code></td>
<td>
<p>a vector of parameters (alpha_2, beta_2).</p>
</td></tr>
<tr><td><code id="sim_spatial_sc_+3A_nsim_t">nsim_t</code></td>
<td>
<p>number of points to simulate.</p>
</td></tr>
<tr><td><code id="sim_spatial_sc_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>vector of lower and upper bounds for the domain (2 for x, 2 for y).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of point locations in the (x,y)-plane.
</p>

<hr>
<h2 id='sim_temporal_sc'>Simulate the temporal component of the self-correcting model</h2><span id='topic+sim_temporal_sc'></span>

<h3>Description</h3>

<p>Simulate the temporal component of the self-correcting model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_temporal_sc(Tmin = 0, Tmax = 1, params = as.numeric(c(0, 0, 0)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_temporal_sc_+3A_tmin">Tmin</code></td>
<td>
<p>minimum time value.</p>
</td></tr>
<tr><td><code id="sim_temporal_sc_+3A_tmax">Tmax</code></td>
<td>
<p>maximum time value.</p>
</td></tr>
<tr><td><code id="sim_temporal_sc_+3A_params">params</code></td>
<td>
<p>a vector of parameters (alpha_1, beta_1, gamma_1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of thinned and unthinned temporal samples.
</p>

<hr>
<h2 id='simulate_mpp'>Simulate a realization of a location dependent marked point process</h2><span id='topic+simulate_mpp'></span>

<h3>Description</h3>

<p>Simulate a realization of a location dependent marked point process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_mpp(
  sc_params = NULL,
  t_min = 0,
  t_max = 1,
  anchor_point = NULL,
  raster_list = NULL,
  scaled_rasters = FALSE,
  mark_model = NULL,
  xy_bounds = NULL,
  include_comp_inds = FALSE,
  competition_radius = 15,
  correction = "none",
  thinning = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate_mpp_+3A_sc_params">sc_params</code></td>
<td>
<p>vector of parameter values corresponding to (alpha_1, beta_1, gamma_1, alpha_2, beta_2, alpha_3, beta_3, gamma_3).</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_t_min">t_min</code></td>
<td>
<p>minimum value for time.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_t_max">t_max</code></td>
<td>
<p>maximum value for time.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_anchor_point">anchor_point</code></td>
<td>
<p>vector of (x,y) coordinates of point to condition on.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_raster_list">raster_list</code></td>
<td>
<p>list of raster objects.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_scaled_rasters">scaled_rasters</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether the rasters have been scaled.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_mark_model">mark_model</code></td>
<td>
<p>a model object (typically from <code>train_mark_model</code>).</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>a vector of domain bounds (2 for x, 2 for y).</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_include_comp_inds">include_comp_inds</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to generate and use competition indices as covariates.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_competition_radius">competition_radius</code></td>
<td>
<p>distance for competition radius if <code>include_comp_inds</code> is 'TRUE'.</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_correction">correction</code></td>
<td>
<p>type of correction to apply (&quot;none&quot; or &quot;toroidal&quot;).</p>
</td></tr>
<tr><td><code id="simulate_mpp_+3A_thinning">thinning</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to thin the realization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the marked point process realization and the data frame of the realization.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specify the generating parameters of the self-correcting process
generating_parameters &lt;- c(2, 8, .02, 2.5, 3, 1, 2.5, .2)

# Specify an anchor point
M_n &lt;- matrix(c(10, 14), ncol = 1)

# Load the raster files
raster_paths &lt;- list.files(system.file("extdata", package = "ldmppr"),
  pattern = "\\.tif$", full.names = TRUE
)
raster_paths &lt;- raster_paths[!grepl("_med\\.tif$", raster_paths)]
rasters &lt;- lapply(raster_paths, terra::rast)

# Scale the rasters
scaled_raster_list &lt;- scale_rasters(rasters)

# Load the example mark model
file_path &lt;- system.file("extdata", "example_mark_model.rds", package = "ldmppr")
mark_model &lt;- bundle::unbundle(readRDS(file_path))

# Simulate a realization
example_mpp &lt;- simulate_mpp(
  sc_params = generating_parameters,
  t_min = 0,
  t_max = 1,
  anchor_point = M_n,
  raster_list = scaled_raster_list,
  scaled_rasters = TRUE,
  mark_model = mark_model,
  xy_bounds = c(0, 25, 0, 25),
  include_comp_inds = TRUE,
  competition_radius = 10,
  correction = "none",
  thinning = TRUE
)

# Plot the realization
plot_mpp(example_mpp$mpp, pattern_type = "simulated")

</code></pre>

<hr>
<h2 id='simulate_sc'>Simulate from the self-correcting model</h2><span id='topic+simulate_sc'></span>

<h3>Description</h3>

<p>Allows the user to simulate a realization from the self-correcting model
given a set of parameters and a point to condition on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_sc(
  t_min = 0,
  t_max = 1,
  sc_params = NULL,
  anchor_point = NULL,
  xy_bounds = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate_sc_+3A_t_min">t_min</code></td>
<td>
<p>minimum value for time.</p>
</td></tr>
<tr><td><code id="simulate_sc_+3A_t_max">t_max</code></td>
<td>
<p>maximum value for time.</p>
</td></tr>
<tr><td><code id="simulate_sc_+3A_sc_params">sc_params</code></td>
<td>
<p>vector of parameter values corresponding to (alpha_1, beta_1, gamma_1, alpha_2, beta_2, alpha_3, beta_3, gamma_3).</p>
</td></tr>
<tr><td><code id="simulate_sc_+3A_anchor_point">anchor_point</code></td>
<td>
<p>vector of (x,y) coordinates of point to condition on.</p>
</td></tr>
<tr><td><code id="simulate_sc_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>a vector of domain bounds (2 for x, 2 for y).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the thinned and unthinned simulation realizations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specify the generating parameters of the self-correcting process
generating_parameters &lt;- c(2, 8, .02, 2.5, 3, 1, 2.5, .2)

# Specify an anchor point
M_n &lt;- matrix(c(10, 14), ncol = 1)

# Simulate the self-correcting process
generated_locs &lt;- simulate_sc(
  t_min = 0,
  t_max = 1,
  sc_params = generating_parameters,
  anchor_point = M_n,
  xy_bounds = c(0, 25, 0, 25)
)

</code></pre>

<hr>
<h2 id='small_example_data'>Small Example Data</h2><span id='topic+small_example_data'></span>

<h3>Description</h3>

<p>A small example dataset for testing and examples consisting of 121 observations in a (25m x 25m) square domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("small_example_data")
</code></pre>


<h3>Format</h3>

<p>## 'small_example_data'
A data frame with 121 rows and 3 columns:
</p>

<dl>
<dt>x</dt><dd><p>x coordinate</p>
</dd>
<dt>y</dt><dd><p>y coordinate</p>
</dd>
<dt>size</dt><dd><p>Size</p>
</dd>
</dl>
<p>...

</p>


<h3>Details</h3>

<p>The dataset was generated using the example raster data and an exponential decay size function.
</p>
<p>The full code to generate this dataset is available in the package's 'data_raw' directory.
</p>


<h3>Source</h3>

<p>Simulated dataset. Code to generate it can be found in 'data_raw/small_example_data.R'.
</p>

<hr>
<h2 id='spat_interaction'>calculates spatial interaction</h2><span id='topic+spat_interaction'></span>

<h3>Description</h3>

<p>calculates spatial interaction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spat_interaction(Hist, newp, params)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spat_interaction_+3A_hist">Hist</code></td>
<td>
<p>a matrix of points.</p>
</td></tr>
<tr><td><code id="spat_interaction_+3A_newp">newp</code></td>
<td>
<p>a new point vector.</p>
</td></tr>
<tr><td><code id="spat_interaction_+3A_params">params</code></td>
<td>
<p>a vector of parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>calculated probability of new point.
</p>

<hr>
<h2 id='temporal_sc'>calculates temporal likelihood</h2><span id='topic+temporal_sc'></span>

<h3>Description</h3>

<p>calculates temporal likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>temporal_sc(params, eval_t, obs_t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="temporal_sc_+3A_params">params</code></td>
<td>
<p>a vector of parameters (alpha_1, beta_1, gamma_1).</p>
</td></tr>
<tr><td><code id="temporal_sc_+3A_eval_t">eval_t</code></td>
<td>
<p>a t value.</p>
</td></tr>
<tr><td><code id="temporal_sc_+3A_obs_t">obs_t</code></td>
<td>
<p>a vector of t values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>evaluation of full temporal likelihood.
</p>

<hr>
<h2 id='toroidal_dist_matrix_optimized'>Optimized function to compute toroidal distance matrix over a rectangular domain</h2><span id='topic+toroidal_dist_matrix_optimized'></span>

<h3>Description</h3>

<p>Optimized function to compute toroidal distance matrix over a rectangular domain
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toroidal_dist_matrix_optimized(location_matrix, x_bound, y_bound)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="toroidal_dist_matrix_optimized_+3A_location_matrix">location_matrix</code></td>
<td>
<p>a 2 column matrix of (x,y) coordinates.</p>
</td></tr>
<tr><td><code id="toroidal_dist_matrix_optimized_+3A_x_bound">x_bound</code></td>
<td>
<p>the upper bound for the x dimension.</p>
</td></tr>
<tr><td><code id="toroidal_dist_matrix_optimized_+3A_y_bound">y_bound</code></td>
<td>
<p>the upper bound for the y dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of toroidal distances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a matrix of locations
location_matrix &lt;- matrix(c(1, 2, 3, 4, 5, 6), ncol = 2)
x_bound &lt;- 10
y_bound &lt;- 10

# Compute the toroidal distance matrix
toroidal_dist_matrix_optimized(location_matrix, x_bound, y_bound)

</code></pre>

<hr>
<h2 id='train_mark_model'>Train a flexible model for the mark distribution</h2><span id='topic+train_mark_model'></span>

<h3>Description</h3>

<p>Trains a predictive model for the mark distribution of a spatio-temporal process.
Allows the user to incorporate location specific information and competition indices as
covariates in the mark model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_mark_model(
  data,
  raster_list = NULL,
  scaled_rasters = FALSE,
  model_type = "xgboost",
  xy_bounds = NULL,
  save_model = FALSE,
  save_path = NULL,
  parallel = TRUE,
  include_comp_inds = FALSE,
  competition_radius = 15,
  correction = "none",
  selection_metric = "rmse",
  cv_folds = 5,
  tuning_grid_size = 200,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="train_mark_model_+3A_data">data</code></td>
<td>
<p>a data frame containing named vectors x, y, size, and time.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_raster_list">raster_list</code></td>
<td>
<p>a list of raster objects.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_scaled_rasters">scaled_rasters</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether the rasters have been scaled.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_model_type">model_type</code></td>
<td>
<p>the machine learning model type (&quot;xgboost&quot; or &quot;random_forest&quot;).</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_xy_bounds">xy_bounds</code></td>
<td>
<p>a vector of domain bounds (2 for x, 2 for y).</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_save_model">save_model</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to save the generated model.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_save_path">save_path</code></td>
<td>
<p>path for saving the generated model.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_parallel">parallel</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to use parallelization in model training.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_include_comp_inds">include_comp_inds</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to generate and use competition indices as covariates.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_competition_radius">competition_radius</code></td>
<td>
<p>distance for competition radius if <code>include_comp_inds</code> is 'TRUE'.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_correction">correction</code></td>
<td>
<p>type of correction to apply (&quot;none&quot;, &quot;toroidal&quot;, or &quot;truncation&quot;).</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_selection_metric">selection_metric</code></td>
<td>
<p>metric to use for identifying the optimal model (&quot;rmse&quot; or &quot;mae&quot;).</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_cv_folds">cv_folds</code></td>
<td>
<p>number of cross-validation folds to use in model training.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_tuning_grid_size">tuning_grid_size</code></td>
<td>
<p>size of the tuning grid for hyperparameter tuning.</p>
</td></tr>
<tr><td><code id="train_mark_model_+3A_verbose">verbose</code></td>
<td>
<p>'TRUE' or 'FALSE' indicating whether to show progress of model training.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the raw trained model and a bundled model object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example raster data
raster_paths &lt;- list.files(system.file("extdata", package = "ldmppr"),
  pattern = "\\.tif$", full.names = TRUE
)
raster_paths &lt;- raster_paths[!grepl("_med\\.tif$", raster_paths)]
rasters &lt;- lapply(raster_paths, terra::rast)

# Scale the rasters
scaled_raster_list &lt;- scale_rasters(rasters)

# Load example locations
locations &lt;- small_example_data %&gt;%
  dplyr::mutate(time = power_law_mapping(size, .5))

# Train the model
train_mark_model(
  data = locations,
  raster_list = scaled_raster_list,
  scaled_rasters = TRUE,
  model_type = "xgboost",
  xy_bounds = c(0, 25, 0, 25),
  parallel = FALSE,
  include_comp_inds = FALSE,
  competition_radius = 10,
  correction = "none",
  selection_metric = "rmse",
  cv_folds = 3,
  tuning_grid_size = 2,
  verbose = TRUE
)

</code></pre>

<hr>
<h2 id='vec_dist'>calculates euclidean distance</h2><span id='topic+vec_dist'></span>

<h3>Description</h3>

<p>calculates euclidean distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec_dist(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vec_dist_+3A_x">x</code></td>
<td>
<p>a vector of x values.</p>
</td></tr>
<tr><td><code id="vec_dist_+3A_y">y</code></td>
<td>
<p>a vector of y values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the distance between the two vectors.
</p>

<hr>
<h2 id='vec_to_mat_dist'>calculates euclidean distance between a vector and a matrix</h2><span id='topic+vec_to_mat_dist'></span>

<h3>Description</h3>

<p>calculates euclidean distance between a vector and a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec_to_mat_dist(eval_u, x_col, y_col)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vec_to_mat_dist_+3A_eval_u">eval_u</code></td>
<td>
<p>a vector of x and y coordinates.</p>
</td></tr>
<tr><td><code id="vec_to_mat_dist_+3A_x_col">x_col</code></td>
<td>
<p>a vector of x coordinates.</p>
</td></tr>
<tr><td><code id="vec_to_mat_dist_+3A_y_col">y_col</code></td>
<td>
<p>a vector of y coordinates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of distances between a vector and each row of a matrix.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
