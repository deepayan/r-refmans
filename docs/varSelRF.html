<!DOCTYPE html><html><head><title>Help for package varSelRF</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {varSelRF}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#plot.varSelRF'><p>Plot a varSelRF object</p></a></li>
<li><a href='#plot.varSelRFBoot'><p>plot a varSelRFBoot object</p></a></li>
<li><a href='#randomVarImpsRF'><p> Variable importances from random forest on permuted class labels</p></a></li>
<li><a href='#randomVarImpsRFplot'><p>Plot random random variable importances</p></a></li>
<li><a href='#selProbPlot'><p>Selection probability plot for variable importance from random forests</p></a></li>
<li><a href='#summary.varSelRFBoot'><p>Summary of a varSelRFBoot object</p></a></li>
<li><a href='#varSelImpSpecRF'><p>Variable selection using the &quot;importance spectrum&quot;</p></a></li>
<li><a href='#varSelRF'><p>Variable selection from random forests using OOB error</p></a></li>
<li><a href='#varSelRFBoot'><p>Bootstrap the variable selection procedure in varSelRF</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.7-8</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-07-10</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Selection using Random Forests</td>
</tr>
<tr>
<td>Author:</td>
<td>Ramon Diaz-Uriarte &lt;rdiaz02@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ramon Diaz-Uriarte &lt;rdiaz02@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.0.0), randomForest, parallel</td>
</tr>
<tr>
<td>Description:</td>
<td>Variable selection from random forests using both
        backwards variable elimination (for the selection of small sets
        of non-redundant variables) and selection based on the
        importance spectrum (somewhat similar to scree plots; for the
        selection of large, potentially highly-correlated variables).
        Main applications in high-dimensional data (e.g., microarray
        data, and other genomics and proteomics applications). </td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>Yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://ligarto.org/rdiaz/Software/Software.html">http://ligarto.org/rdiaz/Software/Software.html</a>,
<a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>,
<a href="https://github.com/rdiaz02/varSelRF">https://github.com/rdiaz02/varSelRF</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-07-10 13:54:22 UTC</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-07-10 10:47:03.738 UTC; ramon</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
</table>
<hr>
<h2 id='plot.varSelRF'>Plot a varSelRF object</h2><span id='topic+plot.varSelRF'></span>

<h3>Description</h3>

<p>Plots a varSelRF object, showing the initial variable importances, and
the change in OOB error with the number of variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varSelRF'
plot(x, nvar = NULL, which = c(1, 2), ...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="plot.varSelRF_+3A_x">x</code></td>
<td>
<p>The varSelRF object.</p>
</td></tr>
<tr><td><code id="plot.varSelRF_+3A_nvar">nvar</code></td>
<td>
<p>The number of variables for which the initial variable
importances should be shown. By default, only the 30 with the
largest importance are shown.</p>
</td></tr>
<tr><td><code id="plot.varSelRF_+3A_which">which</code></td>
<td>
<p>which plots should be drawn, either <code>1</code> (for the initial
variable importance plot), <code>2</code> (for the change in OOB error with the
number of variables) or <code>c(1,2)</code> for drawing both plots</p>
</td></tr>
<tr><td><code id="plot.varSelRF_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function is only used for its side effect of producing plots.
</p>


<h3>Warning </h3>

<p>The OOB Error rate is biased down (and can be
severely biased down) because we do (potentially many) rounds of
reducing the set of predictor variables until we minimize this OOB
error rate.</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Diaz-Uriarte, R. and Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varSelRF">varSelRF</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="randomForest.html#topic+importance">importance</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(25 * 30), ncol = 30)
x[1:10, 1:2] &lt;- x[1:10, 1:2] + 2
cl &lt;- factor(c(rep("A", 10), rep("B", 15)))  

rf.vs1 &lt;- varSelRF(x, cl, ntree = 200, ntreeIterat = 100,
                   vars.drop.frac = 0.2)
rf.vs1
plot(rf.vs1)
</code></pre>

<hr>
<h2 id='plot.varSelRFBoot'>plot a varSelRFBoot object</h2><span id='topic+plot.varSelRFBoot'></span>

<h3>Description</h3>

<p>Plots of out-of-bag predictions and OOB error vs. number of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varSelRFBoot'
plot(x,  oobProb = TRUE,
                  oobProbBoxPlot = FALSE,
                  ErrorNum = TRUE,
                  subject.names = NULL,
                  class.to.plot = NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.varSelRFBoot_+3A_x">x</code></td>
<td>
<p>An object of class varSelRFBoot, such as returned by
function <code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>.</p>
</td></tr>
<tr><td><code id="plot.varSelRFBoot_+3A_oobprob">oobProb</code></td>
<td>
<p>If TRUE plot (average) out-of-bag predictions. See
<code>prob.predictions</code> in <code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code> for more
details about the out-of-bag predictions.</p>
</td></tr>
<tr><td><code id="plot.varSelRFBoot_+3A_oobprobboxplot">oobProbBoxPlot</code></td>
<td>
<p>If TRUE plot a box-plot of out-of-bag predictions.</p>
</td></tr>
<tr><td><code id="plot.varSelRFBoot_+3A_errornum">ErrorNum</code></td>
<td>
<p>If TRUE plot OOB error (as returned by random forest)
vs. the number of variables.</p>
</td></tr>
<tr><td><code id="plot.varSelRFBoot_+3A_subject.names">subject.names</code></td>
<td>
<p>If not NULL, a vector, of the same length as the
number of cases (samples or subjects) with IDs for the
cases/samples/subjects, that will be shown to the left of the
average out-of-bag prediction.</p>
</td></tr>
<tr><td><code id="plot.varSelRFBoot_+3A_class.to.plot">class.to.plot</code></td>
<td>
<p>If not NULL, an integer or a vector of
integers. These integers are those class levels for which 
out-of-bag predictions plots will be returned.</p>
</td></tr> 
<tr><td><code id="plot.varSelRFBoot_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function is only used for its side effects of producing
plots.
</p>


<h3>Warning </h3>

<p>The OOB Error rate is biased down (and can be
severely biased down) because we do (potentially many) rounds of
reducing the set of predictor variables until we minimize this OOB
error rate. Note, however, that this is NOT the error rate reported as the
estimate of the error rate for the procedure (for which we use the
.632+ bootstrap rule).</p>


<h3>Note</h3>

<p>When plotting the out-of-bag predictions, we show one plot for each
class. This is an overkill for two-class problems, but not necessarily
for problems with more than two classes. Use <code>class.to.plot</code> to
plot only those classes that interest you.</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. and Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Efron, B. &amp; Tibshirani, R. J. (1997) Improvements on cross-validation: the .632+ bootstrap method.
<em>J. American Statistical Association</em>, <b>92</b>, 548&ndash;560.  
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+summary.varSelRFBoot">summary.varSelRFBoot</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## This is a small example, but can take some time.

x &lt;- matrix(rnorm(25 * 30), ncol = 30)
x[1:10, 1:2] &lt;- x[1:10, 1:2] + 2
cl &lt;- factor(c(rep("A", 10), rep("B", 15)))  

rf.vs1 &lt;- varSelRF(x, cl, ntree = 200, ntreeIterat = 100,
                   vars.drop.frac = 0.2)
rf.vsb &lt;- varSelRFBoot(x, cl,
                       bootnumber = 10,
                       usingCluster = FALSE,
                       srf = rf.vs1)
rf.vsb
summary(rf.vsb)
plot(rf.vsb)

## End(Not run)
</code></pre>

<hr>
<h2 id='randomVarImpsRF'> Variable importances from random forest on permuted class labels</h2><span id='topic+randomVarImpsRF'></span>

<h3>Description</h3>

<p>Return variable importances from random forests fitted to data sets
like the original except class labels have been randomly permuted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomVarImpsRF(xdata, Class, forest, numrandom = 100,
                whichImp = "impsUnscaled", usingCluster = TRUE,
                TheCluster = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randomVarImpsRF_+3A_xdata">xdata</code></td>
<td>
<p>A data frame or matrix, with subjects/cases in rows and
variables in columns. NAs not allowed.</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_class">Class</code></td>
<td>
<p>The dependent variable; must be a factor.</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_forest">forest</code></td>
<td>
<p>A previously fitted random forest (see <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>).</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_numrandom">numrandom</code></td>
<td>
<p>The number of random permutations of the class labels.</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_whichimp">whichImp</code></td>
<td>
<p>A vector of one or more of <code>impsUnscaled</code>,
<code>impsScaled</code>, <code>impsGini</code>, that correspond, respectively, to
the (unscaled) mean decrease in accuracy, the scaled mean decrease
in accuracy, and the Gini index.  See below and
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="randomForest.html#topic+importance">importance</a></code> and the references for further explanations of the
measures of variable importance.</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_usingcluster">usingCluster</code></td>
<td>
<p>If TRUE use a cluster to parallelize the calculations.</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_thecluster">TheCluster</code></td>
<td>
<p>The name of the cluster, if one is used.</p>
</td></tr>
<tr><td><code id="randomVarImpsRF_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The measure of variable importance most often used is based on the decrease
of classification accuracy when values of a variable in a node of a
tree are permuted randomly (see references);
we use the unscaled version &mdash;see our paper and supplementary
material. Note that, by default, <code><a href="randomForest.html#topic+importance">importance</a></code> returns the scaled
version.  </p>


<h3>Value</h3>

<p>An object of class randomVarImpsRF, which is a list
with one to three named components. The name of each
component corresponds to the types of variable importance measures
selected (i.e., impsUnscaled, impsScaled, impsGini).
</p>
<p>Each component is a matrix, of dimensions number of variables by
<code>numrandom</code>; each element <code>(i,j)</code> of this matrix is the variable
importance for variable <code>i</code> and random permutation <code>j</code>.
</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte  <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. and Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Svetnik, V., Liaw, A. , Tong, C &amp; Wang, T. (2004) Application of
Breiman's random forest to modeling structure-activity relationships of
pharmaceutical molecules.  Pp. 334-343 in <em>F. Roli, J. Kittler, and T. Windeatt</em>
(eds.). <em>Multiple Classier Systems, Fifth International Workshop</em>, MCS
2004, Proceedings, 9-11 June 2004, Cagliari, Italy. Lecture Notes in
Computer Science, vol. 3077.  Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>,
<code><a href="#topic+varSelImpSpecRF">varSelImpSpecRF</a></code>,
<code><a href="#topic+randomVarImpsRFplot">randomVarImpsRFplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(45 * 30), ncol = 30)
x[1:20, 1:2] &lt;- x[1:20, 1:2] + 2
cl &lt;- factor(c(rep("A", 20), rep("B", 25)))  

rf &lt;- randomForest(x, cl, ntree = 200, importance = TRUE)
rf.rvi &lt;- randomVarImpsRF(x, cl, 
                          rf, 
                          numrandom = 20, 
                          usingCluster = FALSE) 

randomVarImpsRFplot(rf.rvi, rf)
</code></pre>

<hr>
<h2 id='randomVarImpsRFplot'>Plot random random variable importances</h2><span id='topic+randomVarImpsRFplot'></span>

<h3>Description</h3>

<p>Plot variable importances from random permutations of class labels and
the variable importances from the original data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomVarImpsRFplot(randomImportances, forest,
                    whichImp = "impsUnscaled", nvars = NULL,
                    show.var.names = FALSE, vars.highlight = NULL,
                    main = NULL, screeRandom = TRUE,
                    lwdBlack = 1.5,
                    lwdRed = 2,
                    lwdLightblue = 1,
                    cexPoint = 1,
                    overlayTrue = FALSE,
                    xlab = NULL,
                    ylab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randomVarImpsRFplot_+3A_randomimportances">randomImportances</code></td>
<td>
<p>A list with a structure such as the object
return by <code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="randomVarImpsRFplot_+3A_forest">forest</code></td>
<td>
<p>A random forest fitted to the original data. This forest
must have been fitted with <code>importances = TRUE</code>.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_whichimp">whichImp</code></td>
<td>
<p>The importance measue to use. One (only one) of
<code>impsUnscaled</code>,
<code>impsScaled</code>, <code>impsGini</code>, that correspond, respectively, to
the (unscaled) mean decrease in accuracy, the scaled mean decrease
in accuracy, and the Gini index.  See below and
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code>importance</code> and the references for further explanations of the
measures of variable importance. </p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_nvars">nvars</code></td>
<td>
<p>If NULL will show the plot for the complete range of
variables. If an integer, will plot only the most important nvars.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_show.var.names">show.var.names</code></td>
<td>
<p>If TRUE, show the variable names in the
plot. Unless you are plotting few variables, it probably won't be of
any use.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_vars.highlight">vars.highlight</code></td>
<td>
<p>A vector indicating the variables to highlight
in the plot with a vertical blue segment. You need to pass here a
vector of variable names, not variable positions.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_main">main</code></td>
<td>
<p>The title for the plot.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_screerandom">screeRandom</code></td>
<td>
<p>If TRUE, order all the variable importances (i.e.,
those from both the original and the permuted class labels data
sets) from
largest to smallest before plotting. The plot will thus resemble a
usual &quot;scree plot&quot;. </p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_lwdblack">lwdBlack</code></td>
<td>
<p>The width of the line to use for the importances from
the original data set.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_lwdred">lwdRed</code></td>
<td>
<p> The width of the line to use for the average of the
importances for the permuted data sets. </p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_lwdlightblue">lwdLightblue</code></td>
<td>
<p> The width of the line for the importances for the
individual permuted data sets.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_cexpoint">cexPoint</code></td>
<td>
 <p><code>cex</code> argument for the points for the
importances from the original data set.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_overlaytrue">overlayTrue</code></td>
<td>
<p>If TRUE, the variable importance from the
original data set will be plotted last, so
you can see it even if buried in the middle of many gree lines; can
be of help when the plot does not allow you to see the black line.</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_xlab">xlab</code></td>
<td>
<p>The title for the x-axis (see <code>xlab</code>).</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_ylab">ylab</code></td>
<td>
<p>The title for the y-axis (see <code>ylab</code>).</p>
</td></tr>
<tr><td><code id="randomVarImpsRFplot_+3A_...">...</code></td>
<td>
<p>Additional arguments to plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Only used for its side effects of producing plots. In particular, you
will see lines of three colors:
</p>
<table>
<tr><td><code>black</code></td>
<td>
<p>Connects the variable importances from the original
simulated data. </p>
</td></tr>
<tr><td><code>green</code></td>
<td>
<p>Connect the variable
importances from the data sets with permuted class labels; there
will be as many lines as <code>numrandom</code> where used when
<code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code> was called to obtain the random
importances.</p>
</td></tr>
<tr><td><code>red</code></td>
<td>
<p>Connects the average of the importances from the permuted
data sets.</p>
</td></tr>
</table>
<p>Additionally, if you used a valid set of values for
<code>vars.highlight</code>, these will be shown with a vertical blue
segment.
</p>


<h3>Note</h3>

<p>These plots resemble the scree plots commonly used with principal
component analysis, and the actual choice of colors was taken from the
importance spectrum plots of <cite>Friedman \&amp; Meulman</cite>.</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. , Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Friedman, J., Meulman, J. (2005) Clustering objects on subsets of attributes (with discussion).
<em>J. Royal Statistical Society, Series B</em>, <b>66</b>, 815&ndash;850. 
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>,
<code><a href="#topic+varSelImpSpecRF">varSelImpSpecRF</a></code>,
<code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(45 * 30), ncol = 30)
x[1:20, 1:2] &lt;- x[1:20, 1:2] + 2
colnames(x) &lt;- paste0("V", seq.int(ncol(x)))
cl &lt;- factor(c(rep("A", 20), rep("B", 25)))  

rf &lt;- randomForest(x, cl, ntree = 200, importance = TRUE)
rf.rvi &lt;- randomVarImpsRF(x, cl, 
                          rf, 
                          numrandom = 20, 
                          usingCluster = FALSE) 

randomVarImpsRFplot(rf.rvi, rf)
op &lt;- par(las = 2)
randomVarImpsRFplot(rf.rvi, rf, show.var.names = TRUE)
par(op)


## Not run: 
## identical, but using a cluster
## make a small cluster, for the sake of illustration
psockCL &lt;- makeCluster(2, "PSOCK")
clusterSetRNGStream(psockCL, iseed = 789)
clusterEvalQ(psockCL, library(varSelRF))

rf.rvi &lt;- randomVarImpsRF(x, cl, 
                          rf, 
                          numrandom = 20, 
                          usingCluster = TRUE,
                          TheCluster = psockCL) 

randomVarImpsRFplot(rf.rvi, rf)
stopCluster(psockCL)

## End(Not run)

</code></pre>

<hr>
<h2 id='selProbPlot'>Selection probability plot for variable importance from random forests</h2><span id='topic+selProbPlot'></span>

<h3>Description</h3>

<p>Plot, for the top ranked <code class="reqn">k</code> variables from the original sample, the
probability that each of these variables is included among the top
ranked <code class="reqn">k</code> genes from the bootstrap samples. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selProbPlot(object, k = c(20, 100),
            color = TRUE,
            legend = FALSE,
            xlegend = 68,
            ylegend = 0.93,
            cexlegend = 1.4,
            main = NULL,
            xlab = "Rank of gene",
            ylab = "Selection probability",
            pch = 19, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selProbPlot_+3A_object">object</code></td>
<td>
<p>An object of class varSelRFBoot such as returned by the
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code> function.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_k">k</code></td>
<td>
<p>A two-component vector with the <code class="reqn">k</code>-th upper variables for
which you want the plots. </p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_color">color</code></td>
<td>
<p>If TRUE a color plot; if FALSE, black and white.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_legend">legend</code></td>
<td>
<p>If TRUE, show a legend.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_xlegend">xlegend</code></td>
<td>
<p>The x-coordinate for the legend.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_ylegend">ylegend</code></td>
<td>
<p>The y-coordinate for the legend.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_cexlegend">cexlegend</code></td>
<td>
<p>The <code>cex</code> argument for the legend.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_main">main</code></td>
<td>
<p><code>main</code> for the plot.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_xlab">xlab</code></td>
<td>
<p><code>xlab</code> for the plot.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_ylab">ylab</code></td>
<td>
<p><code>ylab</code> for the plot.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_pch">pch</code></td>
<td>
<p><code>pch</code> for the plot.</p>
</td></tr>
<tr><td><code id="selProbPlot_+3A_...">...</code></td>
<td>
<p>Additional arguments to plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><cite>Pepe et al., 2003</cite> suggested the use of selection probability
plots to evaluate the stability and confidence on our selection of
&quot;relevant genes.&quot; This paper also presents several more sophisticated
ideas not implemented here.
</p>


<h3>Value</h3>

<p>Used for its side effects of producing a plot. In a single plot show
the &quot;selection probability plot&quot; for the upper
(largest variable importance) <code>kt</code>th variables. By default, show
the upper 20 and the upper 100
colored blue and red respectively.
</p>


<h3>Note</h3>

<p>This function is in very rudimentary shape and could be used for
more general types of data. I wrote specifically to produce Fig.\ 4 of
the paper.</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. , Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Pepe, M. S., Longton, G., Anderson, G. L. &amp; Schummer, M. (2003) Selecting differentially expressed genes from microarray experiments.
<em>Biometrics</em>, <b>59</b>, 133&ndash;142. 
</p>
<p>Svetnik, V., Liaw, A. , Tong, C &amp; Wang, T. (2004) Application of
Breiman's random forest to modeling structure-activity relationships of
pharmaceutical molecules.  Pp. 334-343 in <em>F. Roli, J. Kittler, and T. Windeatt</em>
(eds.). <em>Multiple Classier Systems, Fifth International Workshop</em>, MCS
2004, Proceedings, 9-11 June 2004, Cagliari, Italy. Lecture Notes in
Computer Science, vol. 3077.  Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>,
<code><a href="#topic+randomVarImpsRFplot">randomVarImpsRFplot</a></code>,
<code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is a small example, but can take some time.

x &lt;- matrix(rnorm(25 * 30), ncol = 30)
x[1:10, 1:2] &lt;- x[1:10, 1:2] + 2
cl &lt;- factor(c(rep("A", 10), rep("B", 15)))  

rf.vs1 &lt;- varSelRF(x, cl, ntree = 200, ntreeIterat = 100,
                   vars.drop.frac = 0.2)
rf.vsb &lt;- varSelRFBoot(x, cl,
                       bootnumber = 10,
                       usingCluster = FALSE,
                       srf = rf.vs1)
selProbPlot(rf.vsb, k = c(5, 10), legend = TRUE,
            xlegend = 8, ylegend = 0.8)

</code></pre>

<hr>
<h2 id='summary.varSelRFBoot'>Summary of a varSelRFBoot object</h2><span id='topic+summary.varSelRFBoot'></span>

<h3>Description</h3>

<p>Returns error rate and stability measures of a varSelRFBoot object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varSelRFBoot'
summary(object, return.model.freqs = FALSE,
                     return.class.probs = TRUE,
                     return.var.freqs.b.models = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.varSelRFBoot_+3A_object">object</code></td>
<td>
<p>An object of class varSelRFBoot, as returned from
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>.</p>
</td></tr>
<tr><td><code id="summary.varSelRFBoot_+3A_return.model.freqs">return.model.freqs</code></td>
<td>
<p>If TRUE return a table with the frequencies
of the final &quot;models&quot; (sets of selected variables) over all
bootstrap replications.</p>
</td></tr>
<tr><td><code id="summary.varSelRFBoot_+3A_return.class.probs">return.class.probs</code></td>
<td>
<p>If TRUE return average class probabilities
for each sample based on the out-of-bag probabilites (see
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>, the <code>prob.predictions</code> component).</p>
</td></tr>
<tr><td><code id="summary.varSelRFBoot_+3A_return.var.freqs.b.models">return.var.freqs.b.models</code></td>
<td>
<p>If TRUE return the frequencies of all
variables selected from the bootstrap replicates.</p>
</td></tr>
<tr><td><code id="summary.varSelRFBoot_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>return.class.probs = TRUE</code> a matrix with the average class
probabilities  for each sample based on the out-of-bag probabilites. 
</p>
<p>Regardless of that setting, print out several summaries:

</p>
<table>
<tr><td><code>Summaries related to the "simplified" random forest on the original
    data</code></td>
<td>
<p>Such as the number and identity of the variables selected.</p>
</td></tr>
<tr><td><code>Summaries related to the error rate estimate</code></td>
<td>
<p>Such as the .632+
estimate, and some of its components</p>
</td></tr>
<tr><td><code>Summaries related to the stability (uniqueness) of the results
    obtained</code></td>
<td>
<p>Such as the frequency of the selected variables in the
bootstrap runs, the frequency of the selected variables in the
boostrap runs that are also among the variables selected from the
complete run, the overlap of the bootstrap forests with the forest
from the original data set (see <code><a href="#topic+varSelRF">varSelRF</a></code> for the
definition of overlap), and (optionally) the frequency of the
&quot;models&quot;, where a
model is the set of variables selected in any particular run.</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte  <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. and Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Efron, B. &amp; Tibshirani, R. J. (1997) Improvements on cross-validation: the .632+ bootstrap method.
<em>J. American Statistical Association</em>, <b>92</b>, 548&ndash;560.  
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>,
<code><a href="#topic+plot.varSelRFBoot">plot.varSelRFBoot</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## This is a small example, but can take some time.

x &lt;- matrix(rnorm(25 * 30), ncol = 30)
x[1:10, 1:2] &lt;- x[1:10, 1:2] + 2
cl &lt;- factor(c(rep("A", 10), rep("B", 15)))  

rf.vs1 &lt;- varSelRF(x, cl, ntree = 200, ntreeIterat = 100,
                   vars.drop.frac = 0.2)
rf.vsb &lt;- varSelRFBoot(x, cl,
                       bootnumber = 10,
                       usingCluster = FALSE,
                       srf = rf.vs1)
rf.vsb
summary(rf.vsb)
plot(rf.vsb)

## End(Not run)

</code></pre>

<hr>
<h2 id='varSelImpSpecRF'>Variable selection using the &quot;importance spectrum&quot;</h2><span id='topic+varSelImpSpecRF'></span>

<h3>Description</h3>

<p>Perform variable selection based on a simple heuristic using the
importance spectrum of the
original data compared to the importance spectra from the same data
with the class labels randomly permuted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varSelImpSpecRF(forest, xdata = NULL, Class = NULL,
                randomImps = NULL,
                threshold = 0.1,
                numrandom = 20,
                whichImp = "impsUnscaled",
                usingCluster = TRUE,
                TheCluster = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varSelImpSpecRF_+3A_forest">forest</code></td>
<td>
<p>A previously fitted random forest (see <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>).</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_xdata">xdata</code></td>
<td>
<p>A data frame or matrix, with subjects/cases in rows and
variables in columns. NAs not allowed.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_class">Class</code></td>
<td>
<p>The dependent variable; must be a factor.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_randomimps">randomImps</code></td>
<td>
<p>A list with a structure such as the object
return by <code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="varSelImpSpecRF_+3A_threshold">threshold</code></td>
<td>
<p>The threshold for the selection of variables. See details.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_numrandom">numrandom</code></td>
<td>
<p>The number of random permutations of the class labels.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_whichimp">whichImp</code></td>
<td>
<p>One of <code>impsUnscaled</code>,
<code>impsScaled</code>, <code>impsGini</code>, that correspond, respectively, to
the (unscaled) mean decrease in accuracy, the scaled mean decrease
in accuracy, and the Gini index.  See below and
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code>importance</code> and the references for further explanations of the
measures of variable importance.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_usingcluster">usingCluster</code></td>
<td>
<p>If TRUE use a cluster to parallelize the calculations.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_thecluster">TheCluster</code></td>
<td>
<p>The name of the cluster, if one is used.</p>
</td></tr>
<tr><td><code id="varSelImpSpecRF_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can either pass as arguments a valid object for <code>randomImps</code>,
obtained from a previous call to <code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code> OR
you can pass a covariate data frame and a dependent variable, and
these will be used to obtain the random importances. The former is
preferred for normal use, because this function will not returned the
computed random variable importances, and this computation can  be
lengthy.  If you pass both <code>randomImps</code>, <code>xdata</code>, and <code>Class</code>,
<code>randomImps</code> will be used.
</p>
<p>To select variables, start by  ordering  from largest (<code class="reqn">i=1</code>) to smallest
(<code class="reqn">i = p</code>, where <code class="reqn">p</code> is the number of
variables),  the variable importances from the original data and from
each  of the data sets with permuted class labels. (So the ordering is
done in each data set independently). Compute 
<code class="reqn">q_i</code>, the <code class="reqn">1 - threshold</code> quantile of
the ordered variable importances from the permuted data at ordered
postion <code class="reqn">i</code>. Then,
starting from <code class="reqn">i = 1</code>, let <code class="reqn">i_a</code> be the first <code class="reqn">i</code> for which
the variable importance from the original data is smaller than
<code class="reqn">q_i</code>. Select all variables from <code class="reqn">i=1</code> to <code class="reqn">i = i_a - 1</code>.
</p>


<h3>Value</h3>

<p>A vector with the names of the selected variables, ordered by
decreasing importance.</p>


<h3>Note</h3>

<p>The name
of this function is related to the idea of &quot;importance spectrum plot&quot;,
which is the term that <cite>Friedman \&amp; Meulman, 2005</cite> use in their paper.</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. , Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report. <a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Friedman, J., Meulman, J. (2005) Clustering objects on subsets of attributes (with discussion).
<em>J. Royal Statistical Society, Series B</em>, <b>66</b>, 815&ndash;850. </p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>,
<code><a href="#topic+randomVarImpsRFplot">randomVarImpsRFplot</a></code>,
<code><a href="#topic+randomVarImpsRF">randomVarImpsRF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(45 * 30), ncol = 30)
x[1:20, 1:2] &lt;- x[1:20, 1:2] + 2
cl &lt;- factor(c(rep("A", 20), rep("B", 25)))  

rf &lt;- randomForest(x, cl, ntree = 200, importance = TRUE)
rf.rvi &lt;- randomVarImpsRF(x, cl, 
                          rf, 
                          numrandom = 20, 
                          usingCluster = FALSE) 
varSelImpSpecRF(rf, randomImps = rf.rvi)



## Not run: 
## Identical, but using a cluster
psockCL &lt;- makeCluster(2, "PSOCK")
clusterSetRNGStream(psockCL, iseed = 456)
clusterEvalQ(psockCL, library(varSelRF))

rf.rvi &lt;- randomVarImpsRF(x, cl, 
                          rf, 
                          numrandom = 20, 
                          usingCluster = TRUE,
                          TheCluster = psockCL) 
varSelImpSpecRF(rf, randomImps = rf.rvi)
stopCluster(psockCL)


## End(Not run)



</code></pre>

<hr>
<h2 id='varSelRF'>Variable selection from random forests using OOB error</h2><span id='topic+varSelRF'></span>

<h3>Description</h3>

<p>Using the OOB error as minimization criterion, carry out variable
elimination from
random forest, by successively eliminating the least important
variables (with importance as returned from random forest).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varSelRF(xdata, Class, c.sd = 1, mtryFactor = 1, ntree = 5000,
         ntreeIterat = 2000, vars.drop.num = NULL, vars.drop.frac = 0.2,
         whole.range = TRUE, recompute.var.imp = FALSE, verbose = FALSE,
         returnFirstForest = TRUE, fitted.rf = NULL, keep.forest = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varSelRF_+3A_xdata">xdata</code></td>
<td>
<p>A data frame or matrix, with subjects/cases in rows and
variables in columns. NAs not allowed.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_class">Class</code></td>
<td>
<p>The dependent variable; must be a factor.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_c.sd">c.sd</code></td>
<td>
<p>The factor that multiplies the sd. to decide on stopping
the tierations or choosing the final solution. See reference for details.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_mtryfactor">mtryFactor</code></td>
<td>
<p>The multiplication factor of
<code class="reqn">\sqrt{number.of.variables}</code> for the number of variables to use for
the ntry argument of randomForest.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_ntree">ntree</code></td>
<td>
<p>The number of trees to use for the first forest;
same as ntree for randomForest.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_ntreeiterat">ntreeIterat</code></td>
<td>
<p>The number of trees to use (ntree of randomForest)
for all additional forests.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_vars.drop.num">vars.drop.num</code></td>
<td>
<p>The number of variables to exclude at each iteration.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_vars.drop.frac">vars.drop.frac</code></td>
<td>
<p>The fraction of variables, from those
in the previous forest, to exclude at each iteration.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_whole.range">whole.range</code></td>
<td>
<p>If TRUE continue dropping variables until a forest
with only two variables is built, and choose the best model from the
complete series of models. If
FALSE, stop the iterations if the current OOB error becomes larger
than the initial OOB error (plus c.sd*OOB standard error) or
if the current OOB error becoems larger than the
previous OOB error (plus c.sd*OOB standard error).</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_recompute.var.imp">recompute.var.imp</code></td>
<td>
<p>If TRUE recompute variable importances at
each new iteration.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_verbose">verbose</code></td>
<td>
<p>Give more information about what is being done.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_returnfirstforest">returnFirstForest</code></td>
<td>
<p>If TRUE the random forest from the complete
set of variables is returned.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_fitted.rf">fitted.rf</code></td>
<td>
<p>An (optional) object of class
randomForest previously fitted. In this case, the ntree and
mtryFactor arguments are obtained from the fitted object, not the
arguments to this function.</p>
</td></tr>
<tr><td><code id="varSelRF_+3A_keep.forest">keep.forest</code></td>
<td>
<p>Same argument as in randomForest function. If the
forest is kept, it will be returned as part of the &quot;rf.model&quot;
component of the output. Beware that setting this to TRUE can lead
to very large memory consumption.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With the default parameters, we examine all forest that result from
eliminating, iteratively, a fraction, <code>vars.drop.frac</code>, of the least
important variables used in the previous iteration. By default,
<code>vars.frac.drop = 0.2</code> which allows for relatively fast operation,
is coherent with the idea of an &ldquo;aggressive variable selection&rdquo;
approach, and increases the resolution as the number of variables
considered becomes smaller.  By default, we do not recalculate variable
importances at each step (<code>recompute.var.imp = FALSE</code>)
as <cite>Svetnik et al. 2004</cite> mention severe overfitting
resulting from recalculating variable importances. After fitting all
forests, we examine the OOB error rates from all the fitted random
forests. We choose the solution with the smallest number of genes
whose error rate is within <code>c.sd</code> standard errors of the minimum error
rate of all forests. (The standard error is calculated using the 
expression for a biomial error count [<code class="reqn">\sqrt{p (1-p) * 1/N}</code>]).
Setting <code>c.sd = 0</code> is the same as selecting the set of genes that leads
to the smallest error rate.  Setting <code>c.sd = 1</code> is similar to the
common &ldquo;1 s.e.  rule&rdquo;, used in the classification trees literature;
this strategy can lead to solutions with
fewer genes than selecting the solution with the smallest error rate,
while achieving an error rate that is not different, within sampling
error, from the &ldquo;best solution&rdquo;.
</p>
<p>The use of <code>ntree = 5000</code> and <code>ntreeIterat = 2000</code> is
discussed in longer detail in the references. Essentially, more
iterations rarely seem to lead (with 9 different microarray data sets)
to improved solutions.
</p>
<p>The measure of variable importance used is based on the decrease
of classification accuracy when values of a variable in a node of a
tree are permuted randomly (see references); we use the unscaled
version &mdash;see our paper and supplementary material.
</p>


<h3>Value</h3>

<p>An object of class &quot;varSelRF&quot;: a list with components:
</p>
<table>
<tr><td><code>selec.history</code></td>
<td>
<p>A data frame where the selection history is
stored. The components are:
</p>

<dl>
<dt>Number.Variables</dt><dd><p>The number of variables examined.</p>
</dd>
<dt>Vars.in.Forest</dt><dd><p>The actual variables that were in the forest
at that stage.</p>
</dd>
<dt>OOB</dt><dd><p>Out of bag error rate.</p>
</dd>
<dt>sd.OOB</dt><dd><p>Standard deviation of the error rate.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>rf.model</code></td>
<td>
<p>The final, selected, random forest (only if
<code>whole.range = FALSE</code>). (If you set whole.range = TRUE, the
final model always contains exactly two variables. This is unlikely
to be the forest that interests you).</p>
</td></tr>
<tr><td><code>selected.vars</code></td>
<td>
<p>The variables finally selected.</p>
</td></tr>
<tr><td><code>selected.model</code></td>
<td>
<p>Same as above, but ordered alphabetically and
concatenated with a &quot;+&quot; for easier display.</p>
</td></tr>
<tr><td><code>best.model.nvars</code></td>
<td>
<p>The number of variables in the finally
selected model.</p>
</td></tr>
<tr><td><code>initialImportance</code></td>
<td>
<p>The importances of variables, before any
variable deletion.</p>
</td></tr>
<tr><td><code>initialOrderedImportances</code></td>
<td>
<p>Same as above but ordered in by
decreasing importance.</p>
</td></tr>
<tr><td><code>ntree</code></td>
<td>
<p>The <code>ntree</code> argument.</p>
</td></tr>
<tr><td><code>ntreeIterat</code></td>
<td>
<p>The <code>ntreeIterat</code> argument.</p>
</td></tr>
<tr><td><code>mtryFactor</code></td>
<td>
<p>The <code>mtryFactor</code> argument.</p>
</td></tr>
<tr><td><code>firstForest</code></td>
<td>
<p>The first forest (before any variable selection) fitted.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte  <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. and Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report.
<a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Svetnik, V., Liaw, A. , Tong, C &amp; Wang, T. (2004) Application of
Breiman's random forest to modeling structure-activity relationships of
pharmaceutical molecules.  Pp. 334-343 in <em>F. Roli, J. Kittler, and T. Windeatt</em>
(eds.). <em>Multiple Classier Systems, Fifth International Workshop</em>, MCS
2004, Proceedings, 9-11 June 2004, Cagliari, Italy. Lecture Notes in
Computer Science, vol. 3077.  Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+plot.varSelRF">plot.varSelRF</a></code>,
<code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(rnorm(25 * 30), ncol = 30)
colnames(x) &lt;- paste("v", 1:30, sep = "")
x[1:10, 1:2] &lt;- x[1:10, 1:2] + 1
x[1:4, 5] &lt;- x[1:4, 5] - 1.5
x[5:10, 8] &lt;- x[5:10, 8] + 1.4 

cl &lt;- factor(c(rep("A", 10), rep("B", 15)))  
rf.vs1 &lt;- varSelRF(x, cl, ntree = 500, ntreeIterat = 300,
                   vars.drop.frac = 0.2)
rf.vs1
plot(rf.vs1)


## Note you can use tiny vars.drop.frac
## though you'll rarely want this
rf.vs1tiny &lt;- varSelRF(x, cl, ntree = 500, ntreeIterat = 300,
                   vars.drop.frac = 0.01)

#### Using the final, fitted model to predict other data

## Simulate new data
set.seed(2)
x.new &lt;- matrix(rnorm(25 * 30), ncol = 30)
colnames(x.new) &lt;- paste("v", 1:30, sep = "")
x.new[1:10, 1:2] &lt;- x.new[1:10, 1:2] + 1
x.new[1:10, 5] &lt;- x.new[1:10, 5] - 0.5


## Fit with whole.range = FALSE and keep.forest = TRUE
set.seed(3)
rf.vs2 &lt;- varSelRF(x, cl, ntree = 3000, ntreeIterat = 2000,
                   vars.drop.frac = 0.3, whole.range = FALSE,
                   keep.forest = TRUE)


## To obtain predictions from a data set, you must specify the
## same variables as those used in the final model

rf.vs2$selected.vars


predict(rf.vs2$rf.model,
        newdata = subset(x.new, select = rf.vs2$selected.vars))
predict(rf.vs2$rf.model,
        newdata = subset(x.new, select = rf.vs2$selected.vars),
        type = "prob")


## If you had not kept the forest (keep.forest) you could also try
randomForest(y = cl, x = subset(x, select = rf.vs2$selected.vars),
             ntree = rf.vs2$ntreeIterat,
             xtest = subset(x, select = rf.vs2$selected.vars))$test

## but here the forest is built new (with only the selected variables)
## so results need not be the same



## CAUTION: You will NOT want this (these are similar to resubstitution
##   predictions)

predict(rf.vs2$rf.model, newdata = subset(x, select = rf.vs2$selected.vars))

## nor these (read help of predict.randomForest for why these
## predictions are different from those from previous command)

predict(rf.vs2$rf.model)


</code></pre>

<hr>
<h2 id='varSelRFBoot'>Bootstrap the variable selection procedure in varSelRF</h2><span id='topic+varSelRFBoot'></span>

<h3>Description</h3>

<p>Use the bootstrap to estimate the prediction error rate (wuth the
.632+ rule) and the
stability of the variable selection procedure implemented in <code><a href="#topic+varSelRF">varSelRF</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varSelRFBoot(xdata, Class, c.sd = 1,
             mtryFactor = 1, ntree = 5000, ntreeIterat = 2000,
             vars.drop.frac = 0.2, bootnumber = 200,
             whole.range = TRUE,
             recompute.var.imp = FALSE,
             usingCluster = TRUE,
             TheCluster = NULL, srf = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<p>Most arguments are the same as for <code><a href="#topic+varSelRFBoot">varSelRFBoot</a></code>.
</p>
<table>
<tr><td><code id="varSelRFBoot_+3A_xdata">xdata</code></td>
<td>
<p>A data frame or matrix, with subjects/cases in rows and
variables in columns. NAs not allowed.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_class">Class</code></td>
<td>
<p>The dependent variable; must be a factor.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_c.sd">c.sd</code></td>
<td>
<p>The factor that multiplies the sd. to decide on stopping
the tierations or choosing the final solution. See reference for details.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_mtryfactor">mtryFactor</code></td>
<td>
<p>The multiplication factor of
<code class="reqn">\sqrt{number.of.variables}</code> for the number of variables to use for
the ntry argument of randomForest.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_ntree">ntree</code></td>
<td>
<p>The number of trees to use for the first forest;
same as ntree for randomForest.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_ntreeiterat">ntreeIterat</code></td>
<td>
<p>The number of trees to use (ntree of randomForest)
for all additional forests.</p>
</td></tr>

<tr><td><code id="varSelRFBoot_+3A_vars.drop.frac">vars.drop.frac</code></td>
<td>
<p>The fraction of variables, from those
in the previous forest, to exclude at each iteration.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_whole.range">whole.range</code></td>
<td>
<p>If TRUE continue dropping variables until a forest
with only two variables is built, and choose the best model from the
complete series of models. If
FALSE, stop the iterations if the current OOB error becomes larger
than the initial OOB error (plus c.sd*OOB standard error) or
if the current OOB error becoems larger than the
previous OOB error (plus c.sd*OOB standard error).</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_recompute.var.imp">recompute.var.imp</code></td>
<td>
<p>If TRUE recompute variable importances at
each new iteration.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_bootnumber">bootnumber</code></td>
<td>
<p>The number of bootstrap samples to draw.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_usingcluster">usingCluster</code></td>
<td>
<p>If TRUE use a cluster to parallelize the calculations.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_thecluster">TheCluster</code></td>
<td>
<p>The name of the cluster, if one is used.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_srf">srf</code></td>
<td>
<p>An object of class varSelRF. If used, the ntree and
mtryFactor parameters are taken from this object, not from the
arguments to this function. If used, it allows to skip carrying out
a first iteration to build the random forest to the complete,
original data set.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_verbose">verbose</code></td>
<td>
<p>Give more information about what is being done.</p>
</td></tr>
<tr><td><code id="varSelRFBoot_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a cluster is used for the calculations, it will be used for the
embarrisingly parallelizable task of building as many random forests
as bootstrap samples. 
</p>


<h3>Value</h3>

<p>An object of class varSelRFBoot, which is a list with components:
</p>
<table>
<tr><td><code>number.of.bootsamples</code></td>
<td>
<p>The number of bootstrap replicates.</p>
</td></tr>
<tr><td><code>bootstrap.pred.error</code></td>
<td>
<p>The .632+ estimate of the prediction
error.</p>
</td></tr>
<tr><td><code>leave.one.out.bootstrap</code></td>
<td>
<p>The leave-one-out estimate of the error
rate (used when computing the .632+ estimate).</p>
</td></tr>
<tr><td><code>all.data.randomForest</code></td>
<td>
<p>A random forest built from all the data,
but after the variable selection. Thus, beware because the OOB error
rate is severely biased down.</p>
</td></tr>
<tr><td><code>all.data.vars</code></td>
<td>
<p>The variables selected in the run with all the
data.</p>
</td></tr>
<tr><td><code>all.data.run</code></td>
<td>
<p>An object of class varSelRF; the one obtained from
a run of varSelRF on the original, complete, data set. See
<code><a href="#topic+varSelRF">varSelRF</a></code>.</p>
</td></tr>
<tr><td><code>class.predictions</code></td>
<td>
<p>The out-of-bag predictions from the
bootstrap, of type &quot;response&quot;.See
<code><a href="randomForest.html#topic+predict.randomForest">predict.randomForest</a></code>. This is an array, with
dimensions number of cases by number of bootstrap replicates. </p>
</td></tr>
<tr><td><code>prob.predictions</code></td>
<td>
<p>The out-of-bag predictions from the bootstrap,
of type &quot;class probability&quot;. See
<code><a href="randomForest.html#topic+predict.randomForest">predict.randomForest</a></code>. This is a 3-way array; the last
dimension is the bootstrap replication; for each bootstrap
replication, the 2D array
has dimensions case by number of classes, and each value is the
probability of belonging to that class.</p>
</td></tr>
<tr><td><code>number.of.vars</code></td>
<td>
<p>A vector with the number of variables selected
for each bootstrap sample.</p>
</td></tr>
<tr><td><code>overlap</code></td>
<td>
<p>The &quot;overlap&quot; between the variables selected from the
run in original sample and the variables returned from a bootstrap
sample.  Overlap between the sets of variables A and B is defined as
</p>
<p style="text-align: center;"><code class="reqn">\frac{|variables.in.A \cap variables.in.B|}{\sqrt{|variables.in.A|
	 |variables.in.B|}}</code>
</p>
<p> or size (cardinality) of
intersection between the two sets / sqrt(product of size of each
set).</p>
</td></tr>
<tr><td><code>all.vars.in.solutions</code></td>
<td>
<p>A vector with all the genes selected in
the runs on all the bootstrap samples. If the same gene is selected in several
bootstrap runs, it appears multiple times in this vector.</p>
</td></tr>
<tr><td><code>all.solutions</code></td>
<td>
<p>Each solutions is a character vector with all
the variables in a particular solution concatenated by a &quot;+&quot;. Thus,
all.solutions is a vector, with length equal to
<code>number.of.bootsamples</code>, of the solution from each bootstrap
run.</p>
</td></tr>
<tr><td><code>Class</code></td>
<td>
<p>The original class argument.</p>
</td></tr>
<tr><td><code>allBootRuns</code></td>
<td>
<p>A list of length <code>number.of.bootsamples</code>. Each
component of this list is an element of class <code><a href="#topic+varSelRF">varSelRF</a></code>
and stores the results from the runs on each bootstrap sample.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The out-of-bag predictions stored in <code>class.predictions</code> and
<code>prob.predictions</code> are NOT the OOB votes from random
forest itself for a given run. These are predictions from the
out-of-bag samples for each  bootstrap replication. Thus, these are
samples that have not been used at all in any of the variable selection
procedures in the given bootstrap replication.</p>


<h3>Author(s)</h3>

<p>Ramon Diaz-Uriarte  <a href="mailto:rdiaz02@gmail.com">rdiaz02@gmail.com</a></p>


<h3>References</h3>

<p>Breiman, L. (2001) Random forests.
<em>Machine Learning</em>, <b>45</b>, 5&ndash;32.
</p>
<p>Diaz-Uriarte, R. and Alvarez de Andres,
S. (2005) Variable selection from random forests: application to gene
expression
data. Tech. report.
<a href="http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html">http://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html</a>
</p>
<p>Efron, B. &amp; Tibshirani, R. J. (1997) Improvements on cross-validation: the .632+ bootstrap method.
<em>J. American Statistical Association</em>, <b>92</b>, 548&ndash;560.  
</p>
<p>Svetnik, V., Liaw, A. , Tong, C &amp; Wang, T. (2004) Application of
Breiman's random forest to modeling structure-activity relationships of
pharmaceutical molecules.  Pp. 334-343 in <em>F. Roli, J. Kittler, and T. Windeatt</em>
(eds.). <em>Multiple Classier Systems, Fifth International Workshop</em>, MCS
2004, Proceedings, 9-11 June 2004, Cagliari, Italy. Lecture Notes in
Computer Science, vol. 3077.  Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,
<code><a href="#topic+varSelRF">varSelRF</a></code>,
<code><a href="#topic+summary.varSelRFBoot">summary.varSelRFBoot</a></code>,
<code><a href="#topic+plot.varSelRFBoot">plot.varSelRFBoot</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## This is a small example, but can take some time.

## make a small cluster, for the sake of illustration
forkCL &lt;- makeForkCluster(2)
clusterSetRNGStream(forkCL, iseed = 123)
clusterEvalQ(forkCL, library(varSelRF))


x &lt;- matrix(rnorm(25 * 30), ncol = 30)
x[1:10, 1:2] &lt;- x[1:10, 1:2] + 2
cl &lt;- factor(c(rep("A", 10), rep("B", 15)))  

rf.vs1 &lt;- varSelRF(x, cl, ntree = 200, ntreeIterat = 100,
                   vars.drop.frac = 0.2)
rf.vsb &lt;- varSelRFBoot(x, cl,
                       bootnumber = 10,
                       usingCluster = TRUE,
                       srf = rf.vs1,
                       TheCluster = forkCL)
rf.vsb
summary(rf.vsb)
plot(rf.vsb)
stopCluster(forkCL)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
