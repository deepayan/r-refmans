<!DOCTYPE html><html lang="en"><head><title>Help for package tfruns</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tfruns}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as_run_dir'><p>Extract run directory from an object</p></a></li>
<li><a href='#clean_runs'><p>Clean run directories</p></a></li>
<li><a href='#compare_runs'><p>Compare training runs</p></a></li>
<li><a href='#copy_run'><p>Copy run directories</p></a></li>
<li><a href='#flags'><p>Flags for a training run</p></a></li>
<li><a href='#is_run_active'><p>Check for an active training run</p></a></li>
<li><a href='#latest_run'><p>Latest training run</p></a></li>
<li><a href='#ls_runs'><p>List or view training runs</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#run_dir'><p>Current run directory</p></a></li>
<li><a href='#run_info'><p>Summary of training run</p></a></li>
<li><a href='#save_run_comparison'><p>Save a run comparison as HTML</p></a></li>
<li><a href='#save_run_view'><p>Save a run view as HTML</p></a></li>
<li><a href='#training_run'><p>Run a training script</p></a></li>
<li><a href='#tuning_run'><p>Tune hyperparameters using training flags</p></a></li>
<li><a href='#unique_run_dir'><p>Create a unique run directory</p></a></li>
<li><a href='#view_run'><p>View a training run</p></a></li>
<li><a href='#view_run_metrics'><p>View metrics for a training run</p></a></li>
<li><a href='#write_run_data'><p>Write run data (deprecated)</p></a></li>
<li><a href='#write_run_metadata'><p>Write run metadata</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Training Run Tools for 'TensorFlow'</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Create and manage unique directories for each 'TensorFlow' 
  training run. Provides a unique, time stamped directory for each run
  along with functions to retrieve the directory of the latest run or 
  latest several runs. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/rstudio/tfruns">https://github.com/rstudio/tfruns</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rstudio/tfruns/issues">https://github.com/rstudio/tfruns/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, jsonlite (&ge; 1.2), base64enc, yaml, config, magrittr,
whisker, tidyselect, rlang, rstudioapi (&ge; 0.7), reticulate</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, withr, here, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-19 18:11:30 UTC; tomasz</td>
</tr>
<tr>
<td>Author:</td>
<td>Tomasz Kalinowski [ctb, cre],
  Daniel Falbel [ctb],
  JJ Allaire [aut],
  RStudio [cph, fnd],
  Mike Bostock [cph] (D3 library - https://d3js.org/),
  Masayuki Tanaka [cph] (C3 library - http://c3js.org/),
  jQuery Foundation [cph] (jQuery library),
  jQuery contributors [cph] (jQuery library; authors:
    inst/views/components/jquery-AUTHORS.txt),
  Shaun Bowe [cph] (jQuery visibilityChanged plugin),
  Materialize [cph] (Materizlize library - https://materializecss.com/),
  Yuxi You [cph] (Vue.js library - https://vuejs.org/),
  Kevin Decker [cph] (jsdiff library -
    https://github.com/kpdecker/jsdiff/),
  Rodrigo Fernandes [cph] (diff2html library - https://diff2html.xyz/),
  Ivan Sagalaev [cph] (highlight.js library - https://highlightjs.org/),
  Yauheni Pakala [cph] (highlightjs-line-numbers library)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomasz Kalinowski &lt;tomasz@rstudio.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-19 18:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='as_run_dir'>Extract run directory from an object</h2><span id='topic+as_run_dir'></span>

<h3>Description</h3>

<p>Extract run directory from an object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_run_dir(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_run_dir_+3A_x">x</code></td>
<td>
<p>Object to extract run directory from</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Run directory path(s)
</p>

<hr>
<h2 id='clean_runs'>Clean run directories</h2><span id='topic+clean_runs'></span><span id='topic+purge_runs'></span>

<h3>Description</h3>

<p>Remove run directories from the filesystem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_runs(
  runs = ls_runs(runs_dir = runs_dir),
  runs_dir = getOption("tfruns.runs_dir", "runs"),
  confirm = interactive()
)

purge_runs(
  runs_dir = getOption("tfruns.runs_dir", "runs"),
  confirm = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clean_runs_+3A_runs">runs</code></td>
<td>
<p>Runs to clean. Can be specified as a data frame
(as returned by <code><a href="#topic+ls_runs">ls_runs()</a></code>) or as a character vector of
run directories.</p>
</td></tr>
<tr><td><code id="clean_runs_+3A_runs_dir">runs_dir</code></td>
<td>
<p>Directory containing runs. Defaults to &quot;runs&quot; beneath the
current working directory (or to the value of the <code>tfruns.runs_dir</code> R
option if specified).</p>
</td></tr>
<tr><td><code id="clean_runs_+3A_confirm">confirm</code></td>
<td>
<p><code>TRUE</code> to confirm before performing operation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>clean_runs()</code> function moves the specified runs (by default,
all runs) into an &quot;archive&quot; subdirectory of the &quot;runs&quot; directory.
</p>
<p>The <code>purge_runs()</code> function permanently deletes the &quot;archive&quot;
subdirectory.
</p>


<h3>See Also</h3>

<p>Other run management: 
<code><a href="#topic+copy_run">copy_run</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
clean_runs(ls_runs(completed == FALSE))

## End(Not run)

</code></pre>

<hr>
<h2 id='compare_runs'>Compare training runs</h2><span id='topic+compare_runs'></span>

<h3>Description</h3>

<p>Render a visual comparison of two training runs. The runs are
displayed with the most recent run on the right and the
earlier run on the left.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_runs(runs = ls_runs(latest_n = 2), viewer = getOption("tfruns.viewer"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_runs_+3A_runs">runs</code></td>
<td>
<p>Character vector of 2 training run directories or
data frame returned from <code><a href="#topic+ls_runs">ls_runs()</a></code> with at least 2 elements.</p>
</td></tr>
<tr><td><code id="compare_runs_+3A_viewer">viewer</code></td>
<td>
<p>Viewer to display training run information within
(default to an internal page viewer if available, otherwise
to the R session default web browser).</p>
</td></tr>
</table>

<hr>
<h2 id='copy_run'>Copy run directories</h2><span id='topic+copy_run'></span><span id='topic+copy_run_files'></span>

<h3>Description</h3>

<p>Functions for exporting/copying run directories and run artifact files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copy_run(run_dir, to = ".", rename = NULL)

copy_run_files(run_dir, to = ".", rename = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copy_run_+3A_run_dir">run_dir</code></td>
<td>
<p>Training run directory or data frame returned from
<code><a href="#topic+ls_runs">ls_runs()</a></code>.</p>
</td></tr>
<tr><td><code id="copy_run_+3A_to">to</code></td>
<td>
<p>Name of parent directory to copy run(s) into. Defaults to the
current working directory.</p>
</td></tr>
<tr><td><code id="copy_run_+3A_rename">rename</code></td>
<td>
<p>Rename run directory after copying. If not specified this
defaults to the basename of the run directory (e.g.
&quot;2017-09-24T10-54-00Z&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use <code>copy_run</code> to copy one or more run directories.
</p>
<p>Use <code>copy_run_files</code> to copy only files saved/generated by training run
scripts (e.g. saved models, checkpoints, etc.).
</p>


<h3>Value</h3>

<p>Logical vector indicating which operation succeeded for each of the
run directories specified.
</p>


<h3>See Also</h3>

<p>Other run management: 
<code><a href="#topic+clean_runs">clean_runs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# export a run directory to the current working directory
copy_run("runs/2017-09-24T10-54-00Z")

# export to the current working directory then rename
copy_run("runs/2017-09-24T10-54-00Z", rename = "best-run")

# export artifact files only to the current working directory then rename
copy_run_files("runs/2017-09-24T10-54-00Z", rename = "best-model")

# export 3 best eval_acc to a "best-runs" directory
copy_run(ls_runs(order = eval_acc)[1:3,], to = "best-runs")


## End(Not run)
</code></pre>

<hr>
<h2 id='flags'>Flags for a training run</h2><span id='topic+flags'></span><span id='topic+flag_numeric'></span><span id='topic+flag_integer'></span><span id='topic+flag_boolean'></span><span id='topic+flag_string'></span>

<h3>Description</h3>

<p>Define the flags (name, type, default value, description) which paramaterize
a training run. Optionally read overrides of the default values from a
&quot;flags.yml&quot; config file and/or command line arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flags(
  ...,
  config = Sys.getenv("R_CONFIG_ACTIVE", unset = "default"),
  file = "flags.yml",
  arguments = commandArgs(TRUE)
)

flag_numeric(name, default, description = NULL)

flag_integer(name, default, description = NULL)

flag_boolean(name, default, description = NULL)

flag_string(name, default, description = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flags_+3A_...">...</code></td>
<td>
<p>One or more flag definitions</p>
</td></tr>
<tr><td><code id="flags_+3A_config">config</code></td>
<td>
<p>The configuration to use. Defaults to the active configuration
for the current environment (as specified by the <code>R_CONFIG_ACTIVE</code>
environment variable), or <code>default</code> when unset.</p>
</td></tr>
<tr><td><code id="flags_+3A_file">file</code></td>
<td>
<p>The flags YAML file to read</p>
</td></tr>
<tr><td><code id="flags_+3A_arguments">arguments</code></td>
<td>
<p>The command line arguments (as a character vector) to be
parsed.</p>
</td></tr>
<tr><td><code id="flags_+3A_name">name</code></td>
<td>
<p>Flag name</p>
</td></tr>
<tr><td><code id="flags_+3A_default">default</code></td>
<td>
<p>Flag default value</p>
</td></tr>
<tr><td><code id="flags_+3A_description">description</code></td>
<td>
<p>Flag description</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list of training flags
</p>


<h3>Config File Flags</h3>

<p>Config file flags are defined a YAML configuration file (by default
named &quot;flags.yml&quot;). Flags can either appear at the top-level of
the YAML or can be inclued in named configuration sections
(see the <a href="https://github.com/rstudio/config">config package</a> for
details).
</p>


<h3>Command Line Flags</h3>

<p>Command line flags should be of the form <code>--key=value</code> or
<code style="white-space: pre;">&#8288;--key value&#8288;</code>. The values are assumed to be valid <code>yaml</code> and
will be converted using <code><a href="yaml.html#topic+yaml.load">yaml.load()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(tfruns)

# define flags and parse flag values from flags.yml and the command line
FLAGS &lt;- flags(
  flag_numeric('learning_rate', 0.01, 'Initial learning rate.'),
  flag_integer('max_steps', 5000, 'Number of steps to run trainer.'),
  flag_string('data_dir', 'MNIST-data', 'Directory for training data'),
  flag_boolean('fake_data', FALSE, 'If true, use fake data for testing')
)

## End(Not run)

</code></pre>

<hr>
<h2 id='is_run_active'>Check for an active training run</h2><span id='topic+is_run_active'></span>

<h3>Description</h3>

<p>Check for an active training run
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_run_active()
</code></pre>


<h3>Value</h3>

<p><code>TRUE</code> if a training tun is currently active
</p>

<hr>
<h2 id='latest_run'>Latest training run</h2><span id='topic+latest_run'></span>

<h3>Description</h3>

<p>Latest training run
</p>


<h3>Usage</h3>

<pre><code class='language-R'>latest_run(runs_dir = getOption("tfruns.runs_dir", "runs"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="latest_run_+3A_runs_dir">runs_dir</code></td>
<td>
<p>Directory containing runs. Defaults to &quot;runs&quot; beneath the
current working directory (or to the value of the <code>tfruns.runs_dir</code> R
option if specified).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list with run attributes (or <code>NULL</code> if no runs found)
</p>

<hr>
<h2 id='ls_runs'>List or view training runs</h2><span id='topic+ls_runs'></span>

<h3>Description</h3>

<p>List or view training runs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ls_runs(
  subset = NULL,
  order = "start",
  decreasing = TRUE,
  latest_n = NULL,
  runs_dir = getOption("tfruns.runs_dir", "runs")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ls_runs_+3A_subset">subset</code></td>
<td>
<p>Logical expression indicating rows to keep (missing values are
taken as false). See <code><a href="base.html#topic+subset">subset()</a></code>.</p>
</td></tr>
<tr><td><code id="ls_runs_+3A_order">order</code></td>
<td>
<p>Columns to order by (defaults to run start time)</p>
</td></tr>
<tr><td><code id="ls_runs_+3A_decreasing">decreasing</code></td>
<td>
<p><code>TRUE</code> to use decreasing order (e.g. list most recent runs
first)</p>
</td></tr>
<tr><td><code id="ls_runs_+3A_latest_n">latest_n</code></td>
<td>
<p>Limit query to the <code>latest_n</code> most recent runs</p>
</td></tr>
<tr><td><code id="ls_runs_+3A_runs_dir">runs_dir</code></td>
<td>
<p>Directory containing runs. Defaults to &quot;runs&quot; beneath the
current working directory (or to the value of the <code>tfruns.runs_dir</code> R
option if specified).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When printing the results of <code>ls_runs()</code>, only <code>run_dir</code>,
<code>metric_loss</code>, <code>metric_val_loss</code>,  and any columns specified in <code>order</code> will
be printed.
</p>
<p>To view all fields, use <code>View(ls_runs())</code>.
</p>


<h3>Value</h3>

<p>Data frame with training runs
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='run_dir'>Current run directory</h2><span id='topic+run_dir'></span>

<h3>Description</h3>

<p>Returns the current training run directory. If a training run is
not currently active (see <code><a href="#topic+is_run_active">is_run_active()</a></code>) then the current
working directory is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_dir()
</code></pre>


<h3>Value</h3>

<p>Active run direcotry (or current working directory as a fallback)
</p>

<hr>
<h2 id='run_info'>Summary of training run</h2><span id='topic+run_info'></span>

<h3>Description</h3>

<p>Summary of training run
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_info(run_dir)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="run_info_+3A_run_dir">run_dir</code></td>
<td>
<p>Training run directory or data frame returned from
<code><a href="#topic+ls_runs">ls_runs()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Training run summary object with timing, flags, model info, training
and evaluation metrics, etc. If more than one <code>run_dir</code> is passed then
a list of training run summary objects is returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+view_run">view_run()</a></code>
</p>

<hr>
<h2 id='save_run_comparison'>Save a run comparison as HTML</h2><span id='topic+save_run_comparison'></span>

<h3>Description</h3>

<p>Save a run comparison as HTML
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_run_comparison(runs = ls_runs(latest_n = 2), filename = "auto")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="save_run_comparison_+3A_runs">runs</code></td>
<td>
<p>Character vector of 2 training run directories or
data frame returned from <code><a href="#topic+ls_runs">ls_runs()</a></code> with at least 2 elements.</p>
</td></tr>
<tr><td><code id="save_run_comparison_+3A_filename">filename</code></td>
<td>
<p>Path to save the HTML to. If no <code>filename</code> is specified
then a temporary file is used (the path to the file is returned invisibly).</p>
</td></tr>
</table>

<hr>
<h2 id='save_run_view'>Save a run view as HTML</h2><span id='topic+save_run_view'></span>

<h3>Description</h3>

<p>The saved view includes summary information (flags, metrics, model
attributes, etc.), plot and console output, and the code used for the run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_run_view(run_dir = latest_run(), filename = "auto")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="save_run_view_+3A_run_dir">run_dir</code></td>
<td>
<p>Training run directory or data frame returned from
<code><a href="#topic+ls_runs">ls_runs()</a></code>.</p>
</td></tr>
<tr><td><code id="save_run_view_+3A_filename">filename</code></td>
<td>
<p>Path to save the HTML to. If no <code>filename</code> is specified
then a temporary file is used (the path to the file is returned invisibly).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ls_runs">ls_runs()</a></code>, <code><a href="#topic+run_info">run_info()</a></code>, <code><a href="#topic+view_run">view_run()</a></code>
</p>

<hr>
<h2 id='training_run'>Run a training script</h2><span id='topic+training_run'></span>

<h3>Description</h3>

<p>Run a training script
</p>


<h3>Usage</h3>

<pre><code class='language-R'>training_run(
  file = "train.R",
  context = "local",
  config = Sys.getenv("R_CONFIG_ACTIVE", unset = "default"),
  flags = NULL,
  properties = NULL,
  run_dir = NULL,
  artifacts_dir = getwd(),
  echo = TRUE,
  view = "auto",
  envir = parent.frame(),
  encoding = getOption("encoding")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="training_run_+3A_file">file</code></td>
<td>
<p>Path to training script (defaults to &quot;train.R&quot;)</p>
</td></tr>
<tr><td><code id="training_run_+3A_context">context</code></td>
<td>
<p>Run context (defaults to &quot;local&quot;)</p>
</td></tr>
<tr><td><code id="training_run_+3A_config">config</code></td>
<td>
<p>The configuration to use. Defaults to the active configuration
for the current environment (as specified by the <code>R_CONFIG_ACTIVE</code>
environment variable), or <code>default</code> when unset.</p>
</td></tr>
<tr><td><code id="training_run_+3A_flags">flags</code></td>
<td>
<p>Named list with flag values (see <code><a href="#topic+flags">flags()</a></code>) or path
to YAML file containing flag values.</p>
</td></tr>
<tr><td><code id="training_run_+3A_properties">properties</code></td>
<td>
<p>Named character vector with run properties. Properties are
additional metadata about the run which will be subsequently available via
<code><a href="#topic+ls_runs">ls_runs()</a></code>.</p>
</td></tr>
<tr><td><code id="training_run_+3A_run_dir">run_dir</code></td>
<td>
<p>Directory to store run data within</p>
</td></tr>
<tr><td><code id="training_run_+3A_artifacts_dir">artifacts_dir</code></td>
<td>
<p>Directory to capture created and modified files within.
Pass <code>NULL</code> to not capture any artifcats.</p>
</td></tr>
<tr><td><code id="training_run_+3A_echo">echo</code></td>
<td>
<p>Print expressions within training script</p>
</td></tr>
<tr><td><code id="training_run_+3A_view">view</code></td>
<td>
<p>View the results of the run after training. The default &quot;auto&quot;
will view the run when executing a top-level (printed) statement in an
interactive session. Pass <code>TRUE</code> or <code>FALSE</code> to control whether the view is
shown explictly. You can also pass &quot;save&quot; to save a copy of the
run report at <code>tfruns.d/view.html</code></p>
</td></tr>
<tr><td><code id="training_run_+3A_envir">envir</code></td>
<td>
<p>The environment in which the script should be evaluated</p>
</td></tr>
<tr><td><code id="training_run_+3A_encoding">encoding</code></td>
<td>
<p>The encoding of the training script; see <code><a href="base.html#topic+file">file()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The training run will by default use a unique new run directory
within the &quot;runs&quot; sub-directory of the current working directory (or to the
value of the <code>tfruns.runs_dir</code> R option if specified).
</p>
<p>The directory name will be a timestamp (in GMT time). If a duplicate name is
generated then the function will wait long enough to return a unique one.
</p>
<p>If you want to use an alternate directory to store run data you can either
set the global <code>tfruns.runs_dir</code> R option, or you can pass a <code>run_dir</code>
explicitly to <code>training_run()</code>, optionally using the <code><a href="#topic+unique_run_dir">unique_run_dir()</a></code>
function to generate a timestamp-based directory name.
</p>


<h3>Value</h3>

<p>Single row data frame with run flags, metrics, etc.
</p>

<hr>
<h2 id='tuning_run'>Tune hyperparameters using training flags</h2><span id='topic+tuning_run'></span>

<h3>Description</h3>

<p>Run all combinations of the specifed training flags. The number of
combinations can be reduced by specifying the <code>sample</code> parameter, which
will result in a random sample of the flag combinations being run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuning_run(
  file = "train.R",
  context = "local",
  config = Sys.getenv("R_CONFIG_ACTIVE", unset = "default"),
  flags = NULL,
  sample = NULL,
  properties = NULL,
  runs_dir = getOption("tfruns.runs_dir", "runs"),
  artifacts_dir = getwd(),
  echo = TRUE,
  confirm = interactive(),
  envir = parent.frame(),
  encoding = getOption("encoding")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tuning_run_+3A_file">file</code></td>
<td>
<p>Path to training script (defaults to &quot;train.R&quot;)</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_context">context</code></td>
<td>
<p>Run context (defaults to &quot;local&quot;)</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_config">config</code></td>
<td>
<p>The configuration to use. Defaults to the active configuration
for the current environment (as specified by the <code>R_CONFIG_ACTIVE</code>
environment variable), or <code>default</code> when unset.</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_flags">flags</code></td>
<td>
<p>Either a named list with flag values (multiple values can be
provided for each flag) or a data frame that contains pre-generated
combinations of flags (e.g. via <code><a href="base.html#topic+expand.grid">base::expand.grid()</a></code>). The latter can
be useful for subsetting combinations. See 'Examples'.</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_sample">sample</code></td>
<td>
<p>Sampling rate for flag combinations (defaults to
running all combinations).</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_properties">properties</code></td>
<td>
<p>Named character vector with run properties. Properties are
additional metadata about the run which will be subsequently available via
<code><a href="#topic+ls_runs">ls_runs()</a></code>.</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_runs_dir">runs_dir</code></td>
<td>
<p>Directory containing runs. Defaults to &quot;runs&quot; beneath the
current working directory (or to the value of the <code>tfruns.runs_dir</code> R
option if specified).</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_artifacts_dir">artifacts_dir</code></td>
<td>
<p>Directory to capture created and modified files within.
Pass <code>NULL</code> to not capture any artifcats.</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_echo">echo</code></td>
<td>
<p>Print expressions within training script</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_confirm">confirm</code></td>
<td>
<p>Confirm before executing tuning run.</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_envir">envir</code></td>
<td>
<p>The environment in which the script should be evaluated</p>
</td></tr>
<tr><td><code id="tuning_run_+3A_encoding">encoding</code></td>
<td>
<p>The encoding of the training script; see <code><a href="base.html#topic+file">file()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame with summary of all training runs performed
during tuning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(tfruns)

# using a list as input to the flags argument
runs &lt;- tuning_run(
  system.file("examples/mnist_mlp/mnist_mlp.R", package = "tfruns"),
  flags = list(
    dropout1 = c(0.2, 0.3, 0.4),
    dropout2 = c(0.2, 0.3, 0.4)
  )
)
runs[order(runs$eval_acc, decreasing = TRUE), ]

# using a data frame as input to the flags argument
# resulting in the same combinations above, but remove those
# where the combined dropout rate exceeds 1
grid &lt;- expand.grid(
  dropout1 = c(0.2, 0.3, 0.4),
  dropout2 = c(0.2, 0.3, 0.4)
)
grid$combined_droput &lt;- grid$dropout1 + grid$dropout2
grid &lt;- grid[grid$combined_droput &lt;= 1, ]
runs &lt;- tuning_run(
  system.file("examples/mnist_mlp/mnist_mlp.R", package = "tfruns"),
  flags = grid[, c("dropout1", "dropout2")]
)

## End(Not run)
</code></pre>

<hr>
<h2 id='unique_run_dir'>Create a unique run directory</h2><span id='topic+unique_run_dir'></span>

<h3>Description</h3>

<p>Create a new uniquely named run directory within the specified <code>runs_dir</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unique_run_dir(
  runs_dir = getOption("tfruns.runs_dir", "runs"),
  seconds_scale = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unique_run_dir_+3A_runs_dir">runs_dir</code></td>
<td>
<p>Directory containing runs. Defaults to &quot;runs&quot; beneath the
current working directory (or to the value of the <code>tfruns.runs_dir</code> R
option if specified).</p>
</td></tr>
<tr><td><code id="unique_run_dir_+3A_seconds_scale">seconds_scale</code></td>
<td>
<p>Decimal scale for the seconds component of the
timestamp. Defaults to 0 which results in only the rounded seconds value
being used in the timestamp. Specify larger numbers to include a decimal
component (useful if you need to create many unique run directories at the
same time).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The directory name will be a timestamp (in GMT time). If a duplicate name is
generated then the function will wait long enough to return a unique one.
</p>

<hr>
<h2 id='view_run'>View a training run</h2><span id='topic+view_run'></span>

<h3>Description</h3>

<p>View metrics and other attributes of a training run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>view_run(run_dir = latest_run(), viewer = getOption("tfruns.viewer"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="view_run_+3A_run_dir">run_dir</code></td>
<td>
<p>Training run directory or data frame returned from
<code><a href="#topic+ls_runs">ls_runs()</a></code>.</p>
</td></tr>
<tr><td><code id="view_run_+3A_viewer">viewer</code></td>
<td>
<p>Viewer to display training run information within
(default to an internal page viewer if available, otherwise
to the R session default web browser).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ls_runs">ls_runs()</a></code>, <code><a href="#topic+run_info">run_info()</a></code>
</p>

<hr>
<h2 id='view_run_metrics'>View metrics for a training run</h2><span id='topic+view_run_metrics'></span><span id='topic+update_run_metrics'></span>

<h3>Description</h3>

<p>Interactive D3 visualization of metrics for a training run. Metrics will
be displayed in the RStudio Viewer (if available), otherwise will be
displayed in an external web browser.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>view_run_metrics(metrics)

update_run_metrics(viewer, metrics)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="view_run_metrics_+3A_metrics">metrics</code></td>
<td>
<p>Data frame containing run metrics</p>
</td></tr>
<tr><td><code id="view_run_metrics_+3A_viewer">viewer</code></td>
<td>
<p>Viewer object returned from <code>view_run_metrics()</code>.</p>
</td></tr>
</table>


<h3>Metrics Data Frame</h3>

<p>Metrics should be passed as a data frame with one column for each metric.
If the metrics are not yet complete (e.g. only metrics for the
first several epochs are provided) then metrics in yet to be completed
epochs should use <code>NA</code> as their values. For example:
</p>
<div class="sourceCode"><pre>data.frame':	30 obs. of  4 variables:
$ loss    : num  0.423 0.201 NA NA NA ...
$ acc     : num  0.873 0.942 NA NA NA ...
$ val_loss: num  0.174 0.121 NA NA NA ...
$ val_acc : num  0.949 0.964 NA NA NA ...
</pre></div>
<p>If both metrics and validation metrics are provided, you should preface the
name of the validation metric with <code>"val_"</code> (e.g. for a metric named <code>"loss"</code>
provide validation metrics in <code>"val_loss"</code>). This indicates that the metrics
are related which is useful e.g. when plotting metrics.
</p>


<h3>Realtime Updates</h3>

<p>Metrics can be updated in real-time by calling the <code>update_run_metrics()</code>
with the run viewer instance returned from <code>view_run_metrics()</code>. For example:
</p>
<div class="sourceCode"><pre># view metrics
viewer &lt;- view_run_metrics(metrics)

# update with new metrics
update_run_metrics(viewer, updated_metrics)
</pre></div>


<h3>Note</h3>

<p>Metrics named <code>"acc"</code> or <code>"accuracy"</code> will automatically use <code>1.0</code> as the
maximum value on their y-axis scale.
</p>


<h3>See Also</h3>

<p>write_run_metrics
</p>

<hr>
<h2 id='write_run_data'>Write run data (deprecated)</h2><span id='topic+write_run_data'></span>

<h3>Description</h3>

<p>Deprecated alias for <code><a href="#topic+write_run_metadata">write_run_metadata()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_run_data(type, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_run_data_+3A_type">type</code></td>
<td>
<p>Type of metadata to write. Standard types include &quot;flags&quot;,
&quot;sources&quot;, &quot;properties&quot;, &quot;metrics&quot;, and &quot;evaluation&quot;. You can
also specify a custom type (see <em>Custom Types</em> section below).</p>
</td></tr>
<tr><td><code id="write_run_data_+3A_data">data</code></td>
<td>
<p>Metadata to write:
</p>

<ul>
<li><p> &quot;flags&quot; &mdash; Named list of training flags
</p>
</li>
<li><p> &quot;source&quot; &mdash; Directory to copy source files from
</p>
</li>
<li><p> &quot;properties&quot; &mdash; Named list of arbitrary properties. Note
that properties will be stored as strings.
</p>
</li>
<li><p> &quot;metrics&quot; &mdash; Data frame with training run metrics
(see <em>Metrics Data Frame</em> below).
</p>
</li>
<li><p> &quot;evaluation&quot; &mdash; Named list of evaluation metrics.
</p>
</li>
<li><p> &quot;error&quot; &mdash; Named list with 'message' and 'traceback'
</p>
</li>
<li><p> &quot;\&lt;custom\&gt;&quot; &ndash; Function used to write the data
(see <em>Custom Types</em> section below).
</p>
</li></ul>
</td></tr>
</table>

<hr>
<h2 id='write_run_metadata'>Write run metadata</h2><span id='topic+write_run_metadata'></span>

<h3>Description</h3>

<p>Record various types of training run metadata This function can be called
even when a run directory isn't active (metadata will only be written if
and when a run directory is initialized).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_run_metadata(type, data, run_dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_run_metadata_+3A_type">type</code></td>
<td>
<p>Type of metadata to write. Standard types include &quot;flags&quot;,
&quot;sources&quot;, &quot;properties&quot;, &quot;metrics&quot;, and &quot;evaluation&quot;. You can
also specify a custom type (see <em>Custom Types</em> section below).</p>
</td></tr>
<tr><td><code id="write_run_metadata_+3A_data">data</code></td>
<td>
<p>Metadata to write:
</p>

<ul>
<li><p> &quot;flags&quot; &mdash; Named list of training flags
</p>
</li>
<li><p> &quot;source&quot; &mdash; Directory to copy source files from
</p>
</li>
<li><p> &quot;properties&quot; &mdash; Named list of arbitrary properties. Note
that properties will be stored as strings.
</p>
</li>
<li><p> &quot;metrics&quot; &mdash; Data frame with training run metrics
(see <em>Metrics Data Frame</em> below).
</p>
</li>
<li><p> &quot;evaluation&quot; &mdash; Named list of evaluation metrics.
</p>
</li>
<li><p> &quot;error&quot; &mdash; Named list with 'message' and 'traceback'
</p>
</li>
<li><p> &quot;\&lt;custom\&gt;&quot; &ndash; Function used to write the data
(see <em>Custom Types</em> section below).
</p>
</li></ul>
</td></tr>
<tr><td><code id="write_run_metadata_+3A_run_dir">run_dir</code></td>
<td>
<p>Run directory to write metadata into (defaults
to currently active run)</p>
</td></tr>
</table>


<h3>Metrics Data Frame</h3>

<p>Metrics should be passed as a data frame with one column for each metric.
If the metrics are not yet complete (e.g. only metrics for the
first several epochs are provided) then metrics in yet to be completed
epochs should use <code>NA</code> as their values. For example:
</p>
<div class="sourceCode"><pre>data.frame':	30 obs. of  4 variables:
$ loss    : num  0.423 0.201 NA NA NA ...
$ acc     : num  0.873 0.942 NA NA NA ...
$ val_loss: num  0.174 0.121 NA NA NA ...
$ val_acc : num  0.949 0.964 NA NA NA ...
</pre></div>
<p>If both metrics and validation metrics are provided, you should preface the
name of the validation metric with <code>"val_"</code> (e.g. for a metric named <code>"loss"</code>
provide validation metrics in <code>"val_loss"</code>). This indicates that the metrics
are related which is useful e.g. when plotting metrics.
</p>


<h3>Custom Types</h3>

<p>You can pass a type with an arbitary name along with a function that
should be used to writes the data. The function will be passed a
single <code>data_dir</code> argument. For example:
</p>
<div class="sourceCode r"><pre>write_run_metadata("images", function(data_dir) {
  # write into data_dir here
})
</pre></div>


<h3>Note</h3>

<p><code>write_run_data()</code> is deprecated and is provided as an alias
for backward compatibility.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
