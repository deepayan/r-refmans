<!DOCTYPE html><html><head><title>Help for package Tlasso</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Tlasso}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#biascor'><p>Bias Correction of Sample Covariance of Residuals</p></a></li>
<li><a href='#ChainOmega'><p>Precision Matrix of Triangle Graph</p></a></li>
<li><a href='#covres'><p>Sample Covariance Matrix of Residuals</p></a></li>
<li><a href='#est.analysis'><p>Estimation Errors and TPR/TNR</p></a></li>
<li><a href='#graph.pattern'><p>Graph Pattern Visualization</p></a></li>
<li><a href='#infer.analysis'><p>Inference Performance Measures</p></a></li>
<li><a href='#NeighborOmega'><p>Precision Matrix of Nearest-Neighbor Graph</p></a></li>
<li><a href='#signal'><p>Regression Parameter of Conditional Linear Model</p></a></li>
<li><a href='#Tlasso'><p>Non-Convex Optimization and Statistical Inference for Sparse Tensor Graphical Models</p></a></li>
<li><a href='#Tlasso.fit'><p>Non-Convex Optimization for Sparse Tensor Graphical Models</p></a></li>
<li><a href='#Trnorm'><p>Separable Tensor Normal Distribution</p></a></li>
<li><a href='#varcor'><p>Variance Correction of Sample Covariance of Residuals</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Non-Convex Optimization and Statistical Inference for Sparse
Tensor Graphical Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>An optimal alternating optimization algorithm for estimation of precision matrices of sparse tensor graphical models, and an efficient inference procedure for support recovery of the precision matrices.</td>
</tr>
<tr>
<td>Imports:</td>
<td>huge, expm, rTensor, igraph, stats, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xiang Lyu &lt;xianglyu@berkeley.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-31 08:18:14 UTC; xianglyu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-01 08:20:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='biascor'>Bias Correction of Sample Covariance of Residuals</h2><span id='topic+biascor'></span>

<h3>Description</h3>

<p>Generate a matrix of bias-corrected sample covariance of residuals (excludes diagnoal) described in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biascor(rho, Omega.list, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biascor_+3A_rho">rho</code></td>
<td>
<p>matrix of sample covariance of residuals (includes diagnoal), e.g., output of <code><a href="#topic+covres">covres</a></code>.</p>
</td></tr>
<tr><td><code id="biascor_+3A_omega.list">Omega.list</code></td>
<td>
<p>list of precision matrices of tensor, i.e., <code>Omega.list[[k]]</code> is the precision matrix 
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>. For example, output of <code>link{Tlasso.fit}</code>.</p>
</td></tr>
<tr><td><code id="biascor_+3A_k">k</code></td>
<td>
<p>index of interested mode, default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes bias-corrected sample covariance of residuals (excludes diagnoal, diagnoal is zero vector). 
Note that output matrix excludes diagnoal while sample covariance of residuals includes diagnoal, see <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a> for details. 
Elements in <code>Omega.list</code> are true precision matrices or estimation of the true ones, the latter can be output of <code><a href="#topic+Tlasso.fit">Tlasso.fit</a></code>.
</p>


<h3>Value</h3>

<p>A matrix whose (i,j) entry (excludes diagnoal; diagnoal is zero vector) is bias-corrected sample covariance of the ith and jth residuals in the kth mode. See <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a> for details.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varcor">varcor</a></code>, <code><a href="#topic+covres">covres</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
k=1 # index of interested mode
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=1,lambda.vec = lambda.thm)   
# output is a list of estimation of precision matrices

rho=covres(DATA, out.tlasso, k = k) 
# sample covariance of residuals, including diagnoal 
bias_rho=biascor(rho,out.tlasso,k=k)
bias_rho # bias-corrected sample covariance of residuals
# diagnoal is zero vector

</code></pre>

<hr>
<h2 id='ChainOmega'>Precision Matrix of Triangle Graph</h2><span id='topic+ChainOmega'></span>

<h3>Description</h3>

<p>Generate precision matrix of triangle graph (chain like network) following the set-up in <a href="https://arxiv.org/abs/0908.2053">Fan et al. (2009)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ChainOmega(p, sd = 1, norm.type = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ChainOmega_+3A_p">p</code></td>
<td>
<p>dimension of generated precision matrix.</p>
</td></tr>
<tr><td><code id="ChainOmega_+3A_sd">sd</code></td>
<td>
<p>seed for random number generation, default is 1.</p>
</td></tr>
<tr><td><code id="ChainOmega_+3A_norm.type">norm.type</code></td>
<td>
<p>normalization methods of generated precision matrix, i.e., <code class="reqn">\Omega_{11} = 1</code> 
if norm.type = 1 and <code class="reqn">\|\Omega\|_{F}=1</code> if norm.type = 2. Default value is 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function first construct a covariance matrix <code class="reqn">\Sigma</code> that its (i,j) entry is 
<code class="reqn">\exp (- | h_i - h_j |/2)</code> with <code class="reqn">h_1 &lt; h_2 &lt; \ldots &lt; h_p</code>.
The difference <code class="reqn">h_i - h_{i+1}</code> is generated i.i.d. from Unif(0.5,1). See <a href="https://arxiv.org/abs/0908.2053">Fan et al. (2009)</a> 
for more details.
</p>


<h3>Value</h3>

<p>A precision matrix generated from triangle graph.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NeighborOmega">NeighborOmega</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 

Omega.true.list = list()

for ( k in 1:length(m.vec)){
 Omega.true.list[[k]] = ChainOmega(m.vec[k],sd=k*100,norm.type=2)
}
Omega.true.list  # a list of length 3 contains precision matrices from triangle graph

</code></pre>

<hr>
<h2 id='covres'>Sample Covariance Matrix of Residuals</h2><span id='topic+covres'></span>

<h3>Description</h3>

<p>Generate sample covariance matrix of residuals (includes diagnoal) described in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covres(data, Omega.list, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covres_+3A_data">data</code></td>
<td>
<p>tensor object stored in a m1 * m2 * ... * mK * n array, where n is sample size
and mk is dimension of the kth tensor mode.</p>
</td></tr>
<tr><td><code id="covres_+3A_omega.list">Omega.list</code></td>
<td>
<p>list of precision matrices of tensor, i.e., <code>Omega.list[[k]]</code> is precision matrix 
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>.</p>
</td></tr>
<tr><td><code id="covres_+3A_k">k</code></td>
<td>
<p>index of interested mode, default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes sample covariance of residuals and is the basis for support recovery procedure in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>. Note that output matrix includes 
diagnoal while bias corrected matrix (output of <code><a href="#topic+biascor">biascor</a></code>) for inference is off-diagnoal, see <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a> for details.
Elements in Omega.list are true precision matrices or estimation of the true ones, the latter can be output of <code><a href="#topic+Tlasso.fit">Tlasso.fit</a></code>.
</p>


<h3>Value</h3>

<p>A matrix whose (i,j) entry (includes diagnoal) is sample covariance of the ith and jth residuals in the kth mode. See <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a> for details.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varcor">varcor</a></code>, <code><a href="#topic+biascor">biascor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
k=1 # index of interested mode
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=1,lambda.vec = lambda.thm)   
# output is a list of estimation of precision matrices
rho=covres(DATA, out.tlasso, k = k) # sample covariance of residuals, including diagnoal 
rho

</code></pre>

<hr>
<h2 id='est.analysis'>Estimation Errors and TPR/TNR</h2><span id='topic+est.analysis'></span>

<h3>Description</h3>

<p>Compute estimation errors and TPR/TNR of optimization for sparse tensor graphical models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est.analysis(Omega.hat.list, Omega.true.list, offdiag = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est.analysis_+3A_omega.hat.list">Omega.hat.list</code></td>
<td>
<p>list of estimation of precision matrices of tensor, i.e., <code>Omega.hat.list[[k]]</code> is estimation of precision matrix 
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>. For example, output of <code><a href="#topic+Tlasso.fit">Tlasso.fit</a></code>.</p>
</td></tr>
<tr><td><code id="est.analysis_+3A_omega.true.list">Omega.true.list</code></td>
<td>
<p>list of true precision matrices of tensor, i.e., <code>Omega.true.list[[k]]</code> is true precision matrix 
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>.</p>
</td></tr>
<tr><td><code id="est.analysis_+3A_offdiag">offdiag</code></td>
<td>
<p>logical; indicate if excludes diagnoal when computing performance measures. 
If <code>offdiag = TRUE</code>, diagnoal in each matrix is ingored 
when comparing two matrices. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes performance measures of optimazation for sparse tensor graphical models. 
Errors are measured in Frobenius norm and Max norm. Model selection measures are TPR and TNR. All these measures are computed in each 
mode, average across all modes, and kronecker production of precision matrices.
</p>


<h3>Value</h3>

<p>A list, named <code>Out</code>, of following performance measures:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Out$error.kro</code>  </td><td style="text-align: left;">  error in Frobenius norm of kronecker product </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$tpr.kro</code>  </td><td style="text-align: left;">   TPR of kronecker product </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$tnr.kro</code>  </td><td style="text-align: left;">     TNR of kronecker product </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$av.error.f</code>  </td><td style="text-align: left;">  averaged Frobenius norm error across all modes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$av.error.max</code>  </td><td style="text-align: left;">  averaged Max norm error across all modes </td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code>Out$av.tpr</code>  </td><td style="text-align: left;">  averaged TPR across all modes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$av.tnr</code>  </td><td style="text-align: left;">  averaged TNR across all modes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$error.f</code>  </td><td style="text-align: left;">  vector; error in Frobenius norm of each mode  </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$error.max</code>  </td><td style="text-align: left;">  vector; error in Max norm of each mode  </td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code>Out$tpr</code>  </td><td style="text-align: left;">  vector; TPR of each mode </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Out$tnr</code>  </td><td style="text-align: left;">   vector; TNR of each mode   </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Tlasso.fit">Tlasso.fit</a></code>, <code><a href="#topic+NeighborOmega">NeighborOmega</a></code>, <code><a href="#topic+ChainOmega">ChainOmega</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
k=1 # index of interested mode
Omega.true.list = list()
Omega.true.list[[1]] = ChainOmega(m.vec[1], sd = 1)
Omega.true.list[[2]] = ChainOmega(m.vec[2], sd = 2)
Omega.true.list[[3]] = ChainOmega(m.vec[3], sd = 3)
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=1,lambda.vec = lambda.thm)   
# output is a list of estimation of precision matrices
est.analysis(out.tlasso, Omega.true.list, offdiag=TRUE)
# generate a list of performance measures

</code></pre>

<hr>
<h2 id='graph.pattern'>Graph Pattern Visualization</h2><span id='topic+graph.pattern'></span>

<h3>Description</h3>

<p>Draw an undirected graph based on presicion matrix to present connection among variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph.pattern(
  mat,
  main = NULL,
  edge.color = "gray50",
  vertex.color = "red",
  vertex.size = 3,
  vertex.label = NA,
  thres = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph.pattern_+3A_mat">mat</code></td>
<td>
<p>precision matrix that encodes information of graph struture.</p>
</td></tr>
<tr><td><code id="graph.pattern_+3A_main">main</code></td>
<td>
<p>main title of graph. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="graph.pattern_+3A_edge.color">edge.color</code></td>
<td>
<p>color of edge. Default is <code>"gray50"</code>.</p>
</td></tr>
<tr><td><code id="graph.pattern_+3A_vertex.color">vertex.color</code></td>
<td>
<p>color of vertex. Default is <code>"red"</code>.</p>
</td></tr>
<tr><td><code id="graph.pattern_+3A_vertex.size">vertex.size</code></td>
<td>
<p>size of vertex. Default is 3.</p>
</td></tr>
<tr><td><code id="graph.pattern_+3A_vertex.label">vertex.label</code></td>
<td>
<p>label of vertex. Default is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="graph.pattern_+3A_thres">thres</code></td>
<td>
<p>thresholding level of substituting entry with zero, 
set entry to zero if its absolute value equals or is less than <code>thres</code>. 
If <code>thres</code> is negative or zero, no entry will be substituted with zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates an udirected graph based on precision matrix. 
If an entry is zero, then no edge connects corresponding pair of nodes.
</p>


<h3>Value</h3>

<p>A plot of undirected graph.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+infer.analysis">infer.analysis</a></code>, <code><a href="#topic+est.analysis">est.analysis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
graph.pattern(ChainOmega(5, sd = 13))
# a triangle graph

</code></pre>

<hr>
<h2 id='infer.analysis'>Inference Performance Measures</h2><span id='topic+infer.analysis'></span>

<h3>Description</h3>

<p>False positive, false negative, discoveries, and non-discoveries of inference for sparse tensor graphical models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.analysis(mat.list, critical, Omega.true.list, offdiag = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.analysis_+3A_mat.list">mat.list</code></td>
<td>
<p>list of matrices. (i,j) entry in its kth element is test statistic 
value for (i,j) entry of kth true precision matrix.</p>
</td></tr>
<tr><td><code id="infer.analysis_+3A_critical">critical</code></td>
<td>
<p>critical level of rejecting null hypothesis. If <code>critical</code> is not positive, all null hypothesis will not be rejected.</p>
</td></tr>
<tr><td><code id="infer.analysis_+3A_omega.true.list">Omega.true.list</code></td>
<td>
<p>list of true precision matrices of tensor, i.e., <code>Omega.true.list[[k]]</code> is true precision matrix 
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>.</p>
</td></tr>
<tr><td><code id="infer.analysis_+3A_offdiag">offdiag</code></td>
<td>
<p>logical; indicate if excludes diagnoal when computing performance measures. 
If <code>offdiag = TRUE</code>, diagnoal in each matrix is ingored 
when comparing two matrices. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes performance measures of inference for sparse tensor graphical models. 
False positive, false negative, discovery (number of rejected null hypothesis), non-discovery (number of non-rejected null hypothesis), 
and total non-zero entries of each true precision matrix is listed in output.
</p>


<h3>Value</h3>

<p>A list, named <code>Out</code>, of following performance measures:
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>Out$fp</code>  </td><td style="text-align: left;">  vector; number of false positive of each mode </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>Out$fn</code>  </td><td style="text-align: left;">  vector; number of false negative of each mode </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>Out$d</code>  </td><td style="text-align: left;">   vector; number of all discovery of each mode </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>Out$nd</code>  </td><td style="text-align: left;">  vector; number of all non-discovery of each mode </td>
</tr>
<tr>
 <td style="text-align: left;"> 
 <code>Out$t</code>  </td><td style="text-align: left;">   vector; number of all true non-zero entries in true precision matrix of each mode </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Tlasso.fit">Tlasso.fit</a></code>, <code><a href="#topic+est.analysis">est.analysis</a></code>, <code><a href="#topic+ChainOmega">ChainOmega</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
Omega.true.list = list()
Omega.true.list[[1]] = ChainOmega(m.vec[1], sd = 1)
Omega.true.list[[2]] = ChainOmega(m.vec[2], sd = 2)
Omega.true.list[[3]] = ChainOmega(m.vec[3], sd = 3)
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=1,lambda.vec = lambda.thm)   
# output is a list of estimation of precision matrices
mat.list=list()
for ( k in 1:3) {
  rho=covres(DATA, out.tlasso, k = k) 
  # sample covariance of residuals, including diagnoal 
  varpi2=varcor(DATA, out.tlasso, k = k)
  # variance correction term for kth mode's sample covariance of residuals
  bias_rho=biascor(rho,out.tlasso,k=k)
  # bias corrected 
  
  tautest=matrix(0,m.vec[k],m.vec[k])
  for( i in 1:(m.vec[k]-1)) {
    for ( j in (i+1):m.vec[k]){
      tautest[j,i]=tautest[i,j]=sqrt((n-1)*prod(m.vec[-k]))*
        bias_rho[i,j]/sqrt(varpi2*rho[i,i]*rho[j,j])
    }
  }
  # list of matrices of test statistic values (off-diagnoal). See Sun et al. 2016
  mat.list[[k]]=tautest
}

infer.analysis(mat.list, qnorm(0.975), Omega.true.list, offdiag=TRUE)
# inference measures (off-diagnoal) 

</code></pre>

<hr>
<h2 id='NeighborOmega'>Precision Matrix of Nearest-Neighbor Graph</h2><span id='topic+NeighborOmega'></span>

<h3>Description</h3>

<p>Generate precision matrix of nearest-neighbor network following the set-up in <a href="https://paperity.org/p/38773767/gradient-directed-regularization-for-sparse-gaussian-concentration-graphs-with">Li and Gui (2006)</a>
and <a href="https://www.jmlr.org/papers/volume16/lee15a/lee15a.pdf">Lee and Liu (2006)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NeighborOmega(p, sd = 1, knn = 4, norm.type = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NeighborOmega_+3A_p">p</code></td>
<td>
<p>dimension of generated precision matrix.</p>
</td></tr>
<tr><td><code id="NeighborOmega_+3A_sd">sd</code></td>
<td>
<p>seed for random number generation. Default is 1.</p>
</td></tr>
<tr><td><code id="NeighborOmega_+3A_knn">knn</code></td>
<td>
<p>sparsity of precision matrix, i.e., matrix is generated from a <code>knn</code> nearest-neighbor graph. <code>knn</code> should be less than <code>p</code>. Default is 4.</p>
</td></tr>
<tr><td><code id="NeighborOmega_+3A_norm.type">norm.type</code></td>
<td>
<p>normalization methods of generated precision matrix, i.e., <code class="reqn">\Omega_{11} = 1</code> 
if norm.type = 1 and <code class="reqn">\|\Omega\|_{F}=1</code> if norm.type = 2. Default value is 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a <code>knn</code> nearest-neighbor graph, this function first randomly picks p points from a 
unit square and computes all pairwise distances among the points. Then it searches for the knn nearest-neighbors
of each point and a pair of symmetric entries in the precision matrix that has a random chosen value from <code class="reqn">[-1, -0.5] \cup [0.5, 1]</code>. Finally, to 
ensure positive definite property, it normalizes the matrix as <code class="reqn">\Omega &lt;- \Omega + (\lambda (\Omega) + 0.2 ) 1_p</code> where 
<code class="reqn">\lambda (\cdot )</code> refers to the samllest eigenvalue.
</p>


<h3>Value</h3>

<p>A precision matrix generated from the <code>knn</code> nearest-neighor graph.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ChainOmega">ChainOmega</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
knn=4 # sparsity 

Omega.true.list = list()

for ( k in 1:length(m.vec)){
  Omega.true.list[[k]] = NeighborOmega(m.vec[k],knn=4, sd=k*100,norm.type=2)
}
Omega.true.list  # a list of length 3 contains precision matrices from 4-nearnest neighbor graph

</code></pre>

<hr>
<h2 id='signal'>Regression Parameter of Conditional Linear Model</h2><span id='topic+signal'></span>

<h3>Description</h3>

<p>Compute regression parameter of conditional linear model of separable tensor normal distribution described in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signal(Omega.list, i = 1, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="signal_+3A_omega.list">Omega.list</code></td>
<td>
<p>list of precision matrices of tensor, i.e., <code>Omega.list[[k]]</code> is the kth precision matrix.
Omega.list can be either true precision matrices or output of <code>Tlasso.fit</code>.   
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>.</p>
</td></tr>
<tr><td><code id="signal_+3A_i">i</code></td>
<td>
<p>index of interested regression parameter, default is 1. See details in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.</p>
</td></tr>
<tr><td><code id="signal_+3A_k">k</code></td>
<td>
<p>index of interested mode, default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes regression parameter and is fundamental for sample covariance of residuals and 
bias correction. See details in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.
</p>


<h3>Value</h3>

<p>A vector of regression paramter.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covres">covres</a></code>, <code><a href="#topic+biascor">biascor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
k=1 # index of interested mode
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=1,lambda.vec = lambda.thm)   
# output is a list of estimation of precision matrices
signal(out.tlasso, i=2 , k=k )
# the regression parameter for conditional linear model of 2rd row in 1st mode

</code></pre>

<hr>
<h2 id='Tlasso'>Non-Convex Optimization and Statistical Inference for Sparse Tensor Graphical Models</h2><span id='topic+Tlasso'></span>

<h3>Description</h3>

<p>An optimal alternating optimization algorithm for estimation of precision matrices of sparse tensor graphical models, and an efficient inference procedure for support recovery of the precision matrices.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
  Package: </td><td style="text-align: left;"> Tlasso </td>
</tr>
<tr>
 <td style="text-align: left;">
  Type: </td><td style="text-align: left;"> Package </td>
</tr>
<tr>
 <td style="text-align: left;">
  Date </td><td style="text-align: left;"> 2016-09-17 </td>
</tr>
<tr>
 <td style="text-align: left;">
  License: </td><td style="text-align: left;"> GPL (&gt;= 2) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>


<table>
<tr>
 <td style="text-align: left;">
  Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng. </td>
</tr>
<tr>
 <td style="text-align: left;">
  Maintainer: Xiang Lyu &lt;xianglyu@berkeley.edu&gt;
</td>
</tr>

</table>



<h3>References</h3>


<table>
<tr>
 <td style="text-align: left;">
         Fan J, Feng Y, Wu Y. <em>Network exploration via the adaptive LASSO and SCAD penalties.</em> The annals of applied statistics, 2009, 3(2): 521. </td>
</tr>
<tr>
 <td style="text-align: left;">
         Friedman J, Hastie T, Tibshirani R. <em>Sparse inverse covariance estimation with the graphical lasso.</em> Biostatistics, 2008: 9.3: 432-441. </td>
</tr>
<tr>
 <td style="text-align: left;">
         Lee W, Liu Y. <em>Joint estimation of multiple precision matrices with common structures.</em> Journal of Machine Learning Research, 2015, 16: 1035-1062. </td>
</tr>
<tr>
 <td style="text-align: left;">
         Li H, Gui J. <em>Gradient directed regularization for sparse Gaussian concentration graphs, with applications to inference of genetic networks.</em> Biostatistics, 2006, 7(2): 302-317. </td>
</tr>
<tr>
 <td style="text-align: left;">
         Lyu X, Sun W, Wang Z, Liu H, Yang J, Cheng G. <em>Tensor Graphical Model: Non-convex Optimization and Statistical Inference.</em> IEEE transactions on pattern analysis and machine intelligence, 2019, 42(8): 2024-2037.
    </td>
</tr>

</table>


<hr>
<h2 id='Tlasso.fit'>Non-Convex Optimization for Sparse Tensor Graphical Models</h2><span id='topic+Tlasso.fit'></span>

<h3>Description</h3>

<p>An alternating optimization algorithm for estimation of precision matrices of sparse tensor graphical models. See <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tlasso.fit(data, T = 1, lambda.vec = NULL, norm.type = 2, thres = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tlasso.fit_+3A_data">data</code></td>
<td>
<p>tensor object stored in a m1 * m2 * ... * mK * n array, where n is sample size
and mk is dimension of the kth tensor mode.</p>
</td></tr>
<tr><td><code id="Tlasso.fit_+3A_t">T</code></td>
<td>
<p>number of maximal iteration, default is 1. Each iteration involves update on all modes. 
If output change less than <code>thres</code> after certain iteration, in terms of summation on Frobenius norm, this function will be terminated (before Tth iteration).</p>
</td></tr>
<tr><td><code id="Tlasso.fit_+3A_lambda.vec">lambda.vec</code></td>
<td>
<p>vector of tuning parameters (<code class="reqn">\lambda_1</code>,...,<code class="reqn">\lambda_K</code>). Defalut is NULL, s.t. it is tuned via <code>HUGE</code> package directly.</p>
</td></tr>
<tr><td><code id="Tlasso.fit_+3A_norm.type">norm.type</code></td>
<td>
<p>normalization method of precision matrix, i.e., <code class="reqn">\Omega_{11} = 1</code> 
if norm.type = 1 and <code class="reqn">\|\Omega\|_{F}=1</code> if norm.type = 2. Default value is 2.</p>
</td></tr>
<tr><td><code id="Tlasso.fit_+3A_thres">thres</code></td>
<td>
<p>thresholding value that terminates algorithm before Tth iteration if output change less than <code>thres</code> after certain iteration, in terms of summation over Frobenius norm. 
If <code>thres</code> is negative or zero, this algorithm will iterate T times.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function conducts an alternating optimization algorithm to sparse tensor graphical model. The output is optimal consistent even when <code>T=1</code>, see <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a> for details.
There are two ternimation criteria, <code>T</code> and <code>thres</code>. Algorithm will be terminated if output in certain iteration change less than <code>thres</code>. Otherwise, T iterations will be fully operated.
</p>


<h3>Value</h3>

<p>A length-K list of estimation of precision matrices.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varcor">varcor</a></code>, <code><a href="#topic+biascor">biascor</a></code>, <code><a href="huge.html#topic+huge">huge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                  sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                  sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=10,lambda.vec = lambda.thm,thres=10)   
# terminate by thres
out.tlasso = Tlasso.fit(DATA,T=3,lambda.vec = lambda.thm,thres=0)   
# thres=0, iterate 10 times


</code></pre>

<hr>
<h2 id='Trnorm'>Separable Tensor Normal Distribution</h2><span id='topic+Trnorm'></span>

<h3>Description</h3>

<p>Generate observations from separable tensor normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Trnorm(
  n,
  m.vec,
  mu = array(0, m.vec),
  Sigma.list = NULL,
  type = "Chain",
  sd = 1,
  knn = 4,
  norm.type = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Trnorm_+3A_n">n</code></td>
<td>
<p>number of generated observations.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_m.vec">m.vec</code></td>
<td>
<p>vector of tensor mode dimensions, e.g., <code>m.vec=c(m1, m2, m3)</code> for a 3-mode tensor normal distribution.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_mu">mu</code></td>
<td>
<p>array of mean for tensor normal distribution with dimension <code>m.vec</code>. Default is zero mean.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_sigma.list">Sigma.list</code></td>
<td>
<p>list of covariance matrices in mode sequence. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_type">type</code></td>
<td>
<p>type of precision matrix, default is 'Chain'. Optional values are 'Chain' for 
triangle graph and 'Neighbor' for nearest-neighbor graph. Useless if <code>Sigma.list</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_sd">sd</code></td>
<td>
<p>seed of random number generation, default is 1.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_knn">knn</code></td>
<td>
<p>sparsity of precision matrix, i.e., matrix is generated from a <code>knn</code> nearest-neighbor graph. 
Default is 4. Useless if <code>type='Chain'</code> or <code>Sigma.list</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="Trnorm_+3A_norm.type">norm.type</code></td>
<td>
<p>normalization method of precision matrix, i.e., <code class="reqn">\Omega_{11} = 1</code> 
if norm.type = 1 and <code class="reqn">\|\Omega\|_{F}=1</code> if norm.type = 2. Default value is 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates obeservations from separable tensor normal distribution and returns a <code>m1 * ... * mK * n</code> array. 
If <code>Sigma.list</code> is not given, default distribution is from either triangle graph or nearest-neighbor graph (depends on <code>type</code>).
</p>


<h3>Value</h3>

<p>An array with dimension m_1 * ... * m_K * n.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ChainOmega">ChainOmega</a></code>, <code><a href="#topic+NeighborOmega">NeighborOmega</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
DATA=Trnorm(n,m.vec,type='Chain') 
# a 5*5*5*10 array of oberservation from 5*5*5 separable tensor 
#     normal distribtuion with mean zero and 
#         precision matrices from triangle graph

</code></pre>

<hr>
<h2 id='varcor'>Variance Correction of Sample Covariance of Residuals</h2><span id='topic+varcor'></span>

<h3>Description</h3>

<p>Generate variance correction term of sample covariance of residuals described in <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varcor(data, Omega.list, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varcor_+3A_data">data</code></td>
<td>
<p>tensor object stored in a m1 * m2 * ... * mK * n array, where n is sample size
and mk is dimension of the kth tensor mode.</p>
</td></tr>
<tr><td><code id="varcor_+3A_omega.list">Omega.list</code></td>
<td>
<p>list of precision matrices of tensor, i.e., <code>Omega.list[[k]]</code> is precision matrix 
for the kth tensor mode, <code class="reqn">k \in \{1 , \ldots, K\}</code>. 
Elements in <code>Omega.list</code> are true precision matrices or estimation of the 
true ones, the latter can be output of <code>Tlasso.fit</code>.</p>
</td></tr>
<tr><td><code id="varcor_+3A_k">k</code></td>
<td>
<p>index of interested mode, default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes variance correction term of sample covariance of residuals and
is utilized to normalize test statistic into standord normal, see <a href="https://arxiv.org/abs/1609.04522">Lyu et al. (2019)</a>.
</p>


<h3>Value</h3>

<p>A scalar of variance correction for the kth mode.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Will Wei Sun, Zhaoran Wang, Han Liu, Jian Yang, Guang Cheng.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varcor">varcor</a></code>, <code><a href="#topic+biascor">biascor</a></code>, <code><a href="#topic+covres">covres</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m.vec = c(5,5,5)  # dimensionality of a tensor 
n = 5   # sample size 
k=1 # index of interested mode
lambda.thm = 20*c( sqrt(log(m.vec[1])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[2])/(n*prod(m.vec))), 
                   sqrt(log(m.vec[3])/(n*prod(m.vec))))
DATA=Trnorm(n,m.vec,type='Chain') 
# obersavations from tensor normal distribution
out.tlasso = Tlasso.fit(DATA,T=1,lambda.vec = lambda.thm)   
# output is a list of estimation of precision matrices

rho=covres(DATA, out.tlasso, k = k) 
# sample covariance of residuals, including diagnoal 
varpi2=varcor(DATA, out.tlasso, k = k)
# variance correction term for kth mode's sample covariance of residuals

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
