<!DOCTYPE html><html><head><title>Help for package zoomGroupStats</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {zoomGroupStats}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggSentiment'><p>Helper function to aggregate sentiment variables</p></a></li>
<li><a href='#batchGrabVideoStills'><p>Batch process video files, breaking them into stills</p></a></li>
<li><a href='#batchProcessZoomOutput'><p>Batch process files that have been downloaded from Zoom</p></a></li>
<li><a href='#batchVideoFaceAnalysis'><p>Batch analyze faces in videos</p></a></li>
<li><a href='#createZoomRosetta'><p>Create a file to aid in adding a unique identifier to link to the zoom user name</p></a></li>
<li><a href='#grabVideoStills'><p>Helper function to split a video into still frames</p></a></li>
<li><a href='#importZoomRosetta'><p>Helper function to add unique identifiers to processed Zoom downloads</p></a></li>
<li><a href='#makeTimeWindows'><p>Helper function that creates temporal windows in datasets</p></a></li>
<li><a href='#processZoomChat'><p>Process a Zoom chat file</p></a></li>
<li><a href='#processZoomOutput'><p>Wrapper function to process the raw files from Zoom in a single call</p></a></li>
<li><a href='#processZoomParticipantsInfo'><p>Process participant information from a Zoom meeting export</p></a></li>
<li><a href='#processZoomTranscript'><p>Process Zoom transcript file</p></a></li>
<li><a href='#sample_batch_info'><p>Parsed batch info file in a recorded 'Zoom' meeting</p></a></li>
<li><a href='#sample_chat_processed'><p>Parsed chat file in a 'Zoom' meeting</p></a></li>
<li><a href='#sample_chat_sentiment_aws'><p>Parsed chat file in a 'Zoom' meeting with sentiment analysis using AWS</p></a></li>
<li><a href='#sample_chat_sentiment_syu'><p>Parsed chat file in a 'Zoom' meeting with sentiment analysis using syuzhet</p></a></li>
<li><a href='#sample_transcript_processed'><p>Parsed spoken language in a 'Zoom' meeting.</p></a></li>
<li><a href='#sample_transcript_sentiment_aws'><p>Parsed spoken language in a 'Zoom' meeting with AWS-based sentiment analysis.</p></a></li>
<li><a href='#sample_transcript_sentiment_syu'><p>Parsed spoken language in a 'Zoom' meeting with syuzhet-based sentiment analysis.</p></a></li>
<li><a href='#textConversationAnalysis'><p>Analyze conversation attributes</p></a></li>
<li><a href='#textSentiment'><p>Conduct a sentiment analysis on text data</p></a></li>
<li><a href='#turnTaking'><p>Simple conversational turn-taking analysis</p></a></li>
<li><a href='#videoFaceAnalysis'><p>Analyze the facial features within an exported Zoom video file</p></a></li>
<li><a href='#windowedTextConversationAnalysis'><p>Run a windowed analysis on either a Zoom transcript or chat</p>
This function conducts a temporal window analysis on the conversation in
either a Zoom transcript or chat. It replicates the textConversationAnalysis
function across a set of windows at a window size specified by the user.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Analyze Text, Audio, and Video from 'Zoom' Meetings</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://zoomgroupstats.org">http://zoomgroupstats.org</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Provides utilities for processing and analyzing the files that are exported from a recorded 'Zoom' Meeting. This includes analyzing data captured through video cameras and microphones, the text-based chat, and meta-data. You can analyze aspects of the conversation among meeting participants and their emotional expressions throughout the meeting.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, dplyr, lubridate, magick, openxlsx, paws, pbapply,
stringr, syuzhet, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-11 20:15:39 UTC; apk</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrew Knight [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrew Knight &lt;knightap@wustl.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-13 09:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggSentiment'>Helper function to aggregate sentiment variables</h2><span id='topic+aggSentiment'></span>

<h3>Description</h3>

<p>Used to aggregate the sentiment variables to the individual
and meeting levels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggSentiment(inputData, meetingId = NULL, speakerId = NULL, sentMethod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggSentiment_+3A_inputdata">inputData</code></td>
<td>
<p>data.frame that has been output from textSentiment function</p>
</td></tr>
<tr><td><code id="aggSentiment_+3A_meetingid">meetingId</code></td>
<td>
<p>string that indicates the name of the variable containing the meeting ID</p>
</td></tr>
<tr><td><code id="aggSentiment_+3A_speakerid">speakerId</code></td>
<td>
<p>string that indicates the name of the variable containing the speaker identity</p>
</td></tr>
<tr><td><code id="aggSentiment_+3A_sentmethod">sentMethod</code></td>
<td>
<p>string that indicates what type of
sentiment analysis to aggregate&ndash;must be either 'aws' or 'syuzhet'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame giving the sentiment metrics aggregated to the requested level. If only meetingId
is specified, metrics are aggregated to that level. If only speakerId is specified, metrics
are aggregated to the individual level across any meetings. If both meetingId and speakerId
are specified, metrics are aggregated to the level of the individual within meeting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>agg.out = aggSentiment(inputData=sample_transcript_sentiment_aws, 
meetingId="batchMeetingId", speakerId = "userId", sentMethod="aws")

agg.out = aggSentiment(inputData=sample_chat_sentiment_syu, 
meetingId="batchMeetingId", speakerId = "userName", sentMethod="syuzhet")
</code></pre>

<hr>
<h2 id='batchGrabVideoStills'>Batch process video files, breaking them into stills</h2><span id='topic+batchGrabVideoStills'></span>

<h3>Description</h3>

<p>#' This helper calls grabVideoStills, which function currently
relies on the av package and 'ffmpeg' to split a video file into images.
This function will save the images to the director specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batchGrabVideoStills(
  batchInfo,
  imageDir = NULL,
  overWriteDir = FALSE,
  sampleWindow
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="batchGrabVideoStills_+3A_batchinfo">batchInfo</code></td>
<td>
<p>the batchInfo data.frame that is output from batchProcessZoomOutput</p>
</td></tr>
<tr><td><code id="batchGrabVideoStills_+3A_imagedir">imageDir</code></td>
<td>
<p>the directory where you want the function to write the extracted image files</p>
</td></tr>
<tr><td><code id="batchGrabVideoStills_+3A_overwritedir">overWriteDir</code></td>
<td>
<p>logical indicating whether you want to overwrite imageDir if it exists</p>
</td></tr>
<tr><td><code id="batchGrabVideoStills_+3A_samplewindow">sampleWindow</code></td>
<td>
<p>an integer indicating how frequently you want to sample
images in number of seconds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame that gives information about the batch. Each record
corresponds to one video, with:
</p>

<ul>
<li><p> batchMeetingId - the meeting identifier
</p>
</li>
<li><p> videoExists - boolean indicating whether the video file was there
</p>
</li>
<li><p> imageDir - path to the directory where video images are saved
</p>
</li>
<li><p> sampleWindow - integer with the sampleWindow requested
</p>
</li>
<li><p> numFramesExtracted - the number of image files that were saved
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>vidBatchInfo = batchGrabVideoStills(batchInfo=sample_batch_info,
imageDir=tempdir(), overWriteDir=TRUE, sampleWindow=2)
## Not run: 
vidBatchInfo = batchGrabVideoStills(batchInfo=zoomOut$batchInfo,
imageDir="~/Documents/myMeetings/videoImages", overWriteDir=TRUE,  sampleWindow=600)

## End(Not run)
</code></pre>

<hr>
<h2 id='batchProcessZoomOutput'>Batch process files that have been downloaded from Zoom</h2><span id='topic+batchProcessZoomOutput'></span>

<h3>Description</h3>

<p>Provide the location of a structured batchInput file and this
function will process a set of meetings at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batchProcessZoomOutput(batchInput, exportZoomRosetta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="batchProcessZoomOutput_+3A_batchinput">batchInput</code></td>
<td>
<p>String giving the location of the xlsx file
that contains the information for the zoom meetings. All corresponding
Zoom downloads for the meetings in the batch must be saved in the same
directory as the batchInput file.</p>
</td></tr>
<tr><td><code id="batchProcessZoomOutput_+3A_exportzoomrosetta">exportZoomRosetta</code></td>
<td>
<p>optional string giving the path for exporting the
zoomRosetta file to link up unique individual IDs manually. Providing this
path will write the zoomRosetta file to that location.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list that has a data.frame for each of the elements
of a Zoom output that are available in the input directory:
</p>

<ul>
<li><p> batchInfo - Each row is a meeting included in batchInput. Columns
provide information about each meeting.
</p>
</li>
<li><p> meetInfo - Each row is a meeting for which there was a downloaded
participants file. Columns provide information about the meeting from the Zoom
Cloud recording site.
</p>
</li>
<li><p> partInfo - Each row is a Zoom display name (with display name changes
in parentheses). Columns provide information about participants from the Zoom Cloud
recording site.
</p>
</li>
<li><p> transcript - Each row is an utterance in the audio transcript. This is the
output from processZoomTranscript.
</p>
</li>
<li><p> chat - Each row is a message posted to the chat. This is the output
from processZoomChat.
</p>
</li>
<li><p> rosetta - Each row is a unique display name (within meeting) encountered
in the batchInput. This is used to reconcile user identities.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>batchOut = batchProcessZoomOutput(batchInput=system.file('extdata', 
'myMeetingsBatch.xlsx', package = 'zoomGroupStats'), 
exportZoomRosetta=file.path(tempdir(),"_rosetta.xlsx"))

</code></pre>

<hr>
<h2 id='batchVideoFaceAnalysis'>Batch analyze faces in videos</h2><span id='topic+batchVideoFaceAnalysis'></span>

<h3>Description</h3>

<p>Using this function you can analyze attributes of facial expressions within
a batch of video files. This batch approach requires breaking the videos into
still frames in advance by using the batchGrabVideoStills() function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batchVideoFaceAnalysis(
  batchInfo,
  imageDir,
  sampleWindow,
  facesCollectionID = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="batchVideoFaceAnalysis_+3A_batchinfo">batchInfo</code></td>
<td>
<p>the batchInfo data.frame that is output from batchProcessZoomOutput</p>
</td></tr>
<tr><td><code id="batchVideoFaceAnalysis_+3A_imagedir">imageDir</code></td>
<td>
<p>the path to the top-level directory of where all the images are stored</p>
</td></tr>
<tr><td><code id="batchVideoFaceAnalysis_+3A_samplewindow">sampleWindow</code></td>
<td>
<p>an integer indicating how frequently you have sampled images
in number of seconds.</p>
</td></tr>
<tr><td><code id="batchVideoFaceAnalysis_+3A_facescollectionid">facesCollectionID</code></td>
<td>
<p>name of an 'AWS' collection with identified faces</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with one record for every face detected in each frame across all meetings. For each face, there is an abundance of information from 'AWS Rekognition'. This output is quite detailed. Note that there will be a varying number of faces per sampled frame in the video. Imagine that you have sampled the meeting and had someone rate each person's face within that sampled moment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  vidOut = batchVideoFaceAnalysis(batchInfo=zoomOut$batchInfo, 
  imageDir="~/Documents/meetingImages",
  sampleWindow = 300)

## End(Not run)
</code></pre>

<hr>
<h2 id='createZoomRosetta'>Create a file to aid in adding a unique identifier to link to the zoom user name</h2><span id='topic+createZoomRosetta'></span>

<h3>Description</h3>

<p>A major challenge in analyzing virtual meetings is reconciling the display
name that zoom users in chat and transcript. This function outputs a data.frame
that can be helpful in manually adding a new unique identifier to use in
further data anlaysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createZoomRosetta(zoomOutput)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createZoomRosetta_+3A_zoomoutput">zoomOutput</code></td>
<td>
<p>the output from running processZoomOutput</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame that has unique values for the zoom display name
that show up across any files that are available, including
participants, transcript, and chat. If the user gives the participants
file, it will separate display name changes and include all versions. If
there are emails attached to display names, it will include those.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rosetta.out = createZoomRosetta(processZoomOutput(fileRoot=
file.path(system.file('extdata', package = 'zoomGroupStats'),"meeting001")))
## Not run: 
rosetta.out = createZoomRosetta(processZoomOutput(fileRoot="~/zoomMeetings/meeting001"))

## End(Not run)
</code></pre>

<hr>
<h2 id='grabVideoStills'>Helper function to split a video into still frames</h2><span id='topic+grabVideoStills'></span>

<h3>Description</h3>

<p>This function currently relies on the av package and
'ffmpeg' to split a video file into images. This function will save
the images to the directory specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grabVideoStills(
  inputVideo,
  imageDir = NULL,
  overWriteDir = FALSE,
  sampleWindow
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grabVideoStills_+3A_inputvideo">inputVideo</code></td>
<td>
<p>full filepath to a video file</p>
</td></tr>
<tr><td><code id="grabVideoStills_+3A_imagedir">imageDir</code></td>
<td>
<p>the directory where you want the function to write the extracted image files</p>
</td></tr>
<tr><td><code id="grabVideoStills_+3A_overwritedir">overWriteDir</code></td>
<td>
<p>logical indicating whether you want to overwrite imageDir if it exists</p>
</td></tr>
<tr><td><code id="grabVideoStills_+3A_samplewindow">sampleWindow</code></td>
<td>
<p>an integer indicating how frequently you want to sample
images in number of seconds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame that gives information about the still frames. Each record is
a stillframe, with the following info:
</p>

<ul>
<li><p> imageSeconds - number of seconds from the start of the video when this image was captured
</p>
</li>
<li><p> imageName - full path to where the image has been saved as a .png
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>vidOut = grabVideoStills(inputVideo=system.file('extdata', "meeting001_video.mp4", 
package = 'zoomGroupStats'), imageDir=tempdir(), overWriteDir=TRUE, sampleWindow=2)
## Not run: 
grabVideoStills(inputVideo='myMeeting.mp4', 
imageDir="~/Documents/myMeetings/videoImages", overWriteDir=TRUE,  sampleWindow=45)

## End(Not run)
</code></pre>

<hr>
<h2 id='importZoomRosetta'>Helper function to add unique identifiers to processed Zoom downloads</h2><span id='topic+importZoomRosetta'></span>

<h3>Description</h3>

<p>Import an edited zoomRosetta file that tells how to
link up Zoom display names to some unique individual
identifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importZoomRosetta(zoomOutput, zoomRosetta, meetingId)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importZoomRosetta_+3A_zoomoutput">zoomOutput</code></td>
<td>
<p>the output of batchProcessZoomOutput</p>
</td></tr>
<tr><td><code id="importZoomRosetta_+3A_zoomrosetta">zoomRosetta</code></td>
<td>
<p>the path to an edited zoomRosetta xlsx</p>
</td></tr>
<tr><td><code id="importZoomRosetta_+3A_meetingid">meetingId</code></td>
<td>
<p>the name of the meetingId you want to use</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns zoomOutput with identifiers in zoomRosetta
merged to any available data.frames in the zoomOutput file
</p>


<h3>Examples</h3>

<pre><code class='language-R'>batchOutIds = importZoomRosetta(zoomOutput=
batchProcessZoomOutput(batchInput=system.file('extdata', 
'myMeetingsBatch.xlsx', package = 'zoomGroupStats')), 
zoomRosetta=system.file('extdata', 
'myMeetingsBatch_rosetta_edited.xlsx', package = 'zoomGroupStats'), 
meetingId="batchMeetingId")

## Not run: 
batchOutIds = importZoomRosetta(zoomOutput=batchOut, zoomRosetta="myEditedRosetta.xlsx", 
meetingId="batchMeetingId")

## End(Not run)
</code></pre>

<hr>
<h2 id='makeTimeWindows'>Helper function that creates temporal windows in datasets</h2><span id='topic+makeTimeWindows'></span>

<h3>Description</h3>

<p>This creates a set of temporal windows of specified size so that metrics
can be computed within those windows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTimeWindows(inputData, timeVar, windowSize)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTimeWindows_+3A_inputdata">inputData</code></td>
<td>
<p>data.frame that has data over time, usually within a single meeting</p>
</td></tr>
<tr><td><code id="makeTimeWindows_+3A_timevar">timeVar</code></td>
<td>
<p>name of a numeric column that contains the time variable you want to use</p>
</td></tr>
<tr><td><code id="makeTimeWindows_+3A_windowsize">windowSize</code></td>
<td>
<p>numeric value giving the length of time window</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with two data.frames:
</p>

<ul>
<li><p> windowedData - inputData with the temporal window identifying information included
</p>
</li>
<li><p> allWindows - contains the full set of temporal windows and identifying information. This is valuable because inputData may not have records within all of the possible temporal windows
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>win.out = makeTimeWindows(sample_transcript_processed, 
timeVar="utteranceStartSeconds", windowSize=10)
</code></pre>

<hr>
<h2 id='processZoomChat'>Process a Zoom chat file</h2><span id='topic+processZoomChat'></span>

<h3>Description</h3>

<p>Parses the data from the chatfile that is downloaded from the Zoom Cloud recording
site. Note that this is the file that accompanies a recording. This is not the file
that you might download directly within a given Zoom session, nor is it the one
that is saved locally on your computer. This is the file that you can access
after a session if you record in the cloud.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processZoomChat(
  fname,
  sessionStartDateTime = "1970-01-01 00:00:00",
  languageCode = "en"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="processZoomChat_+3A_fname">fname</code></td>
<td>
<p>String that is the path to the downloaded Zoom .txt chat file</p>
</td></tr>
<tr><td><code id="processZoomChat_+3A_sessionstartdatetime">sessionStartDateTime</code></td>
<td>
<p>String that is the start of the session in YYYY-MM-DD HH:MM:SS</p>
</td></tr>
<tr><td><code id="processZoomChat_+3A_languagecode">languageCode</code></td>
<td>
<p>String denoting the language</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame where each record is a message submission in the chat, containing columns:
</p>

<ul>
<li><p> messageId - Numeric identifier for each message, only unique within a given meeting
</p>
</li>
<li><p> messageSeconds - When message was posted, in number of seconds from start of session
</p>
</li>
<li><p> messageTime - When message was posted as POSIXct, using the supplied sessionStartDateTime
</p>
</li>
<li><p> userName - Display name of user who posted the message
</p>
</li>
<li><p> message - Text of the message that was posted
</p>
</li>
<li><p> messageLanguage - Language code for the message
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>ch.out = processZoomChat(
fname=system.file('extdata', "meeting001_chat.txt", package = 'zoomGroupStats'), 
sessionStartDateTime = '2020-04-20 13:30:00', 
languageCode = 'en')
</code></pre>

<hr>
<h2 id='processZoomOutput'>Wrapper function to process the raw files from Zoom in a single call</h2><span id='topic+processZoomOutput'></span>

<h3>Description</h3>

<p>The user provides a fileRoot that is used for a given meeting. Output
files should be named as fileRoot_chat.txt; fileRoot_transcript.vtt;
and fileRoot_participants.csv. Any relevant files will be processed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processZoomOutput(
  fileRoot,
  rosetta = TRUE,
  sessionStartDateTime = "1970-01-01 00:00:00",
  recordingStartDateTime = "1970-01-01 00:00:00",
  languageCode = "en"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="processZoomOutput_+3A_fileroot">fileRoot</code></td>
<td>
<p>string giving the path to the files and the root</p>
</td></tr>
<tr><td><code id="processZoomOutput_+3A_rosetta">rosetta</code></td>
<td>
<p>boolean to produce the rosetta file or not</p>
</td></tr>
<tr><td><code id="processZoomOutput_+3A_sessionstartdatetime">sessionStartDateTime</code></td>
<td>
<p>string giving the start of the session in YYYY-MM-DD HH:MM:SS</p>
</td></tr>
<tr><td><code id="processZoomOutput_+3A_recordingstartdatetime">recordingStartDateTime</code></td>
<td>
<p>string giving the start of the recording in YYYY-MM-DD HH:MM:SS</p>
</td></tr>
<tr><td><code id="processZoomOutput_+3A_languagecode">languageCode</code></td>
<td>
<p>string giving the language code</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing data.frames for each of the available files:
</p>

<ul>
<li><p> meetInfo - A single row with info for the meeting that is in the
participants file. Columns provide information about the meeting from the Zoom
Cloud recording site.
</p>
</li>
<li><p> partInfo - Each row is a Zoom display name (with display name changes
in parentheses). Columns provide information about participants from the Zoom Cloud
recording site.
</p>
</li>
<li><p> transcript - Each row is an utterance in the audio transcript. This is the
output from processZoomTranscript.
</p>
</li>
<li><p> chat - Each row is a message posted to the chat. This is the output
from processZoomChat.
</p>
</li>
<li><p> rosetta - Each row is a unique display name (within meeting) encountered
in the batchInput. This is used to reconcile user identities.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>zoomOut = processZoomOutput(fileRoot=file.path(
system.file('extdata', package = 'zoomGroupStats'),"meeting001"
), rosetta=TRUE)
## Not run: 
zoomOut = processZoomOutput(fileRoot="~/zoomMeetings/myMeeting", rosetta=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='processZoomParticipantsInfo'>Process participant information from a Zoom meeting export</h2><span id='topic+processZoomParticipantsInfo'></span>

<h3>Description</h3>

<p>This function parses the information from the downloadable meeting information file in Zooms reports section.
The function presumes that you have checked the box to
include the meeting information in the file.
That means that there is a header (2 rows) containing the zoom meeting information.
Following that header are four columns:
Name of user, user email, total duration, and guest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processZoomParticipantsInfo(inputPath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="processZoomParticipantsInfo_+3A_inputpath">inputPath</code></td>
<td>
<p>character</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of two data.frames with parsed information from the downloadable
Zoom participants file
</p>

<ul>
<li><p> meetInfo - provides the meeting level information that Zoom Cloud gives
</p>
</li>
<li><p> partInfo - provides the participant level information that Zoom Cloud gives
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>partInfo = processZoomParticipantsInfo(
system.file('extdata', "meeting001_participants.csv", package = 'zoomGroupStats')
)
</code></pre>

<hr>
<h2 id='processZoomTranscript'>Process Zoom transcript file</h2><span id='topic+processZoomTranscript'></span>

<h3>Description</h3>

<p>Process Zoom transcript file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processZoomTranscript(
  fname,
  recordingStartDateTime = "1970-01-01 00:00:00",
  languageCode = "en"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="processZoomTranscript_+3A_fname">fname</code></td>
<td>
<p>String that is the path to the exported Zoom .vtt transcript chat file</p>
</td></tr>
<tr><td><code id="processZoomTranscript_+3A_recordingstartdatetime">recordingStartDateTime</code></td>
<td>
<p>String that is the timestamp when the recording was started in YYYY-MM-DD HH:MM:SS</p>
</td></tr>
<tr><td><code id="processZoomTranscript_+3A_languagecode">languageCode</code></td>
<td>
<p>String denoting the language</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame where each record is an utterance in the transcript, with columns:
</p>

<ul>
<li><p> utteranceId - Numeric identifier for each utterance in the transcript
</p>
</li>
<li><p> utteranceStartSeconds - number of seconds from the start of the recording when utterance began
</p>
</li>
<li><p> utteranceStartTime - POSIXct timestamp of the start of the utterance, using recordingStartDateTime as the zero
</p>
</li>
<li><p> utteranceEndSeconds - number of seconds from the start of the recording when utterance ended
</p>
</li>
<li><p> utteranceEndTime - POSIXct timestamp of the end of the utterance, using recordingStartDateTime as the zero
</p>
</li>
<li><p> utteranceTimeWindow - number of seconds that this utterance lasted
</p>
</li>
<li><p> userName - Zoom display name of the person who spoke this utterance
</p>
</li>
<li><p> utteranceMessage - transcribed spoken words of this utterance
</p>
</li>
<li><p> utteranceLanguage - language code for this utterance
</p>
</li></ul>



<h3>Zoom Recording Transcript File Processing</h3>

<p>This function parses the data from the transcript file (.vtt) that is downloaded from the Zoom website.
NOTE: This is the file that accompanies a recording to the cloud.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tr.out = processZoomTranscript(
fname=system.file('extdata', 'meeting001_transcript.vtt', package = 'zoomGroupStats'), 
recordingStartDateTime = '2020-04-20 13:30:00', languageCode = 'en')
</code></pre>

<hr>
<h2 id='sample_batch_info'>Parsed batch info file in a recorded 'Zoom' meeting</h2><span id='topic+sample_batch_info'></span>

<h3>Description</h3>

<p>Parsed batch info file in a recorded 'Zoom' meeting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_batch_info
</code></pre>


<h3>Format</h3>

<p>A data frame with 3 rows of 13 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>fileRoot</dt><dd><p>the prefix to the files for this particular meeting</p>
</dd>
<dt>participants</dt><dd><p>binary indicating whether there is a participants file downloaded</p>
</dd>
<dt>transcript</dt><dd><p>binary indicating whether there is a transcript file downloaded</p>
</dd>
<dt>chat</dt><dd><p>binary indicating whether there is a chat file downloaded</p>
</dd>
<dt>video</dt><dd><p>binary indicating whether there is a video file downloaded</p>
</dd>
<dt>sessionStartDateTime</dt><dd><p>start of the actual session as a character YYYY-MM-DD HH:MM:SS</p>
</dd>
<dt>recordingStartDateTime</dt><dd><p>start of the actual recording as a character YYYY-MM-DD HH:MM:SS</p>
</dd>
<dt>participants_processed</dt><dd><p>binary indicating whether there is a participants file already processed</p>
</dd>
<dt>transcript_processed</dt><dd><p>binary indicating whether there is a transcript file already processed</p>
</dd>
<dt>chat_processed</dt><dd><p>binary indicating whether there is a chat file already processed</p>
</dd>
<dt>video_processed</dt><dd><p>binary indicating whether there is a video file already processed</p>
</dd>
<dt>dirRoot</dt><dd><p>character giving the directory in which all files will be found</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='sample_chat_processed'>Parsed chat file in a 'Zoom' meeting</h2><span id='topic+sample_chat_processed'></span>

<h3>Description</h3>

<p>Parsed chat file in a 'Zoom' meeting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_chat_processed
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 rows of 9 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>userName</dt><dd><p>'Zoom' display name attached to this speaker</p>
</dd>
<dt>messageId</dt><dd><p>an incremented numeric identifier for a marked chat message</p>
</dd>
<dt>messageSeconds</dt><dd><p>when the message was posted as the number of seconds from the start of the recording</p>
</dd>
<dt>messageTime</dt><dd><p>timestamp for message</p>
</dd>
<dt>message</dt><dd><p>text of the message</p>
</dd>
<dt>messageLanguage</dt><dd><p>language code of the message</p>
</dd>
<dt>userEmail</dt><dd><p>character email address</p>
</dd>
<dt>userId</dt><dd><p>numeric id of each speaker</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='sample_chat_sentiment_aws'>Parsed chat file in a 'Zoom' meeting with sentiment analysis using AWS</h2><span id='topic+sample_chat_sentiment_aws'></span>

<h3>Description</h3>

<p>Parsed chat file in a 'Zoom' meeting with sentiment analysis using AWS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_chat_sentiment_aws
</code></pre>


<h3>Format</h3>

<p>A data frame with 10 rows of 14 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>messageId</dt><dd><p>an incremented numeric identifier for a marked chat message</p>
</dd>
<dt>userName</dt><dd><p>'Zoom' display name attached to the messager</p>
</dd>
<dt>messageSeconds</dt><dd><p>when the message was posted as the number of seconds from the start of the recording</p>
</dd>
<dt>messageTime</dt><dd><p>timestamp for message</p>
</dd>
<dt>message</dt><dd><p>text of the message</p>
</dd>
<dt>messageLanguage</dt><dd><p>language code of the message</p>
</dd>
<dt>userEmail</dt><dd><p>character email address</p>
</dd>
<dt>userId</dt><dd><p>numeric id of each speaker</p>
</dd>
<dt>aws_sentClass</dt><dd><p>character giving the sentiment classification of this text</p>
</dd>
<dt>aws_positive</dt><dd><p>probability that this text is mixed emotion</p>
</dd>
<dt>aws_negative</dt><dd><p>probability that this text is negative</p>
</dd>
<dt>aws_neutral</dt><dd><p>probability that this text is neutral</p>
</dd>
<dt>aws_mixed</dt><dd><p>probability that this text is positive</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='sample_chat_sentiment_syu'>Parsed chat file in a 'Zoom' meeting with sentiment analysis using syuzhet</h2><span id='topic+sample_chat_sentiment_syu'></span>

<h3>Description</h3>

<p>Parsed chat file in a 'Zoom' meeting with sentiment analysis using syuzhet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_chat_sentiment_syu
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 rows of 30 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>messageId</dt><dd><p>an incremented numeric identifier for a marked chat message</p>
</dd>
<dt>userName</dt><dd><p>'Zoom' display name attached to the messager</p>
</dd>
<dt>messageSeconds</dt><dd><p>when the message was posted as the number of seconds from the start of the recording</p>
</dd>
<dt>messageTime</dt><dd><p>timestamp for message</p>
</dd>
<dt>message</dt><dd><p>text of the message</p>
</dd>
<dt>messageLanguage</dt><dd><p>language code of the message</p>
</dd>
<dt>userEmail</dt><dd><p>character email address</p>
</dd>
<dt>userId</dt><dd><p>numeric id of each speaker</p>
</dd>
<dt>wordCount</dt><dd><p>number of words in this utterance</p>
</dd>
<dt>syu_anger</dt><dd><p>number of anger words</p>
</dd>
<dt>syu_anticipation</dt><dd><p>number of anticipation words</p>
</dd>
<dt>syu_disgust</dt><dd><p>number of disgust words</p>
</dd>
<dt>syu_fear</dt><dd><p>number of fear words</p>
</dd>
<dt>syu_joy</dt><dd><p>number of joy words</p>
</dd>
<dt>syu_sadness</dt><dd><p>number of sadness words</p>
</dd>
<dt>syu_surprise</dt><dd><p>number of surprise words</p>
</dd>
<dt>syu_trust</dt><dd><p>number of trust words</p>
</dd>
<dt>syu_negative</dt><dd><p>number of negative words</p>
</dd>
<dt>syu_positive</dt><dd><p>number of positive words</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='sample_transcript_processed'>Parsed spoken language in a 'Zoom' meeting.</h2><span id='topic+sample_transcript_processed'></span>

<h3>Description</h3>

<p>Parsed spoken language in a 'Zoom' meeting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_transcript_processed
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 rows of 12 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>userName</dt><dd><p>'Zoom' display name attached to this speaker</p>
</dd>
<dt>utteranceId</dt><dd><p>an incremented numeric identifier for a marked speech utterance</p>
</dd>
<dt>utteranceStartSeconds</dt><dd><p>when the utterance started as the number of seconds from the start of the recording</p>
</dd>
<dt>utteranceStartTime</dt><dd><p>timestamp for the start of the utterance</p>
</dd>
<dt>utteranceEndSeconds</dt><dd><p>when the utterance ended as the number of seconds from the start of the recording</p>
</dd>
<dt>utteranceEndTime</dt><dd><p>timestamp for the end of the utterance</p>
</dd>
<dt>utteranceTimeWindow</dt><dd><p>duration of the utterance, in seconds</p>
</dd>
<dt>utteranceMessage</dt><dd><p>the text of the utterance</p>
</dd>
<dt>utteranceLanguage</dt><dd><p>language code of the utterance</p>
</dd>
<dt>userEmail</dt><dd><p>character email address</p>
</dd>
<dt>userId</dt><dd><p>numeric id of each speaker</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='sample_transcript_sentiment_aws'>Parsed spoken language in a 'Zoom' meeting with AWS-based sentiment analysis.</h2><span id='topic+sample_transcript_sentiment_aws'></span>

<h3>Description</h3>

<p>Parsed spoken language in a 'Zoom' meeting with AWS-based sentiment analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_transcript_sentiment_aws
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 rows of 17 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>utteranceId</dt><dd><p>an incremented numeric identifier for a marked speech utterance</p>
</dd>
<dt>userName</dt><dd><p>'Zoom' display name attached to this speaker</p>
</dd>
<dt>utteranceStartSeconds</dt><dd><p>when the utterance started as the number of seconds from the start of the recording</p>
</dd>
<dt>utteranceStartTime</dt><dd><p>timestamp for the start of the utterance</p>
</dd>
<dt>utteranceEndSeconds</dt><dd><p>when the utterance ended as the number of seconds from the start of the recording</p>
</dd>
<dt>utteranceEndTime</dt><dd><p>timestamp for the end of the utterance</p>
</dd>
<dt>utteranceTimeWindow</dt><dd><p>duration of the utterance, in seconds</p>
</dd>
<dt>utteranceMessage</dt><dd><p>the text of the utterance</p>
</dd>
<dt>utteranceLanguage</dt><dd><p>language code of the utterance</p>
</dd>
<dt>userEmail</dt><dd><p>character email address</p>
</dd>
<dt>userId</dt><dd><p>numeric id of each speaker</p>
</dd>
<dt>aws_sentClass</dt><dd><p>character giving the sentiment classification of this text</p>
</dd>
<dt>aws_positive</dt><dd><p>probability that this text is mixed emotion</p>
</dd>
<dt>aws_negative</dt><dd><p>probability that this text is negative</p>
</dd>
<dt>aws_neutral</dt><dd><p>probability that this text is neutral</p>
</dd>
<dt>aws_mixed</dt><dd><p>probability that this text is positive</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='sample_transcript_sentiment_syu'>Parsed spoken language in a 'Zoom' meeting with syuzhet-based sentiment analysis.</h2><span id='topic+sample_transcript_sentiment_syu'></span>

<h3>Description</h3>

<p>Parsed spoken language in a 'Zoom' meeting with syuzhet-based sentiment analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_transcript_sentiment_syu
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 rows of 23 variables:
</p>

<dl>
<dt>batchMeetingId</dt><dd><p>a character meeting identification variable</p>
</dd>
<dt>utteranceId</dt><dd><p>an incremented numeric identifier for a marked speech utterance</p>
</dd>
<dt>userName</dt><dd><p>'Zoom' display name attached to this speaker</p>
</dd>
<dt>utteranceStartSeconds</dt><dd><p>when the utterance started as the number of seconds from the start of the recording</p>
</dd>
<dt>utteranceStartTime</dt><dd><p>timestamp for the start of the utterance</p>
</dd>
<dt>utteranceEndSeconds</dt><dd><p>when the utterance ended as the number of seconds from the start of the recording</p>
</dd>
<dt>utteranceEndTime</dt><dd><p>timestamp for the end of the utterance</p>
</dd>
<dt>utteranceTimeWindow</dt><dd><p>duration of the utterance, in seconds</p>
</dd>
<dt>utteranceMessage</dt><dd><p>the text of the utterance</p>
</dd>
<dt>utteranceLanguage</dt><dd><p>language code of the utterance</p>
</dd>
<dt>userEmail</dt><dd><p>character email address</p>
</dd>
<dt>userId</dt><dd><p>numeric id of each speaker</p>
</dd>
<dt>wordCount</dt><dd><p>number of words in this utterance</p>
</dd>
<dt>syu_anger</dt><dd><p>number of anger words</p>
</dd>
<dt>syu_anticipation</dt><dd><p>number of anticipation words</p>
</dd>
<dt>syu_disgust</dt><dd><p>number of disgust words</p>
</dd>
<dt>syu_fear</dt><dd><p>number of fear words</p>
</dd>
<dt>syu_joy</dt><dd><p>number of joy words</p>
</dd>
<dt>syu_sadness</dt><dd><p>number of sadness words</p>
</dd>
<dt>syu_surprise</dt><dd><p>number of surprise words</p>
</dd>
<dt>syu_trust</dt><dd><p>number of trust words</p>
</dd>
<dt>syu_negative</dt><dd><p>number of negative words</p>
</dd>
<dt>syu_positive</dt><dd><p>number of positive words</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://zoomgroupstats.org/">http://zoomgroupstats.org/</a>
</p>

<hr>
<h2 id='textConversationAnalysis'>Analyze conversation attributes</h2><span id='topic+textConversationAnalysis'></span>

<h3>Description</h3>

<p>This function takes in the output of one of the other functions (either processZoomChat or processZoomTranscript)
and produces a set of conversation measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textConversationAnalysis(
  inputData,
  inputType,
  meetingId,
  speakerId,
  sentMethod = "none"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textConversationAnalysis_+3A_inputdata">inputData</code></td>
<td>
<p>data.frame that is the output of either processZoomChat or processZoomTranscript</p>
</td></tr>
<tr><td><code id="textConversationAnalysis_+3A_inputtype">inputType</code></td>
<td>
<p>string of either 'transcript' or 'chat'</p>
</td></tr>
<tr><td><code id="textConversationAnalysis_+3A_meetingid">meetingId</code></td>
<td>
<p>string giving the name of the variable with the meetingId</p>
</td></tr>
<tr><td><code id="textConversationAnalysis_+3A_speakerid">speakerId</code></td>
<td>
<p>string giving the name of the identifier for the individual who made this contribution</p>
</td></tr>
<tr><td><code id="textConversationAnalysis_+3A_sentmethod">sentMethod</code></td>
<td>
<p>string giving the type of sentiment analysis to include, either 'aws' or 'syuzhet'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two data.frames, with names conditional on your choice to analyze
a parsed transcript file or a parsed chat file. The first list item contains
statistics at the corpus level. The second list item contains statistics
at the speaker/messager level of analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>convo.out = textConversationAnalysis(inputData=sample_transcript_processed, 
inputType='transcript', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="none")

convo.out = textConversationAnalysis(inputData=sample_transcript_sentiment_syu, 
inputType='transcript', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="syuzhet")

convo.out = textConversationAnalysis(inputData=sample_chat_sentiment_aws, 
inputType='chat', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="aws")

## Not run: 
convo.out = textConversationAnalysis(inputData=sample_transcript_sentiment_aws, 
inputType='transcript', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="aws")

convo.out = textConversationAnalysis(inputData=sample_transcript_sentiment_syu, 
inputType='transcript', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="syuzhet")

convo.out = textConversationAnalysis(inputData=sample_chat_processed, 
inputType='chat', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="none")

convo.out = textConversationAnalysis(inputData=sample_chat_sentiment_aws, 
inputType='chat', meetingId='batchMeetingId', 
speakerId='userName', sentMethod="aws")

convo.out = textConversationAnalysis(inputData=sample_chat_sentiment_syu, 
inputType='chat',meetingId='batchMeetingId',  
speakerId='userName', sentMethod="syuzhet")

## End(Not run)
</code></pre>

<hr>
<h2 id='textSentiment'>Conduct a sentiment analysis on text data</h2><span id='topic+textSentiment'></span>

<h3>Description</h3>

<p>This function takes in the output of the chat and transcript functions. It then
conducts a sentiment analysis on an identified chunk of text
and returns the values.
To use the aws option, you must have an aws account that with privileges for the comprehend service
However you authenticate for AWS, you should do so before running calling the function
with this option in sentMethods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textSentiment(
  inputData,
  idVars,
  textVar,
  sentMethods,
  appendOut = FALSE,
  languageCodeVar
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textSentiment_+3A_inputdata">inputData</code></td>
<td>
<p>data.frame that has been output by either the processZoomTranscript or processZoomChat functions</p>
</td></tr>
<tr><td><code id="textSentiment_+3A_idvars">idVars</code></td>
<td>
<p>vector with the name of variables that give the unique identifiers for this piece of text. Usually this will be a the meeting id variable and the text id variable (e.g., utteranceId, messageId)</p>
</td></tr>
<tr><td><code id="textSentiment_+3A_textvar">textVar</code></td>
<td>
<p>name of variable that contains the text</p>
</td></tr>
<tr><td><code id="textSentiment_+3A_sentmethods">sentMethods</code></td>
<td>
<p>a vector specifying the types of sentiment analysis-currently
either &quot;aws&quot; or &quot;syuzhet&quot;</p>
</td></tr>
<tr><td><code id="textSentiment_+3A_appendout">appendOut</code></td>
<td>
<p>boolean indicating whether you want the sentiment results
merged to the inputData in your output</p>
</td></tr>
<tr><td><code id="textSentiment_+3A_languagecodevar">languageCodeVar</code></td>
<td>
<p>name of variable that contains the language code</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing as data.frames the output of the sentiment analyses
that were requested in sentMethods. For each output data.frame, the first columns
are the idVars specified to enable combining back with the original inputData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sent.out = textSentiment(inputData=sample_chat_processed,
idVars=c('batchMeetingId', 'messageId'), 
textVar='message', sentMethods='syuzhet',appendOut=TRUE,
languageCodeVar='messageLanguage')

## Not run: 
sent.out = textSentiment(inputData=sample_transcript_processed, 
idVars=c('batchMeetingId','utteranceId'), 
textVar='utteranceMessage', sentMethods=c('aws','syuzhet'), 
appendOut=TRUE, languageCodeVar='utteranceLanguage')

## End(Not run)

</code></pre>

<hr>
<h2 id='turnTaking'>Simple conversational turn-taking analysis</h2><span id='topic+turnTaking'></span>

<h3>Description</h3>

<p>Generate a very basic analysis of the conversational turntaking in
either a Zoom transcript or a Zoom chat file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>turnTaking(inputData, inputType, meetingId, speakerId)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="turnTaking_+3A_inputdata">inputData</code></td>
<td>
<p>data.frame output from either processZoomChat or processZoomTranscript</p>
</td></tr>
<tr><td><code id="turnTaking_+3A_inputtype">inputType</code></td>
<td>
<p>string of either 'chat' or 'transcript'</p>
</td></tr>
<tr><td><code id="turnTaking_+3A_meetingid">meetingId</code></td>
<td>
<p>string giving the name of the meeting identifier</p>
</td></tr>
<tr><td><code id="turnTaking_+3A_speakerid">speakerId</code></td>
<td>
<p>string giving the name of the variable with the identity of the speaker</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of four data.frames giving different levels of analysis for turn taking:
</p>

<ul>
<li><p> rawTurn - This data.frame gives a dataset with a
lagged column so that you could calculate custom metrics
</p>
</li>
<li><p> aggTurnsDyad - This gives a dyad-level dataset so that
you know whose speech patterns came before whose
</p>
</li>
<li><p> aggTurnsSpeaker - This gives a speaker-level dataset
with metrics that you could use to assess each given
person's influence on the conversation
</p>
</li>
<li><p> aggTurnsSpeaker_noself - This is a replication of
the aggTurnsSpeaker dataset, but it excludes turns where
a speaker self-follows (i.e., Speaker A =&gt; Speaker A)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>turn.out = turnTaking(inputData=sample_transcript_processed, 
inputType='transcript', meetingId='batchMeetingId', 
speakerId='userName')

turn.out = turnTaking(inputData=sample_chat_processed, 
inputType='chat', meetingId='batchMeetingId', 
speakerId='userName')

</code></pre>

<hr>
<h2 id='videoFaceAnalysis'>Analyze the facial features within an exported Zoom video file</h2><span id='topic+videoFaceAnalysis'></span>

<h3>Description</h3>

<p>Using this function you can analyze attributes of facial expressions within
a video file. There are two ways to supply the video information. First, you
can provide the actual video file. The function will then break it down
into still frames using the grabVideoStills() function. Second, you can use
the videoImageDirectory argument to give the location of a directory where
images have been pre-saved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>videoFaceAnalysis(
  inputVideo,
  recordingStartDateTime,
  sampleWindow,
  facesCollectionID = NA,
  videoImageDirectory = NULL,
  grabVideoStills = FALSE,
  overWriteDir = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="videoFaceAnalysis_+3A_inputvideo">inputVideo</code></td>
<td>
<p>string path to the video file (ideal is gallery)</p>
</td></tr>
<tr><td><code id="videoFaceAnalysis_+3A_recordingstartdatetime">recordingStartDateTime</code></td>
<td>
<p>YYYY-MM-DD HH:MM:SS of the start of the recording</p>
</td></tr>
<tr><td><code id="videoFaceAnalysis_+3A_samplewindow">sampleWindow</code></td>
<td>
<p>Frame rate for the analysis</p>
</td></tr>
<tr><td><code id="videoFaceAnalysis_+3A_facescollectionid">facesCollectionID</code></td>
<td>
<p>name of an 'AWS' collection with identified faces</p>
</td></tr>
<tr><td><code id="videoFaceAnalysis_+3A_videoimagedirectory">videoImageDirectory</code></td>
<td>
<p>path to a directory that either contains image files or where you want to save image files</p>
</td></tr>
<tr><td><code id="videoFaceAnalysis_+3A_grabvideostills">grabVideoStills</code></td>
<td>
<p>logical indicating whether you want the function to split the video file or not</p>
</td></tr>
<tr><td><code id="videoFaceAnalysis_+3A_overwritedir">overWriteDir</code></td>
<td>
<p>logical indicating whether to overwrite videoImageDirectory if it exists</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with one record for every face detected in each frame. For each face, there is an abundance of information from 'AWS Rekognition'. This output is quite detailed. Note that there will be a varying number of faces per sampled frame in the video. Imagine that you have sampled the meeting and had someone rate each person's face within that sampled moment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
vid.out = videoFaceAnalysis(inputVideo="meeting001_video.mp4", 
recordingStartDateTime="2020-04-20 13:30:00", 
sampleWindow=1, facesCollectionID="group-r",
videoImageDirectory="~/Documents/meetingImages", 
grabVideoStills=FALSE, overWriteDir=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='windowedTextConversationAnalysis'>Run a windowed analysis on either a Zoom transcript or chat
This function conducts a temporal window analysis on the conversation in
either a Zoom transcript or chat. It replicates the textConversationAnalysis
function across a set of windows at a window size specified by the user.</h2><span id='topic+windowedTextConversationAnalysis'></span>

<h3>Description</h3>

<p>Run a windowed analysis on either a Zoom transcript or chat
This function conducts a temporal window analysis on the conversation in
either a Zoom transcript or chat. It replicates the textConversationAnalysis
function across a set of windows at a window size specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>windowedTextConversationAnalysis(
  inputData,
  inputType,
  meetingId,
  speakerId,
  sentMethod = "none",
  timeVar = "automatic",
  windowSize
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="windowedTextConversationAnalysis_+3A_inputdata">inputData</code></td>
<td>
<p>data.frame output of either processZoomTranscript or processZoomChat</p>
</td></tr>
<tr><td><code id="windowedTextConversationAnalysis_+3A_inputtype">inputType</code></td>
<td>
<p>string of either 'chat' or 'transcript'</p>
</td></tr>
<tr><td><code id="windowedTextConversationAnalysis_+3A_meetingid">meetingId</code></td>
<td>
<p>string giving the column with the meeting identifier</p>
</td></tr>
<tr><td><code id="windowedTextConversationAnalysis_+3A_speakerid">speakerId</code></td>
<td>
<p>string giving the name of the identifier for the individual who made this contribution</p>
</td></tr>
<tr><td><code id="windowedTextConversationAnalysis_+3A_sentmethod">sentMethod</code></td>
<td>
<p>string giving the type of sentiment analysis to include, either 'aws' or 'syuzhet'</p>
</td></tr>
<tr><td><code id="windowedTextConversationAnalysis_+3A_timevar">timeVar</code></td>
<td>
<p>name of variable giving the time marker to be used.
For transcript, either use 'utteranceStartSeconds' or 'utteranceEndSeconds';
for chat use 'messageTime'</p>
</td></tr>
<tr><td><code id="windowedTextConversationAnalysis_+3A_windowsize">windowSize</code></td>
<td>
<p>integer value of the duration of the window in number of seconds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with two data.frames. In the first (windowlevel), each row is a temporal window.
In the second (speakerlevel), each row is a user's metrics within a given temporal window.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>win.text.out = windowedTextConversationAnalysis(inputData=sample_transcript_sentiment_aws, 
inputType="transcript", meetingId="batchMeetingId", speakerId="userName", sentMethod="aws", 
timeVar="utteranceStartSeconds", windowSize=600)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
