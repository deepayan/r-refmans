<!DOCTYPE html><html><head><title>Help for package predictMe</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {predictMe}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#binBinary'><p>Categorization of predicted probabilities and the corresponding mean number of events for each category.</p></a></li>
<li><a href='#binContinuous'><p>Categorization of measured and predicted outcome values.</p></a></li>
<li><a href='#get2by2'><p>Return of five common results, based on the 2x2 cross-table (a.k.a. confusion matrix).</p></a></li>
<li><a href='#makeDiffPlot'><p>Plot individual differences between measured and predicted outcome values.</p></a></li>
<li><a href='#makeDiffPlotColor'><p>Same as function makeDiffPlot, but add information by using colors.</p></a></li>
<li><a href='#makeTablePlot'><p>Tabularize the essential result of the predictMe package.</p></a></li>
<li><a href='#predictMe'><p>Documentation of this predictMe package.</p></a></li>
<li><a href='#quickSim'><p>Quick simulation of a data.frame for demonstration purposes.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Visualize Individual Prediction Performance</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-24 09:40:02 UTC</td>
</tr>
<tr>
<td>Author:</td>
<td>Marcel Miché</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marcel Miché &lt;marcel.miche.predictme@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Enables researchers to visualize the prediction performance of any algorithm on the individual level (or close to it), given that the predicted outcome is either binary or continuous. Visual results are instantly comprehensible.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mmiche/predictMe">https://github.com/mmiche/predictMe</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rdpack, ggplot2, reshape2</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-21 06:23:17 UTC; mmiche</td>
</tr>
</table>
<hr>
<h2 id='binBinary'>Categorization of predicted probabilities and the corresponding mean number of events for each category.</h2><span id='topic+binBinary'></span>

<h3>Description</h3>

<p>Predicted probabilities are categorized as bins, depending on the selected 'binWidth', and corresponding mean outcome per bin is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binBinary(x = NULL, measColumn = NULL, binWidth = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binBinary_+3A_x">x</code></td>
<td>
<p>A data.frame with exactly two columns, one of the columns must be the measured outcome, the other column must be the predicted outcome values, as returned by some algorithm.</p>
</td></tr>
<tr><td><code id="binBinary_+3A_meascolumn">measColumn</code></td>
<td>
<p>A single integer number that denotes which of the two columns of function argument 'x' contains the measured outcome.</p>
</td></tr>
<tr><td><code id="binBinary_+3A_binwidth">binWidth</code></td>
<td>
<p>A single integer value greater than 0 and less than 100, which separates 100 into equal bins, e.g., 20 (100/20 = 5 equal bins).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predicted values (probability in percent) less than 0 or greater than 100 are replaced by 0 and 100, respectively.
</p>
<p>Beware: Since binning continuous values always introduces noise, some of the differences in column 7 (bin differences) require explicit attention. When the outcome is binary, the binning of the predicted probabilities (fitted values) will also automatically introduce noise in column 5, since the mean number of measured events depends on the width and on the exact borders of the bins (see package vignette, headline <strong>Bin noise</strong>).
</p>


<h3>Value</h3>

<p>a list with two data.frames and one vector. Each data.frame has 7 columns:
</p>

<ol>
<li><p> xTrans Data set, with columns 1 and 2 being categorized, according to the user's selected bin width. Each in percent, column 3 displays the observed frequencies per bin, whereas column 4 display the predicted probabilities (fitted values) per bin. Column 5 shows the difference between values in column 3 and column 4. Column 6 shows the unique individual identifiers. Column 7 shows the differences in terms of bins. See <strong>Details</strong>.
</p>
</li>
<li><p> xTrans2 Same as xTrans, only that original or transformed values less than 0 or greater than 100 have not been replaced with 0 or 100, respectively.
</p>
</li>
<li><p> idxExceed logical vector. TRUE shows the row of xTrans or xTrans2 where values were either less than 0 or greater than 100.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with binary outcome
dfBinary &lt;- quickSim(type="binary")
# Logistic regression, used as algorithm to predict the response variable
# (estimated probability of outcome being present).
glmRes &lt;- glm(y~x1+x2,data=dfBinary,family="binomial")
# Extract measured outcome and the predicted probability (fitted values)
# from the logistic regression output, put both in a data.frame.
glmDf &lt;- data.frame(measOutcome=dfBinary$y,
                    fitted=glmRes$fitted.values)
# Apply function binBinary, generate 5 equal bins (probabilities in
# percent, bin width 20, yields 5 bins).
x100b &lt;- binBinary(x=glmDf, measColumn = 1, binWidth = 20)
</code></pre>

<hr>
<h2 id='binContinuous'>Categorization of measured and predicted outcome values.</h2><span id='topic+binContinuous'></span>

<h3>Description</h3>

<p>Measured and predicted continuous outcome values (transformed to range between 0 and 100) are categorized as bins, depending on the selected 'binWidth'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binContinuous(
  x = NULL,
  measColumn = NULL,
  binWidth = 20,
  computeRange = TRUE,
  range_x = c(0, 0)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binContinuous_+3A_x">x</code></td>
<td>
<p>A data.frame with exactly two columns, one of the columns must be the measured outcome, the other column must be the predicted outcome values, as returned by some algorithm.</p>
</td></tr>
<tr><td><code id="binContinuous_+3A_meascolumn">measColumn</code></td>
<td>
<p>A single integer number that denotes which of the two columns of function argument 'x' contains the measured outcome.</p>
</td></tr>
<tr><td><code id="binContinuous_+3A_binwidth">binWidth</code></td>
<td>
<p>A single integer value greater than 0 and less than 100, which separates 100 into equal bins, e.g., 20 (100/20 = 5 equal bins).</p>
</td></tr>
<tr><td><code id="binContinuous_+3A_computerange">computeRange</code></td>
<td>
<p>Logical value, defaults to TRUE, meaning that the range of the column with the measured outcome values will be computed. Else set this argument to FALSE (see <strong>Details</strong>).</p>
</td></tr>
<tr><td><code id="binContinuous_+3A_range_x">range_x</code></td>
<td>
<p>A vector with the minimum and maximum possible value of the continuous outcome scale (see <strong>Details</strong>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regarding function arguments 'computeRange' and 'range_x': If either the minimum or maximum possible value of the outcome scale has not occurred, e.g., none of the participants selected the maximum possible answer option, then the user must pass the possible range of outcome values to this function, using the function argument 'range_x', e.g., range_x = c(1, 5), if the original outcome scale ranged from 1 to 5.
</p>
<p>Regarding function output 'xTrans' (see <strong>Value</strong>): Predicted values less than 0 or greater than 100 are replaced by 0 and 100, respectively.
</p>
<p>Beware: The differences in column 5 are as accurate (no information loss) as if the original measured and predicted outcome values were subtracted from one another. However, since binning continuous values always introduces noise, some of the differences in column 7 (bin differences) require explicit attention (see package vignette, headline <strong>Bin noise</strong>).
</p>


<h3>Value</h3>

<p>a list with two data.frames and one vector. Each data.frame has 7 columns:
</p>

<ol>
<li><p> xTrans Data set, with columns 1 and 2 being categorized, according to the user's selected bin width. Column 3 displays the observed outcome values, whereas column 4 displays the predicted outocme values (fitted values), both transformed to range between 0 and 100. Column 5 shows the difference between values in column 3 and column 4. Column 6 shows the unique individual identifiers. Column 7 shows the differences in terms of bins. See <strong>Details</strong>.
</p>
</li>
<li><p> xTrans2 Same as xTrans, only that original or transformed values less than 0 or greater than 100 have not been replaced with 0 or 100, respectively.
</p>
</li>
<li><p> idxExceed logical vector. TRUE shows the row of xTrans or xTrans2 where values were either less than 0 or greater than 100.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with continuous outcome (use all default values)
dfContinuous &lt;- quickSim()
# Use multiple linear regression as algorithm to predict the outcome.
lmRes &lt;- lm(y~x1+x2,data=dfContinuous)
# Extract measured outcome and the predicted outcome (fitted values)
# from the regression output, put both in a data.frame.
lmDf &lt;- data.frame(measOutcome=dfContinuous$y,
                   fitted=lmRes$fitted.values)
# Apply function binContinuous, generate 5 equal bins (transformed
# outcome 0-100, bin width = 20, yields 5 bins).
x100c &lt;- binContinuous(x=lmDf, measColumn = 1, binWidth = 20)
</code></pre>

<hr>
<h2 id='get2by2'>Return of five common results, based on the 2x2 cross-table (a.k.a. confusion matrix).</h2><span id='topic+get2by2'></span>

<h3>Description</h3>

<p>Upon receiving two binary variables (only 0 and 1 permitted) of equal length, return sensitivity, specificity, positive predictive value, negative predictive value, and the base rate of the outcome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get2by2(xr, measColumn = NULL, print2by2 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get2by2_+3A_xr">xr</code></td>
<td>
<p>A data.frame with exactly two columns, one of the columns must be the binary measured outcome, the other column must be the binary predicted outcome, based on some algorithm's predictions (see <strong>Details</strong>).</p>
</td></tr>
<tr><td><code id="get2by2_+3A_meascolumn">measColumn</code></td>
<td>
<p>A single integer number that denotes which of the two columns of function argument 'x' contains the measured outcome.</p>
</td></tr>
<tr><td><code id="get2by2_+3A_print2by2">print2by2</code></td>
<td>
<p>Logical value, defaults to FALSE. If set TRUE, two 2by2 matrices will be printed with explanations of what they display.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The r in the argument 'xr' stands for response, meaning that the predicted probabilities must have been transformed to a binary outcome, usually by using the default cutoff of 0.5; although it may also be any other cutoff between 0 and 1.
</p>
<p>If you wish to additionally print the 2x2 matrix, set the argument 'print2by2' TRUE (default: FALSE).
</p>


<h3>Value</h3>

<p>a list with five elements (seven, if argument print2by2 is set TRUE; see <strong>Details</strong>):
</p>

<ol>
<li><p> sens Sensitivity (a.k.a.: Recall, True Positive Rate).
</p>
</li>
<li><p> spec Specificity (a.k.a.: True Negative Rate).
</p>
</li>
<li><p> ppv Positive Predictive Value (a.k.a.: Precision).
</p>
</li>
<li><p> npv Negative Predictive Value.
</p>
</li>
<li><p> br Base rate of the outcome (mean outcome occurrence in the sample).
</p>
</li>
<li><p> tbl1 2x2 matrix. Test-theoretic perspective: Specificity in top left cell, sensitivity in bottom right cell.
</p>
</li>
<li><p> tbl2 2x2 matrix. Test-practical perspective (apply test in the real world): Negative predictive value (npv) in top left cell, positive predictive value (ppv) in bottom right cell.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with binary outcome
dfBinary &lt;- quickSim(type="binary")
# Logistic regression, used as algorithm to predict the response variable
# (response = estimated probability of outcome being present).
glmRes &lt;- glm(y~x1+x2,data=dfBinary,family="binomial")
# Extract measured outcome and the predicted probability (fitted values)
# from the logistic regression output, put both in a data.frame.
glmDf &lt;- data.frame(measOutcome=dfBinary$y,
                    fitted=glmRes$fitted.values)
# binary outcome, based on the default probability threshold of 0.5.
get2by2Df &lt;- data.frame(
    measuredOutcome=glmDf$measOutcome,
    predictedOutcome=ifelse(glmDf$fitted&lt;.5, 0, 1))
# Demand 2x2 matrix to be part of the resulting list.
my2x2 &lt;- get2by2(xr=get2by2Df, measColumn=1, print2by2 = TRUE)
# Display both 2x2 matrices
# tbl1: Theoretical perspective, with specificity in top left cell,
# sensitivity in bottom right cell.
my2x2$tbl1
# tbl2: Practical perspective, with negative predictive value (npv)
# in top left cell, positive predictive value (ppv) in bottom right
# cell.
my2x2$tbl2
</code></pre>

<hr>
<h2 id='makeDiffPlot'>Plot individual differences between measured and predicted outcome values.</h2><span id='topic+makeDiffPlot'></span>

<h3>Description</h3>

<p>Plot the differences between measured and predicted outcome for all individuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeDiffPlot(xd = NULL, idCol = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeDiffPlot_+3A_xd">xd</code></td>
<td>
<p>A data.frame with exactly two columns, one of the columns must be the identifier of all individuals, the other column must be the differences between the measured and the predicted outcome values.</p>
</td></tr>
<tr><td><code id="makeDiffPlot_+3A_idcol">idCol</code></td>
<td>
<p>A single integer that denotes which of the columns of the data.frame contains the identifier of the individuals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The d in 'xd' stands for differences, meaning that the column of interest contain the differences between the measured and the predicted outcome values, logically requiring the column that identifies the individuals.
</p>
<p>Irrespective of whether the original outcome was continuous or binary, outcome values always range between 0 and 100. For instance, for a binary outcome the 'probabilities' are represented as percentage.
</p>
<p>Use the column diff (from function <code><a href="#topic+binContinuous">binContinuous</a></code>) or diffPerc (from function <code><a href="#topic+binBinary">binBinary</a></code>) and column xAxisIds, both columns being part of both data.frames that are returned by the two mentioned functions.
</p>


<h3>Value</h3>

<p>a list with the plot that shows the differences between the measured and predicted outcome for all individuals. See <strong>Details</strong>.
</p>


<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>References</h3>

<p>Wickham H (2016).
<em>ggplot2: Elegant Graphics for Data Analysis</em>.
Springer-Verlag New York.
ISBN 978-3-319-24277-4, <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with continuous outcome (use all default values)
dfContinuous &lt;- quickSim()
# Use multiple linear regression as algorithm to predict the outcome.
lmRes &lt;- lm(y~x1+x2,data=dfContinuous)
# Extract measured outcome and the predicted outcome (fitted values)
# from the regression output, put both in a data.frame.
lmDf &lt;- data.frame(measOutcome=dfContinuous$y,
                   fitted=lmRes$fitted.values)
# Apply function binContinuous.
x100c &lt;- binContinuous(x=lmDf, measColumn = 1, binWidth = 20)
# Apply function makeDiffPlot, using columns 5 and 6 from x100c[["xTrans"]]
# The second of columns 5 and 6 contains the identifiers of the individuals.
dp &lt;- makeDiffPlot(x100c[["xTrans"]][,5:6], idCol = 2)
# dp is the plot that shows the individual differences.
# makeDiffPlot works the same way if binBinary had be used instead of
# binContinuous.
</code></pre>

<hr>
<h2 id='makeDiffPlotColor'>Same as function makeDiffPlot, but add information by using colors.</h2><span id='topic+makeDiffPlotColor'></span>

<h3>Description</h3>

<p>Does the same as makeDiffPlot. However, additionally the difference between bins are added by using colors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeDiffPlotColor(xdc = NULL, idCol = NULL, colorCol = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeDiffPlotColor_+3A_xdc">xdc</code></td>
<td>
<p>A data.frame with exactly three columns, one of the columns must be the identifier of all individuals, another column must be the differences between the measured and the predicted outcome values, and the third column must be the absolute differences between the bins of the measured and the predicted outcome.</p>
</td></tr>
<tr><td><code id="makeDiffPlotColor_+3A_idcol">idCol</code></td>
<td>
<p>A single integer that denotes which of the columns of the data.frame contains the identifier of the individuals.</p>
</td></tr>
<tr><td><code id="makeDiffPlotColor_+3A_colorcol">colorCol</code></td>
<td>
<p>A single integer that denotes which of the columns of the data.frame contains the absolute differences between the bins of the measured and the predicted outcome.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recommendation: Use some of the ggplot2 options to enhance the plot, e.g., using the function facet_wrap (for an example, see vignette <strong>predictMe Why and how to?, headline 'Function makeDiffPlotColor (to go into more detail)'</strong>).
</p>


<h3>Value</h3>

<p>a list with the plot that shows the differences between the measured and predicted outcome for all individuals, using colorized points that express the differences in terms of number of bins.
</p>


<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>References</h3>

<p>Wickham H (2016).
<em>ggplot2: Elegant Graphics for Data Analysis</em>.
Springer-Verlag New York.
ISBN 978-3-319-24277-4, <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with continuous outcome (use all default values)
dfContinuous &lt;- quickSim()
# Use multiple linear regression as algorithm to predict the outcome.
lmRes &lt;- lm(y~x1+x2,data=dfContinuous)
# Extract measured outcome and the predicted outcome (fitted values)
# from the regression output, put both in a data.frame.
lmDf &lt;- data.frame(measOutcome=dfContinuous$y,
                   fitted=lmRes$fitted.values)
# Apply function binContinuous.
x100c &lt;- binContinuous(x=lmDf, measColumn = 1, binWidth = 20)
# Apply function makeDiffPlotColor, using columns 5 and 6 from x100c[["xTrans"]]
# The second of columns 5 and 6 contains the identifiers of the individuals.
dpc &lt;- makeDiffPlotColor(x100c[["xTrans"]][,5:7], idCol = 2, colorCol=3)
# dpc is the plot that shows the individual differences, in colorized form.
# makeDiffPlotColor works the same way if binBinary had be used instead of
# binContinuous.
</code></pre>

<hr>
<h2 id='makeTablePlot'>Tabularize the essential result of the predictMe package.</h2><span id='topic+makeTablePlot'></span>

<h3>Description</h3>

<p>Provides the essential result of the predictMe package, three tables, and, optionally, two plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTablePlot(xc = NULL, measColumn = NULL, plot = FALSE, plotCellRes = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTablePlot_+3A_xc">xc</code></td>
<td>
<p>A data.frame with exactly two columns, one of the columns must be the categorized measured outcome, the other column must be the categorized predicted outcome.</p>
</td></tr>
<tr><td><code id="makeTablePlot_+3A_meascolumn">measColumn</code></td>
<td>
<p>A single integer number that denotes which of the two columns of function argument 'x' contains the measured outcome.</p>
</td></tr>
<tr><td><code id="makeTablePlot_+3A_plot">plot</code></td>
<td>
<p>Logical value, defaults to FALSE. If set TRUE, two complementary plots will be part of the list that this function returns.</p>
</td></tr>
<tr><td><code id="makeTablePlot_+3A_plotcellres">plotCellRes</code></td>
<td>
<p>Logical value, defaults to TRUE (is ignored if function argument 'plot' is set FALSE). If set FALSE, the heatmap is returned without frequency results in the cellls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The c in 'xc' stands for categorized, meaning that the outcome values are expected to have been categorized, so that both columns contain the exact same categories, and are of the class factor.
</p>
<p>Columns 1 and 2 of the output 'xTrans' from function <code><a href="#topic+binBinary">binBinary</a></code> and from function <code><a href="#topic+binContinuous">binContinuous</a></code> provide the expected input of this <code>makeTablePlot</code> function (see <strong>Examples</strong>).
</p>
<p>The returned list will contain 7 items, if function argument 'plot' is set TRUE, if FALSE, it will return the first 5 items (see <strong>Values</strong>).
</p>


<h3>Value</h3>

<p>a list with five or seven items (see <strong>Details</strong>):
</p>

<ol>
<li><p> totalCountTable A table with the total counts.
</p>
</li>
<li><p> rowSumTable A table with proportions that sum up to 1, per row (summing across columns).
</p>
</li>
<li><p> colSumTable A table with proportions that sum up to 1, per column (summing across rows).
</p>
</li>
<li><p> rowSumTable_melt The rowSumTable, reformated by the function melt of the reshape2 package.
</p>
</li>
<li><p> colSumTable_melt The colSumTable, reformated by the function melt of the reshape2 package.
</p>
</li>
<li><p> rowSumTable_plot The rowSumTable_melt data, plotted by the function ggplot of the ggplot2 package.
</p>
</li>
<li><p> colSumTable_plot The colSumTable_melt data, plotted by the function ggplot of the ggplot2 package.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>References</h3>

<p>Wickham H (2016).
<em>ggplot2: Elegant Graphics for Data Analysis</em>.
Springer-Verlag New York.
ISBN 978-3-319-24277-4, <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</p>
<p>Wickham H (2007).
&ldquo;Reshaping Data with the reshape Package.&rdquo;
<em>Journal of Statistical Software</em>, <b>21</b>(12), 1&ndash;20.
<a href="https://www.jstatsoft.org/v21/i12/">https://www.jstatsoft.org/v21/i12/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with continuous outcome (use all default values)
dfContinuous &lt;- quickSim()
# Use multiple linear regression as algorithm to predict the outcome.
lmRes &lt;- lm(y~x1+x2,data=dfContinuous)
# Extract measured outcome and the predicted outcome (fitted values)
# from the regression output, put both in a data.frame.
lmDf &lt;- data.frame(measOutcome=dfContinuous$y,
                   fitted=lmRes$fitted.values)
# Apply function binBinary
x100c &lt;- binContinuous(x=lmDf, measColumn = 1, binWidth = 20)
# Apply function makeDiffPlot, using columns 1 and 2 from x100c[["xTrans"]]
# The first of columns 1 and 2 contains the measured outcome values.
tp &lt;- makeTablePlot(x100c[["xTrans"]][,1:2], measColumn = 1, plot = TRUE)
# tp is a list with 7 items, items 6 and 7 are the plots that represent
# the numeric information of items 2 and 3 (and 4 and 5, which merely have
# a different format).
# Display item 6 (plot no.1). Perfect performance if the diagonal cells all
# contain the value 1.
tp$rowSumTable_plot
</code></pre>

<hr>
<h2 id='predictMe'>Documentation of this predictMe package.</h2><span id='topic+predictMe'></span>

<h3>Description</h3>

<p>This package enables researchers to visualize the prediction performance of an algorithm, either on the individual level or approximating this level. The visualized result is instantly comprehensible, only depending on being familiar with the concept of 'difference' (yes or no) and the related concept of 'distance' (if difference yes, how large is it). The predictMe package can be applied to the output of any algorithm, given that the measured (and therefore also the predicted) outcome is either continuous or binary.
</p>
<p>Importantly, predictMe only takes the two relevant columns, that is, the measured outcome and the predicted outcome. The values in the two columns will be transformed, to range between 0 and 100 (see <strong>Details</strong> in the documentation of functions <code><a href="#topic+binContinuous">binContinuous</a></code> or <code><a href="#topic+binBinary">binBinary</a></code>), finally returning the transformed values as bins. The user can decide how small the bins shall be, using the function argument <code>binWidth</code>. The smaller the bins, the more bins will be produced, which means the more will the visualized prediction performance approximate the individual level (see function <code><a href="#topic+makeTablePlot">makeTablePlot</a></code>). Differences between measured and predicted outcome on the individual level can also be visualized (see function <code><a href="#topic+makeDiffPlot">makeDiffPlot</a></code>).
</p>
<p>The predictMe package provides the transformed data (see functions <code><a href="#topic+binContinuous">binContinuous</a></code> or <code><a href="#topic+binBinary">binBinary</a></code>) and the visualization (see functions functions <code><a href="#topic+makeTablePlot">makeTablePlot</a></code> or <code><a href="#topic+makeDiffPlot">makeDiffPlot</a></code>). Nevertheless, the user is free to experiment with visualizing the results, which are returned in different formats (see vignette of predictMe for a few examples of how the data may be visualized).
</p>
<p>The predictMe package depends on two packages: ggplot2 (Wickham, 2016) for providing suggested visualizations, and reshape (Wickham, 2007) for providing the results in a format that is readily compatible with ggplot2 experimentation. The conventional format may also be used, which is compatible with base R plotting functions.
</p>
<p>Importantly, the predictMe package was developed with the aim of extreme ease of both, use and comprehension of the output. This, I hope, may make this package powerful, in terms of being actually used. The first four out of the six references (see below) contain bits of the intended usefulness of this package (see <strong>Note</strong> below). The actual idea for this package came while trying to achieve something specific, using the ggplot2 package (Wickham, 2016).
</p>


<h3>Note</h3>

<p>These are the bits in the first four references below, that pertain to the intended usefulness of the predictMe package:
</p>
<p>Altman and Royston (2000) provide this introductory quote (by Alvan Feinstein):
'Validation is one of those words ... that is constantly used and seldom defined.'
This surely is strange in the vicinity of developing prognostic models, especially in the machine learning age, unless the statement was meant as a joke (which appears not to be the case), or is no longer valid in 2022 (which might be true or false, who knows).
</p>
<p>Bickel and Lehman (2012):
If two different people, who both provided the exact same relevant input data for an algorithm, with which a risk percentage of some adverse outcome is computed, say complications due to an operation, they will receive the exact same risk estimation, e.g., 1 percent. However, both individuals may understand this number very differently, depending on their individual inclinations in general and/or at that moment. Therefore, one of the two individuals may simply say ok to the operation, while the other individual may ask for more detailed information. This more detailed information can be computed with the predictMe functions <code><a href="#topic+binContinuous">binContinuous</a></code> or <code><a href="#topic+binBinary">binBinary</a></code>, and visualized with the predictMe function <code><a href="#topic+makeDiffPlot">makeDiffPlot</a></code>. The differences can be colorized with the function <code><a href="#topic+makeDiffPlotColor">makeDiffPlotColor</a></code>, which may help in seeing how far away an individual's prediction is from being perfect (no difference between measured and predicted outcome). Even though perfect prediction is practically utopian, it still might be relevant to the individual whether his or her predictions are closer to this utopian reference, compared to the predictions of all individuals, who have been used to develop the model that underlies this algorithm's individual predictions.
</p>
<p>Assel et al. (2017): In line with Altman and Royston (2000), Assel et al. (2017) recommend to clarify whether a published prediction model is at an early stage of development or whether it approaches an advanced stage, maybe even suggesting implementation in the real world. In the latter case, much stricter performance criteria must be met, compared to the former case (early stage of model development), due to actual individuals of the real world being the supposed beneficiaries of the algorithmic decision support.
</p>
<p>Offord and Kraemer (2000): In line with Altman and Royston (2000), Offord and Kraemer (2000) emphasize that a risk factor must in any case demonstrate that it can accurately split a group into individuals with low risk and individuals with high risk. In the real world, this requires much more than meeting statistical significance criteria or meeting other (similarly thin) model fit criteria. Again, if model development was at an early stage (see Assel et al., 2017), such criteria may suffice. However, at later stages, real world criteria must be met, that is, real-world relevant results must either replace or at least complement the commonly reported results of prediction performance.
</p>
<p>Conclusion: The predictMe package provides the opportunity to provide some real-world relevant 'results', if visualized individual prediction performance may be considered as 'results'.
</p>


<h3>References</h3>

<p>Altman DG, Royston P (2000).
&ldquo;What do we mean by validating a prognostic model?&rdquo;
<em>Statistics in medicine</em>, <b>19</b>(4), 453&ndash;473.
</p>
<p>Assel M, Sjoberg DD, Vickers AJ (2017).
&ldquo;The Brier score does not evaluate the clinical utility of diagnostic tests or prediction models.&rdquo;
<em>Diagnostic and prognostic research</em>, <b>1</b>(1), 1&ndash;7.
</p>
<p>Bickel PJ, Lehmann EL (2012).
&ldquo;Frequentist interpretation of probability.&rdquo;
In <em>Selected Works of EL Lehmann</em>, 1083&ndash;1085.
Springer.
</p>
<p>Offord DR, Kraemer HC (2000).
&ldquo;Risk factors and prevention.&rdquo;
<em>Evidence-Based Mental Health</em>, <b>3</b>(3), 70&ndash;71.
</p>
<p>Wickham H (2016).
<em>ggplot2: Elegant Graphics for Data Analysis</em>.
Springer-Verlag New York.
ISBN 978-3-319-24277-4, <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</p>
<p>Wickham H (2007).
&ldquo;Reshaping Data with the reshape Package.&rdquo;
<em>Journal of Statistical Software</em>, <b>21</b>(12), 1&ndash;20.
<a href="https://www.jstatsoft.org/v21/i12/">https://www.jstatsoft.org/v21/i12/</a>.
</p>

<hr>
<h2 id='quickSim'>Quick simulation of a data.frame for demonstration purposes.</h2><span id='topic+quickSim'></span>

<h3>Description</h3>

<p>Quick simulation of a data.frame, either with a continuous or with a binary outcome. This is merely to enable showcasing the main purpose of the predictMe package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quickSim(
  n = 1000,
  intercept = 1,
  coefs = c(2, 3),
  errMean = 30,
  errSD = 3,
  seed = 1,
  type = "continuous"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quickSim_+3A_n">n</code></td>
<td>
<p>Sample size, defaults to 1000.</p>
</td></tr>
<tr><td><code id="quickSim_+3A_intercept">intercept</code></td>
<td>
<p>Intercept of a simulated model output, defaults to 1.</p>
</td></tr>
<tr><td><code id="quickSim_+3A_coefs">coefs</code></td>
<td>
<p>Regression coefficients of a simulated model output, defaults to two predictors with coefficients 2 and 3, respectively.</p>
</td></tr>
<tr><td><code id="quickSim_+3A_errmean">errMean</code></td>
<td>
<p>Mean prediction error, present in the simulated data, defaults to 30 (will be ignored, if function argument 'type' (see below) is set to 'binary').</p>
</td></tr>
<tr><td><code id="quickSim_+3A_errsd">errSD</code></td>
<td>
<p>Standard deviation of the error, present in the simulated data, defaults to 3 (will be ignored, if function argument 'type' (see below) is set to 'binary').</p>
</td></tr>
<tr><td><code id="quickSim_+3A_seed">seed</code></td>
<td>
<p>A single integer value. Setting a seed ensures reproducibility of a once simulated data set.</p>
</td></tr>
<tr><td><code id="quickSim_+3A_type">type</code></td>
<td>
<p>A single character value, either 'continuous' or 'binary', depending on what scale the simulated outcome shall have.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned simulated data set will have as many predictors, as the user entered regression coefficients to the function argument 'coefs'. For instance, coefs = c(.5, -2, -.9) will result in three predictors x1, x2, and x3 in the returned data set.
</p>
<p>The simulated data set is merely serving the need to provide the main functions of this package with the data they require (demonstration purpose; several simulation packages exist in R).
</p>


<h3>Value</h3>

<p>simDf A data.frame with one outcome column y, and as many predictor columns (named: x1, x2, …) as the user selected (default: 2). See <strong>Details</strong>.
</p>


<h3>Author(s)</h3>

<p>Marcel Miché
</p>


<h3>References</h3>

<p>Simulation code inside this function was largely taken from <a href="https://stats.stackexchange.com/questions/46523/how-to-simulate-artificial-data-for-logistic-regression/46525">Stéphane Laurent's</a> answer on StackExchange.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data set with continuous outcome (use all default values)
dfContinuous &lt;- quickSim()
# Simulate data set with continuous outcome (set sample size to 149)
dfContinuous &lt;- quickSim(n = 149)
nrow(dfContinuous) # 149
# Simulate data set with binary outcome (set sample size to 100, and
# coefficients to 3, 1, and -2.5)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
