<!DOCTYPE html><html><head><title>Help for package aifeducation</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {aifeducation}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aifeducation_config'><p>R6 object of class AifeducationConfiguration</p></a></li>
<li><a href='#AifeducationConfiguration'><p>R6 class for settting the global machine learning framework.</p></a></li>
<li><a href='#array_to_matrix'><p>Array to matrix</p></a></li>
<li><a href='#bow_pp_create_basic_text_rep'><p>Prepare texts for text embeddings with a bag of word approach.</p></a></li>
<li><a href='#bow_pp_create_vocab_draft'><p>Function for creating a first draft of a vocabulary</p>
This function creates a list of tokens which refer to specific
universal part-of-speech tags (UPOS) and provides the corresponding lemmas.</a></li>
<li><a href='#calc_standard_classification_measures'><p>Calculate standard classification measures</p></a></li>
<li><a href='#check_aif_py_modules'><p>Check if all necessary python modules are available</p></a></li>
<li><a href='#check_embedding_models'><p>Check of compatible text embedding models</p></a></li>
<li><a href='#clean_pytorch_log_transformers'><p>Clean pytorch log of transformers</p></a></li>
<li><a href='#combine_embeddings'><p>Combine embedded texts</p></a></li>
<li><a href='#create_bert_model'><p>Function for creating a new transformer based on BERT</p></a></li>
<li><a href='#create_deberta_v2_model'><p>Function for creating a new transformer based on DeBERTa-V2</p></a></li>
<li><a href='#create_funnel_model'><p>Function for creating a new transformer based on Funnel Transformer</p></a></li>
<li><a href='#create_iota2_mean_object'><p>Create an iota2 object</p></a></li>
<li><a href='#create_longformer_model'><p>Function for creating a new transformer based on Longformer</p></a></li>
<li><a href='#create_roberta_model'><p>Function for creating a new transformer based on RoBERTa</p></a></li>
<li><a href='#create_synthetic_units'><p>Create synthetic units</p></a></li>
<li><a href='#EmbeddedText'><p>Embedded text</p></a></li>
<li><a href='#generate_id'><p>Generate ID suffix for objects</p></a></li>
<li><a href='#get_coder_metrics'><p>Calculate reliability measures based on content analysis</p></a></li>
<li><a href='#get_folds'><p>Create cross-validation samples</p></a></li>
<li><a href='#get_n_chunks'><p>Get the number of chunks/sequences for each case</p></a></li>
<li><a href='#get_stratified_train_test_split'><p>Create a stratified random sample</p></a></li>
<li><a href='#get_synthetic_cases'><p>Create synthetic cases for balancing training data</p></a></li>
<li><a href='#get_train_test_split'><p>Function for splitting data into a train and validation sample</p></a></li>
<li><a href='#install_py_modules'><p>Installing necessary python modules to an environment</p></a></li>
<li><a href='#is.null_or_na'><p>Check if NULL or NA</p></a></li>
<li><a href='#load_ai_model'><p>Loading models created with 'aifeducation'</p></a></li>
<li><a href='#matrix_to_array_c'><p>Reshape matrix to array</p></a></li>
<li><a href='#save_ai_model'><p>Saving models created with 'aifeducation'</p></a></li>
<li><a href='#set_config_cpu_only'><p>Setting cpu only for 'tensorflow'</p></a></li>
<li><a href='#set_config_gpu_low_memory'><p>Setting gpus' memory usage</p></a></li>
<li><a href='#set_config_os_environ_logger'><p>Sets the level for logging information in tensor flow.</p></a></li>
<li><a href='#set_config_tf_logger'><p>Sets the level for logging information in tensor flow.</p></a></li>
<li><a href='#set_transformers_logger'><p>Sets the level for logging information of the 'transformers' library.</p></a></li>
<li><a href='#split_labeled_unlabeled'><p>Split data into labeled and unlabeled data</p></a></li>
<li><a href='#start_aifeducation_studio'><p>Aifeducation Studio</p></a></li>
<li><a href='#summarize_tracked_sustainability'><p>Summarizing tracked sustainability data</p></a></li>
<li><a href='#test_classifier_sustainability'><p>Sustainability data for an example classifier</p></a></li>
<li><a href='#test_metric_mean'><p>Test metric for an example classifier</p></a></li>
<li><a href='#TextEmbeddingClassifierNeuralNet'><p>Text embedding classifier with a neural net</p></a></li>
<li><a href='#TextEmbeddingModel'><p>Text embedding model</p></a></li>
<li><a href='#to_categorical_c'><p>Transforming classes to one-hot encoding</p></a></li>
<li><a href='#train_tune_bert_model'><p>Function for training and fine-tuning a BERT model</p></a></li>
<li><a href='#train_tune_deberta_v2_model'><p>Function for training and fine-tuning a DeBERTa-V2 model</p></a></li>
<li><a href='#train_tune_funnel_model'><p>Function for training and fine-tuning a Funnel Transformer model</p></a></li>
<li><a href='#train_tune_longformer_model'><p>Function for training and fine-tuning a Longformer model</p></a></li>
<li><a href='#train_tune_roberta_model'><p>Function for training and fine-tuning a RoBERTa model</p></a></li>
<li><a href='#update_aifeducation_progress_bar'><p>Update master progress bar in aifeducation shiny app.</p></a></li>
<li><a href='#update_aifeducation_progress_bar_epochs'><p>Update epoch progress bar in aifeducation shiny app.</p></a></li>
<li><a href='#update_aifeducation_progress_bar_steps'><p>Update step/batch progress bar in aifeducation shiny app.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Artificial Intelligence for Education</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Description:</td>
<td>In social and educational settings, the use of Artificial
    Intelligence (AI) is a challenging task. Relevant data is often only
    available in handwritten forms, or the use of data is restricted by
    privacy policies. This often leads to small data sets. Furthermore, in the educational and social sciences,
    data is often unbalanced in terms of
    frequencies. To support educators as well as educational and social
    researchers in using the potentials of AI for their work, this package
    provides a unified interface for neural nets in 'keras',
    'tensorflow', and 'pytorch' to deal with natural language problems. In addition,
    the package ships with a shiny app, providing a graphical user interface.
    This allows the usage of AI for people without skills in writing python/R scripts.
    The tools integrate existing mathematical and statistical methods for dealing
    with small data sets via pseudo-labeling (e.g. Lee (2013)
    <a href="https://www.researchgate.net/publication/280581078_Pseudo-Label_The_Simple_and_Efficient_Semi-Supervised_Learning_Method_for_Deep_Neural_Networks">https://www.researchgate.net/publication/280581078_Pseudo-Label_The_Simple_and_Efficient_Semi-Supervised_Learning_Method_for_Deep_Neural_Networks</a>,
    Cascante-Bonilla et al. (2020) &lt;<a href="https://doi.org/10.48550%2FarXiv.2001.06001">doi:10.48550/arXiv.2001.06001</a>&gt;) and
    imbalanced data via the creation of synthetic cases (e.g.
    Bunkhumpornpat et al. (2012) &lt;<a href="https://doi.org/10.1007%2Fs10489-011-0287-y">doi:10.1007/s10489-011-0287-y</a>&gt;).
    Performance evaluation of AI is connected to measures from content
    analysis which educational and social researchers are generally more
    familiar with (e.g. Berding &amp; Pargmann (2022) &lt;<a href="https://doi.org/10.30819%2F5581">doi:10.30819/5581</a>&gt;,
    Gwet (2014) &lt;ISBN:978-0-9708062-8-4&gt;, Krippendorff (2019)
    &lt;<a href="https://doi.org/10.4135%2F9781071878781">doi:10.4135/9781071878781</a>&gt;). Estimation of energy consumption and CO2
    emissions during model training is done with the 'python' library
    'codecarbon'.  Finally, all objects created with this package allow to
    share trained AI models with other people.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://fberding.github.io/aifeducation/">https://fberding.github.io/aifeducation/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cran/aifeducation/issues">https://github.com/cran/aifeducation/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, foreach, doParallel, iotarelr(&ge; 0.1.5), irr, irrCAC,
methods, Rcpp (&ge; 1.0.10), reshape2, reticulate (&ge; 1.34.0),
smotefamily, stringr, rlang, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>text2vec, tidytext, topicmodels, udpipe, quanteda,
quanteda.textmodels, knitr, rmarkdown, testthat (&ge; 3.0.0),
ggplot2, shiny, shinyFiles, shinyWidgets, shinydashboard,
shinyjs, fs, readtext, readxl</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-15 21:13:59 UTC; WissMit</td>
</tr>
<tr>
<td>Author:</td>
<td>Berding Florian <a href="https://orcid.org/0000-0002-3593-1695"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Pargmann Julia [ctb],
  Riebenbauer Elisabeth [ctb],
  Rebmann Karin [ctb],
  Slopinski Andreas [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Berding Florian &lt;florian.berding@uni-hamburg.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-15 21:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aifeducation_config'>R6 object of class AifeducationConfiguration</h2><span id='topic+aifeducation_config'></span>

<h3>Description</h3>

<p>Object for managing setting the machine learning framework of a session.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aifeducation_config
</code></pre>


<h3>Format</h3>

<p>An object of class <code>aifeducationConfiguration</code> (inherits from <code>R6</code>) of length 5.
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='AifeducationConfiguration'>R6 class for settting the global machine learning framework.</h2><span id='topic+AifeducationConfiguration'></span>

<h3>Description</h3>

<p>R6 class for settting the global machine learning framework.
</p>
<p>R6 class for settting the global machine learning framework.
</p>


<h3>Details</h3>

<p>R6 class for setting the global machine learning framework to 'PyTorch' or
'tensorflow'.
</p>


<h3>Value</h3>

<p>The function does nothing return. It is used for its side effects.
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-aifeducationConfiguration-get_framework"><code>AifeducationConfiguration$get_framework()</code></a>
</p>
</li>
<li> <p><a href="#method-aifeducationConfiguration-set_global_ml_backend"><code>AifeducationConfiguration$set_global_ml_backend()</code></a>
</p>
</li>
<li> <p><a href="#method-aifeducationConfiguration-global_framework_set"><code>AifeducationConfiguration$global_framework_set()</code></a>
</p>
</li>
<li> <p><a href="#method-aifeducationConfiguration-clone"><code>AifeducationConfiguration$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-aifeducationConfiguration-get_framework"></a>



<h4>Method <code>get_framework()</code></h4>

<p>Method for requesting the used machine learning framework.
</p>


<h5>Usage</h5>

<div class="r"><pre>AifeducationConfiguration$get_framework()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>string</code> containing the used machine learning framework
for <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>s as well as for <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>.
</p>


<hr>
<a id="method-aifeducationConfiguration-set_global_ml_backend"></a>



<h4>Method <code>set_global_ml_backend()</code></h4>

<p>Method for setting the global machine learning framework.
</p>


<h5>Usage</h5>

<div class="r"><pre>AifeducationConfiguration$set_global_ml_backend(backend)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>backend</code></dt><dd><p><code>string</code> Framework to use for training and inference.
<code>backend="tensorflow"</code> for 'tensorflow' and <code>backend="pytorch"</code>
for 'PyTorch'.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>This method does nothing return. It is used for setting the global
configuration of 'aifeducation'.
</p>


<hr>
<a id="method-aifeducationConfiguration-global_framework_set"></a>



<h4>Method <code>global_framework_set()</code></h4>

<p>Method for checking if the global ml framework is set.
</p>


<h5>Usage</h5>

<div class="r"><pre>AifeducationConfiguration$global_framework_set()</pre></div>



<h5>Returns</h5>

<p>Return <code>TRUE</code> if the global machine learning framework is set.
Otherwise <code>FALSE</code>.
</p>


<hr>
<a id="method-aifeducationConfiguration-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>AifeducationConfiguration$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='array_to_matrix'>Array to matrix</h2><span id='topic+array_to_matrix'></span>

<h3>Description</h3>

<p>Function transforming an array to a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>array_to_matrix(text_embedding)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="array_to_matrix_+3A_text_embedding">text_embedding</code></td>
<td>
<p><code>array</code> containing the text embedding. The array
should be created via an object of class <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix which contains the cases in the rows and the columns
represent the features of all sequences. The sequences are concatenated.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='bow_pp_create_basic_text_rep'>Prepare texts for text embeddings with a bag of word approach.</h2><span id='topic+bow_pp_create_basic_text_rep'></span>

<h3>Description</h3>

<p>This function prepares raw texts for use with <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bow_pp_create_basic_text_rep(
  data,
  vocab_draft,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_numbers = TRUE,
  remove_url = TRUE,
  remove_separators = TRUE,
  split_hyphens = FALSE,
  split_tags = FALSE,
  language_stopwords = "de",
  use_lemmata = FALSE,
  to_lower = FALSE,
  min_termfreq = NULL,
  min_docfreq = NULL,
  max_docfreq = NULL,
  window = 5,
  weights = 1/(1:5),
  trace = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_data">data</code></td>
<td>
<p><code>vector</code> containing the raw texts.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_vocab_draft">vocab_draft</code></td>
<td>
<p>Object created with <a href="#topic+bow_pp_create_vocab_draft">bow_pp_create_vocab_draft</a>.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_remove_punct">remove_punct</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if punctuation should be removed.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_remove_symbols">remove_symbols</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if symbols should be removed.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_remove_numbers">remove_numbers</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if numbers should be removed.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_remove_url">remove_url</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if urls should be removed.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_remove_separators">remove_separators</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if separators should be removed.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_split_hyphens">split_hyphens</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if hyphens should be split into several tokens.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_split_tags">split_tags</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if tags should be split.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_language_stopwords">language_stopwords</code></td>
<td>
<p><code>string</code> Abbreviation for the language for which stopwords should be
removed.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_use_lemmata">use_lemmata</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> lemmas instead of original tokens should be used.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_to_lower">to_lower</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if tokens or lemmas should be used with lower cases.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_min_termfreq">min_termfreq</code></td>
<td>
<p><code>int</code> Minimum frequency of a token to be part of the vocabulary.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_min_docfreq">min_docfreq</code></td>
<td>
<p><code>int</code> Minimum appearance of a token in documents to be part of the vocabulary.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_max_docfreq">max_docfreq</code></td>
<td>
<p><code>int</code> Maximum appearance of a token in documents to be part of the vocabulary.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_window">window</code></td>
<td>
<p><code>int</code> size of the window for creating the feature-co-occurance matrix.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_weights">weights</code></td>
<td>
<p><code>vector</code> weights for the corresponding window. The vector length must be equal to the window size.</p>
</td></tr>
<tr><td><code id="bow_pp_create_basic_text_rep_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be
printed to console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>list</code> of class <code>basic_text_rep</code> with the following components.
</p>

<ul>
<li><p><code>dfm: </code> Document-Feature-Matrix. Rows correspond to the documents. Columns represent
the number of tokens in the document.
</p>
</li>
<li><p><code>fcm: </code> Feature-Co-Occurance-Matrix.
</p>
</li>
<li><p><code>information: </code> <code>list</code> containing information about the used vocabulary. These are:
</p>

<ul>
<li><p><code>n_sentence: </code>Number of sentences
</p>
</li>
<li><p><code>n_document_segments: </code>Number of document segments/raw texts
</p>
</li>
<li><p><code>n_token_init: </code>Number of initial tokens
</p>
</li>
<li><p><code>n_token_final: </code>Number of final tokens
</p>
</li>
<li><p><code>n_lemmata: </code>Number of lemmas
</p>
</li></ul>

</li>
<li><p><code>configuration: </code> <code>list</code> containing information if the vocabulary was
created with lower cases and if the vocabulary uses original tokens or lemmas.
</p>
</li>
<li><p><code>language_model: </code> <code>list</code> containing information about the applied
language model. These are:
</p>

<ul>
<li><p><code>model: </code>the udpipe language model
</p>
</li>
<li><p><code>label: </code>the label of the udpipe language model
</p>
</li>
<li><p><code>upos: </code>the applied universal part-of-speech tags
</p>
</li>
<li><p><code>language: </code>the language
</p>
</li>
<li><p><code>vocab: </code>a <code>data.frame</code> with the original vocabulary
</p>
</li></ul>

</li></ul>



<h3>See Also</h3>

<p>Other Preparation: 
<code><a href="#topic+bow_pp_create_vocab_draft">bow_pp_create_vocab_draft</a>()</code>
</p>

<hr>
<h2 id='bow_pp_create_vocab_draft'>Function for creating a first draft of a vocabulary
This function creates a list of tokens which refer to specific
universal part-of-speech tags (UPOS) and provides the corresponding lemmas.</h2><span id='topic+bow_pp_create_vocab_draft'></span>

<h3>Description</h3>

<p>Function for creating a first draft of a vocabulary
This function creates a list of tokens which refer to specific
universal part-of-speech tags (UPOS) and provides the corresponding lemmas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bow_pp_create_vocab_draft(
  path_language_model,
  data,
  upos = c("NOUN", "ADJ", "VERB"),
  label_language_model = NULL,
  language = NULL,
  chunk_size = 100,
  trace = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_path_language_model">path_language_model</code></td>
<td>
<p><code>string</code> Path to a udpipe language model that
should be used for tagging and lemmatization.</p>
</td></tr>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_data">data</code></td>
<td>
<p><code>vector</code> containing the raw texts.</p>
</td></tr>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_upos">upos</code></td>
<td>
<p><code>vector</code> containing the universal part-of-speech tags which
should be used to build the vocabulary.</p>
</td></tr>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_label_language_model">label_language_model</code></td>
<td>
<p><code>string</code> Label for the udpipe language model used.</p>
</td></tr>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_language">language</code></td>
<td>
<p><code>string</code> Name of the language (e.g., English, German)</p>
</td></tr>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_chunk_size">chunk_size</code></td>
<td>
<p><code>int</code> Number of raw texts which should be processed at once.</p>
</td></tr>
<tr><td><code id="bow_pp_create_vocab_draft_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be printed to console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> with the following components.
</p>

<ul>
<li><p><code>vocab:</code> <code>data.frame</code> containing the tokens, lemmas, tokens in lower case, and
lemmas in lower case.
</p>
</li>
<li><p><code>ud_language_model</code> udpipe language model that is used for tagging.
</p>
</li>
<li><p><code>label_language_model</code> Label of the udpipe language model.
</p>
</li>
<li><p><code>language</code> Language of the raw texts.
</p>
</li>
<li><p><code>upos</code> Used univerisal part-of-speech tags.
</p>
</li>
<li><p><code>n_sentence</code> <code>int</code> Estimated number of sentences in the raw texts.
</p>
</li>
<li><p><code>n_token</code> <code>int</code> Estimated number of tokens in the raw texts.
</p>
</li>
<li><p><code>n_document_segments</code> <code>int</code> Estimated number of document segments/raw texts.
</p>
</li></ul>



<h3>Note</h3>

<p>A list of possible tags can be found
here: <a href="https://universaldependencies.org/u/pos/index.html">https://universaldependencies.org/u/pos/index.html</a>.
</p>
<p>A huge number of models can be found
here: <a href="https://ufal.mff.cuni.cz/udpipe/2/models">https://ufal.mff.cuni.cz/udpipe/2/models</a>.
</p>


<h3>See Also</h3>

<p>Other Preparation: 
<code><a href="#topic+bow_pp_create_basic_text_rep">bow_pp_create_basic_text_rep</a>()</code>
</p>

<hr>
<h2 id='calc_standard_classification_measures'>Calculate standard classification measures</h2><span id='topic+calc_standard_classification_measures'></span>

<h3>Description</h3>

<p>Function for calculating recall, precision, and f1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_standard_classification_measures(true_values, predicted_values)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_standard_classification_measures_+3A_true_values">true_values</code></td>
<td>
<p><code>factor</code> containing the true labels/categories.</p>
</td></tr>
<tr><td><code id="calc_standard_classification_measures_+3A_predicted_values">predicted_values</code></td>
<td>
<p><code>factor</code> containing the predicted labels/categories.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix which contains the cases categories in the rows and
the measures (precision, recall, f1) in the columns.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='check_aif_py_modules'>Check if all necessary python modules are available</h2><span id='topic+check_aif_py_modules'></span>

<h3>Description</h3>

<p>This function checks if all  python modules necessary for the package
aifeducation to work are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_aif_py_modules(trace = TRUE, check = "all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_aif_py_modules_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if a list with all modules and their
availability should be printed to the console.</p>
</td></tr>
<tr><td><code id="check_aif_py_modules_+3A_check">check</code></td>
<td>
<p><code>string</code> determining the machine learning framework to check for.
<code>check="pytorch"</code> for 'pytorch', <code>check="tensorflow"</code> for 'tensorflow',
and <code>check="all"</code> for both frameworks.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function prints a table with all relevant packages and shows
which modules are available or unavailable.
</p>
<p>If all relevant modules are available, the functions returns <code>TRUE</code>.
In all other cases it returns <code>FALSE</code>
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='check_embedding_models'>Check of compatible text embedding models</h2><span id='topic+check_embedding_models'></span>

<h3>Description</h3>

<p>This function checks if different objects are based on the same text
embedding model. This is necessary to ensure that classifiers are used
only with data generated through compatible embedding models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_embedding_models(object_list, same_class = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_embedding_models_+3A_object_list">object_list</code></td>
<td>
<p><code>list</code> of object of class <a href="#topic+EmbeddedText">EmbeddedText</a> or
<a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>.</p>
</td></tr>
<tr><td><code id="check_embedding_models_+3A_same_class">same_class</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if all object must be from the same class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>TRUE</code> if all objects refer to the same text embedding model.
<code>FALSE</code> in all other cases.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='clean_pytorch_log_transformers'>Clean pytorch log of transformers</h2><span id='topic+clean_pytorch_log_transformers'></span>

<h3>Description</h3>

<p>Function for preparing and cleaning the log created by an object of class Trainer
from the python library 'transformer's
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_pytorch_log_transformers(log)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_pytorch_log_transformers_+3A_log">log</code></td>
<td>
<p><code>data.frame</code> containing the log.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>data.frame</code> containing epochs, loss, and val_loss.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='combine_embeddings'>Combine embedded texts</h2><span id='topic+combine_embeddings'></span>

<h3>Description</h3>

<p>Function for combining embedded texts of the same model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_embeddings(embeddings_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combine_embeddings_+3A_embeddings_list">embeddings_list</code></td>
<td>
<p><code>list</code> of objects of class <a href="#topic+EmbeddedText">EmbeddedText</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <a href="#topic+EmbeddedText">EmbeddedText</a> which contains all
unique cases of the input objects.
</p>


<h3>See Also</h3>

<p>Other Text Embedding: 
<code><a href="#topic+EmbeddedText">EmbeddedText</a></code>,
<code><a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a></code>
</p>

<hr>
<h2 id='create_bert_model'>Function for creating a new transformer based on BERT</h2><span id='topic+create_bert_model'></span>

<h3>Description</h3>

<p>This function creates a transformer configuration based on the BERT base architecture
and a vocabulary based on WordPiece by using
the python libraries 'transformers' and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_bert_model(
  ml_framework = aifeducation_config$get_framework(),
  model_dir,
  vocab_raw_texts = NULL,
  vocab_size = 30522,
  vocab_do_lower_case = FALSE,
  max_position_embeddings = 512,
  hidden_size = 768,
  num_hidden_layer = 12,
  num_attention_heads = 12,
  intermediate_size = 3072,
  hidden_act = "gelu",
  hidden_dropout_prob = 0.1,
  attention_probs_dropout_prob = 0.1,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_bert_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_model_dir">model_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the model should be saved.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_vocab_raw_texts">vocab_raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for creating the
vocabulary.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_vocab_size">vocab_size</code></td>
<td>
<p><code>int</code> Size of the vocabulary.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_vocab_do_lower_case">vocab_do_lower_case</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if all words/tokens should be lower case.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_max_position_embeddings">max_position_embeddings</code></td>
<td>
<p><code>int</code> Number of maximal position embeddings. This parameter
also determines the maximum length of a sequence which can be processed with the model.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_hidden_size">hidden_size</code></td>
<td>
<p><code>int</code> Number of neurons in each layer. This parameter determines the
dimensionality of the resulting text embedding.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_num_hidden_layer">num_hidden_layer</code></td>
<td>
<p><code>int</code> Number of hidden layers.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_num_attention_heads">num_attention_heads</code></td>
<td>
<p><code>int</code> Number of attention heads.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_intermediate_size">intermediate_size</code></td>
<td>
<p><code>int</code> Number of neurons in the intermediate layer of
the attention mechanism.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_hidden_act">hidden_act</code></td>
<td>
<p><code>string</code> name of the activation function.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_hidden_dropout_prob">hidden_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_attention_probs_dropout_prob">attention_probs_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout for attention
probabilities.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be
printed to the console.</p>
</td></tr>
<tr><td><code id="create_bert_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the configuration
and the vocabulary of the new model are saved on disk.
</p>


<h3>Note</h3>

<p>To train the model, pass the directory of the model to the function
<a href="#topic+train_tune_bert_model">train_tune_bert_model</a>.
</p>
<p>This models uses a WordPiece Tokenizer like BERT and can be trained with
whole word masking. Transformer library may show a warning which can be ignored.
</p>


<h3>References</h3>

<p>Devlin, J., Chang, M.‑W., Lee, K., &amp; Toutanova, K. (2019). BERT:
Pre-training of Deep Bidirectional Transformers for Language
Understanding. In J. Burstein, C. Doran, &amp; T. Solorio (Eds.),
Proceedings of the 2019 Conference of the North (pp. 4171&ndash;4186).
Association for Computational Linguistics.
<a href="https://doi.org/10.18653/v1/N19-1423">doi:10.18653/v1/N19-1423</a>
</p>
<p>Hugging Face documentation
<a href="https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForMaskedLM">https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForMaskedLM</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='create_deberta_v2_model'>Function for creating a new transformer based on DeBERTa-V2</h2><span id='topic+create_deberta_v2_model'></span>

<h3>Description</h3>

<p>This function creates a transformer configuration based on the DeBERTa-V2 base architecture
and a vocabulary based on SentencePiece tokenizer by using
the python libraries 'transformers' and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_deberta_v2_model(
  ml_framework = aifeducation_config$get_framework(),
  model_dir,
  vocab_raw_texts = NULL,
  vocab_size = 128100,
  do_lower_case = FALSE,
  max_position_embeddings = 512,
  hidden_size = 1536,
  num_hidden_layer = 24,
  num_attention_heads = 24,
  intermediate_size = 6144,
  hidden_act = "gelu",
  hidden_dropout_prob = 0.1,
  attention_probs_dropout_prob = 0.1,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_deberta_v2_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_model_dir">model_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the model should be saved.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_vocab_raw_texts">vocab_raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for creating the
vocabulary.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_vocab_size">vocab_size</code></td>
<td>
<p><code>int</code> Size of the vocabulary.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_do_lower_case">do_lower_case</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> all characters are transformed to lower case.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_max_position_embeddings">max_position_embeddings</code></td>
<td>
<p><code>int</code> Number of maximal position embeddings. This parameter
also determines the maximum length of a sequence which can be processed with the model.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_hidden_size">hidden_size</code></td>
<td>
<p><code>int</code> Number of neurons in each layer. This parameter determines the
dimensionality of the resulting text embedding.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_num_hidden_layer">num_hidden_layer</code></td>
<td>
<p><code>int</code> Number of hidden layers.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_num_attention_heads">num_attention_heads</code></td>
<td>
<p><code>int</code> Number of attention heads.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_intermediate_size">intermediate_size</code></td>
<td>
<p><code>int</code> Number of neurons in the intermediate layer of
the attention mechanism.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_hidden_act">hidden_act</code></td>
<td>
<p><code>string</code> name of the activation function.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_hidden_dropout_prob">hidden_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_attention_probs_dropout_prob">attention_probs_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout for attention
probabilities.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be
printed to the console.</p>
</td></tr>
<tr><td><code id="create_deberta_v2_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the configuration
and the vocabulary of the new model are saved on disk.
</p>


<h3>Note</h3>

<p>To train the model, pass the directory of the model to the function
<a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>.
</p>
<p>For this model a WordPiece tokenizer is created. The standard implementation
of DeBERTa version 2 from HuggingFace uses a SentencePiece tokenizer. Thus, please
use <code>AutoTokenizer</code> from the 'transformers' library to use this model.
</p>


<h3>References</h3>

<p>He, P., Liu, X., Gao, J. &amp; Chen, W. (2020). DeBERTa: Decoding-enhanced BERT
with Disentangled Attention. <a href="https://doi.org/10.48550/arXiv.2006.03654">doi:10.48550/arXiv.2006.03654</a>
</p>
<p>Hugging Face Documentation
<a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2#debertav2">https://huggingface.co/docs/transformers/model_doc/deberta-v2#debertav2</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='create_funnel_model'>Function for creating a new transformer based on Funnel Transformer</h2><span id='topic+create_funnel_model'></span>

<h3>Description</h3>

<p>This function creates a transformer configuration based on the Funnel Transformer
base architecture
and a vocabulary based on WordPiece by using
the python libraries 'transformers' and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_funnel_model(
  ml_framework = aifeducation_config$get_framework(),
  model_dir,
  vocab_raw_texts = NULL,
  vocab_size = 30522,
  vocab_do_lower_case = FALSE,
  max_position_embeddings = 512,
  hidden_size = 768,
  target_hidden_size = 64,
  block_sizes = c(4, 4, 4),
  num_attention_heads = 12,
  intermediate_size = 3072,
  num_decoder_layers = 2,
  pooling_type = "mean",
  hidden_act = "gelu",
  hidden_dropout_prob = 0.1,
  attention_probs_dropout_prob = 0.1,
  activation_dropout = 0,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_funnel_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_model_dir">model_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the model should be saved.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_vocab_raw_texts">vocab_raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for creating the
vocabulary.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_vocab_size">vocab_size</code></td>
<td>
<p><code>int</code> Size of the vocabulary.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_vocab_do_lower_case">vocab_do_lower_case</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if all words/tokens should be lower case.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_max_position_embeddings">max_position_embeddings</code></td>
<td>
<p><code>int</code> Number of maximal position embeddings. This parameter
also determines the maximum length of a sequence which can be processed with the model.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_hidden_size">hidden_size</code></td>
<td>
<p><code>int</code> Initial number of neurons in each layer.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_target_hidden_size">target_hidden_size</code></td>
<td>
<p><code>int</code> Number of neurons in the final layer.
This parameter determines the dimensionality of the resulting text embedding.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_block_sizes">block_sizes</code></td>
<td>
<p><code>vector</code> of <code>int</code> determining the number and sizes
of each block.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_num_attention_heads">num_attention_heads</code></td>
<td>
<p><code>int</code> Number of attention heads.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_intermediate_size">intermediate_size</code></td>
<td>
<p><code>int</code> Number of neurons in the intermediate layer of
the attention mechanism.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_num_decoder_layers">num_decoder_layers</code></td>
<td>
<p><code>int</code> Number of decoding layers.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_pooling_type">pooling_type</code></td>
<td>
<p><code>string</code> <code>"mean"</code> for pooling with mean and <code>"max"</code>
for pooling with maximum values.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_hidden_act">hidden_act</code></td>
<td>
<p><code>string</code> name of the activation function.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_hidden_dropout_prob">hidden_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_attention_probs_dropout_prob">attention_probs_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout for attention
probabilities.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_activation_dropout">activation_dropout</code></td>
<td>
<p><code>float</code> Dropout probability between the layers of
the feed-forward blocks.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be
printed to the console.</p>
</td></tr>
<tr><td><code id="create_funnel_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the configuration
and the vocabulary of the new model are saved on disk.
</p>


<h3>Note</h3>

<p>The model uses a configuration with <code>truncate_seq=TRUE</code> to avoid
implementation problems with tensorflow.
</p>
<p>To train the model, pass the directory of the model to the function
<a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>.
</p>
<p>Model is created with <code>separete_cls=TRUE</code>,<code>truncate_seq=TRUE</code>, and
<code>pool_q_only=TRUE</code>.
</p>
<p>This models uses a WordPiece Tokenizer like BERT and can be trained with
whole word masking. Transformer library may show a warning which can be ignored.
</p>


<h3>References</h3>

<p>Dai, Z., Lai, G., Yang, Y. &amp; Le, Q. V. (2020). Funnel-Transformer: Filtering
out Sequential Redundancy for Efficient Language Processing.
<a href="https://doi.org/10.48550/arXiv.2006.03236">doi:10.48550/arXiv.2006.03236</a>
</p>
<p>Hugging Face documentation
<a href="https://huggingface.co/docs/transformers/model_doc/funnel#funnel-transformer">https://huggingface.co/docs/transformers/model_doc/funnel#funnel-transformer</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='create_iota2_mean_object'>Create an iota2 object</h2><span id='topic+create_iota2_mean_object'></span>

<h3>Description</h3>

<p>Function creates an object of class <code>iotarelr_iota2</code> which can be used
with the package iotarelr. This function is for internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_iota2_mean_object(
  iota2_list,
  free_aem = FALSE,
  call = "aifeducation::te_classifier_neuralnet",
  original_cat_labels
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_iota2_mean_object_+3A_iota2_list">iota2_list</code></td>
<td>
<p><code>list</code> of objects of class <code>iotarelr_iota2</code>.</p>
</td></tr>
<tr><td><code id="create_iota2_mean_object_+3A_free_aem">free_aem</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if the iota2 objects are estimated
without forcing the assumption of weak superiority.</p>
</td></tr>
<tr><td><code id="create_iota2_mean_object_+3A_call">call</code></td>
<td>
<p><code>string</code> characterizing the source of estimation. That is, the
function within the object was estimated.</p>
</td></tr>
<tr><td><code id="create_iota2_mean_object_+3A_original_cat_labels">original_cat_labels</code></td>
<td>
<p><code>vector</code> containing the original labels of each
category.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>iotarelr_iota2</code> which is the mean
iota2 object.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='create_longformer_model'>Function for creating a new transformer based on Longformer</h2><span id='topic+create_longformer_model'></span>

<h3>Description</h3>

<p>This function creates a transformer configuration based on the Longformer base architecture
and a vocabulary based on Byte-Pair Encoding (BPE) tokenizer by using
the python libraries 'transformers' and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_longformer_model(
  ml_framework = aifeducation_config$get_framework,
  model_dir,
  vocab_raw_texts = NULL,
  vocab_size = 30522,
  add_prefix_space = FALSE,
  trim_offsets = TRUE,
  max_position_embeddings = 512,
  hidden_size = 768,
  num_hidden_layer = 12,
  num_attention_heads = 12,
  intermediate_size = 3072,
  hidden_act = "gelu",
  hidden_dropout_prob = 0.1,
  attention_probs_dropout_prob = 0.1,
  attention_window = 512,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_longformer_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_model_dir">model_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the model should be saved.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_vocab_raw_texts">vocab_raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for creating the
vocabulary.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_vocab_size">vocab_size</code></td>
<td>
<p><code>int</code> Size of the vocabulary.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_add_prefix_space">add_prefix_space</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if an additional space should be insert
to the leading words.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_trim_offsets">trim_offsets</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> trims the whitespaces from the produced offsets.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_max_position_embeddings">max_position_embeddings</code></td>
<td>
<p><code>int</code> Number of maximal position embeddings. This parameter
also determines the maximum length of a sequence which can be processed with the model.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_hidden_size">hidden_size</code></td>
<td>
<p><code>int</code> Number of neurons in each layer. This parameter determines the
dimensionality of the resulting text embedding.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_num_hidden_layer">num_hidden_layer</code></td>
<td>
<p><code>int</code> Number of hidden layers.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_num_attention_heads">num_attention_heads</code></td>
<td>
<p><code>int</code> Number of attention heads.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_intermediate_size">intermediate_size</code></td>
<td>
<p><code>int</code> Number of neurons in the intermediate layer of
the attention mechanism.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_hidden_act">hidden_act</code></td>
<td>
<p><code>string</code> name of the activation function.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_hidden_dropout_prob">hidden_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_attention_probs_dropout_prob">attention_probs_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout for attention
probabilities.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_attention_window">attention_window</code></td>
<td>
<p><code>int</code> Size of the window around each token for
attention mechanism in every layer.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be
printed to the console.</p>
</td></tr>
<tr><td><code id="create_longformer_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the configuration
and the vocabulary of the new model are saved on disk.
</p>


<h3>Note</h3>

<p>To train the model, pass the directory of the model to the function
<a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>.
</p>


<h3>References</h3>

<p>Beltagy, I., Peters, M. E., &amp; Cohan, A. (2020). Longformer: The
Long-Document Transformer. <a href="https://doi.org/10.48550/arXiv.2004.05150">doi:10.48550/arXiv.2004.05150</a>
</p>
<p>Hugging Face Documentation
<a href="https://huggingface.co/docs/transformers/model_doc/longformer#transformers.LongformerConfig">https://huggingface.co/docs/transformers/model_doc/longformer#transformers.LongformerConfig</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='create_roberta_model'>Function for creating a new transformer based on RoBERTa</h2><span id='topic+create_roberta_model'></span>

<h3>Description</h3>

<p>This function creates a transformer configuration based on the RoBERTa base architecture
and a vocabulary based on Byte-Pair Encoding (BPE) tokenizer by using
the python libraries 'transformers' and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_roberta_model(
  ml_framework = aifeducation_config$get_framework(),
  model_dir,
  vocab_raw_texts = NULL,
  vocab_size = 30522,
  add_prefix_space = FALSE,
  trim_offsets = TRUE,
  max_position_embeddings = 512,
  hidden_size = 768,
  num_hidden_layer = 12,
  num_attention_heads = 12,
  intermediate_size = 3072,
  hidden_act = "gelu",
  hidden_dropout_prob = 0.1,
  attention_probs_dropout_prob = 0.1,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_roberta_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_model_dir">model_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the model should be saved.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_vocab_raw_texts">vocab_raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for creating the
vocabulary.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_vocab_size">vocab_size</code></td>
<td>
<p><code>int</code> Size of the vocabulary.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_add_prefix_space">add_prefix_space</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if an additional space should be insert
to the leading words.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_trim_offsets">trim_offsets</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> post processing trims offsets
to avoid including whitespaces.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_max_position_embeddings">max_position_embeddings</code></td>
<td>
<p><code>int</code> Number of maximal position embeddings. This parameter
also determines the maximum length of a sequence which can be processed with the model.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_hidden_size">hidden_size</code></td>
<td>
<p><code>int</code> Number of neurons in each layer. This parameter determines the
dimensionality of the resulting text embedding.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_num_hidden_layer">num_hidden_layer</code></td>
<td>
<p><code>int</code> Number of hidden layers.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_num_attention_heads">num_attention_heads</code></td>
<td>
<p><code>int</code> Number of attention heads.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_intermediate_size">intermediate_size</code></td>
<td>
<p><code>int</code> Number of neurons in the intermediate layer of
the attention mechanism.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_hidden_act">hidden_act</code></td>
<td>
<p><code>string</code> name of the activation function.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_hidden_dropout_prob">hidden_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_attention_probs_dropout_prob">attention_probs_dropout_prob</code></td>
<td>
<p><code>double</code> Ratio of dropout for attention
probabilities.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information about the progress should be
printed to the console.</p>
</td></tr>
<tr><td><code id="create_roberta_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the configuration
and the vocabulary of the new model are saved on disk.
</p>


<h3>Note</h3>

<p>To train the model, pass the directory of the model to the function
<a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>.
</p>


<h3>References</h3>

<p>Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O.,
Lewis, M., Zettlemoyer, L., &amp; Stoyanov, V. (2019). RoBERTa: A Robustly
Optimized BERT Pretraining Approach.
<a href="https://doi.org/10.48550/arXiv.1907.11692">doi:10.48550/arXiv.1907.11692</a>
</p>
<p>Hugging Face Documentation
<a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaConfig">https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaConfig</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='create_synthetic_units'>Create synthetic units</h2><span id='topic+create_synthetic_units'></span>

<h3>Description</h3>

<p>Function for creating synthetic cases in order to balance the data for
training with <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>. This is an auxiliary
function for use with <a href="#topic+get_synthetic_cases">get_synthetic_cases</a> to allow parallel
computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_synthetic_units(embedding, target, k, max_k, method, cat, cat_freq)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_synthetic_units_+3A_embedding">embedding</code></td>
<td>
<p>Named <code>data.frame</code> containing the text embeddings.
In most cases this object is taken from <a href="#topic+EmbeddedText">EmbeddedText</a>$embeddings.</p>
</td></tr>
<tr><td><code id="create_synthetic_units_+3A_target">target</code></td>
<td>
<p>Named <code>factor</code> containing the labels/categories of the corresponding cases.</p>
</td></tr>
<tr><td><code id="create_synthetic_units_+3A_k">k</code></td>
<td>
<p><code>int</code> The number of nearest neighbors during sampling process.</p>
</td></tr>
<tr><td><code id="create_synthetic_units_+3A_max_k">max_k</code></td>
<td>
<p><code>int</code> The maximum number of nearest neighbors during sampling process.</p>
</td></tr>
<tr><td><code id="create_synthetic_units_+3A_method">method</code></td>
<td>
<p><code>vector</code> containing strings of the requested methods for generating new cases.
Currently &quot;smote&quot;,&quot;dbsmote&quot;, and &quot;adas&quot; from the package smotefamily are available.</p>
</td></tr>
<tr><td><code id="create_synthetic_units_+3A_cat">cat</code></td>
<td>
<p><code>string</code> The category for which new cases should be created.</p>
</td></tr>
<tr><td><code id="create_synthetic_units_+3A_cat_freq">cat_freq</code></td>
<td>
<p>Object of class <code>"table"</code> containing the absolute frequencies
of every category/label.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>list</code> which contains the text embeddings of the
new synthetic cases as a named <code>data.frame</code> and their labels as a named
<code>factor</code>.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='EmbeddedText'>Embedded text</h2><span id='topic+EmbeddedText'></span>

<h3>Description</h3>

<p>Object of class <a href="R6.html#topic+R6">R6</a> which stores the text embeddings
generated by an object of class <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a> via the method
<code>embed()</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>EmbeddedText</code>. These objects are used
for storing and managing the text embeddings created with objects of class <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>.
Objects of class <code>EmbeddedText</code> serve as input for classifiers of class
<a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>. The main aim of this class is to provide a structured link between
embedding models and classifiers. Since objects of this class save information on
the text embedding model that created the text embedding it ensures that only
embedding generated with same embedding model are combined. Furthermore, the stored information allows
classifiers to check if embeddings of the correct text embedding model are used for
training and predicting.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>embeddings</code></dt><dd><p>('data.frame()')<br />
data.frame containing the text embeddings for all chunks. Documents are
in the rows. Embedding dimensions are in the columns.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-EmbeddedText-new"><code>EmbeddedText$new()</code></a>
</p>
</li>
<li> <p><a href="#method-EmbeddedText-get_model_info"><code>EmbeddedText$get_model_info()</code></a>
</p>
</li>
<li> <p><a href="#method-EmbeddedText-get_model_label"><code>EmbeddedText$get_model_label()</code></a>
</p>
</li>
<li> <p><a href="#method-EmbeddedText-clone"><code>EmbeddedText$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-EmbeddedText-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new object representing text embeddings.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmbeddedText$new(
  model_name = NA,
  model_label = NA,
  model_date = NA,
  model_method = NA,
  model_version = NA,
  model_language = NA,
  param_seq_length = NA,
  param_chunks = NULL,
  param_overlap = NULL,
  param_emb_layer_min = NULL,
  param_emb_layer_max = NULL,
  param_emb_pool_type = NULL,
  param_aggregation = NULL,
  embeddings
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_name</code></dt><dd><p><code>string</code> Name of the model that generates this embedding.</p>
</dd>
<dt><code>model_label</code></dt><dd><p><code>string</code> Label of the model that generates this embedding.</p>
</dd>
<dt><code>model_date</code></dt><dd><p><code>string</code> Date when the embedding generating model was created.</p>
</dd>
<dt><code>model_method</code></dt><dd><p><code>string</code> Method of the underlying embedding model.</p>
</dd>
<dt><code>model_version</code></dt><dd><p><code>string</code> Version of the model that generated this embedding.</p>
</dd>
<dt><code>model_language</code></dt><dd><p><code>string</code> Language of the model that generated this embedding.</p>
</dd>
<dt><code>param_seq_length</code></dt><dd><p><code>int</code> Maximum number of tokens that processes the generating model for a chunk.</p>
</dd>
<dt><code>param_chunks</code></dt><dd><p><code>int</code> Maximum number of chunks which are supported by the generating model.</p>
</dd>
<dt><code>param_overlap</code></dt><dd><p><code>int</code> Number of tokens that were added at the beginning of the sequence for the next chunk
by this model.</p>
</dd>
<dt><code>param_emb_layer_min</code></dt><dd><p><code>int</code> or <code>string</code> determining the first layer to be included
in the creation of embeddings.</p>
</dd>
<dt><code>param_emb_layer_max</code></dt><dd><p><code>int</code> or <code>string</code> determining the last layer to be included
in the creation of embeddings.</p>
</dd>
<dt><code>param_emb_pool_type</code></dt><dd><p><code>string</code> determining the method for pooling the token embeddings
within each layer.</p>
</dd>
<dt><code>param_aggregation</code></dt><dd><p><code>string</code> Aggregation method of the hidden states. Deprecated. Only included
for backward compatibility.</p>
</dd>
<dt><code>embeddings</code></dt><dd><p><code>data.frame</code> containing the text embeddings.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Returns an object of class <a href="#topic+EmbeddedText">EmbeddedText</a> which stores the
text embeddings produced by an objects of class <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>.
The object serves as input for objects of class <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>.
</p>


<hr>
<a id="method-EmbeddedText-get_model_info"></a>



<h4>Method <code>get_model_info()</code></h4>

<p>Method for retrieving information about the model that
generated this embedding.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmbeddedText$get_model_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> contains all saved information about the underlying
text embedding model.
</p>


<hr>
<a id="method-EmbeddedText-get_model_label"></a>



<h4>Method <code>get_model_label()</code></h4>

<p>Method for retrieving the label of the model that
generated this embedding.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmbeddedText$get_model_label()</pre></div>



<h5>Returns</h5>

<p><code>string</code> Label of the corresponding text embedding model
</p>


<hr>
<a id="method-EmbeddedText-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmbeddedText$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Text Embedding: 
<code><a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a></code>,
<code><a href="#topic+combine_embeddings">combine_embeddings</a>()</code>
</p>

<hr>
<h2 id='generate_id'>Generate ID suffix for objects</h2><span id='topic+generate_id'></span>

<h3>Description</h3>

<p>Function for generating an ID suffix for objects of class
<a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a> and <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_id(length = 16)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_id_+3A_length">length</code></td>
<td>
<p><code>int</code> determining the length of the id suffix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>string</code> of the requested length
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='get_coder_metrics'>Calculate reliability measures based on content analysis</h2><span id='topic+get_coder_metrics'></span>

<h3>Description</h3>

<p>This function calculates different reliability measures which are based on the
empirical research method of content analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_coder_metrics(
  true_values = NULL,
  predicted_values = NULL,
  return_names_only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_coder_metrics_+3A_true_values">true_values</code></td>
<td>
<p><code>factor</code> containing the true labels/categories.</p>
</td></tr>
<tr><td><code id="get_coder_metrics_+3A_predicted_values">predicted_values</code></td>
<td>
<p><code>factor</code> containing the predicted labels/categories.</p>
</td></tr>
<tr><td><code id="get_coder_metrics_+3A_return_names_only">return_names_only</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> returns only the names
of the resulting vector. Use <code>FALSE</code> to request computation of the values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>return_names_only=FALSE</code> returns a <code>vector</code> with the following reliability measures:
#'</p>

<ul>
<li><p><strong>iota_index: </strong>Iota Index from the Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>min_iota2: </strong>Minimal Iota from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>avg_iota2: </strong>Average Iota from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>max_iota2: </strong>Maximum Iota from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>min_alpha: </strong>Minmal Alpha Reliability from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>avg_alpha: </strong>Average Alpha Reliability from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>max_alpha: </strong>Maximum Alpha Reliability from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>static_iota_index: </strong>Static Iota Index from Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>dynamic_iota_index: </strong>Dynamic Iota Index Iota Reliability Concept Version 2.
</p>
</li>
<li><p><strong>kalpha_nominal: </strong>Krippendorff's Alpha for nominal variables.
</p>
</li>
<li><p><strong>kalpha_ordinal: </strong>Krippendorff's Alpha for ordinal variables.
</p>
</li>
<li><p><strong>kendall: </strong>Kendall's coefficient of concordance W.
</p>
</li>
<li><p><strong>kappa2_unweighted: </strong>Cohen's Kappa unweighted.
</p>
</li>
<li><p><strong>kappa2_equal_weighted: </strong>Weighted Cohen's Kappa with equal weights.
</p>
</li>
<li><p><strong>kappa2_squared_weighted: </strong>Weighted Cohen's Kappa with squared weights.
</p>
</li>
<li><p><strong>kappa_fleiss: </strong>Fleiss' Kappa for multiple raters without exact estimation.
</p>
</li>
<li><p><strong>percentage_agreement: </strong>Percentage Agreement.
</p>
</li>
<li><p><strong>balanced_accuracy: </strong>Average accuracy within each class.
</p>
</li>
<li><p><strong>gwet_ac: </strong>Gwet's AC1/AC2 agreement coefficient.
</p>
</li></ul>

<p>If <code>return_names_only=TRUE</code> returns only the names of the vector elements.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='get_folds'>Create cross-validation samples</h2><span id='topic+get_folds'></span>

<h3>Description</h3>

<p>Function creates cross-validation samples and ensures that the relative
frequency for every category/label within a fold equals the relative frequency of
the category/label within the initial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_folds(target, k_folds)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_folds_+3A_target">target</code></td>
<td>
<p>Named <code>factor</code> containing the relevant labels/categories. Missing cases
should be declared with <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get_folds_+3A_k_folds">k_folds</code></td>
<td>
<p><code>int</code> number of folds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a <code>list</code> with the following components:
</p>

<ul>
<li><p><code>val_sample: </code><code>vector</code> of <code>strings</code> containing the names of cases of the validation sample.
</p>
</li>
<li><p><code>train_sample: </code><code>vector</code> of <code>strings</code> containing the names of cases of the train sample.
</p>
</li>
<li><p><code>n_folds: </code><code>int</code> Number of realized folds.
</p>
</li>
<li><p><code>unlabeled_cases: </code><code>vector</code> of <code>strings</code> containing the names of the unlabeled cases.
</p>
</li></ul>



<h3>Note</h3>

<p>The parameter <code>target</code> allows cases with missing categories/labels.
These should be declared with <code>NA</code>. All these cases are ignored for creating the
different folds. Their names are saved within the component <code>unlabeled_cases</code>.
These cases can be used for Pseudo Labeling.
</p>
<p>the function checks the absolute frequencies of every category/label. If the
absolute frequency is not sufficient to ensure at least four cases in every fold,
the number of folds is adjusted. In these cases, a warning is printed to the console.
At least four cases per fold are necessary to ensure that the training of
<a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a> works well with all options turned on.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='get_n_chunks'>Get the number of chunks/sequences for each case</h2><span id='topic+get_n_chunks'></span>

<h3>Description</h3>

<p>Function for calculating the number of chunks/sequences for every case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_n_chunks(text_embeddings, features, times)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_n_chunks_+3A_text_embeddings">text_embeddings</code></td>
<td>
<p><code>data.frame</code> containing the text embeddings.</p>
</td></tr>
<tr><td><code id="get_n_chunks_+3A_features">features</code></td>
<td>
<p><code>int</code> Number of features within each sequence.</p>
</td></tr>
<tr><td><code id="get_n_chunks_+3A_times">times</code></td>
<td>
<p><code>int</code> Number of sequences</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named<code>vector</code> of integers representing the number of chunks/sequences
for every case.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='get_stratified_train_test_split'>Create a stratified random sample</h2><span id='topic+get_stratified_train_test_split'></span>

<h3>Description</h3>

<p>This function creates a stratified random sample.The difference to
<a href="#topic+get_train_test_split">get_train_test_split</a> is that this function does not require text
embeddings and does not split the text embeddings into a train and validation
sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_stratified_train_test_split(targets, val_size = 0.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_stratified_train_test_split_+3A_targets">targets</code></td>
<td>
<p>Named <code>vector</code> containing the labels/categories for each case.</p>
</td></tr>
<tr><td><code id="get_stratified_train_test_split_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Value between 0 and 1 indicating how many cases of
each label/category should be part of the validation sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> which contains the names of the cases belonging to the train
sample and to the validation sample.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='get_synthetic_cases'>Create synthetic cases for balancing training data</h2><span id='topic+get_synthetic_cases'></span>

<h3>Description</h3>

<p>This function creates synthetic cases for balancing the training with an
object of the class <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_synthetic_cases(
  embedding,
  times,
  features,
  target,
  method = c("smote"),
  max_k = 6
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_synthetic_cases_+3A_embedding">embedding</code></td>
<td>
<p>Named <code>data.frame</code> containing the text embeddings.
In most cases, this object is taken from <a href="#topic+EmbeddedText">EmbeddedText</a>$embeddings.</p>
</td></tr>
<tr><td><code id="get_synthetic_cases_+3A_times">times</code></td>
<td>
<p><code>int</code> for the number of sequences/times.</p>
</td></tr>
<tr><td><code id="get_synthetic_cases_+3A_features">features</code></td>
<td>
<p><code>int</code> for the number of features within each sequence.</p>
</td></tr>
<tr><td><code id="get_synthetic_cases_+3A_target">target</code></td>
<td>
<p>Named <code>factor</code> containing the labels of the corresponding embeddings.</p>
</td></tr>
<tr><td><code id="get_synthetic_cases_+3A_method">method</code></td>
<td>
<p><code>vector</code> containing strings of the requested methods for generating new cases.
Currently &quot;smote&quot;,&quot;dbsmote&quot;, and &quot;adas&quot; from the package smotefamily are available.</p>
</td></tr>
<tr><td><code id="get_synthetic_cases_+3A_max_k">max_k</code></td>
<td>
<p><code>int</code> The maximum number of nearest neighbors during sampling process.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> with the following components.
</p>

<ul>
<li><p><code>syntetic_embeddings: </code>Named <code>data.frame</code> containing the text embeddings of
the synthetic cases.
</p>
</li>
<li><p><code>syntetic_targets </code>Named <code>factor</code> containing the labels of the corresponding
synthetic cases.
</p>
</li>
<li><p><code>n_syntetic_units </code><code>table</code> showing the number of synthetic cases for every
label/category.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='get_train_test_split'>Function for splitting data into a train and validation sample</h2><span id='topic+get_train_test_split'></span>

<h3>Description</h3>

<p>This function creates a train and validation sample based on stratified random
sampling. The relative frequencies of each category in the train and validation sample
equal the relative frequencies of the initial data (proportional stratified sampling).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_train_test_split(embedding, target, val_size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_train_test_split_+3A_embedding">embedding</code></td>
<td>
<p>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a>.</p>
</td></tr>
<tr><td><code id="get_train_test_split_+3A_target">target</code></td>
<td>
<p>Named <code>factor</code> containing the labels of every case.</p>
</td></tr>
<tr><td><code id="get_train_test_split_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Ratio between 0 and 1 indicating the relative
frequency of cases which should be used as validation sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>list</code> with the following components.
</p>

<ul>
<li><p><code>target_train: </code>Named <code>factor</code> containing the labels of the training sample.
</p>
</li>
<li><p><code>embeddings_train: </code>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a> containing the text embeddings for the training sample
</p>
</li>
<li><p><code>target_test: </code>Named <code>factor</code> containing the labels of the validation sample.
</p>
</li>
<li><p><code>embeddings_test: </code>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a> containing the text embeddings for the validation sample
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='install_py_modules'>Installing necessary python modules to an environment</h2><span id='topic+install_py_modules'></span>

<h3>Description</h3>

<p>Function for installing the necessary python modules
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_py_modules(
  envname = "aifeducation",
  install = "pytorch",
  tf_version = "&lt;=2.15",
  pytorch_cuda_version = "12.1",
  python_version = "3.9",
  remove_first = FALSE,
  cpu_only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_py_modules_+3A_envname">envname</code></td>
<td>
<p><code>string</code> Name of the environment where the packages should
be installed.</p>
</td></tr>
<tr><td><code id="install_py_modules_+3A_install">install</code></td>
<td>
<p><code>character</code> determining which machine learning frameworks
should be installed. <code>install="all"</code>  for 'pytorch' and 'tensorflow'.
<code>install="pytorch"</code>  for 'pytorch', and <code>install="tensorflow"</code>  for 'tensorflow'.</p>
</td></tr>
<tr><td><code id="install_py_modules_+3A_tf_version">tf_version</code></td>
<td>
<p><code>string</code> determining the desired version of 'tensorflow'.</p>
</td></tr>
<tr><td><code id="install_py_modules_+3A_pytorch_cuda_version">pytorch_cuda_version</code></td>
<td>
<p><code>string</code> determining the desired version of 'cuda' for
'PyTorch'.</p>
</td></tr>
<tr><td><code id="install_py_modules_+3A_python_version">python_version</code></td>
<td>
<p><code>string</code> Python version to use.</p>
</td></tr>
<tr><td><code id="install_py_modules_+3A_remove_first">remove_first</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> removes the environment completely before
recreating the environment and installing the packages. If <code>FALSE</code> the packages
are installed in the existing environment without any prior changes.</p>
</td></tr>
<tr><td><code id="install_py_modules_+3A_cpu_only">cpu_only</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> installs the cpu only version of the
machine learning frameworks.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns no values or objects. Function is used for installing the
necessary python libraries in a conda environment.
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='is.null_or_na'>Check if NULL or NA</h2><span id='topic+is.null_or_na'></span>

<h3>Description</h3>

<p>Function for checking if an object is <code>NULL</code> or <code>NA</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.null_or_na(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.null_or_na_+3A_object">object</code></td>
<td>
<p>An object to test.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>FALSE</code> if the object is not <code>NULL</code> and not <code>NA</code>.
Returns <code>TRUE</code> in all other cases.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='load_ai_model'>Loading models created with 'aifeducation'</h2><span id='topic+load_ai_model'></span>

<h3>Description</h3>

<p>Function for loading models created with 'aifeducation'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_ai_model(model_dir, ml_framework = aifeducation_config$get_framework())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_ai_model_+3A_model_dir">model_dir</code></td>
<td>
<p>Path to the directory where the model is stored.</p>
</td></tr>
<tr><td><code id="load_ai_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Determines the machine learning framework
for using the model. Possible are <code>ml_framework="pytorch"</code> for 'pytorch',
<code>ml_framework="tensorflow"</code> for 'tensorflow', and <code>ml_framework="auto"</code>.
for using the framework used when saving the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a> or
<a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>.
</p>


<h3>See Also</h3>

<p>Other Saving and Loading: 
<code><a href="#topic+save_ai_model">save_ai_model</a>()</code>
</p>

<hr>
<h2 id='matrix_to_array_c'>Reshape matrix to array</h2><span id='topic+matrix_to_array_c'></span>

<h3>Description</h3>

<p>Function written in C++ for reshaping a matrix containing sequential data into
an array for use with keras.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix_to_array_c(matrix, times, features)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matrix_to_array_c_+3A_matrix">matrix</code></td>
<td>
<p><code>matrix</code> containing the sequential data.</p>
</td></tr>
<tr><td><code id="matrix_to_array_c_+3A_times">times</code></td>
<td>
<p><code>uword</code> Number of sequences.</p>
</td></tr>
<tr><td><code id="matrix_to_array_c_+3A_features">features</code></td>
<td>
<p><code>uword</code> Number of features within each sequence.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an array. The first dimension corresponds to the cases,
the second to the times, and the third to the features.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='save_ai_model'>Saving models created with 'aifeducation'</h2><span id='topic+save_ai_model'></span>

<h3>Description</h3>

<p>Function for saving models created with 'aifeducation'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_ai_model(
  model,
  model_dir,
  dir_name = NULL,
  save_format = "default",
  append_ID = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_ai_model_+3A_model">model</code></td>
<td>
<p>Object of class <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a> or
<a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a> which should be saved.</p>
</td></tr>
<tr><td><code id="save_ai_model_+3A_model_dir">model_dir</code></td>
<td>
<p>Path to the directory where the should model is stored.</p>
</td></tr>
<tr><td><code id="save_ai_model_+3A_dir_name">dir_name</code></td>
<td>
<p>Name of the folder that will be created at <code>model_dir</code>.
If<code>dir_name=NULL</code> the model's name will be used. If additionally <code>append_ID=TRUE</code>
the models's name and ID will be used for generating a name for that directory.</p>
</td></tr>
<tr><td><code id="save_ai_model_+3A_save_format">save_format</code></td>
<td>
<p>Only relevant for <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a>.
Format for saving the model. For 'tensorflow'/'keras' models
<code>"keras"</code> for 'Keras v3 format',
<code>"tf"</code> for SavedModel
or <code>"h5"</code> for HDF5.
For 'pytorch' models <code>"safetensors"</code> for 'safetensors' or
<code>"pt"</code> for 'pytorch via pickle'.
Use <code>"default"</code> for the standard format. This is keras for
'tensorflow'/'keras' models and safetensors for 'pytorch' models.</p>
</td></tr>
<tr><td><code id="save_ai_model_+3A_append_id">append_ID</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if the ID should be appended to
the model directory for saving purposes. <code>FALSE</code> if not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function does not return a value. It saves the model to disk.
</p>
<p>No return value, called for side effects.
</p>


<h3>See Also</h3>

<p>Other Saving and Loading: 
<code><a href="#topic+load_ai_model">load_ai_model</a>()</code>
</p>

<hr>
<h2 id='set_config_cpu_only'>Setting cpu only for 'tensorflow'</h2><span id='topic+set_config_cpu_only'></span>

<h3>Description</h3>

<p>This functions configurates 'tensorflow' to use only cpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_config_cpu_only()
</code></pre>


<h3>Value</h3>

<p>This function does not return anything. It is used for its
side effects.
</p>


<h3>Note</h3>

<p>os$environ$setdefault(&quot;CUDA_VISIBLE_DEVICES&quot;,&quot;-1&quot;)
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='set_config_gpu_low_memory'>Setting gpus' memory usage</h2><span id='topic+set_config_gpu_low_memory'></span>

<h3>Description</h3>

<p>This function changes the memory usage of the gpus to allow computations
on machines with small memory. With this function, some computations of large
models may be possible but the speed of computation decreases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_config_gpu_low_memory()
</code></pre>


<h3>Value</h3>

<p>This function does not return anything. It is used for its
side effects.
</p>


<h3>Note</h3>

<p>This function sets TF_GPU_ALLOCATOR to <code>"cuda_malloc_async"</code> and
sets memory growth to <code>TRUE</code>.
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='set_config_os_environ_logger'>Sets the level for logging information in tensor flow.</h2><span id='topic+set_config_os_environ_logger'></span>

<h3>Description</h3>

<p>This function changes the level for logging information with 'tensorflow' via
the os environment. This function must be called before importing 'tensorflow'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_config_os_environ_logger(level = "ERROR")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_config_os_environ_logger_+3A_level">level</code></td>
<td>
<p><code>string</code> Minimal level that should be printed to console. Four
levels are available: INFO, WARNING, ERROR and NONE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return anything. It is used for its
side effects.
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='set_config_tf_logger'>Sets the level for logging information in tensor flow.</h2><span id='topic+set_config_tf_logger'></span>

<h3>Description</h3>

<p>This function changes the level for logging information with 'tensorflow'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_config_tf_logger(level = "ERROR")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_config_tf_logger_+3A_level">level</code></td>
<td>
<p><code>string</code> Minimal level that should be printed to console. Five
levels are available: FATAL, ERROR, WARN, INFO, and DEBUG.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return anything. It is used for its
side effects.
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_transformers_logger">set_transformers_logger</a>()</code>
</p>

<hr>
<h2 id='set_transformers_logger'>Sets the level for logging information of the 'transformers' library.</h2><span id='topic+set_transformers_logger'></span>

<h3>Description</h3>

<p>This function changes the level for logging information of the 'transformers' library.
It influences the output printed to console for creating and training transformer models as well as
<a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_transformers_logger(level = "ERROR")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_transformers_logger_+3A_level">level</code></td>
<td>
<p><code>string</code> Minimal level that should be printed to console. Four
levels are available: INFO, WARNING, ERROR and DEBUG</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return anything. It is used for its
side effects.
</p>


<h3>See Also</h3>

<p>Other Installation and Configuration: 
<code><a href="#topic+AifeducationConfiguration">AifeducationConfiguration</a></code>,
<code><a href="#topic+aifeducation_config">aifeducation_config</a></code>,
<code><a href="#topic+check_aif_py_modules">check_aif_py_modules</a>()</code>,
<code><a href="#topic+install_py_modules">install_py_modules</a>()</code>,
<code><a href="#topic+set_config_cpu_only">set_config_cpu_only</a>()</code>,
<code><a href="#topic+set_config_gpu_low_memory">set_config_gpu_low_memory</a>()</code>,
<code><a href="#topic+set_config_os_environ_logger">set_config_os_environ_logger</a>()</code>,
<code><a href="#topic+set_config_tf_logger">set_config_tf_logger</a>()</code>
</p>

<hr>
<h2 id='split_labeled_unlabeled'>Split data into labeled and unlabeled data</h2><span id='topic+split_labeled_unlabeled'></span>

<h3>Description</h3>

<p>This functions splits data into labeled and unlabeled data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_labeled_unlabeled(embedding, target)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_labeled_unlabeled_+3A_embedding">embedding</code></td>
<td>
<p>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a>.</p>
</td></tr>
<tr><td><code id="split_labeled_unlabeled_+3A_target">target</code></td>
<td>
<p>Named <code>factor</code> containing all cases with labels and missing
labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>list</code> with the following components
</p>

<ul>
<li><p><code>embeddings_labeled: </code>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a> containing
only the cases which have labels.
</p>
</li>
<li><p><code>embeddings_unlabeled: </code>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a> containing
only the cases which have no labels.
</p>
</li>
<li><p><code>targets_labeled: </code>Named <code>factor</code> containing the labels of
relevant cases.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='start_aifeducation_studio'>Aifeducation Studio</h2><span id='topic+start_aifeducation_studio'></span>

<h3>Description</h3>

<p>Functions starts a shiny app that represents Aifeducation Studio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>start_aifeducation_studio()
</code></pre>


<h3>Value</h3>

<p>This function does nothing return. It is used to start a shiny app.
</p>

<hr>
<h2 id='summarize_tracked_sustainability'>Summarizing tracked sustainability data</h2><span id='topic+summarize_tracked_sustainability'></span>

<h3>Description</h3>

<p>Function for summarizing the tracked sustainability data with a tracker
of the python library 'codecarbon'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_tracked_sustainability(sustainability_tracker)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_tracked_sustainability_+3A_sustainability_tracker">sustainability_tracker</code></td>
<td>
<p>Object of class <code>codecarbon.emissions_tracker.OfflineEmissionsTracker</code>
of the python library codecarbon.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>list</code> which contains the tracked sustainability data.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+to_categorical_c">to_categorical_c</a>()</code>
</p>

<hr>
<h2 id='test_classifier_sustainability'>Sustainability data for an example classifier</h2><span id='topic+test_classifier_sustainability'></span>

<h3>Description</h3>

<p>A list of length 5 containing the used energy consumption and co2 emissions of a classifier
during training. The purpose of the data is for illustration in vignettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_classifier_sustainability
</code></pre>


<h3>Format</h3>

<p>list
</p>

<hr>
<h2 id='test_metric_mean'>Test metric for an example classifier</h2><span id='topic+test_metric_mean'></span>

<h3>Description</h3>

<p>A matrix of 4 rows and 17 columns containing test metrics for an example
classifier. The purpose of the data is for illustration in vignettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_metric_mean
</code></pre>


<h3>Format</h3>

<p>matrix
</p>

<hr>
<h2 id='TextEmbeddingClassifierNeuralNet'>Text embedding classifier with a neural net</h2><span id='topic+TextEmbeddingClassifierNeuralNet'></span>

<h3>Description</h3>

<p>Abstract class for neural nets with 'keras'/'tensorflow' and
'pytorch'.
</p>


<h3>Value</h3>

<p>Objects of this class are used for assigning texts to classes/categories. For
the creation and training of a classifier an object of class <a href="#topic+EmbeddedText">EmbeddedText</a> and a <code>factor</code>
are necessary. The object of class <a href="#topic+EmbeddedText">EmbeddedText</a> contains the numerical text
representations (text embeddings) of the raw texts generated by an object of class
<a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>. The <code>factor</code> contains the classes/categories for every
text. Missing values (unlabeled cases) are supported. For predictions an object of class
<a href="#topic+EmbeddedText">EmbeddedText</a> has to be used which was created with the same text embedding model as
for training.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>model</code></dt><dd><p>('tensorflow_model()')<br />
Field for storing the tensorflow model after loading.</p>
</dd>
<dt><code>model_config</code></dt><dd><p>('list()')<br />
List for storing information about the configuration of the model. This
information is used to predict new data.
</p>

<ul>
<li><p><code>model_config$n_rec: </code>Number of recurrent layers.
</p>
</li>
<li><p><code>model_config$n_hidden: </code>Number of dense layers.
</p>
</li>
<li><p><code>model_config$target_levels: </code>Levels of the target variable. Do not change this manually.
</p>
</li>
<li><p><code>model_config$input_variables: </code>Order and name of the input variables. Do not change this manually.
</p>
</li>
<li><p><code>model_config$init_config: </code>List storing all parameters passed to method new().
</p>
</li></ul>
</dd>
<dt><code>last_training</code></dt><dd><p>('list()')<br />
List for storing the history and the results of the last training. This
information will be overwritten if a new training is started.
</p>

<ul>
<li><p><code>last_training$learning_time: </code>Duration of the training process.
</p>
</li>
<li><p><code>config$history: </code>History of the last training.
</p>
</li>
<li><p><code>config$data: </code>Object of class table storing the initial frequencies of the passed data.
</p>
</li>
<li><p><code>config$data_pb:l </code>Matrix storing the number of additional cases (test and training) added
during balanced pseudo-labeling. The rows refer to folds and final training.
The columns refer to the steps during pseudo-labeling.
</p>
</li>
<li><p><code>config$data_bsc_test: </code>Matrix storing the number of cases for each category used for testing
during the phase of balanced synthetic units. Please note that the
frequencies include original and synthetic cases. In case the number
of original and synthetic cases exceeds the limit for the majority classes,
the frequency represents the number of cases created by cluster analysis.
</p>
</li>
<li><p><code>config$date: </code>Time when the last training finished.
</p>
</li>
<li><p><code>config$config: </code>List storing which kind of estimation was requested during the last training.
</p>

<ul>
<li><p><code>config$config$use_bsc:  </code><code>TRUE</code> if  balanced synthetic cases were requested. <code>FALSE</code>
if not.
</p>
</li>
<li><p><code>config$config$use_baseline: </code><code>TRUE</code> if baseline estimation were requested. <code>FALSE</code>
if not.
</p>
</li>
<li><p><code> config$config$use_bpl: </code><code>TRUE</code> if  balanced, pseudo-labeling cases were requested. <code>FALSE</code>
if not.
</p>
</li></ul>

</li></ul>
</dd>
<dt><code>reliability</code></dt><dd><p>('list()')<br />
List for storing central reliability measures of the last training.
</p>

<ul>
<li><p><code>reliability$test_metric: </code>Array containing the reliability measures for the validation data for
every fold, method, and step (in case of pseudo-labeling).
</p>
</li>
<li><p><code>reliability$test_metric_mean: </code>Array containing the reliability measures for the validation data for
every method and step (in case of pseudo-labeling). The values represent
the mean values for every fold.
</p>
</li>
<li><p><code>reliability$raw_iota_objects: </code>List containing all iota_object generated with the package <code>iotarelr</code>
for every fold at the start and the end of the last training.
</p>

<ul>
<li><p><code>reliability$raw_iota_objects$iota_objects_start: </code>List of objects with class <code>iotarelr_iota2</code> containing the
estimated iota reliability of the second generation for the baseline model
for every fold.
If the estimation of the baseline model is not requested, the list is
set to <code>NULL</code>.
</p>
</li>
<li><p><code>reliability$raw_iota_objects$iota_objects_end: </code>List of objects with class <code>iotarelr_iota2</code> containing the
estimated iota reliability of the second generation for the final model
for every fold. Depending of the requested training method these values
refer to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo labeling or a combination of balanced
synthetic cases with pseudo labeling.
</p>
</li>
<li><p><code>reliability$raw_iota_objects$iota_objects_start_free: </code>List of objects with class <code>iotarelr_iota2</code> containing the
estimated iota reliability of the second generation for the baseline model
for every fold.
If the estimation of the baseline model is not requested, the list is
set to <code>NULL</code>.Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.
</p>
</li>
<li><p><code>reliability$raw_iota_objects$iota_objects_end_free: </code>List of objects with class <code>iotarelr_iota2</code> containing the
estimated iota reliability of the second generation for the final model
for every fold. Depending of the requested training method, these values
refer to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo-labeling or a combination of balanced
synthetic cases and pseudo-labeling.
Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.
</p>
</li></ul>


</li>
<li><p><code>reliability$iota_object_start: </code>Object of class <code>iotarelr_iota2</code> as a mean of the individual objects
for every fold. If the estimation of the baseline model is not requested, the list is
set to <code>NULL</code>.
</p>
</li>
<li><p><code> reliability$iota_object_start_free: </code>Object of class <code>iotarelr_iota2</code> as a mean of the individual objects
for every fold. If the estimation of the baseline model is not requested, the list is
set to <code>NULL</code>.
Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.
</p>
</li>
<li><p><code>reliability$iota_object_end: </code>Object of class <code>iotarelr_iota2</code> as a mean of the individual objects
for every fold.
Depending on the requested training method, this object
refers to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo-labeling or a combination of balanced
synthetic cases and pseudo-labeling.
</p>
</li>
<li><p><code>reliability$iota_object_end_free: </code>Object of class <code>iotarelr_iota2</code> as a mean of the individual objects
for every fold.
Depending on the requested training method, this object
refers to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo-labeling or a combination of balanced
synthetic cases and pseudo-labeling.
Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.
</p>
</li>
<li><p><code>reliability$standard_measures_end: </code>Object of class <code>list</code> containing the final
measures for precision, recall, and f1 for every fold.
Depending of the requested training method, these values
refer to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo-labeling or a combination of balanced
synthetic cases and pseudo-labeling.
</p>
</li>
<li><p><code>reliability$standard_measures_mean: </code><code>matrix</code> containing the mean
measures for precision, recall, and f1 at the end of every fold.
</p>
</li></ul>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-new"><code>TextEmbeddingClassifierNeuralNet$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-train"><code>TextEmbeddingClassifierNeuralNet$train()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-predict"><code>TextEmbeddingClassifierNeuralNet$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-check_embedding_model"><code>TextEmbeddingClassifierNeuralNet$check_embedding_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_model_info"><code>TextEmbeddingClassifierNeuralNet$get_model_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_text_embedding_model"><code>TextEmbeddingClassifierNeuralNet$get_text_embedding_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-set_publication_info"><code>TextEmbeddingClassifierNeuralNet$set_publication_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_publication_info"><code>TextEmbeddingClassifierNeuralNet$get_publication_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-set_software_license"><code>TextEmbeddingClassifierNeuralNet$set_software_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_software_license"><code>TextEmbeddingClassifierNeuralNet$get_software_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-set_documentation_license"><code>TextEmbeddingClassifierNeuralNet$set_documentation_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_documentation_license"><code>TextEmbeddingClassifierNeuralNet$get_documentation_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-set_model_description"><code>TextEmbeddingClassifierNeuralNet$set_model_description()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_model_description"><code>TextEmbeddingClassifierNeuralNet$get_model_description()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-save_model"><code>TextEmbeddingClassifierNeuralNet$save_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-load_model"><code>TextEmbeddingClassifierNeuralNet$load_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_package_versions"><code>TextEmbeddingClassifierNeuralNet$get_package_versions()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_sustainability_data"><code>TextEmbeddingClassifierNeuralNet$get_sustainability_data()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-get_ml_framework"><code>TextEmbeddingClassifierNeuralNet$get_ml_framework()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingClassifierNeuralNet-clone"><code>TextEmbeddingClassifierNeuralNet$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creating a new instance of this class.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$new(
  ml_framework = aifeducation_config$get_framework(),
  name = NULL,
  label = NULL,
  text_embeddings = NULL,
  targets = NULL,
  hidden = c(128),
  rec = c(128),
  self_attention_heads = 0,
  intermediate_size = NULL,
  attention_type = "fourier",
  add_pos_embedding = TRUE,
  rec_dropout = 0.1,
  repeat_encoder = 1,
  dense_dropout = 0.4,
  recurrent_dropout = 0.4,
  encoder_dropout = 0.1,
  optimizer = "adam"
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>ml_framework</code></dt><dd><p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'</p>
</dd>
<dt><code>name</code></dt><dd><p><code>Character</code> Name of the new classifier. Please refer to
common name conventions. Free text can be used with parameter <code>label</code>.</p>
</dd>
<dt><code>label</code></dt><dd><p><code>Character</code> Label for the new classifier. Here you can use
free text.</p>
</dd>
<dt><code>text_embeddings</code></dt><dd><p>An object of class<code>TextEmbeddingModel</code>.</p>
</dd>
<dt><code>targets</code></dt><dd><p><code>factor</code> containing the target values of the classifier.</p>
</dd>
<dt><code>hidden</code></dt><dd><p><code>vector</code> containing the number of neurons for each dense layer.
The length of the vector determines the number of dense layers. If you want no dense layer,
set this parameter to <code>NULL</code>.</p>
</dd>
<dt><code>rec</code></dt><dd><p><code>vector</code> containing the number of neurons for each recurrent layer.
The length of the vector determines the number of dense layers. If you want no dense layer,
set this parameter to <code>NULL</code>.</p>
</dd>
<dt><code>self_attention_heads</code></dt><dd><p><code>integer</code> determining the number of attention heads
for a self-attention layer. Only relevant if <code>attention_type="multihead"</code></p>
</dd>
<dt><code>intermediate_size</code></dt><dd><p><code>int</code> determining the size of the projection layer within
a each transformer encoder.</p>
</dd>
<dt><code>attention_type</code></dt><dd><p><code>string</code> Choose the relevant attention type. Possible values
are <code>"fourier"</code> and <code>multihead</code>.</p>
</dd>
<dt><code>add_pos_embedding</code></dt><dd><p><code>bool</code> <code>TRUE</code> if positional embedding should be used.</p>
</dd>
<dt><code>rec_dropout</code></dt><dd><p><code>double</code> ranging between 0 and lower 1, determining the
dropout between bidirectional gru layers.</p>
</dd>
<dt><code>repeat_encoder</code></dt><dd><p><code>int</code> determining how many times the encoder should be
added to the network.</p>
</dd>
<dt><code>dense_dropout</code></dt><dd><p><code>double</code> ranging between 0 and lower 1, determining the
dropout between dense layers.</p>
</dd>
<dt><code>recurrent_dropout</code></dt><dd><p><code>double</code> ranging between 0 and lower 1, determining the
recurrent dropout for each recurrent layer. Only relevant for keras models.</p>
</dd>
<dt><code>encoder_dropout</code></dt><dd><p><code>double</code> ranging between 0 and lower 1, determining the
dropout for the dense projection within the encoder layers.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>Object of class <code>keras.optimizers</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Returns an object of class <a href="#topic+TextEmbeddingClassifierNeuralNet">TextEmbeddingClassifierNeuralNet</a> which is ready for
training.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-train"></a>



<h4>Method <code>train()</code></h4>

<p>Method for training a neural net.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$train(
  data_embeddings,
  data_targets,
  data_n_test_samples = 5,
  balance_class_weights = TRUE,
  use_baseline = TRUE,
  bsl_val_size = 0.25,
  use_bsc = TRUE,
  bsc_methods = c("dbsmote"),
  bsc_max_k = 10,
  bsc_val_size = 0.25,
  bsc_add_all = FALSE,
  use_bpl = TRUE,
  bpl_max_steps = 3,
  bpl_epochs_per_step = 1,
  bpl_dynamic_inc = FALSE,
  bpl_balance = FALSE,
  bpl_max = 1,
  bpl_anchor = 1,
  bpl_min = 0,
  bpl_weight_inc = 0.02,
  bpl_weight_start = 0,
  bpl_model_reset = FALSE,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  epochs = 40,
  batch_size = 32,
  dir_checkpoint,
  trace = TRUE,
  keras_trace = 2,
  pytorch_trace = 2,
  n_cores = 2
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data_embeddings</code></dt><dd><p>Object of class <code>TextEmbeddingModel</code>.</p>
</dd>
<dt><code>data_targets</code></dt><dd><p><code>Factor</code> containing the labels for cases
stored in <code>data_embeddings</code>. Factor must be named and has to use the
same names used in <code>data_embeddings</code>.</p>
</dd>
<dt><code>data_n_test_samples</code></dt><dd><p><code>int</code> determining the number of cross-fold
samples.</p>
</dd>
<dt><code>balance_class_weights</code></dt><dd><p><code>bool</code> If <code>TRUE</code> class weights are
generated based on the frequencies of the training data with the method
Inverse Class Frequency'. If <code>FALSE</code> each class has the weight 1.</p>
</dd>
<dt><code>use_baseline</code></dt><dd><p><code>bool</code> <code>TRUE</code> if the calculation of a baseline
model is requested. This option is only relevant for <code>use_bsc=TRUE</code> or
<code>use_pbl=TRUE</code>. If both are <code>FALSE</code>, a baseline model is calculated.</p>
</dd>
<dt><code>bsl_val_size</code></dt><dd><p><code>double</code> between 0 and 1, indicating the proportion of cases of each class
which should be used for the validation sample during the estimation of the baseline model.
The remaining cases are part of the training data.</p>
</dd>
<dt><code>use_bsc</code></dt><dd><p><code>bool</code> <code>TRUE</code> if the estimation should integrate
balanced synthetic cases. <code>FALSE</code> if not.</p>
</dd>
<dt><code>bsc_methods</code></dt><dd><p><code>vector</code> containing the methods for generating
synthetic cases via 'smotefamily'. Multiple methods can
be passed. Currently <code>bsc_methods=c("adas")</code>, <code>bsc_methods=c("smote")</code>
and <code>bsc_methods=c("dbsmote")</code> are possible.</p>
</dd>
<dt><code>bsc_max_k</code></dt><dd><p><code>int</code> determining the maximal number of k which is used
for creating synthetic units.</p>
</dd>
<dt><code>bsc_val_size</code></dt><dd><p><code>double</code> between 0 and 1, indicating the proportion of cases of each class
which should be used for the validation sample during the estimation with synthetic cases.</p>
</dd>
<dt><code>bsc_add_all</code></dt><dd><p><code>bool</code> If <code>FALSE</code> only synthetic cases necessary to fill
the gab between the class and the major class are added to the data. If <code>TRUE</code> all
generated synthetic cases are added to the data.</p>
</dd>
<dt><code>use_bpl</code></dt><dd><p><code>bool</code> <code>TRUE</code> if the estimation should integrate
balanced pseudo-labeling. <code>FALSE</code> if not.</p>
</dd>
<dt><code>bpl_max_steps</code></dt><dd><p><code>int</code> determining the maximum number of steps during
pseudo-labeling.</p>
</dd>
<dt><code>bpl_epochs_per_step</code></dt><dd><p><code>int</code> Number of training epochs within every step.</p>
</dd>
<dt><code>bpl_dynamic_inc</code></dt><dd><p><code>bool</code> If <code>TRUE</code>, only a specific percentage
of cases is included during each step. The percentage is determined by
<code class="reqn">step/bpl_max_steps</code>. If <code>FALSE</code>, all cases are used.</p>
</dd>
<dt><code>bpl_balance</code></dt><dd><p><code>bool</code> If <code>TRUE</code>, the same number of cases for
every category/class of the pseudo-labeled data are used with training. That
is, the number of cases is determined by the minor class/category.</p>
</dd>
<dt><code>bpl_max</code></dt><dd><p><code>double</code> between 0 and 1, setting the maximal level of
confidence for considering a case for pseudo-labeling.</p>
</dd>
<dt><code>bpl_anchor</code></dt><dd><p><code>double</code> between 0 and 1 indicating the reference
point for sorting the new cases of every label. See notes for more details.</p>
</dd>
<dt><code>bpl_min</code></dt><dd><p><code>double</code> between 0 and 1, setting the minimal level of
confidence for considering a case for pseudo-labeling.</p>
</dd>
<dt><code>bpl_weight_inc</code></dt><dd><p><code>double</code> value how much the sample weights
should be increased for the cases with pseudo-labels in every step.</p>
</dd>
<dt><code>bpl_weight_start</code></dt><dd><p><code>dobule</code> Starting value for the weights of the
unlabeled cases.</p>
</dd>
<dt><code>bpl_model_reset</code></dt><dd><p><code>bool</code> If <code>TRUE</code>, model is re-initialized at every
step.</p>
</dd>
<dt><code>sustain_track</code></dt><dd><p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</dd>
<dt><code>sustain_iso_code</code></dt><dd><p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</dd>
<dt><code>sustain_region</code></dt><dd><p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</dd>
<dt><code>sustain_interval</code></dt><dd><p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</dd>
<dt><code>epochs</code></dt><dd><p><code>int</code> Number of training epochs.</p>
</dd>
<dt><code>batch_size</code></dt><dd><p><code>int</code> Size of batches.</p>
</dd>
<dt><code>dir_checkpoint</code></dt><dd><p><code>string</code> Path to the directory where
the checkpoint during training should be saved. If the directory does not
exist, it is created.</p>
</dd>
<dt><code>trace</code></dt><dd><p><code>bool</code> <code>TRUE</code>, if information about the estimation
phase should be printed to the console.</p>
</dd>
<dt><code>keras_trace</code></dt><dd><p><code>int</code> <code>keras_trace=0</code> does not print any
information about the training process from keras on the console.</p>
</dd>
<dt><code>pytorch_trace</code></dt><dd><p><code>int</code> <code>pytorch_trace=0</code> does not print any
information about the training process from pytorch on the console.
<code>pytorch_trace=1</code> prints a progress bar. <code>pytorch_trace=2</code> prints
one line of information for every epoch.</p>
</dd>
<dt><code>n_cores</code></dt><dd><p><code>int</code> Number of cores used for creating synthetic units.</p>
</dd>
</dl>

</div>



<h5>Details</h5>


<ul>
<li><p><code>bsc_max_k: </code>All values from 2 up to bsc_max_k are successively used. If
the number of bsc_max_k is too high, the value is reduced to a number that
allows the calculating of synthetic units.
</p>
</li>
<li><p><code>bpl_anchor: </code>With the help of this value, the new cases are sorted. For
this aim, the distance from the anchor is calculated and all cases are arranged
into an ascending order.

</p>
</li></ul>




<h5>Returns</h5>

<p>Function does not return a value. It changes the object into a trained
classifier.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Method for predicting new data with a trained neural net.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$predict(newdata, batch_size = 32, verbose = 1)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>newdata</code></dt><dd><p>Object of class <code>TextEmbeddingModel</code> or
<code>data.frame</code> for which predictions should be made.</p>
</dd>
<dt><code>batch_size</code></dt><dd><p><code>int</code> Size of batches.</p>
</dd>
<dt><code>verbose</code></dt><dd><p><code>int</code> <code>verbose=0</code> does not cat any
information about the training process from keras on the console.
<code>verbose=1</code> prints a progress bar. <code>verbose=2</code> prints
one line of information for every epoch.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Returns a <code>data.frame</code> containing the predictions and
the probabilities of the different labels for each case.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-check_embedding_model"></a>



<h4>Method <code>check_embedding_model()</code></h4>

<p>Method for checking if the provided text embeddings are
created with the same <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a> as the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$check_embedding_model(text_embeddings)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>text_embeddings</code></dt><dd><p>Object of class <a href="#topic+EmbeddedText">EmbeddedText</a>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>TRUE</code> if the underlying <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a> are the same.
<code>FALSE</code> if the models differ.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_model_info"></a>



<h4>Method <code>get_model_info()</code></h4>

<p>Method for requesting the model information
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_model_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> of all relevant model information
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_text_embedding_model"></a>



<h4>Method <code>get_text_embedding_model()</code></h4>

<p>Method for requesting the text embedding model information
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_text_embedding_model()</pre></div>



<h5>Returns</h5>

<p><code>list</code> of all relevant model information on the text embedding model
underlying the classifier
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-set_publication_info"></a>



<h4>Method <code>set_publication_info()</code></h4>

<p>Method for setting publication information of the classifier
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$set_publication_info(
  authors,
  citation,
  url = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>authors</code></dt><dd><p>List of authors.</p>
</dd>
<dt><code>citation</code></dt><dd><p>Free text citation.</p>
</dd>
<dt><code>url</code></dt><dd><p>URL of a corresponding homepage.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for setting the private
members for publication information.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_publication_info"></a>



<h4>Method <code>get_publication_info()</code></h4>

<p>Method for requesting the bibliographic information of the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_publication_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> with all saved bibliographic information.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-set_software_license"></a>



<h4>Method <code>set_software_license()</code></h4>

<p>Method for setting the license of the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$set_software_license(license = "GPL-3")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for setting the private member for
the software license of the model.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_software_license"></a>



<h4>Method <code>get_software_license()</code></h4>

<p>Method for getting the license of the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_software_license()</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>string</code> representing the license for the software.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-set_documentation_license"></a>



<h4>Method <code>set_documentation_license()</code></h4>

<p>Method for setting the license of the classifier's documentation.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$set_documentation_license(
  license = "CC BY-SA"
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for setting the private member for
the documentation license of the model.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_documentation_license"></a>



<h4>Method <code>get_documentation_license()</code></h4>

<p>Method for getting the license of the classifier's documentation.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_documentation_license()</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Returns the license as a <code>string</code>.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-set_model_description"></a>



<h4>Method <code>set_model_description()</code></h4>

<p>Method for setting a description of the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$set_model_description(
  eng = NULL,
  native = NULL,
  abstract_eng = NULL,
  abstract_native = NULL,
  keywords_eng = NULL,
  keywords_native = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>eng</code></dt><dd><p><code>string</code> A text describing the training of the learner,
its theoretical and empirical background, and the different output labels
in English.</p>
</dd>
<dt><code>native</code></dt><dd><p><code>string</code> A text describing the training of the learner,
its theoretical and empirical background, and the different output labels
in the native language of the classifier.</p>
</dd>
<dt><code>abstract_eng</code></dt><dd><p><code>string</code> A text providing a summary of the description
in English.</p>
</dd>
<dt><code>abstract_native</code></dt><dd><p><code>string</code> A text providing a summary of the description
in the native language of the classifier.</p>
</dd>
<dt><code>keywords_eng</code></dt><dd><p><code>vector</code> of keyword in English.</p>
</dd>
<dt><code>keywords_native</code></dt><dd><p><code>vector</code> of keyword in the native language of the classifier.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for setting the private members for the
description of the model.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_model_description"></a>



<h4>Method <code>get_model_description()</code></h4>

<p>Method for requesting the model description.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_model_description()</pre></div>



<h5>Returns</h5>

<p><code>list</code> with the description of the classifier in English
and the native language.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-save_model"></a>



<h4>Method <code>save_model()</code></h4>

<p>Method for saving a model to 'Keras v3 format',
'tensorflow' SavedModel format or h5 format.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$save_model(dir_path, save_format = "default")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dir_path</code></dt><dd><p><code>string()</code> Path of the directory where the model should be
saved.</p>
</dd>
<dt><code>save_format</code></dt><dd><p>Format for saving the model. For 'tensorflow'/'keras' models
<code>"keras"</code> for 'Keras v3 format',
<code>"tf"</code> for SavedModel
or <code>"h5"</code> for HDF5.
For 'pytorch' models <code>"safetensors"</code> for 'safetensors' or
<code>"pt"</code> for 'pytorch' via pickle.
Use <code>"default"</code> for the standard format. This is keras for
'tensorflow'/'keras' models and safetensors for 'pytorch' models.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It saves the model to disk.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-load_model"></a>



<h4>Method <code>load_model()</code></h4>

<p>Method for importing a model from 'Keras v3 format',
'tensorflow' SavedModel format or h5 format.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$load_model(dir_path, ml_framework = "auto")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dir_path</code></dt><dd><p><code>string()</code> Path of the directory where the model is
saved.</p>
</dd>
<dt><code>ml_framework</code></dt><dd><p><code>string</code> Determines the machine learning framework
for using the model. Possible are <code>ml_framework="pytorch"</code> for 'pytorch',
<code>ml_framework="tensorflow"</code> for 'tensorflow', and <code>ml_framework="auto"</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to load the weights
of a model.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_package_versions"></a>



<h4>Method <code>get_package_versions()</code></h4>

<p>Method for requesting a summary of the R and python packages'
versions used for creating the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_package_versions()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code> containing the versions of the relevant
R and python packages.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_sustainability_data"></a>



<h4>Method <code>get_sustainability_data()</code></h4>

<p>Method for requesting a summary of tracked energy consumption
during training and an estimate of the resulting CO2 equivalents in kg.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_sustainability_data()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code> containing the tracked energy consumption,
CO2 equivalents in kg, information on the tracker used, and technical
information on the training infrastructure.
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-get_ml_framework"></a>



<h4>Method <code>get_ml_framework()</code></h4>

<p>Method for requesting the machine learning framework used
for the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$get_ml_framework()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>string</code> describing the machine learning framework used
for the classifier
</p>


<hr>
<a id="method-TextEmbeddingClassifierNeuralNet-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingClassifierNeuralNet$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='TextEmbeddingModel'>Text embedding model</h2><span id='topic+TextEmbeddingModel'></span>

<h3>Description</h3>

<p>This <a href="R6.html#topic+R6">R6</a> class stores a text embedding model which can be
used to tokenize, encode, decode, and embed raw texts. The object provides a
unique interface for different text processing methods.
</p>


<h3>Value</h3>

<p>Objects of class <code>TextEmbeddingModel</code> transform raw texts into numerical
representations which can be used for downstream tasks. For this aim objects of this class
allow to tokenize raw texts, to encode tokens to sequences of integers, and to decode sequences
of integers back to tokens.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>last_training</code></dt><dd><p>('list()')<br />
List for storing the history and the results of the last training. This
information will be overwritten if a new training is started.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TextEmbeddingModel-new"><code>TextEmbeddingModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-load_model"><code>TextEmbeddingModel$load_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-save_model"><code>TextEmbeddingModel$save_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-encode"><code>TextEmbeddingModel$encode()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-decode"><code>TextEmbeddingModel$decode()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_special_tokens"><code>TextEmbeddingModel$get_special_tokens()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-embed"><code>TextEmbeddingModel$embed()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-fill_mask"><code>TextEmbeddingModel$fill_mask()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_publication_info"><code>TextEmbeddingModel$set_publication_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_publication_info"><code>TextEmbeddingModel$get_publication_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_software_license"><code>TextEmbeddingModel$set_software_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_software_license"><code>TextEmbeddingModel$get_software_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_documentation_license"><code>TextEmbeddingModel$set_documentation_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_documentation_license"><code>TextEmbeddingModel$get_documentation_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_model_description"><code>TextEmbeddingModel$set_model_description()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_model_description"><code>TextEmbeddingModel$get_model_description()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_model_info"><code>TextEmbeddingModel$get_model_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_package_versions"><code>TextEmbeddingModel$get_package_versions()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_basic_components"><code>TextEmbeddingModel$get_basic_components()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_bow_components"><code>TextEmbeddingModel$get_bow_components()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_transformer_components"><code>TextEmbeddingModel$get_transformer_components()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_sustainability_data"><code>TextEmbeddingModel$get_sustainability_data()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_ml_framework"><code>TextEmbeddingModel$get_ml_framework()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-clone"><code>TextEmbeddingModel$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-TextEmbeddingModel-new"></a>



<h4>Method <code>new()</code></h4>

<p>Method for creating a new text embedding model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$new(
  model_name = NULL,
  model_label = NULL,
  model_version = NULL,
  model_language = NULL,
  method = NULL,
  ml_framework = aifeducation_config$get_framework()$TextEmbeddingFramework,
  max_length = 0,
  chunks = 1,
  overlap = 0,
  emb_layer_min = "middle",
  emb_layer_max = "2_3_layer",
  emb_pool_type = "average",
  model_dir,
  bow_basic_text_rep,
  bow_n_dim = 10,
  bow_n_cluster = 100,
  bow_max_iter = 500,
  bow_max_iter_cluster = 500,
  bow_cr_criterion = 1e-08,
  bow_learning_rate = 1e-08,
  trace = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_name</code></dt><dd><p><code>string</code> containing the name of the new model.</p>
</dd>
<dt><code>model_label</code></dt><dd><p><code>string</code> containing the label/title of the new model.</p>
</dd>
<dt><code>model_version</code></dt><dd><p><code>string</code> version of the model.</p>
</dd>
<dt><code>model_language</code></dt><dd><p><code>string</code> containing the language which the model
represents (e.g., English).</p>
</dd>
<dt><code>method</code></dt><dd><p><code>string</code> determining the kind of embedding model. Currently
the following models are supported:
<code>method="bert"</code> for Bidirectional Encoder Representations from Transformers (BERT),
<code>method="roberta"</code> for A Robustly Optimized BERT Pretraining Approach (RoBERTa),
<code>method="longformer"</code> for Long-Document Transformer,
<code>method="funnel"</code> for Funnel-Transformer,
<code>method="deberta_v2"</code> for Decoding-enhanced BERT with Disentangled Attention (DeBERTa V2),
<code>method="glove"</code> for
GlobalVector Clusters, and
<code>method="lda"</code> for topic modeling. See
details for more information.</p>
</dd>
<dt><code>ml_framework</code></dt><dd><p><code>string</code> Framework to use for the model.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'. Only relevant for transformer models.</p>
</dd>
<dt><code>max_length</code></dt><dd><p><code>int</code> determining the maximum length of token
sequences used in transformer models. Not relevant for the other methods.</p>
</dd>
<dt><code>chunks</code></dt><dd><p><code>int</code> Maximum number of chunks. Only relevant for
transformer models.</p>
</dd>
<dt><code>overlap</code></dt><dd><p><code>int</code> determining the number of tokens which should be added
at the beginning of the next chunk. Only relevant for BERT models.</p>
</dd>
<dt><code>emb_layer_min</code></dt><dd><p><code>int</code> or <code>string</code> determining the first layer to be included
in the creation of embeddings. An integer correspondents to the layer number. The first
layer has the number 1. Instead of an integer the following strings are possible:
<code>"start"</code> for the first layer, <code>"middle"</code> for the middle layer,
<code>"2_3_layer"</code> for the layer two-third layer, and <code>"last"</code> for the last layer.</p>
</dd>
<dt><code>emb_layer_max</code></dt><dd><p><code>int</code> or <code>string</code> determining the last layer to be included
in the creation of embeddings. An integer correspondents to the layer number. The first
layer has the number 1. Instead of an integer the following strings are possible:
<code>"start"</code> for the first layer, <code>"middle"</code> for the middle layer,
<code>"2_3_layer"</code> for the layer two-third layer, and <code>"last"</code> for the last layer.</p>
</dd>
<dt><code>emb_pool_type</code></dt><dd><p><code>string</code> determining the method for pooling the token embeddings
within each layer. If <code>"cls"</code> only the embedding of the CLS token is used. If
<code>"average"</code> the token embedding of all tokens are averaged (excluding padding tokens).</p>
</dd>
<dt><code>model_dir</code></dt><dd><p><code>string</code> path to the directory where the
BERT model is stored.</p>
</dd>
<dt><code>bow_basic_text_rep</code></dt><dd><p>object of class <code>basic_text_rep</code> created via
the function <a href="#topic+bow_pp_create_basic_text_rep">bow_pp_create_basic_text_rep</a>. Only relevant for <code>method="glove_cluster"</code>
and <code>method="lda"</code>.</p>
</dd>
<dt><code>bow_n_dim</code></dt><dd><p><code>int</code> Number of dimensions of the GlobalVector or
number of topics for LDA.</p>
</dd>
<dt><code>bow_n_cluster</code></dt><dd><p><code>int</code> Number of clusters created on the basis
of GlobalVectors. Parameter is not relevant for <code>method="lda"</code> and
<code>method="bert"</code></p>
</dd>
<dt><code>bow_max_iter</code></dt><dd><p><code>int</code> Maximum number of iterations for fitting
GlobalVectors and Topic Models.</p>
</dd>
<dt><code>bow_max_iter_cluster</code></dt><dd><p><code>int</code> Maximum number of iterations for
fitting cluster if <code>method="glove"</code>.</p>
</dd>
<dt><code>bow_cr_criterion</code></dt><dd><p><code>double</code> convergence criterion for GlobalVectors.</p>
</dd>
<dt><code>bow_learning_rate</code></dt><dd><p><code>double</code> initial learning rate for GlobalVectors.</p>
</dd>
<dt><code>trace</code></dt><dd><p><code>bool</code> <code>TRUE</code> prints information about the progress.
<code>FALSE</code> does not.</p>
</dd>
</dl>

</div>



<h5>Details</h5>


<ul>
<li><p>method: In the case of <code>method="bert"</code>, <code>method="roberta"</code>, and <code>method="longformer"</code>,
a pretrained transformer model
must be supplied via <code>model_dir</code>. For <code>method="glove"</code>
and <code>method="lda"</code> a new model will be created based on the data provided
via <code>bow_basic_text_rep</code>. The original algorithm for GlobalVectors provides
only word embeddings, not text embeddings. To achieve text embeddings the words
are clustered based on their word embeddings with kmeans.
</p>
</li></ul>




<h5>Returns</h5>

<p>Returns an object of class <a href="#topic+TextEmbeddingModel">TextEmbeddingModel</a>.
</p>


<hr>
<a id="method-TextEmbeddingModel-load_model"></a>



<h4>Method <code>load_model()</code></h4>

<p>Method for loading a transformers model into R.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$load_model(model_dir, ml_framework = "auto")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_dir</code></dt><dd><p><code>string</code> containing the path to the relevant
model directory.</p>
</dd>
<dt><code>ml_framework</code></dt><dd><p><code>string</code> Determines the machine learning framework
for using the model. Possible are <code>ml_framework="pytorch"</code> for 'pytorch',
<code>ml_framework="tensorflow"</code> for 'tensorflow', and <code>ml_framework="auto"</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for loading a saved
transformer model into the R interface.
</p>


<hr>
<a id="method-TextEmbeddingModel-save_model"></a>



<h4>Method <code>save_model()</code></h4>

<p>Method for saving a transformer model on disk.Relevant
only for transformer models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$save_model(model_dir, save_format = "default")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_dir</code></dt><dd><p><code>string</code> containing the path to the relevant
model directory.</p>
</dd>
<dt><code>save_format</code></dt><dd><p>Format for saving the model. For 'tensorflow'/'keras' models
<code>"h5"</code> for HDF5.
For 'pytorch' models <code>"safetensors"</code> for 'safetensors' or
<code>"pt"</code> for 'pytorch' via pickle.
Use <code>"default"</code> for the standard format. This is h5 for
'tensorflow'/'keras' models and safetensors for 'pytorch' models.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for saving a transformer model
to disk.
</p>


<hr>
<a id="method-TextEmbeddingModel-encode"></a>



<h4>Method <code>encode()</code></h4>

<p>Method for encoding words of raw texts into integers.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$encode(
  raw_text,
  token_encodings_only = FALSE,
  to_int = TRUE,
  trace = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>raw_text</code></dt><dd><p><code>vector</code> containing the raw texts.</p>
</dd>
<dt><code>token_encodings_only</code></dt><dd><p><code>bool</code> If <code>TRUE</code>, only the token
encodings are returned. If <code>FALSE</code>, the complete encoding is returned
which is important for BERT models.</p>
</dd>
<dt><code>to_int</code></dt><dd><p><code>bool</code> If <code>TRUE</code> the integer ids of the tokens are
returned. If <code>FALSE</code> the tokens are returned. Argument only applies
for transformer models and if <code>token_encodings_only==TRUE</code>.</p>
</dd>
<dt><code>trace</code></dt><dd><p><code>bool</code> If <code>TRUE</code>, information of the progress
is printed. <code>FALSE</code> if not requested.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>list</code> containing the integer sequences of the raw texts with
special tokens.
</p>


<hr>
<a id="method-TextEmbeddingModel-decode"></a>



<h4>Method <code>decode()</code></h4>

<p>Method for decoding a sequence of integers into tokens
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$decode(int_seqence, to_token = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>int_seqence</code></dt><dd><p><code>list</code> containing the integer sequences which
should be transformed to tokens or plain text.</p>
</dd>
<dt><code>to_token</code></dt><dd><p><code>bool</code> If <code>FALSE</code> a plain text is returned.
if <code>TRUE</code> a sequence of tokens is returned. Argument only relevant
if the model is based on a transformer.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>list</code> of token sequences
</p>


<hr>
<a id="method-TextEmbeddingModel-get_special_tokens"></a>



<h4>Method <code>get_special_tokens()</code></h4>

<p>Method for receiving the special tokens of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_special_tokens()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>matrix</code> containing the special tokens in the rows
and their type, token, and id in the columns.
</p>


<hr>
<a id="method-TextEmbeddingModel-embed"></a>



<h4>Method <code>embed()</code></h4>

<p>Method for creating text embeddings from raw texts
</p>
<p>In the case of using a GPU and running out of memory reduce the
batch size or restart R and switch to use cpu only via <a href="#topic+set_config_cpu_only">set_config_cpu_only</a>.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$embed(
  raw_text = NULL,
  doc_id = NULL,
  batch_size = 8,
  trace = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>raw_text</code></dt><dd><p><code>vector</code> containing the raw texts.</p>
</dd>
<dt><code>doc_id</code></dt><dd><p><code>vector</code> containing the corresponding IDs for every text.</p>
</dd>
<dt><code>batch_size</code></dt><dd><p><code>int</code> determining the maximal size of every batch.</p>
</dd>
<dt><code>trace</code></dt><dd><p><code>bool</code> <code>TRUE</code>, if information about the progression
should be printed on console.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Method returns a <a href="R6.html#topic+R6">R6</a> object of class <a href="#topic+EmbeddedText">EmbeddedText</a>. This object
contains the embeddings as a <code>data.frame</code> and information about the
model creating the embeddings.
</p>


<hr>
<a id="method-TextEmbeddingModel-fill_mask"></a>



<h4>Method <code>fill_mask()</code></h4>

<p>Method for calculating tokens behind mask tokens.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$fill_mask(text, n_solutions = 5)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>text</code></dt><dd><p><code>string</code> Text containing mask tokens.</p>
</dd>
<dt><code>n_solutions</code></dt><dd><p><code>int</code> Number estimated tokens for every mask.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Returns a <code>list</code> containing a <code>data.frame</code> for every
mask. The <code>data.frame</code> contains the solutions in the rows and reports
the score, token id, and token string in the columns.
</p>


<hr>
<a id="method-TextEmbeddingModel-set_publication_info"></a>



<h4>Method <code>set_publication_info()</code></h4>

<p>Method for setting the bibliographic information of the model.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_publication_info(type, authors, citation, url = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>type</code></dt><dd><p><code>string</code> Type of information which should be changed/added.
<code>type="developer"</code>, and <code>type="modifier"</code> are possible.</p>
</dd>
<dt><code>authors</code></dt><dd><p>List of people.</p>
</dd>
<dt><code>citation</code></dt><dd><p><code>string</code> Citation in free text.</p>
</dd>
<dt><code>url</code></dt><dd><p><code>string</code> Corresponding URL if applicable.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to set the private
members for publication information of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_publication_info"></a>



<h4>Method <code>get_publication_info()</code></h4>

<p>Method for getting the bibliographic information of the model.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_publication_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> of bibliographic information.
</p>


<hr>
<a id="method-TextEmbeddingModel-set_software_license"></a>



<h4>Method <code>set_software_license()</code></h4>

<p>Method for setting the license of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_software_license(license = "GPL-3")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for setting the private
member for the software license of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_software_license"></a>



<h4>Method <code>get_software_license()</code></h4>

<p>Method for requesting the license of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_software_license()</pre></div>



<h5>Returns</h5>

<p><code>string</code> License of the model
</p>


<hr>
<a id="method-TextEmbeddingModel-set_documentation_license"></a>



<h4>Method <code>set_documentation_license()</code></h4>

<p>Method for setting the license of models' documentation.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_documentation_license(license = "CC BY-SA")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to set the private member for the
documentation license of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_documentation_license"></a>



<h4>Method <code>get_documentation_license()</code></h4>

<p>Method for getting the license of the models' documentation.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_documentation_license()</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt><dd><p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TextEmbeddingModel-set_model_description"></a>



<h4>Method <code>set_model_description()</code></h4>

<p>Method for setting a description of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_model_description(
  eng = NULL,
  native = NULL,
  abstract_eng = NULL,
  abstract_native = NULL,
  keywords_eng = NULL,
  keywords_native = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>eng</code></dt><dd><p><code>string</code> A text describing the training of the classifier,
its theoretical and empirical background, and the different output labels
in English.</p>
</dd>
<dt><code>native</code></dt><dd><p><code>string</code> A text describing the training of the classifier,
its theoretical and empirical background, and the different output labels
in the native language of the model.</p>
</dd>
<dt><code>abstract_eng</code></dt><dd><p><code>string</code> A text providing a summary of the description
in English.</p>
</dd>
<dt><code>abstract_native</code></dt><dd><p><code>string</code> A text providing a summary of the description
in the native language of the classifier.</p>
</dd>
<dt><code>keywords_eng</code></dt><dd><p><code>vector</code> of keywords in English.</p>
</dd>
<dt><code>keywords_native</code></dt><dd><p><code>vector</code> of keywords in the native language of the classifier.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to set the private members for the
description of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_model_description"></a>



<h4>Method <code>get_model_description()</code></h4>

<p>Method for requesting the model description.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_model_description()</pre></div>



<h5>Returns</h5>

<p><code>list</code> with the description of the model in English
and the native language.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_model_info"></a>



<h4>Method <code>get_model_info()</code></h4>

<p>Method for requesting the model information
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_model_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> of all relevant model information
</p>


<hr>
<a id="method-TextEmbeddingModel-get_package_versions"></a>



<h4>Method <code>get_package_versions()</code></h4>

<p>Method for requesting a summary of the R and python packages'
versions used for creating the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_package_versions()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code> containing the versions of the relevant
R and python packages.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_basic_components"></a>



<h4>Method <code>get_basic_components()</code></h4>

<p>Method for requesting the part of interface's configuration that is
necessary for all models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_basic_components()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code>.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_bow_components"></a>



<h4>Method <code>get_bow_components()</code></h4>

<p>Method for requesting the part of interface's configuration that is
necessary bag-of-words models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_bow_components()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code>.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_transformer_components"></a>



<h4>Method <code>get_transformer_components()</code></h4>

<p>Method for requesting the part of interface's configuration that is
necessary for transformer models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_transformer_components()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code>.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_sustainability_data"></a>



<h4>Method <code>get_sustainability_data()</code></h4>

<p>Method for requesting a log of tracked energy consumption
during training and an estimate of the resulting CO2 equivalents in kg.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_sustainability_data()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>matrix</code> containing the tracked energy consumption,
CO2 equivalents in kg, information on the tracker used, and technical
information on the training infrastructure for every training run.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_ml_framework"></a>



<h4>Method <code>get_ml_framework()</code></h4>

<p>Method for requesting the machine learning framework used
for the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_ml_framework()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>string</code> describing the machine learning framework used
for the classifier
</p>


<hr>
<a id="method-TextEmbeddingModel-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Text Embedding: 
<code><a href="#topic+EmbeddedText">EmbeddedText</a></code>,
<code><a href="#topic+combine_embeddings">combine_embeddings</a>()</code>
</p>

<hr>
<h2 id='to_categorical_c'>Transforming classes to one-hot encoding</h2><span id='topic+to_categorical_c'></span>

<h3>Description</h3>

<p>Function written in C++ transforming a vector of classes (int) into
a binary class matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_categorical_c(class_vector, n_classes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_categorical_c_+3A_class_vector">class_vector</code></td>
<td>
<p><code>vector</code> containing integers for every class. The
integers must range from 0 to n_classes-1.</p>
</td></tr>
<tr><td><code id="to_categorical_c_+3A_n_classes">n_classes</code></td>
<td>
<p><code>int</code> Total number of classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>matrix</code> containing the binary representation for
every class.
</p>


<h3>See Also</h3>

<p>Other Auxiliary Functions: 
<code><a href="#topic+array_to_matrix">array_to_matrix</a>()</code>,
<code><a href="#topic+calc_standard_classification_measures">calc_standard_classification_measures</a>()</code>,
<code><a href="#topic+check_embedding_models">check_embedding_models</a>()</code>,
<code><a href="#topic+clean_pytorch_log_transformers">clean_pytorch_log_transformers</a>()</code>,
<code><a href="#topic+create_iota2_mean_object">create_iota2_mean_object</a>()</code>,
<code><a href="#topic+create_synthetic_units">create_synthetic_units</a>()</code>,
<code><a href="#topic+generate_id">generate_id</a>()</code>,
<code><a href="#topic+get_coder_metrics">get_coder_metrics</a>()</code>,
<code><a href="#topic+get_folds">get_folds</a>()</code>,
<code><a href="#topic+get_n_chunks">get_n_chunks</a>()</code>,
<code><a href="#topic+get_stratified_train_test_split">get_stratified_train_test_split</a>()</code>,
<code><a href="#topic+get_synthetic_cases">get_synthetic_cases</a>()</code>,
<code><a href="#topic+get_train_test_split">get_train_test_split</a>()</code>,
<code><a href="#topic+is.null_or_na">is.null_or_na</a>()</code>,
<code><a href="#topic+matrix_to_array_c">matrix_to_array_c</a>()</code>,
<code><a href="#topic+split_labeled_unlabeled">split_labeled_unlabeled</a>()</code>,
<code><a href="#topic+summarize_tracked_sustainability">summarize_tracked_sustainability</a>()</code>
</p>

<hr>
<h2 id='train_tune_bert_model'>Function for training and fine-tuning a BERT model</h2><span id='topic+train_tune_bert_model'></span>

<h3>Description</h3>

<p>This function can be used to train or fine-tune a transformer
based on BERT architecture with the help of the python libraries 'transformers',
'datasets', and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_tune_bert_model(
  ml_framework = aifeducation_config$get_framework(),
  output_dir,
  model_dir_path,
  raw_texts,
  p_mask = 0.15,
  whole_word = TRUE,
  val_size = 0.1,
  n_epoch = 1,
  batch_size = 12,
  chunk_size = 250,
  full_sequences_only = FALSE,
  min_seq_len = 50,
  learning_rate = 0.003,
  n_workers = 1,
  multi_process = FALSE,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  keras_trace = 1,
  pytorch_trace = 1,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_tune_bert_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_output_dir">output_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the final model
should be saved. If the directory does not exist, it will be created.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_model_dir_path">model_dir_path</code></td>
<td>
<p><code>string</code> Path to the directory where the original
model is stored.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_raw_texts">raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for training.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_p_mask">p_mask</code></td>
<td>
<p><code>double</code> Ratio determining the number of words/tokens for masking.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_whole_word">whole_word</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if whole word masking should be applied.
If <code>FALSE</code> token masking is used.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Ratio determining the amount of token chunks used for
validation.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_n_epoch">n_epoch</code></td>
<td>
<p><code>int</code> Number of epochs for training.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_batch_size">batch_size</code></td>
<td>
<p><code>int</code> Size of batches.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_chunk_size">chunk_size</code></td>
<td>
<p><code>int</code> Size of every chunk for training.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_full_sequences_only">full_sequences_only</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> for using only chunks
with a sequence length equal to <code>chunk_size</code>.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_min_seq_len">min_seq_len</code></td>
<td>
<p><code>int</code> Only relevant if <code>full_sequences_only=FALSE</code>.
Value determines the minimal sequence length for inclusion in training process.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_learning_rate">learning_rate</code></td>
<td>
<p><code>double</code> Learning rate for adam optimizer.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_n_workers">n_workers</code></td>
<td>
<p><code>int</code> Number of workers. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_multi_process">multi_process</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if multiple processes should be activated.
Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information on the progress should be printed
to the console.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_keras_trace">keras_trace</code></td>
<td>
<p><code>int</code> <code>keras_trace=0</code> does not print any
information about the training process from keras on the console.
<code>keras_trace=1</code> prints a progress bar. <code>keras_trace=2</code> prints
one line of information for every epoch. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_pytorch_trace">pytorch_trace</code></td>
<td>
<p><code>int</code> <code>pytorch_trace=0</code> does not print any
information about the training process from pytorch on the console.
<code>pytorch_trace=1</code> prints a progress bar.</p>
</td></tr>
<tr><td><code id="train_tune_bert_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the trained or fine-tuned
model is saved to disk.
</p>


<h3>Note</h3>

<p>This models uses a WordPiece Tokenizer like BERT and can be trained with
whole word masking. Transformer library may show a warning which can be ignored.
</p>
<p>Pre-Trained models which can be fine-tuned with this function are available
at <a href="https://huggingface.co/">https://huggingface.co/</a>.
</p>
<p>New models can be created via the function <a href="#topic+create_bert_model">create_bert_model</a>.
</p>
<p>Training of the model makes use of dynamic masking in contrast to the
original paper where static masking was applied.
</p>


<h3>References</h3>

<p>Devlin, J., Chang, M.‑W., Lee, K., &amp; Toutanova, K. (2019). BERT:
Pre-training of Deep Bidirectional Transformers for Language
Understanding. In J. Burstein, C. Doran, &amp; T. Solorio (Eds.),
Proceedings of the 2019 Conference of the North (pp. 4171&ndash;4186).
Association for Computational Linguistics.
<a href="https://doi.org/10.18653/v1/N19-1423">doi:10.18653/v1/N19-1423</a>
</p>
<p>Hugging Face documentation
<a href="https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForMaskedLM">https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForMaskedLM</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='train_tune_deberta_v2_model'>Function for training and fine-tuning a DeBERTa-V2 model</h2><span id='topic+train_tune_deberta_v2_model'></span>

<h3>Description</h3>

<p>This function can be used to train or fine-tune a transformer
based on DeBERTa-V2 architecture with the help of the python libraries 'transformers',
'datasets', and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_tune_deberta_v2_model(
  ml_framework = aifeducation_config$get_framework(),
  output_dir,
  model_dir_path,
  raw_texts,
  p_mask = 0.15,
  whole_word = TRUE,
  val_size = 0.1,
  n_epoch = 1,
  batch_size = 12,
  chunk_size = 250,
  full_sequences_only = FALSE,
  min_seq_len = 50,
  learning_rate = 0.03,
  n_workers = 1,
  multi_process = FALSE,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  keras_trace = 1,
  pytorch_trace = 1,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_tune_deberta_v2_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_output_dir">output_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the final model
should be saved. If the directory does not exist, it will be created.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_model_dir_path">model_dir_path</code></td>
<td>
<p><code>string</code> Path to the directory where the original
model is stored.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_raw_texts">raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for training.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_p_mask">p_mask</code></td>
<td>
<p><code>double</code> Ratio determining the number of words/tokens for masking.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_whole_word">whole_word</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if whole word masking should be applied.
If <code>FALSE</code> token masking is used.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Ratio determining the amount of token chunks used for
validation.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_n_epoch">n_epoch</code></td>
<td>
<p><code>int</code> Number of epochs for training.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_batch_size">batch_size</code></td>
<td>
<p><code>int</code> Size of batches.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_chunk_size">chunk_size</code></td>
<td>
<p><code>int</code> Size of every chunk for training.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_full_sequences_only">full_sequences_only</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> for using only chunks
with a sequence length equal to <code>chunk_size</code>.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_min_seq_len">min_seq_len</code></td>
<td>
<p><code>int</code> Only relevant if <code>full_sequences_only=FALSE</code>.
Value determines the minimal sequence length for inclusion in training process.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_learning_rate">learning_rate</code></td>
<td>
<p><code>bool</code> Learning rate for adam optimizer.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_n_workers">n_workers</code></td>
<td>
<p><code>int</code> Number of workers. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_multi_process">multi_process</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if multiple processes should be activated.
Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information on the progress should be printed
to the console.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_keras_trace">keras_trace</code></td>
<td>
<p><code>int</code> <code>keras_trace=0</code> does not print any
information about the training process from keras on the console.
<code>keras_trace=1</code> prints a progress bar. <code>keras_trace=2</code> prints
one line of information for every epoch. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_pytorch_trace">pytorch_trace</code></td>
<td>
<p><code>int</code> <code>pytorch_trace=0</code> does not print any
information about the training process from pytorch on the console.
<code>pytorch_trace=1</code> prints a progress bar.</p>
</td></tr>
<tr><td><code id="train_tune_deberta_v2_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the trained or fine-tuned
model is saved to disk.
</p>


<h3>Note</h3>

<p>Pre-Trained models which can be fine-tuned with this function are available
at <a href="https://huggingface.co/">https://huggingface.co/</a>. New models can be created via the function
<a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>.
</p>
<p>Training of this model makes use of dynamic masking.
</p>


<h3>References</h3>

<p>He, P., Liu, X., Gao, J. &amp; Chen, W. (2020). DeBERTa: Decoding-enhanced BERT
with Disentangled Attention. <a href="https://doi.org/10.48550/arXiv.2006.03654">doi:10.48550/arXiv.2006.03654</a>
</p>
<p>Hugging Face Documentation
<a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2#debertav2">https://huggingface.co/docs/transformers/model_doc/deberta-v2#debertav2</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='train_tune_funnel_model'>Function for training and fine-tuning a Funnel Transformer model</h2><span id='topic+train_tune_funnel_model'></span>

<h3>Description</h3>

<p>This function can be used to train or fine-tune a transformer
based on Funnel Transformer architecture with the help of the python libraries 'transformers',
'datasets', and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_tune_funnel_model(
  ml_framework = aifeducation_config$get_framework(),
  output_dir,
  model_dir_path,
  raw_texts,
  p_mask = 0.15,
  whole_word = TRUE,
  val_size = 0.1,
  n_epoch = 1,
  batch_size = 12,
  chunk_size = 250,
  min_seq_len = 50,
  full_sequences_only = FALSE,
  learning_rate = 0.003,
  n_workers = 1,
  multi_process = FALSE,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  keras_trace = 1,
  pytorch_trace = 1,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_tune_funnel_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_output_dir">output_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the final model
should be saved. If the directory does not exist, it will be created.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_model_dir_path">model_dir_path</code></td>
<td>
<p><code>string</code> Path to the directory where the original
model is stored.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_raw_texts">raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for training.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_p_mask">p_mask</code></td>
<td>
<p><code>double</code> Ratio determining the number of words/tokens for masking.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_whole_word">whole_word</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if whole word masking should be applied.
If <code>FALSE</code> token masking is used.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Ratio determining the amount of token chunks used for
validation.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_n_epoch">n_epoch</code></td>
<td>
<p><code>int</code> Number of epochs for training.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_batch_size">batch_size</code></td>
<td>
<p><code>int</code> Size of batches.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_chunk_size">chunk_size</code></td>
<td>
<p><code>int</code> Size of every chunk for training.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_min_seq_len">min_seq_len</code></td>
<td>
<p><code>int</code> Only relevant if <code>full_sequences_only=FALSE</code>.
Value determines the minimal sequence length for inclusion in training process.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_full_sequences_only">full_sequences_only</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if only token sequences with
a length equal to <code>chunk_size</code> should be used for training.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_learning_rate">learning_rate</code></td>
<td>
<p><code>double</code> Learning rate for adam optimizer.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_n_workers">n_workers</code></td>
<td>
<p><code>int</code> Number of workers.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_multi_process">multi_process</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if multiple processes should be activated.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information on the progress should be printed
to the console.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_keras_trace">keras_trace</code></td>
<td>
<p><code>int</code> <code>keras_trace=0</code> does not print any
information about the training process from keras on the console.
<code>keras_trace=1</code> prints a progress bar. <code>keras_trace=2</code> prints
one line of information for every epoch.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_pytorch_trace">pytorch_trace</code></td>
<td>
<p><code>int</code> <code>pytorch_trace=0</code> does not print any
information about the training process from pytorch on the console.
<code>pytorch_trace=1</code> prints a progress bar.</p>
</td></tr>
<tr><td><code id="train_tune_funnel_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the trained or fine-tuned
model is saved to disk.
</p>


<h3>Note</h3>

<p>if <code>aug_vocab_by &gt; 0</code> the raw text is used for training a WordPiece
tokenizer. At the end of this process, additional entries are added to the vocabulary
that are not part of the original vocabulary. This is in an experimental state.
</p>
<p>Pre-Trained models which can be fine-tuned with this function are available
at <a href="https://huggingface.co/">https://huggingface.co/</a>.
</p>
<p>New models can be created via the function <a href="#topic+create_funnel_model">create_funnel_model</a>.
</p>
<p>Training of the model makes use of dynamic masking.
</p>


<h3>References</h3>

<p>Dai, Z., Lai, G., Yang, Y. &amp; Le, Q. V. (2020). Funnel-Transformer: Filtering
out Sequential Redundancy for Efficient Language Processing.
<a href="https://doi.org/10.48550/arXiv.2006.03236">doi:10.48550/arXiv.2006.03236</a>
</p>
<p>Hugging Face documentation
<a href="https://huggingface.co/docs/transformers/model_doc/funnel#funnel-transformer">https://huggingface.co/docs/transformers/model_doc/funnel#funnel-transformer</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='train_tune_longformer_model'>Function for training and fine-tuning a Longformer model</h2><span id='topic+train_tune_longformer_model'></span>

<h3>Description</h3>

<p>This function can be used to train or fine-tune a transformer
based on Longformer architecture with the help of the python libraries 'transformers',
'datasets', and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_tune_longformer_model(
  ml_framework = aifeducation_config$get_framework,
  output_dir,
  model_dir_path,
  raw_texts,
  p_mask = 0.15,
  val_size = 0.1,
  n_epoch = 1,
  batch_size = 12,
  chunk_size = 250,
  full_sequences_only = FALSE,
  min_seq_len = 50,
  learning_rate = 0.03,
  n_workers = 1,
  multi_process = FALSE,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  keras_trace = 1,
  pytorch_trace = 1,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_tune_longformer_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_output_dir">output_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the final model
should be saved. If the directory does not exist, it will be created.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_model_dir_path">model_dir_path</code></td>
<td>
<p><code>string</code> Path to the directory where the original
model is stored.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_raw_texts">raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for training.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_p_mask">p_mask</code></td>
<td>
<p><code>double</code> Ratio determining the number of words/tokens for masking.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Ratio determining the amount of token chunks used for
validation.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_n_epoch">n_epoch</code></td>
<td>
<p><code>int</code> Number of epochs for training.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_batch_size">batch_size</code></td>
<td>
<p><code>int</code> Size of batches.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_chunk_size">chunk_size</code></td>
<td>
<p><code>int</code> Size of every chunk for training.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_full_sequences_only">full_sequences_only</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> for using only chunks
with a sequence length equal to <code>chunk_size</code>.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_min_seq_len">min_seq_len</code></td>
<td>
<p><code>int</code> Only relevant if <code>full_sequences_only=FALSE</code>.
Value determines the minimal sequence length for inclusion in training process.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_learning_rate">learning_rate</code></td>
<td>
<p><code>bool</code> Learning rate for adam optimizer.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_n_workers">n_workers</code></td>
<td>
<p><code>int</code> Number of workers. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_multi_process">multi_process</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if multiple processes should be activated.
Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information on the progress should be printed
to the console.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_keras_trace">keras_trace</code></td>
<td>
<p><code>int</code> <code>keras_trace=0</code> does not print any
information about the training process from keras on the console.
<code>keras_trace=1</code> prints a progress bar. <code>keras_trace=2</code> prints
one line of information for every epoch.
Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_pytorch_trace">pytorch_trace</code></td>
<td>
<p><code>int</code> <code>pytorch_trace=0</code> does not print any
information about the training process from pytorch on the console.
<code>pytorch_trace=1</code> prints a progress bar.</p>
</td></tr>
<tr><td><code id="train_tune_longformer_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the trained or fine-tuned
model is saved to disk.
</p>


<h3>Note</h3>

<p>Pre-Trained models which can be fine-tuned with this function are available
at <a href="https://huggingface.co/">https://huggingface.co/</a>. New models can be created via the function
<a href="#topic+create_roberta_model">create_roberta_model</a>.
</p>
<p>Training of this model makes use of dynamic masking.
</p>


<h3>References</h3>

<p>Beltagy, I., Peters, M. E., &amp; Cohan, A. (2020). Longformer: The
Long-Document Transformer. <a href="https://doi.org/10.48550/arXiv.2004.05150">doi:10.48550/arXiv.2004.05150</a>
</p>
<p>Hugging Face Documentation
<a href="https://huggingface.co/docs/transformers/model_doc/longformer#transformers.LongformerConfig">https://huggingface.co/docs/transformers/model_doc/longformer#transformers.LongformerConfig</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_roberta_model">train_tune_roberta_model</a>()</code>
</p>

<hr>
<h2 id='train_tune_roberta_model'>Function for training and fine-tuning a RoBERTa model</h2><span id='topic+train_tune_roberta_model'></span>

<h3>Description</h3>

<p>This function can be used to train or fine-tune a transformer
based on RoBERTa architecture with the help of the python libraries 'transformers',
'datasets', and 'tokenizers'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_tune_roberta_model(
  ml_framework = aifeducation_config$get_framework(),
  output_dir,
  model_dir_path,
  raw_texts,
  p_mask = 0.15,
  val_size = 0.1,
  n_epoch = 1,
  batch_size = 12,
  chunk_size = 250,
  full_sequences_only = FALSE,
  min_seq_len = 50,
  learning_rate = 0.03,
  n_workers = 1,
  multi_process = FALSE,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  trace = TRUE,
  keras_trace = 1,
  pytorch_trace = 1,
  pytorch_safetensors = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_tune_roberta_model_+3A_ml_framework">ml_framework</code></td>
<td>
<p><code>string</code> Framework to use for training and inference.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_output_dir">output_dir</code></td>
<td>
<p><code>string</code> Path to the directory where the final model
should be saved. If the directory does not exist, it will be created.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_model_dir_path">model_dir_path</code></td>
<td>
<p><code>string</code> Path to the directory where the original
model is stored.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_raw_texts">raw_texts</code></td>
<td>
<p><code>vector</code> containing the raw texts for training.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_p_mask">p_mask</code></td>
<td>
<p><code>double</code> Ratio determining the number of words/tokens for masking.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_val_size">val_size</code></td>
<td>
<p><code>double</code> Ratio determining the amount of token chunks used for
validation.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_n_epoch">n_epoch</code></td>
<td>
<p><code>int</code> Number of epochs for training.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_batch_size">batch_size</code></td>
<td>
<p><code>int</code> Size of batches.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_chunk_size">chunk_size</code></td>
<td>
<p><code>int</code> Size of every chunk for training.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_full_sequences_only">full_sequences_only</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> for using only chunks
with a sequence length equal to <code>chunk_size</code>.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_min_seq_len">min_seq_len</code></td>
<td>
<p><code>int</code> Only relevant if <code>full_sequences_only=FALSE</code>.
Value determines the minimal sequence length for inclusion in training process.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_learning_rate">learning_rate</code></td>
<td>
<p><code>bool</code> Learning rate for adam optimizer.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_n_workers">n_workers</code></td>
<td>
<p><code>int</code> Number of workers. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_multi_process">multi_process</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if multiple processes should be activated.
Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_sustain_track">sustain_track</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> energy consumption is tracked
during training via the python library codecarbon.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_sustain_iso_code">sustain_iso_code</code></td>
<td>
<p><code>string</code> ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: <a href="https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes">https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</a>.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_sustain_region">sustain_region</code></td>
<td>
<p>Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
<a href="https://mlco2.github.io/codecarbon/parameters.html">https://mlco2.github.io/codecarbon/parameters.html</a></p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_sustain_interval">sustain_interval</code></td>
<td>
<p><code>integer</code> Interval in seconds for measuring power
usage.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_trace">trace</code></td>
<td>
<p><code>bool</code> <code>TRUE</code> if information on the progress should be printed
to the console.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_keras_trace">keras_trace</code></td>
<td>
<p><code>int</code> <code>keras_trace=0</code> does not print any
information about the training process from keras on the console.
<code>keras_trace=1</code> prints a progress bar. <code>keras_trace=2</code> prints
one line of information for every epoch. Only relevant if <code>ml_framework="tensorflow"</code>.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_pytorch_trace">pytorch_trace</code></td>
<td>
<p><code>int</code> <code>pytorch_trace=0</code> does not print any
information about the training process from pytorch on the console.
<code>pytorch_trace=1</code> prints a progress bar.</p>
</td></tr>
<tr><td><code id="train_tune_roberta_model_+3A_pytorch_safetensors">pytorch_safetensors</code></td>
<td>
<p><code>bool</code> If <code>TRUE</code> a 'pytorch' model
is saved in safetensors format. If <code>FALSE</code> or 'safetensors' not available
it is saved in the standard pytorch format (.bin). Only relevant for pytorch models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return an object. Instead the trained or fine-tuned
model is saved to disk.
</p>


<h3>Note</h3>

<p>Pre-Trained models which can be fine-tuned with this function are available
at <a href="https://huggingface.co/">https://huggingface.co/</a>. New models can be created via the function
<a href="#topic+create_roberta_model">create_roberta_model</a>.
</p>
<p>Training of this model makes use of dynamic masking.
</p>


<h3>References</h3>

<p>Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O.,
Lewis, M., Zettlemoyer, L., &amp; Stoyanov, V. (2019). RoBERTa: A Robustly
Optimized BERT Pretraining Approach.
<a href="https://doi.org/10.48550/arXiv.1907.11692">doi:10.48550/arXiv.1907.11692</a>
</p>
<p>Hugging Face Documentation
<a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaConfig">https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaConfig</a>
</p>


<h3>See Also</h3>

<p>Other Transformer: 
<code><a href="#topic+create_bert_model">create_bert_model</a>()</code>,
<code><a href="#topic+create_deberta_v2_model">create_deberta_v2_model</a>()</code>,
<code><a href="#topic+create_funnel_model">create_funnel_model</a>()</code>,
<code><a href="#topic+create_longformer_model">create_longformer_model</a>()</code>,
<code><a href="#topic+create_roberta_model">create_roberta_model</a>()</code>,
<code><a href="#topic+train_tune_bert_model">train_tune_bert_model</a>()</code>,
<code><a href="#topic+train_tune_deberta_v2_model">train_tune_deberta_v2_model</a>()</code>,
<code><a href="#topic+train_tune_funnel_model">train_tune_funnel_model</a>()</code>,
<code><a href="#topic+train_tune_longformer_model">train_tune_longformer_model</a>()</code>
</p>

<hr>
<h2 id='update_aifeducation_progress_bar'>Update master progress bar in aifeducation shiny app.</h2><span id='topic+update_aifeducation_progress_bar'></span>

<h3>Description</h3>

<p>This function updates the master progress bar in aifeducation shiny app. The
progress bar reports the current state of the overall process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_aifeducation_progress_bar(value, total, title = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_aifeducation_progress_bar_+3A_value">value</code></td>
<td>
<p><code>int</code> Value describing the current step of the process.</p>
</td></tr>
<tr><td><code id="update_aifeducation_progress_bar_+3A_total">total</code></td>
<td>
<p><code>int</code> Total number of steps of the process.</p>
</td></tr>
<tr><td><code id="update_aifeducation_progress_bar_+3A_title">title</code></td>
<td>
<p><code>string</code> Title displaying in the top of the progress bar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function does nothing returns. It updates the progress bar with the id
<code>"pgr_bar_aifeducation"</code>.
</p>


<h3>See Also</h3>

<p>Other Auxiliary GUI Functions: 
<code><a href="#topic+update_aifeducation_progress_bar_epochs">update_aifeducation_progress_bar_epochs</a>()</code>,
<code><a href="#topic+update_aifeducation_progress_bar_steps">update_aifeducation_progress_bar_steps</a>()</code>
</p>

<hr>
<h2 id='update_aifeducation_progress_bar_epochs'>Update epoch progress bar in aifeducation shiny app.</h2><span id='topic+update_aifeducation_progress_bar_epochs'></span>

<h3>Description</h3>

<p>This function updates the epoch progress bar in aifeducation shiny app. The
progress bar reports the current state of the overall process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_aifeducation_progress_bar_epochs(value, total, title = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_aifeducation_progress_bar_epochs_+3A_value">value</code></td>
<td>
<p><code>int</code> Value describing the current step of the process.</p>
</td></tr>
<tr><td><code id="update_aifeducation_progress_bar_epochs_+3A_total">total</code></td>
<td>
<p><code>int</code> Total number of steps of the process.</p>
</td></tr>
<tr><td><code id="update_aifeducation_progress_bar_epochs_+3A_title">title</code></td>
<td>
<p><code>string</code> Title displaying in the top of the progress bar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called very often during training a model. Thus, the
function does not check the requirements for updating the progress bar to reduce
computational time. The check for fulfilling the necessary conditions must be
implemented separately.
</p>


<h3>Value</h3>

<p>Function does nothing returns. It updates the progress bar with the id
<code>"pgr_bar_aifeducation_epochs"</code>.
</p>


<h3>See Also</h3>

<p>Other Auxiliary GUI Functions: 
<code><a href="#topic+update_aifeducation_progress_bar">update_aifeducation_progress_bar</a>()</code>,
<code><a href="#topic+update_aifeducation_progress_bar_steps">update_aifeducation_progress_bar_steps</a>()</code>
</p>

<hr>
<h2 id='update_aifeducation_progress_bar_steps'>Update step/batch progress bar in aifeducation shiny app.</h2><span id='topic+update_aifeducation_progress_bar_steps'></span>

<h3>Description</h3>

<p>This function updates the step/batch progress bar in aifeducation shiny app. The
progress bar reports the current state of the overall process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_aifeducation_progress_bar_steps(value, total, title = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_aifeducation_progress_bar_steps_+3A_value">value</code></td>
<td>
<p><code>int</code> Value describing the current step of the process.</p>
</td></tr>
<tr><td><code id="update_aifeducation_progress_bar_steps_+3A_total">total</code></td>
<td>
<p><code>int</code> Total number of steps of the process.</p>
</td></tr>
<tr><td><code id="update_aifeducation_progress_bar_steps_+3A_title">title</code></td>
<td>
<p><code>string</code> Title displaying in the top of the progress bar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called very often during training a model. Thus, the
function does not check the requirements for updating the progress bar to reduce
computational time. The check for fulfilling the necessary conditions must be
implemented separately.
</p>


<h3>Value</h3>

<p>Function does nothing returns. It updates the progress bar with the id
<code>"pgr_bar_aifeducation_steps"</code>.
</p>


<h3>See Also</h3>

<p>Other Auxiliary GUI Functions: 
<code><a href="#topic+update_aifeducation_progress_bar">update_aifeducation_progress_bar</a>()</code>,
<code><a href="#topic+update_aifeducation_progress_bar_epochs">update_aifeducation_progress_bar_epochs</a>()</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
