<!DOCTYPE html><html><head><title>Help for package ottr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ottr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#check'><p>Run the test cases in a test file</p></a></li>
<li><a href='#CheckCollector'><p>An R6 class for collecting TestFileResult objects during grading.</p></a></li>
<li><a href='#collector_env'><p>An environment into which a collector will be initialized (so we don't need to update</p>
global variables).</a></li>
<li><a href='#collector_varname'><p>The name of the active collector variable in collector_env</p></a></li>
<li><a href='#execute_script'><p>Generate an environment from an R script</p></a></li>
<li><a href='#export'><p>Export a submission to a zip file</p></a></li>
<li><a href='#get_collector'><p>Retrieve the global CheckCollector</p></a></li>
<li><a href='#grade_script'><p>Grade an R script against a series of test files</p></a></li>
<li><a href='#GradingResults'><p>An R6 class representing a collection of test case results</p></a></li>
<li><a href='#initialize_collector'><p>Create a new global CheckCollector</p></a></li>
<li><a href='#load_test_cases'><p>Load test cases from a test file</p></a></li>
<li><a href='#run_autograder'><p>Grade an R script against test files in a directory</p></a></li>
<li><a href='#running_on_jupyter'><p>Determine whether this R session is running on Jupyter.</p></a></li>
<li><a href='#save_notebook'><p>Attempt to save the current notebook.</p></a></li>
<li><a href='#TestCase'><p>An R6 class representing a test case</p></a></li>
<li><a href='#TestCaseResult'><p>An R6 representing the results of running a test case</p></a></li>
<li><a href='#TestFileResult'><p>An R6 class representing a collection of test case results</p></a></li>
<li><a href='#update_ast_check_calls'><p>Collect results of calls to <code>ottr::check</code> in an AST</p></a></li>
<li><a href='#valid_syntax'><p>Check whether a string is valid R code</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>An R Autograding Extension for Otter-Grader</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Christopher Pyles &lt;cpyles@berkeley.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    An R autograding extension for Otter-Grader (<a href="https://otter-grader.readthedocs.io">https://otter-grader.readthedocs.io</a>). It supports 
    grading R scripts, R Markdown documents, and R Jupyter Notebooks.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>jsonlite, testthat, tools, R6, zip, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>IRdisplay, mockery, rmarkdown, stringr, withr, IRkernel</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-01 07:12:02 UTC; chrispyles</td>
</tr>
<tr>
<td>Author:</td>
<td>Christopher Pyles <a href="https://orcid.org/0000-0001-8520-7593"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  UC Berkeley Data Science Education Program [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-01 07:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='check'>Run the test cases in a test file</h2><span id='topic+check'></span>

<h3>Description</h3>

<p>Execute checks in a test suite and return the <a href="#topic+TestFileResult">TestFileResult</a> object from executing
the test. Optionally prints results of the test to console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check(test_file, test_env, show_results)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_+3A_test_file">test_file</code></td>
<td>
<p>Path to a test file</p>
</td></tr>
<tr><td><code id="check_+3A_test_env">test_env</code></td>
<td>
<p>An environment against which to run tests</p>
</td></tr>
<tr><td><code id="check_+3A_show_results">show_results</code></td>
<td>
<p>Whether to print the results to stdout</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The parsed test results for the suite
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
check("tests/q1.R")

## End(Not run)
</code></pre>

<hr>
<h2 id='CheckCollector'>An R6 class for collecting <a href="#topic+TestFileResult">TestFileResult</a> objects during grading.</h2><span id='topic+CheckCollector'></span>

<h3>Description</h3>

<p>A collection of test file results created while grading an assignment
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>test_file_results</code></dt><dd><p>The <a href="#topic+TestFileResult">TestFileResult</a> objects created during grading</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CheckCollector-new"><code>CheckCollector$new()</code></a>
</p>
</li>
<li> <p><a href="#method-CheckCollector-add_result"><code>CheckCollector$add_result()</code></a>
</p>
</li>
<li> <p><a href="#method-CheckCollector-get_results"><code>CheckCollector$get_results()</code></a>
</p>
</li>
<li> <p><a href="#method-CheckCollector-clone"><code>CheckCollector$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-CheckCollector-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a <a href="#topic+CheckCollector">CheckCollector</a>.
Add a <a href="#topic+TestFileResult">TestFileResult</a> to this collector.
</p>


<h5>Usage</h5>

<div class="r"><pre>CheckCollector$new()</pre></div>


<hr>
<a id="method-CheckCollector-add_result"></a>



<h4>Method <code>add_result()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>CheckCollector$add_result(test_file_result)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>test_file_result</code></dt><dd><p>The <a href="#topic+TestFileResult">TestFileResult</a> to add
Retrieve the list <a href="#topic+TestFileResult">TestFileResult</a> objects stored in this collector.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-CheckCollector-get_results"></a>



<h4>Method <code>get_results()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>CheckCollector$get_results()</pre></div>



<h5>Returns</h5>

<p>The list of <a href="#topic+TestFileResult">TestFileResult</a> objects
</p>


<hr>
<a id="method-CheckCollector-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>CheckCollector$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='collector_env'>An environment into which a collector will be initialized (so we don't need to update
global variables).</h2><span id='topic+collector_env'></span>

<h3>Description</h3>

<p>An environment into which a collector will be initialized (so we don't need to update
global variables).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collector_env
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 0.
</p>

<hr>
<h2 id='collector_varname'>The name of the active collector variable in <a href="#topic+collector_env">collector_env</a></h2><span id='topic+collector_varname'></span>

<h3>Description</h3>

<p>The name of the active collector variable in <a href="#topic+collector_env">collector_env</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collector_varname
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='execute_script'>Generate an environment from an R script</h2><span id='topic+execute_script'></span>

<h3>Description</h3>

<p>Execute a string as an R script and return the environment from that execution.
</p>
<p>Converts a string to an AST and executes that script in a dummy environment for running test
cases against. Transforms all expressions of the form <code>. = ottr::check(...)</code> by replacing the <code>.</code>
with an index into a list in the environment with name <code style="white-space: pre;">&#8288;check_results_{SECRET}&#8288;</code> to collect the
<a href="#topic+TestFileResult">TestFileResult</a> objects generated from those checks. (This helps to handle variable
name collisions in tests when grading a script.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>execute_script(script, ignore_errors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="execute_script_+3A_script">script</code></td>
<td>
<p>The string to be executed</p>
</td></tr>
<tr><td><code id="execute_script_+3A_ignore_errors">ignore_errors</code></td>
<td>
<p>Whether to ignore errors thrown while executing the script</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The global environment after executing the script
</p>

<hr>
<h2 id='export'>Export a submission to a zip file</h2><span id='topic+export'></span>

<h3>Description</h3>

<p>Export a submission to a zip file for submitting. If indicated, a PDF of the
submission is generated and included in the zip file. (PDF generation is only supported for Rmd
and ipynb files.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export(
  submission_path,
  export_path = NULL,
  display_link = TRUE,
  pdf = FALSE,
  force_save = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="export_+3A_submission_path">submission_path</code></td>
<td>
<p>The path to the submission</p>
</td></tr>
<tr><td><code id="export_+3A_export_path">export_path</code></td>
<td>
<p>The path at which to write the zip file (optional)</p>
</td></tr>
<tr><td><code id="export_+3A_display_link">display_link</code></td>
<td>
<p>Whether to display a download link with <code>IRdisplay</code></p>
</td></tr>
<tr><td><code id="export_+3A_pdf">pdf</code></td>
<td>
<p>Whether to include a PDF of the submission (only works for Rmd and ipynb files)</p>
</td></tr>
<tr><td><code id="export_+3A_force_save">force_save</code></td>
<td>
<p>Whether to attempt to force-save the notebook if running on Jupyter</p>
</td></tr>
<tr><td><code id="export_+3A_debug">debug</code></td>
<td>
<p>Whether to stop on PDF generation errors</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
export("hw01.ipynb")

# with pdf
export("hw01.ipynb", pdf = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_collector'>Retrieve the global <a href="#topic+CheckCollector">CheckCollector</a></h2><span id='topic+get_collector'></span>

<h3>Description</h3>

<p>Retrieve the global <a href="#topic+CheckCollector">CheckCollector</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_collector()
</code></pre>

<hr>
<h2 id='grade_script'>Grade an R script against a series of test files</h2><span id='topic+grade_script'></span>

<h3>Description</h3>

<p>Execute a script, parse check outputs, and run additional tests specified by the
glob pattern <code>tests_glob</code> on the test environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grade_script(script_path, tests_glob, ignore_errors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grade_script_+3A_script_path">script_path</code></td>
<td>
<p>The path to the script</p>
</td></tr>
<tr><td><code id="grade_script_+3A_tests_glob">tests_glob</code></td>
<td>
<p>The pattern to search for extra tests</p>
</td></tr>
<tr><td><code id="grade_script_+3A_ignore_errors">ignore_errors</code></td>
<td>
<p>Whether to ignore errors thrown while executing the script</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <a href="#topic+GradingResults">GradingResults</a> object after executing tests referenced in the script
and those specified by <code>tests_glob</code>
</p>

<hr>
<h2 id='GradingResults'>An R6 class representing a collection of test case results</h2><span id='topic+GradingResults'></span>

<h3>Description</h3>

<p>A collection of test case results that correspond to a single test file.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>test_file_results</code></dt><dd><p>The <a href="#topic+TestFileResult">TestFileResult</a> objects that make up this grading</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-GradingResults-new"><code>GradingResults$new()</code></a>
</p>
</li>
<li> <p><a href="#method-GradingResults-to_list"><code>GradingResults$to_list()</code></a>
</p>
</li>
<li> <p><a href="#method-GradingResults-to_json"><code>GradingResults$to_json()</code></a>
</p>
</li>
<li> <p><a href="#method-GradingResults-clone"><code>GradingResults$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-GradingResults-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a grading result.
</p>


<h5>Usage</h5>

<div class="r"><pre>GradingResults$new(test_file_results)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>test_file_results</code></dt><dd><p>The <a href="#topic+TestFileResult">TestFileResult</a> objects that make up this grading
result</p>
</dd>
</dl>

</div>


<hr>
<a id="method-GradingResults-to_list"></a>



<h4>Method <code>to_list()</code></h4>

<p>Convert these results to a JSON-like <code>list</code> that can be convert to a
<code>GradingResults</code> object by Otter's Python library.
</p>
<p>The returned list has the JSON format
</p>
<div class="sourceCode"><pre>{
  "test_file_results": [
    {
      // output of TestFileResult$to_list
    }
  ]
}
</pre></div>


<h5>Usage</h5>

<div class="r"><pre>GradingResults$to_list()</pre></div>



<h5>Returns</h5>

<p>The generated list
</p>


<hr>
<a id="method-GradingResults-to_json"></a>



<h4>Method <code>to_json()</code></h4>

<p>Export these results to a JSON string.
</p>


<h5>Usage</h5>

<div class="r"><pre>GradingResults$to_json()</pre></div>



<h5>Returns</h5>

<p>The JSON string
</p>


<hr>
<a id="method-GradingResults-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>GradingResults$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='initialize_collector'>Create a new global <a href="#topic+CheckCollector">CheckCollector</a></h2><span id='topic+initialize_collector'></span>

<h3>Description</h3>

<p>Create a new global <a href="#topic+CheckCollector">CheckCollector</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initialize_collector()
</code></pre>

<hr>
<h2 id='load_test_cases'>Load test cases from a test file</h2><span id='topic+load_test_cases'></span>

<h3>Description</h3>

<p>Load test case data from a test file. Executes the file and grabs the global <code>test</code>
variable, which should be a <code>list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_test_cases(test_file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_test_cases_+3A_test_file">test_file</code></td>
<td>
<p>The path to the test file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The test cases
</p>

<hr>
<h2 id='run_autograder'>Grade an R script against test files in a directory</h2><span id='topic+run_autograder'></span>

<h3>Description</h3>

<p>Run autograder in a Gradescope container and return the results as a
properly-formatted JSON string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_autograder(script_path, ignore_errors, test_dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run_autograder_+3A_script_path">script_path</code></td>
<td>
<p>The path to the script</p>
</td></tr>
<tr><td><code id="run_autograder_+3A_ignore_errors">ignore_errors</code></td>
<td>
<p>Whether to ignore errors thrown while executing the script</p>
</td></tr>
<tr><td><code id="run_autograder_+3A_test_dir">test_dir</code></td>
<td>
<p>A directory of tests to glob from</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The JSON string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
run_autograder("hw01.R", "ABC123", TRUE, "tests")

## End(Not run)
</code></pre>

<hr>
<h2 id='running_on_jupyter'>Determine whether this R session is running on Jupyter.</h2><span id='topic+running_on_jupyter'></span>

<h3>Description</h3>

<p>Determine whether this R session is running on Jupyter by checking for a CommManager
in IRkernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>running_on_jupyter()
</code></pre>


<h3>Value</h3>

<p>A boolean indicating whether IRkernel is running.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
running_on_jupyter()

## End(Not run)
</code></pre>

<hr>
<h2 id='save_notebook'>Attempt to save the current notebook.</h2><span id='topic+save_notebook'></span>

<h3>Description</h3>

<p>Attempt to save the notebook by displaying Javascript if running on Jupyter. This
function waits until the modification time of the file has changed or until the specified timeout
expires.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_notebook(nb_path, timeout = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_notebook_+3A_nb_path">nb_path</code></td>
<td>
<p>The path to the notebook</p>
</td></tr>
<tr><td><code id="save_notebook_+3A_timeout">timeout</code></td>
<td>
<p>Number of seconds to wait for save</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean indicating whether the file was saved successfully. If
Jupyter is not running, this function returns TRUE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
save_notebook("foo.ipynb")

## End(Not run)
</code></pre>

<hr>
<h2 id='TestCase'>An R6 class representing a test case</h2><span id='topic+TestCase'></span>

<h3>Description</h3>

<p>A test case for Ottr. Contains configurations and code to be executed for the test.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>name</code></dt><dd><p>The name of the test case</p>
</dd>
<dt><code>code</code></dt><dd><p>The code to be executed as part of the test case</p>
</dd>
<dt><code>points</code></dt><dd><p>The point value of the test case</p>
</dd>
<dt><code>hidden</code></dt><dd><p>Whether the test case is hidden</p>
</dd>
<dt><code>success_message</code></dt><dd><p>A message to show to students if the test passes</p>
</dd>
<dt><code>failure_message</code></dt><dd><p>A message to show to students if the test fails</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TestCase-new"><code>TestCase$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCase-run"><code>TestCase$run()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCase-to_list"><code>TestCase$to_list()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCase-clone"><code>TestCase$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-TestCase-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a test case.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCase$new(
  name,
  code,
  points = 1,
  hidden = FALSE,
  success_message = NA,
  failure_message = NA
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>name</code></dt><dd><p>The name of the test case</p>
</dd>
<dt><code>code</code></dt><dd><p>The code to be executed as part of the test case</p>
</dd>
<dt><code>points</code></dt><dd><p>The point value of the test case</p>
</dd>
<dt><code>hidden</code></dt><dd><p>Whether the test case is hidden</p>
</dd>
<dt><code>success_message</code></dt><dd><p>A message to show to students if the test passes</p>
</dd>
<dt><code>failure_message</code></dt><dd><p>A message to show to students if the test fails</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TestCase-run"></a>



<h4>Method <code>run()</code></h4>

<p>Run the test case against the provided environment.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCase$run(env)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>env</code></dt><dd><p>The environment to run the test case in</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TestCase-to_list"></a>



<h4>Method <code>to_list()</code></h4>

<p>Convert this test case to a JSON-compatible list with all of its fields.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCase$to_list()</pre></div>



<h5>Returns</h5>

<p>The list representation of this test case
</p>


<hr>
<a id="method-TestCase-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCase$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>tc = TestCase$new("q1", {
  testthat::assert_true(q1.ans)
})
env = new.env()
env$q1.ans = TRUE
tc$run(env)
</code></pre>

<hr>
<h2 id='TestCaseResult'>An R6 representing the results of running a test case</h2><span id='topic+TestCaseResult'></span>

<h3>Description</h3>

<p>Represents the results of running a test case against a global environment. Contains
metadata about the passing/failing of the test case as well as a reference to the test case
itself.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>passed</code></dt><dd><p>Whether the test passed</p>
</dd>
<dt><code>error</code></dt><dd><p>An error raised by executing the test, if any</p>
</dd>
<dt><code>test_case</code></dt><dd><p>The <a href="#topic+TestCase">TestCase</a> that this result tracks</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TestCaseResult-new"><code>TestCaseResult$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCaseResult-get_score"><code>TestCaseResult$get_score()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCaseResult-repr"><code>TestCaseResult$repr()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCaseResult-to_list"><code>TestCaseResult$to_list()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCaseResult-get_message"><code>TestCaseResult$get_message()</code></a>
</p>
</li>
<li> <p><a href="#method-TestCaseResult-clone"><code>TestCaseResult$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-TestCaseResult-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a test case result.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCaseResult$new(passed, error, test_case)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>passed</code></dt><dd><p>Whether the test passed</p>
</dd>
<dt><code>error</code></dt><dd><p>An error raised by executing the test, if any</p>
</dd>
<dt><code>test_case</code></dt><dd><p>The <code>TestCase</code> that this result tracks</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TestCaseResult-get_score"></a>



<h4>Method <code>get_score()</code></h4>

<p>Get the score earned for this test case, accounting for whether the test passed
or failed.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCaseResult$get_score()</pre></div>



<h5>Returns</h5>

<p>The score
</p>


<hr>
<a id="method-TestCaseResult-repr"></a>



<h4>Method <code>repr()</code></h4>

<p>Convert this result into a human-readable string for display.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCaseResult$repr()</pre></div>



<h5>Returns</h5>

<p>The string representation of this result
</p>


<hr>
<a id="method-TestCaseResult-to_list"></a>



<h4>Method <code>to_list()</code></h4>

<p>Convert this result to a JSON-compatible list with all of its fields.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCaseResult$to_list()</pre></div>



<h5>Returns</h5>

<p>The list representation of this result
</p>


<hr>
<a id="method-TestCaseResult-get_message"></a>



<h4>Method <code>get_message()</code></h4>

<p>Get the message to be displayed to the student based on whether the test case
passed or failed, if any.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCaseResult$get_message()</pre></div>



<h5>Returns</h5>

<p>The message or <code>NA</code>
</p>


<hr>
<a id="method-TestCaseResult-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestCaseResult$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='TestFileResult'>An R6 class representing a collection of test case results</h2><span id='topic+TestFileResult'></span>

<h3>Description</h3>

<p>A collection of test case results that correspond to a single test file.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>test_case_results</code></dt><dd><p>The <a href="#topic+TestCaseResult">TestCaseResult</a> objects that make up this test file</p>
</dd>
<dt><code>filename</code></dt><dd><p>The name of the test file</p>
</dd>
<dt><code>points</code></dt><dd><p>The point value of the test file or a list of test case point values</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TestFileResult-new"><code>TestFileResult$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TestFileResult-get_basename"><code>TestFileResult$get_basename()</code></a>
</p>
</li>
<li> <p><a href="#method-TestFileResult-get_score"><code>TestFileResult$get_score()</code></a>
</p>
</li>
<li> <p><a href="#method-TestFileResult-repr"><code>TestFileResult$repr()</code></a>
</p>
</li>
<li> <p><a href="#method-TestFileResult-to_list"><code>TestFileResult$to_list()</code></a>
</p>
</li>
<li> <p><a href="#method-TestFileResult-clone"><code>TestFileResult$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-TestFileResult-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a test file result.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestFileResult$new(filename, test_case_results, points = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>filename</code></dt><dd><p>The name of the test file</p>
</dd>
<dt><code>test_case_results</code></dt><dd><p>The <a href="#topic+TestCaseResult">TestCaseResult</a> objects that make up this test file</p>
</dd>
<dt><code>points</code></dt><dd><p>The point value of the test file or a list of test case point values</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TestFileResult-get_basename"></a>



<h4>Method <code>get_basename()</code></h4>

<p>Get the basename of the file this result corresponds to.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestFileResult$get_basename()</pre></div>



<h5>Returns</h5>

<p>The basename of the test file
</p>


<hr>
<a id="method-TestFileResult-get_score"></a>



<h4>Method <code>get_score()</code></h4>

<p>Get the total score earned for this test file as a percentage. Uses
<code><a href="#topic+TestCaseResult">TestCaseResult$get_score()</a></code> to determine the points earned for each test
case.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestFileResult$get_score()</pre></div>



<h5>Returns</h5>

<p>The score as a percentage.
</p>


<hr>
<a id="method-TestFileResult-repr"></a>



<h4>Method <code>repr()</code></h4>

<p>Convert this result into a human-readable string for display.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestFileResult$repr()</pre></div>



<h5>Returns</h5>

<p>The string representation of this result
</p>


<hr>
<a id="method-TestFileResult-to_list"></a>



<h4>Method <code>to_list()</code></h4>

<p>Convert this result to a JSON-compatible list with all of its fields.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestFileResult$to_list()</pre></div>



<h5>Returns</h5>

<p>The list representation of this result
</p>


<hr>
<a id="method-TestFileResult-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TestFileResult$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='update_ast_check_calls'>Collect results of calls to <code>ottr::check</code> in an AST</h2><span id='topic+update_ast_check_calls'></span>

<h3>Description</h3>

<p>Traverse an AST (a list of expressions) and change calls of the form
<code>. = ottr::check(...)</code> so that they are appended to a list with name <code>list_name</code>.
</p>
<p>If <code>list_name</code> is <code>check_results_XX</code>, then <code>. = ottr::check(...)</code> becomes
<code style="white-space: pre;">&#8288;check_results_XX[[&lt;int&gt;]] = ottr::check(...)&#8288;</code>, where <code style="white-space: pre;">&#8288;&lt;int&gt;&#8288;</code> is an integer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_ast_check_calls(tree, list_name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_ast_check_calls_+3A_tree">tree</code></td>
<td>
<p>The tree to traverse</p>
</td></tr>
<tr><td><code id="update_ast_check_calls_+3A_list_name">list_name</code></td>
<td>
<p>The quoted name of the list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The tree with substitutions made
</p>

<hr>
<h2 id='valid_syntax'>Check whether a string is valid R code</h2><span id='topic+valid_syntax'></span>

<h3>Description</h3>

<p>Determine whether a code snippet has any syntax errors.
</p>
<p>Determine whether a code snippet has any syntax errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>valid_syntax(script)

valid_syntax(script)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="valid_syntax_+3A_script">script</code></td>
<td>
<p>The code snippet</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Whether the code snippet is valid (can be parsed with <code>parse</code>)
</p>
<p>Whether the code snippet is valid (can be parsed with <code>parse</code>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = "
a = TRUE
b = c(1, 2, 3)
d = function(x) x ^ 2
f = d(b)
"
valid_syntax(s)
#&gt; [1] TRUE

s = "
if (TRUE) {
  a = c(1, 2)
"
valid_syntax(s)
#&gt; [1] FALSE
s = "
a = TRUE
b = c(1, 2, 3)
d = function(x) x ^ 2
f = d(b)
"
valid_syntax(s)
#&gt; [1] TRUE

s = "
if (TRUE) {
  a = c(1, 2)
"
valid_syntax(s)
#&gt; [1] FALSE
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
