<!DOCTYPE html><html><head><title>Help for package alabama</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {alabama}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#alabama'><p>Constrained Nonlinear Optimization</p></a></li>
<li><a href='#auglag'>
<p>Nonlinear optimization with constraints</p></a></li>
<li><a href='#constrOptim.nl'>
<p>Nonlinear optimization with constraints</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Constrained Nonlinear Optimization</td>
</tr>
<tr>
<td>Description:</td>
<td>Augmented Lagrangian Adaptive Barrier Minimization
        Algorithm for optimizing smooth nonlinear objective functions
        with constraints. Linear or nonlinear equality and inequality
        constraints are allowed.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.1), numDeriv</td>
</tr>
<tr>
<td>Version:</td>
<td>2023.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Ravi Varadhan (with contributions from Gabor Grothendieck)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ravi Varadhan &lt;ravi.varadhan@jhu.edu&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-21 19:02:18 UTC; rvaradh1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-22 22:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='alabama'>Constrained Nonlinear Optimization
</h2><span id='topic+alabama-package'></span>

<h3>Description</h3>

<p>Augmented Lagrangian and Adaptive Barrier Minimization Algorithm for optimizing smooth nonlinear objective functions with constraints. Linear or nonlinear equality and inequality constraints are allowed.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> alabama</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2023.1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-08-21</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2 or greater</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Ravi Varadhan (with contributions from Gabor Grothendieck)
</p>
<p>Ravi Varadhan &lt;ravi.varadhan@jhu.edu&gt;
</p>


<h3>See Also</h3>

<p><code>constrOptim</code>, <code>spg</code>
</p>

<hr>
<h2 id='auglag'>
Nonlinear optimization with constraints
</h2><span id='topic+auglag'></span><span id='topic+auglag1'></span><span id='topic+auglag2'></span><span id='topic+auglag3'></span>

<h3>Description</h3>

<p>Augmented Lagrangian Minimization Algorithm for optimizing smooth nonlinear objective functions with constraints. Linear or nonlinear equality and inequality constraints are allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auglag(par, fn, gr, hin, hin.jac, heq, heq.jac, 
control.outer=list(), control.optim = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auglag_+3A_par">par</code></td>
<td>
<p>Starting vector of parameter values.  Any initial vector, even those violating inequality constraints, may be specified.  This is in contrast to <code>constrOptim.nl</code> which requires  &quot;feasible&quot; initial values with respect to inequality constraints</p>
</td></tr>
<tr><td><code id="auglag_+3A_fn">fn</code></td>
<td>

<p>Nonlinear objective function that is to be optimized. 
A scalar function that takes a real vector as argument and 
returns a scalar that is the value of the function at that point 
(see details).</p>
</td></tr>
<tr><td><code id="auglag_+3A_gr">gr</code></td>
<td>

<p>The gradient of the objective function <code>fn</code> evaluated at the 
argument.  This is a vector-function that takes a real 
vector as argument and returns a real vector of the same length.  
It defaults to &quot;NULL&quot;, which means that gradient is evaluated numerically.  Computations are dramatically faster in high-dimensional problems when the exact gradient is provided.  See *Example*. 
</p>
</td></tr>
<tr><td><code id="auglag_+3A_hin">hin</code></td>
<td>

<p>a vector function specifying inequality constraints such that hin[j] &gt; 0 for all j
</p>
</td></tr>
<tr><td><code id="auglag_+3A_hin.jac">hin.jac</code></td>
<td>

<p>Jacobian of <code>hin</code>.  If unspecified, it will be computed using finite-difference, but computations will be faster if specified.
</p>
</td></tr>
<tr><td><code id="auglag_+3A_heq">heq</code></td>
<td>

<p>a vector function specifying equality constraints such that heq[j] = 0 for all j
</p>
</td></tr>
<tr><td><code id="auglag_+3A_heq.jac">heq.jac</code></td>
<td>

<p>Jacobian of <code>heq</code>.  If unspecified, it will be computed using finite-difference, but computations will be faster if specified.
</p>
</td></tr>
<tr><td><code id="auglag_+3A_control.outer">control.outer</code></td>
<td>
<p>A list of control parameters to be used by the outer loop in <code>constrOptim.nl</code>.  See *Details* for more information.</p>
</td></tr>
<tr><td><code id="auglag_+3A_control.optim">control.optim</code></td>
<td>
<p>A list of control parameters to be used by the unconstrained optimization algorithm in the inner loop. Identical to that used in <code>optim</code> or in <code>nlminb</code>.</p>
</td></tr>
<tr><td><code id="auglag_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>fn</code>, <code>gr</code>, <code>hin</code>, <code>heq</code>.  All of them must accept any specified arguments, either explicitly or by having a ... argument, but they do not need to use them all.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Argument <code>control.outer</code> is a list specifing any changes to default values of algorithm control parameters for the outer loop.  Note that the names of these must be specified completely.  Partial matching will not work. The list items are as follows:
</p>
<p><code>lam0</code>: Initial value for the Lagrangian parameter.
</p>
<p><code>sig0</code>: A scaling parameter for penalty term that is augmented to the Lagrangian.
</p>
<p><code>eps</code>: Tolerance for convergence of outer iterations of the barrier and/or augmented lagrangian algorithm
</p>
<p><code>itmax</code>: Maximum number of outer iterations.
</p>
<p><code>ilack.max</code>: Maximum number of outer iterations where no change in parameters is tolerated.
</p>
<p><code>trace</code>: A logical variable indicating whether information on outer iterations should be printed out.  If TRUE, at each outer iteration information is displayed on: (i) how well the inequality and equalities are satisfied, (ii) current parameter values, and (iii) current objective function value.
</p>
<p><code>method</code>: Unconstrained optimization algorithm for inner loop optimization.  User can specify any algorithm in <code>optim</code>(). The default is the &quot;BFGS&quot; variable metric method.  However, the user can also invoke the <code>nlminb</code>() algorithm by specifying method=&quot;nlminb&quot;, which can often perform better than &quot;BFGS.&quot;
</p>
<p><code>NMinit</code>: A logical variable indicating whether &quot;Nelder-Mead&quot; algorithm should be used in optim() for the first outer iteration.
</p>
<p><code>i.scale</code>: A vector of length equal to number of inequalities that may be used to scale the inequalities or it can be a scalar in which case all the inequalities are scaled by the same value. 
</p>
<p><code>e.scale</code>: A vector of length equal to number of equalities that may be used to scale the equalities or it can be a scalar in which case all the equalities are scaled by the same value. 
</p>
<p><code>kkt2.check</code>: A logical variable (TRUE/FALSE) indicating whether the second-order KKT condition should be checked.  Deafult is TRUE.  It may be set to FALSE in problems where the Hessian computation can b etime consuming.  
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>Parameters that optimize the nonlinear objective function, satisfying constraints, if convergence is successful.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the objective function at termination.</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>
<p>A vector of length 2 denoting the number of times the objective <code>fn</code> and the <code>gr</code> were evaluated, respectively.
</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  <code>0</code> indicates successful convergence. Positive integer codes indicate failure to converge.    
</p>
</td></tr>
<tr><td><code>outer.iterations</code></td>
<td>
<p>Number of outer iterations</p>
</td></tr> 
<tr><td><code>lambda</code></td>
<td>
<p>Values of the Lagrangian parameter.  This is a vector of same length as the total number of inequalities and equalities.  It must be zero for inactive inequalities; non-negative for active inequalities; and can have any sign for equalities.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Value of augmented penalty parameter for the quadratic term</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>Gradient of the augmented Lagrangian function at convergence. It should be small.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian of the augmented Lagrangian function at convergence. It should be positive (negative) definite for minimization (maximization)</p>
</td></tr>
<tr><td><code>ineq</code></td>
<td>
<p>Values of inequlaity constraints at convergence. All of them must be non-negative</p>
</td></tr>
<tr><td><code>equal</code></td>
<td>
<p>Values of equlaity constraints at convergence. All of them must be close to zero.</p>
</td></tr>
<tr><td><code>kkt1</code></td>
<td>
<p>A logical variable indicating whether or not the first-order KKT conditions were satisfied.</p>
</td></tr>
<tr><td><code>kkt2</code></td>
<td>
<p>A logical variable indicating whether or not the second-order KKT conditions were satisfied.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ravi Varadhan, Center on Aging and Health, Johns Hopkins University.
</p>


<h3>References</h3>

<p>Lange K, <em>Optimization</em>, 2004, Springer.
</p>
<p>Madsen K, Nielsen HB, Tingleff O, <em>Optimization With Constraints</em>, 2004, IMM, Technical University of Denmark.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+constrOptim.nl">constrOptim.nl</a></code>, <code><a href="stats.html#topic+nlminb">nlminb</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fn &lt;- function(x) (x[1] + 3*x[2] + x[3])^2 + 4 * (x[1] - x[2])^2

gr &lt;- function(x) {
g &lt;- rep(NA, 3)
g[1] &lt;- 2*(x[1] + 3*x[2] + x[3]) + 8*(x[1] - x[2]) 
g[2] &lt;- 6*(x[1] + 3*x[2] + x[3]) - 8*(x[1] - x[2]) 
g[3] &lt;- 2*(x[1] + 3*x[2] + x[3])
g
}

heq &lt;- function(x) {
h &lt;- rep(NA, 1)
h[1] &lt;- x[1] + x[2] + x[3] - 1
h
}


heq.jac &lt;- function(x) {
j &lt;- matrix(NA, 1, length(x))
j[1, ] &lt;- c(1, 1, 1)
j
}

hin &lt;- function(x) {
h &lt;- rep(NA, 1)
h[1] &lt;- 6*x[2] + 4*x[3] - x[1]^3 - 3
h[2] &lt;- x[1]
h[3] &lt;- x[2]
h[4] &lt;- x[3]
h
}


hin.jac &lt;- function(x) {
j &lt;- matrix(NA, 4, length(x))
j[1, ] &lt;- c(-3*x[1]^2, 6, 4)
j[2, ] &lt;- c(1, 0, 0)
j[3, ] &lt;- c(0, 1, 0)
j[4, ] &lt;- c(0, 0, 1)
j
}

# Note: `auglag' accepts infeasible starting values
#
p0 &lt;- runif(3)
ans &lt;- auglag(par=p0, fn=fn, gr=gr, heq=heq, heq.jac=heq.jac, hin=hin, hin.jac=hin.jac) 
ans

# Not specifying the gradient and the Jacobians
set.seed(12)
p0 &lt;- runif(3)
ans2 &lt;- auglag(par=p0, fn=fn, heq=heq, hin=hin) 
ans2

# Using "nlminb" algorithm
ans3 &lt;- auglag(par=p0, fn=fn, heq=heq, hin=hin, control.outer=list(method="nlminb")) 
ans3

# Turning off the second-order KKT condition check
ans4 &lt;- auglag(par=p0, fn=fn, heq=heq, hin=hin, control.outer=list(kkt2.check=FALSE)) 
ans4

</code></pre>

<hr>
<h2 id='constrOptim.nl'>
Nonlinear optimization with constraints
</h2><span id='topic+constrOptim.nl'></span><span id='topic+adpbar'></span><span id='topic+augpen'></span><span id='topic+alabama'></span>

<h3>Description</h3>

<p>Augmented Lagrangian Adaptive Barrier Minimization Algorithm for optimizing smooth nonlinear objective functions with constraints. Linear or nonlinear equality and inequality constraints are allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constrOptim.nl(par, fn, gr = NULL, 
hin = NULL, hin.jac = NULL, heq = NULL, heq.jac = NULL, 
control.outer=list(), control.optim = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constrOptim.nl_+3A_par">par</code></td>
<td>
<p>starting vector of parameter values; initial vector must be &quot;feasible&quot;</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_fn">fn</code></td>
<td>

<p>Nonlinear objective function that is to be optimized. 
A scalar function that takes a real vector as argument and 
returns a scalar that is the value of the function at that point 
(see details).</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_gr">gr</code></td>
<td>

<p>The gradient of the objective function <code>fn</code> evaluated at the 
argument.  This is a vector-function that takes a real 
vector as argument and returns a real vector of the same length.  
It defaults to &quot;NULL&quot;, which means that gradient is evaluated numerically.  Computations are dramatically faster in high-dimensional problems when the exact gradient is provided.  See *Example*. 
</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_hin">hin</code></td>
<td>

<p>a vector function specifying inequality constraints such that hin[j] &gt; 0 for all j
</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_hin.jac">hin.jac</code></td>
<td>

<p>Jacobian of <code>hin</code>.  If unspecified, it will be computed using finite-difference, but computations will be faster if specified.
</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_heq">heq</code></td>
<td>

<p>a vector function specifying equality constraints such that heq[j] = 0 for all j
</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_heq.jac">heq.jac</code></td>
<td>

<p>Jacobian of <code>heq</code>.  If unspecified, it will be computed using finite-difference, but computations will be faster if specified.
</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_control.outer">control.outer</code></td>
<td>
<p>A list of control parameters to be used by the outer loop in <code>constrOptim.nl</code>.  See *Details* for more information.</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_control.optim">control.optim</code></td>
<td>
<p>A list of control parameters to be used by the unconstrained optimization algorithm in the inner loop. Identical to that used in <code>optim</code>.</p>
</td></tr>
<tr><td><code id="constrOptim.nl_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>fn</code>, <code>gr</code>, <code>hin</code>, <code>heq</code>.  All of them must accept any specified arguments, either explicitly or by having a ... argument, but they do not need to use them all.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Argument <code>control.outer</code> is a list specifing any changes to default values of algorithm control parameters for the outer loop.  Note that the names of these must be specified completely.  Partial matching will not work. The list items are as follows:
</p>
<p><code>mu0</code>: A scaling parameter for barrier penalty for inequality constraints.
</p>
<p><code>sig0</code>: A scaling parameter for augmented lagrangian for equality constraints
</p>
<p><code>eps</code>: Tolerance for convergence of outer iterations of the barrier and/or augmented lagrangian algorithm
</p>
<p><code>itmax</code>: Maximum number of outer iterations.
</p>
<p><code>trace</code>: A logical variable indicating whether information on outer iterations should be printed out.  If TRUE, at each outer iteration information is displayed on: (i) how well the inequality and equalities are satisfied, (ii) current parameter values, and (iii) current objective function value.
</p>
<p><code>method</code>: Unconstrained optimization algorithm in optim() to be used; default is the &quot;BFGS&quot; variable metric method.
</p>
<p><code>NMinit</code>: A logical variable indicating whether &quot;Nelder-Mead&quot; algorithm should be used in optim() for the first outer iteration.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>Parameters that optimize the nonlinear objective function, satisfying constraints, if convergence is successful.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the objective function at termination.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  <code>0</code> indicates successful convergence. Positive integer codes indicate failure to converge.    
</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>Text message indicating the type of convergence or failure.    
</p>
</td></tr>
<tr><td><code>outer.iterations</code></td>
<td>
<p>Number of outer iterations</p>
</td></tr> 
<tr><td><code>lambda</code></td>
<td>
<p>Value of augmented Lagrangian penalty parameter</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Value of augmented Lagrangian penalty parameter for the quadratic term</p>
</td></tr>
<tr><td><code>barrier.value</code></td>
<td>
<p>Reduction in the value of the function from its initial value. This is negative in maximization.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>Residual norm of equality constraints.  Must be small at convergence.</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>
<p>A vector of length 2 denoting the number of times the objective <code>fn</code> and the <code>gr</code> were evaluated, respectively.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ravi Varadhan, Center on Aging and Health, Johns Hopkins University.
</p>


<h3>References</h3>

<p>Lange K, <em>Optimization</em>, 2004, Springer.
</p>
<p>Madsen K, Nielsen HB, Tingleff O, <em>Optimization With Constraints</em>, 2004, IMM, Technical University of Denmark.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+auglag">auglag</a></code>, <code><a href="stats.html#topic+constrOptim">constrOptim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fn &lt;- function(x) (x[1] + 3*x[2] + x[3])^2 + 4 * (x[1] - x[2])^2

gr &lt;- function(x) {
g &lt;- rep(NA, 3)
g[1] &lt;- 2*(x[1] + 3*x[2] + x[3]) + 8*(x[1] - x[2]) 
g[2] &lt;- 6*(x[1] + 3*x[2] + x[3]) - 8*(x[1] - x[2]) 
g[3] &lt;- 2*(x[1] + 3*x[2] + x[3])
g
}

heq &lt;- function(x) {
h &lt;- rep(NA, 1)
h[1] &lt;- x[1] + x[2] + x[3] - 1
h
}


heq.jac &lt;- function(x) {
j &lt;- matrix(NA, 1, length(x))
j[1, ] &lt;- c(1, 1, 1)
j
}

hin &lt;- function(x) {
h &lt;- rep(NA, 1)
h[1] &lt;- 6*x[2] + 4*x[3] - x[1]^3 - 3
h[2] &lt;- x[1]
h[3] &lt;- x[2]
h[4] &lt;- x[3]
h
}


hin.jac &lt;- function(x) {
j &lt;- matrix(NA, 4, length(x))
j[1, ] &lt;- c(-3*x[1]^2, 6, 4)
j[2, ] &lt;- c(1, 0, 0)
j[3, ] &lt;- c(0, 1, 0)
j[4, ] &lt;- c(0, 0, 1)
j
}

set.seed(12)
p0 &lt;- runif(3)
ans &lt;- constrOptim.nl(par=p0, fn=fn, gr=gr, heq=heq, heq.jac=heq.jac, hin=hin, hin.jac=hin.jac) 

# Not specifying the gradient and the Jacobians
set.seed(12)
p0 &lt;- runif(3)
ans2 &lt;- constrOptim.nl(par=p0, fn=fn, heq=heq, hin=hin) 

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
