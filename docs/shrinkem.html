<!DOCTYPE html><html lang="en"><head><title>Help for package shrinkem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {shrinkem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#F'><p>The (scaled) F Distribution</p></a></li>
<li><a href='#mvF'><p>The matrix F Distribution</p></a></li>
<li><a href='#shrinkem'><p>Fast Bayesian regularization using Gaussian approximations</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Approximate Bayesian Regularization for Parsimonious Estimates</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-01</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Joris Mulder [aut, cre],
  Diana Karimova [aut, ctb],
  Sara van Erp [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Joris Mulder &lt;j.mulder3@tilburguniversity.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Approximate Bayesian regularization using Gaussian approximations. The input is a vector of estimates
             and a Gaussian error covariance matrix of the key parameters. Bayesian shrinkage is then applied
             to obtain parsimonious solutions. The method is described on 
             Karimova, van Erp, Leenders, and Mulder (2024) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2F2g8qm">doi:10.31234/osf.io/2g8qm</a>&gt;. Gibbs samplers are used
             for model fitting. The shrinkage priors that are supported are Gaussian (ridge) priors, Laplace
             (lasso) priors (Park and Casella, 2008 &lt;<a href="https://doi.org/10.1198%2F016214508000000337">doi:10.1198/016214508000000337</a>&gt;), and horseshoe priors
             (Carvalho, et al., 2010; &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasq017">doi:10.1093/biomet/asq017</a>&gt;). These priors include an option
             for grouped regularization of different subsets of parameters (Meier et al., 2008; 
             &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2007.00627.x">doi:10.1111/j.1467-9868.2007.00627.x</a>&gt;). F priors are used for the penalty
             parameters lambda^2 (Mulder and Pericchi, 2018 &lt;<a href="https://doi.org/10.1214%2F17-BA1092">doi:10.1214/17-BA1092</a>&gt;). This correspond to
             half-Cauchy priors on lambda (Carvalho, Polson, Scott, 2010 &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasq017">doi:10.1093/biomet/asq017</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, mvtnorm, extraDistr, brms, CholWishart, matrixcalc</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-03 13:55:45 UTC; jorismulder</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-05 10:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='F'>The (scaled) F Distribution</h2><span id='topic+F'></span><span id='topic+dF'></span><span id='topic+rF'></span>

<h3>Description</h3>

<p>Density and random generation for the F distribution with first degrees of freedom <code>df1</code>,
second degrees of freedom <code>df2</code>, and scale parameter <code>beta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dF(x, df1, df2, beta, log = FALSE)

rF(n, df1, df2, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="F_+3A_x">x</code></td>
<td>
<p>vector of quantities.</p>
</td></tr>
<tr><td><code id="F_+3A_df1">df1</code></td>
<td>
<p>First degrees of freedom</p>
</td></tr>
<tr><td><code id="F_+3A_df2">df2</code></td>
<td>
<p>Second degrees of freedom</p>
</td></tr>
<tr><td><code id="F_+3A_beta">beta</code></td>
<td>
<p>Scale parameter</p>
</td></tr>
<tr><td><code id="F_+3A_log">log</code></td>
<td>
<p>logical; if TRUE, density is given as log(p).</p>
</td></tr>
<tr><td><code id="F_+3A_n">n</code></td>
<td>
<p>number of draws</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dF</code> gives the probability density of the F distribution. <code>rF</code> gives random draws from the F distribution.
</p>


<h3>References</h3>

<p>Mulder and Pericchi (2018). The Matrix-F Prior for Estimating and Testing Covariance Matrices.
Bayesian Analysis, 13(4), 1193-1214. &lt;https://doi.org/10.1214/17-BA1092&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
draws_F &lt;- rF(n=1e4, df1=2, df2=4, beta=1)
hist(draws_F,500,xlim=c(0,10),freq=FALSE)
seqx &lt;- seq(0,10,length=1e5)
lines(seqx,dF(seqx, df1=2, df2=4, beta=1),col=2,lwd=2)

</code></pre>

<hr>
<h2 id='mvF'>The matrix F Distribution</h2><span id='topic+mvF'></span><span id='topic+dmvF'></span><span id='topic+rmvF'></span>

<h3>Description</h3>

<p>Density and random generation for the matrix variate F distribution with first degrees
of freedom <code>df1</code>, second degrees of freedom <code>df2</code>, and scale matrix <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmvF(x, df1, df2, B, log = FALSE)

rmvF(n, df1, df2, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvF_+3A_x">x</code></td>
<td>
<p>Positive definite matrix of quantities.</p>
</td></tr>
<tr><td><code id="mvF_+3A_df1">df1</code></td>
<td>
<p>First degrees of freedom</p>
</td></tr>
<tr><td><code id="mvF_+3A_df2">df2</code></td>
<td>
<p>Second degrees of freedom</p>
</td></tr>
<tr><td><code id="mvF_+3A_b">B</code></td>
<td>
<p>Positive definite scale matrix</p>
</td></tr>
<tr><td><code id="mvF_+3A_log">log</code></td>
<td>
<p>logical; if TRUE, density is given as log(p).</p>
</td></tr>
<tr><td><code id="mvF_+3A_n">n</code></td>
<td>
<p>Number of draws</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dmvF</code> returns the probability density of the matrix F distribution.
<code>rmvF</code> returns a numeric array, say <code>R</code>, of dimension  <code class="reqn">p \times p \times n</code>, where each element
<code>R[,,i]</code> is a positive definite matrix, a realization of the matrix F distribution.
</p>


<h3>References</h3>

<p>Mulder and Pericchi (2018). The Matrix-F Prior for Estimating and Testing Covariance Matrices.
Bayesian Analysis, 13(4), 1193-1214. &lt;https://doi.org/10.1214/17-BA1092&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(20180222)
draws_F &lt;- rmvF(n=1, df1=2, df2=4, B=diag(2))
dmvF(draws_F[,,1], df1=2, df2=4, B=diag(2))
</code></pre>

<hr>
<h2 id='shrinkem'>Fast Bayesian regularization using Gaussian approximations</h2><span id='topic+shrinkem'></span>

<h3>Description</h3>

<p>The <code>shrinkem</code> function can be used for regularizing a vector
of estimates using Bayesian shrinkage methods where the uncertainty of the estimates
are assumed to follow a Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shrinkem(
  x,
  Sigma,
  type,
  group,
  iterations,
  burnin,
  store,
  cred.level,
  df1,
  df2,
  scale2,
  lambda2.fixed,
  lambda2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shrinkem_+3A_x">x</code></td>
<td>
<p>A vector of estimates.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_sigma">Sigma</code></td>
<td>
<p>A covariance matrix capturing the uncertainty of the estimates (e.g., error covariance matrix).</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_type">type</code></td>
<td>
<p>A character string which specifies the type of regularization method is used. Currently, the
types &quot;ridge&quot;, &quot;lasso&quot;, and &quot;horseshoe&quot;, are supported.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_group">group</code></td>
<td>
<p>A vector of integers denoting the group membership of the estimates, where each group receives
a different global shrinkage parameter which is adapted to the observed data.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_iterations">iterations</code></td>
<td>
<p>Number of posterior draws after burnin. Default = 5e4.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_burnin">burnin</code></td>
<td>
<p>Number of posterior draws in burnin. Default = 1e3.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_store">store</code></td>
<td>
<p>Store every store-th draw from posterior. Default = 1 (implying that every draw is stored).</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_cred.level">cred.level</code></td>
<td>
<p>The significance level that is used to check whether a parameter is nonzero depending on whether
0 is contained in the credible interval. The default is <code>cred.level = 0.95</code>.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_df1">df1</code></td>
<td>
<p>First hyperparameter (degrees of freedom) of the prior for a shrinkage parameter lambda^2, which follows a F(df1,df2,scale2)
distribution. The default is <code>df1 = 1</code>. For <code>df1 = 1</code>, this corresponds to half-t distribution for lambda with degrees of freedom <code>df2</code>
and scale parameter <code>sqrt(scale2/df2)</code>.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_df2">df2</code></td>
<td>
<p>Second hyperparameter (degrees of freedom) of the prior for a shrinkage parameter lambda^2, which follows a F(df1,df2,scale2)
distribution. The default is <code>df2 = 1</code>.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_scale2">scale2</code></td>
<td>
<p>Second hyperparameter (scale parameter) of the prior for a shrinkage parameter lambda^2, which follows a F(df1,df2,scale2)
distribution. The default is <code>df2 = 1e3</code>.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_lambda2.fixed">lambda2.fixed</code></td>
<td>
<p>Logical indicating whether the penalty parameters(s) is/are fixed. Default is FALSE.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_lambda2">lambda2</code></td>
<td>
<p>Positive scalars of length equal to the number of groups in 'group'. The argument is only
used if the argument 'lambda2.fixed' is 'TRUE'.</p>
</td></tr>
<tr><td><code id="shrinkem_+3A_...">...</code></td>
<td>
<p>Parameters passed to and from other functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output is an object of class <code>shrinkem</code>. The object has elements:
</p>

<ul>
<li> <p><code>estimates</code>: A data frame with the input estimates, the shrunken posterior mean, median, and mode,
the lower and upperbound of the credbility interval based on the shrunken posterior, and a logical which indicates if
zero is contained in the credibility interval.
</p>
</li>
<li> <p><code>draws</code>: List containing the posterior draws of the effects (<code>beta</code>), the prior parameters (<code>tau2</code>, <code>gamma2</code>),
and the penalty parameters (<code>psi2</code> and <code>lambda2</code>).
</p>
</li>
<li> <p><code>dim.est</code>: The dimension of the input estimates of <code>beta</code>.
</p>
</li>
<li> <p><code>input.est</code>: The input vector of the unshrunken estimates of <code>beta</code>.
</p>
</li>
<li> <p><code>call</code>: Input call.
</p>
</li></ul>



<h3>References</h3>

<p>Karimovo, van Erp, Leenders, and Mulder (2024). Honey, I Shrunk the Irrelevant Effects! Simple and Fast Approximate Bayesian
Regularization. &lt;https://doi.org/10.31234/osf.io/2g8qm&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# EXAMPLE
estimates &lt;- -5:5
covmatrix &lt;- diag(11)
# Bayesian horseshoe where all beta's have the same global shrinkage
# (using default 'group' argument)
shrink1 &lt;- shrinkem(estimates, covmatrix, type="horseshoe")
# posterior modes of middle three estimates are practically zero

# plot posterior densities
old.par.mfrow &lt;- par(mfrow = c(1,1))
old.par.mar &lt;- par(mar = c(0, 0, 0, 0))
par(mfrow = c(11,1))
par(mar = c(1,2,1,2))
for(p in 1:ncol(shrink1$draws$beta)){plot(density(shrink1$draws$beta[,p]),
  xlim=c(-10,10),main=colnames(shrink1$draws$beta)[p])}
par(mfrow = old.par.mfrow)
par(mar = old.par.mar)

# Bayesian horseshoe where first three and last three beta's have different
# global shrinkage parameter than other beta's
shrink2 &lt;- shrinkem(estimates, covmatrix, type="horseshoe",
   group=c(rep(1,3),rep(2,5),rep(1,3)))
# posterior modes of middle five estimates are virtually zero

# plot posterior densities
par(mfrow = c(11,1))
par(mar = c(1,2,1,2))
for(p in 1:ncol(shrink2$draws$beta)){plot(density(shrink2$draws$beta[,p]),xlim=c(-10,10),
  main=colnames(shrink2$draws$beta)[p])}
par(mfrow = old.par.mfrow)
par(mar = old.par.mar)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
